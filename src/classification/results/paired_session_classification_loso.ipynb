{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from src import config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.437999800Z",
     "start_time": "2023-11-02T11:29:12.188786800Z"
    }
   },
   "id": "7c6fcef270881191"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "features_df = pd.read_pickle(os.path.join(config.classification_resource_dir, \"pairwise_sessions_features_df.pkl\"))\n",
    "labels_df = pd.read_pickle(os.path.join(config.classification_resource_dir, \"pairwise_sessions_labels_df.pkl\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.594153600Z",
     "start_time": "2023-11-02T11:29:12.193787600Z"
    }
   },
   "id": "9447514d4b35cb20"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "   Movie DVA_Mean_Gaze_Pre DVA_Median_Gaze_Pre DVA_Std_Gaze_Pre  \\\n0     18          4.705333            5.327558        30.301857   \n1      4               NaN                 NaN              NaN   \n2     42          1.876357           -0.429372       -10.096539   \n3     33         23.142747           37.816947        -6.590418   \n4     16         -0.465211           -1.561712        -9.397422   \n\n  DVA_Max_Gaze_Pre DVA_Min_Gaze_Pre DVA_Sem_Gaze_Pre DVA_AUC_Gaze_Pre  \\\n0        16.588726          9.31113         30.18593         5.021545   \n1              NaN              NaN              NaN              NaN   \n2         1.922603        56.610295       -10.096539         1.876357   \n3         7.827757        16.808915        -8.547459        26.329512   \n4         6.251171         34.31603        -9.582931         -0.05636   \n\n  DVA_Mean_Fixations_Pre DVA_Median_Fixations_Pre DVA_Std_Fixations_Pre  \\\n0               9.766384                 5.607735             -5.433003   \n1             -22.224863                -18.83514             20.447195   \n2              -1.330319                -0.270313             -0.704113   \n3              17.709321                25.296673            -27.293228   \n4              -0.267279                 1.091429             -8.900171   \n\n  DVA_Max_Fixations_Pre DVA_Min_Fixations_Pre DVA_Sem_Fixations_Pre  \\\n0              22.73986              5.814925            -27.773263   \n1            -12.522196             -9.397203              8.140333   \n2              2.402706             31.549975              8.065585   \n3              8.278788             27.068901             -8.857238   \n4             -0.888553             36.204349             -6.007396   \n\n  DVA_AUC_Fixations_Pre  \n0             47.363724  \n1              3.568154  \n2            -17.775265  \n3            -22.668807  \n4             -6.311687  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Movie</th>\n      <th>DVA_Mean_Gaze_Pre</th>\n      <th>DVA_Median_Gaze_Pre</th>\n      <th>DVA_Std_Gaze_Pre</th>\n      <th>DVA_Max_Gaze_Pre</th>\n      <th>DVA_Min_Gaze_Pre</th>\n      <th>DVA_Sem_Gaze_Pre</th>\n      <th>DVA_AUC_Gaze_Pre</th>\n      <th>DVA_Mean_Fixations_Pre</th>\n      <th>DVA_Median_Fixations_Pre</th>\n      <th>DVA_Std_Fixations_Pre</th>\n      <th>DVA_Max_Fixations_Pre</th>\n      <th>DVA_Min_Fixations_Pre</th>\n      <th>DVA_Sem_Fixations_Pre</th>\n      <th>DVA_AUC_Fixations_Pre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18</td>\n      <td>4.705333</td>\n      <td>5.327558</td>\n      <td>30.301857</td>\n      <td>16.588726</td>\n      <td>9.31113</td>\n      <td>30.18593</td>\n      <td>5.021545</td>\n      <td>9.766384</td>\n      <td>5.607735</td>\n      <td>-5.433003</td>\n      <td>22.73986</td>\n      <td>5.814925</td>\n      <td>-27.773263</td>\n      <td>47.363724</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-22.224863</td>\n      <td>-18.83514</td>\n      <td>20.447195</td>\n      <td>-12.522196</td>\n      <td>-9.397203</td>\n      <td>8.140333</td>\n      <td>3.568154</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>42</td>\n      <td>1.876357</td>\n      <td>-0.429372</td>\n      <td>-10.096539</td>\n      <td>1.922603</td>\n      <td>56.610295</td>\n      <td>-10.096539</td>\n      <td>1.876357</td>\n      <td>-1.330319</td>\n      <td>-0.270313</td>\n      <td>-0.704113</td>\n      <td>2.402706</td>\n      <td>31.549975</td>\n      <td>8.065585</td>\n      <td>-17.775265</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>23.142747</td>\n      <td>37.816947</td>\n      <td>-6.590418</td>\n      <td>7.827757</td>\n      <td>16.808915</td>\n      <td>-8.547459</td>\n      <td>26.329512</td>\n      <td>17.709321</td>\n      <td>25.296673</td>\n      <td>-27.293228</td>\n      <td>8.278788</td>\n      <td>27.068901</td>\n      <td>-8.857238</td>\n      <td>-22.668807</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n      <td>-0.465211</td>\n      <td>-1.561712</td>\n      <td>-9.397422</td>\n      <td>6.251171</td>\n      <td>34.31603</td>\n      <td>-9.582931</td>\n      <td>-0.05636</td>\n      <td>-0.267279</td>\n      <td>1.091429</td>\n      <td>-8.900171</td>\n      <td>-0.888553</td>\n      <td>36.204349</td>\n      <td>-6.007396</td>\n      <td>-6.311687</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all the features that are not contains 'Pre' in their name\n",
    "features_df = features_df.loc[:, ~features_df.columns.str.contains('Post')]\n",
    "\n",
    "# Remove all the features that are not contains 'DVA' in their name or config.MOVIE\n",
    "features_df = features_df.loc[:, features_df.columns.str.contains('DVA') | features_df.columns.str.contains(config.MOVIE)]\n",
    "\n",
    "features_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.795231300Z",
     "start_time": "2023-11-02T11:29:12.247510500Z"
    }
   },
   "id": "c2e51e57ddd33cf3"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4080 entries, 0 to 4079\n",
      "Data columns (total 15 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Movie                     4080 non-null   int8  \n",
      " 1   DVA_Mean_Gaze_Pre         3864 non-null   object\n",
      " 2   DVA_Median_Gaze_Pre       3864 non-null   object\n",
      " 3   DVA_Std_Gaze_Pre          3864 non-null   object\n",
      " 4   DVA_Max_Gaze_Pre          3864 non-null   object\n",
      " 5   DVA_Min_Gaze_Pre          3864 non-null   object\n",
      " 6   DVA_Sem_Gaze_Pre          3864 non-null   object\n",
      " 7   DVA_AUC_Gaze_Pre          3864 non-null   object\n",
      " 8   DVA_Mean_Fixations_Pre    4068 non-null   object\n",
      " 9   DVA_Median_Fixations_Pre  4068 non-null   object\n",
      " 10  DVA_Std_Fixations_Pre     4056 non-null   object\n",
      " 11  DVA_Max_Fixations_Pre     4068 non-null   object\n",
      " 12  DVA_Min_Fixations_Pre     4068 non-null   object\n",
      " 13  DVA_Sem_Fixations_Pre     4056 non-null   object\n",
      " 14  DVA_AUC_Fixations_Pre     4068 non-null   object\n",
      "dtypes: int8(1), object(14)\n",
      "memory usage: 450.4+ KB\n"
     ]
    }
   ],
   "source": [
    "features_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.802231600Z",
     "start_time": "2023-11-02T11:29:12.281509900Z"
    }
   },
   "id": "26878df6c8e95564"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "           normalized_by_session_a\nseries_id                         \n0                                1\n1                                0\n2                                0\n3                                0\n4                                0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>normalized_by_session_a</th>\n    </tr>\n    <tr>\n      <th>series_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.835748500Z",
     "start_time": "2023-11-02T11:29:12.288513Z"
    }
   },
   "id": "e6f77a26d5f5ac9e"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4080 entries, 0 to 4079\n",
      "Data columns (total 1 columns):\n",
      " #   Column                   Non-Null Count  Dtype\n",
      "---  ------                   --------------  -----\n",
      " 0   normalized_by_session_a  4080 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 63.8 KB\n"
     ]
    }
   ],
   "source": [
    "labels_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.836749500Z",
     "start_time": "2023-11-02T11:29:12.302521600Z"
    }
   },
   "id": "55d5ddd75248e2af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1f209597785e848"
  },
  {
   "cell_type": "markdown",
   "source": [
    "how many missing values / inf values are there in each column? show the top 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aafd11558e49d132"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in each column: DVA_Mean_Gaze_Pre         216\n",
      "DVA_Median_Gaze_Pre       216\n",
      "DVA_Std_Gaze_Pre          216\n",
      "DVA_Max_Gaze_Pre          216\n",
      "DVA_Min_Gaze_Pre          216\n",
      "DVA_Sem_Gaze_Pre          216\n",
      "DVA_AUC_Gaze_Pre          216\n",
      "DVA_Std_Fixations_Pre      24\n",
      "DVA_Sem_Fixations_Pre      24\n",
      "DVA_Mean_Fixations_Pre     12\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of missing values in each column:', features_df.isin([np.nan, np.inf, -np.inf]).sum(axis=0).sort_values(ascending=False).head(10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.836749500Z",
     "start_time": "2023-11-02T11:29:12.318534100Z"
    }
   },
   "id": "85ef8ca47e4d3dfc"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c1007ccd1578dad8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove columns with more than 30% missing values or inf values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dc4acced1407154"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "features_df = features_df.loc[:, features_df.isin([np.nan, np.inf, -np.inf]).mean(axis=0) < 0.3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.836749500Z",
     "start_time": "2023-11-02T11:29:12.335037600Z"
    }
   },
   "id": "c7a3396286e92939"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "DVA_Mean_Gaze_Pre         0.052941\nDVA_Median_Gaze_Pre       0.052941\nDVA_Std_Gaze_Pre          0.052941\nDVA_Max_Gaze_Pre          0.052941\nDVA_Min_Gaze_Pre          0.052941\nDVA_Sem_Gaze_Pre          0.052941\nDVA_AUC_Gaze_Pre          0.052941\nDVA_Std_Fixations_Pre     0.005882\nDVA_Sem_Fixations_Pre     0.005882\nDVA_Mean_Fixations_Pre    0.002941\ndtype: float64"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.isin([np.nan, np.inf, -np.inf]).mean(axis=0).sort_values(ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.837750200Z",
     "start_time": "2023-11-02T11:29:12.349045800Z"
    }
   },
   "id": "79c74410a4cfbc36"
  },
  {
   "cell_type": "markdown",
   "source": [
    "how many missing values / inf values are there in each row? show the top 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f57be7d57f24fd0"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "1885    0.933333\n1421    0.933333\n900     0.933333\n3291    0.933333\n3324    0.933333\n1732    0.933333\n4050    0.933333\n1845    0.933333\n2399    0.933333\n2363    0.933333\ndtype: float64"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.isin([np.nan, np.inf, -np.inf]).mean(axis=1).sort_values(ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.837750200Z",
     "start_time": "2023-11-02T11:29:12.366034600Z"
    }
   },
   "id": "6f98ce4187c228ec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove rows with more than 50% missing values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "145589330b707337"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "features_df = features_df.loc[features_df.isin([np.nan, np.inf, -np.inf]).mean(axis=1) < 0.5]\n",
    "# remove the corresponding rows from y_train\n",
    "labels_df = labels_df.loc[labels_df.index.isin(features_df.index)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.837750200Z",
     "start_time": "2023-11-02T11:29:12.382033500Z"
    }
   },
   "id": "792221419802df14"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "2910    0.466667\n531     0.466667\n2252    0.466667\n2902    0.466667\n3402    0.466667\n200     0.466667\n3400    0.466667\n2504    0.466667\n2897    0.466667\n3186    0.466667\ndtype: float64"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.isin([np.nan, np.inf, -np.inf]).mean(axis=1).sort_values(ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.837750200Z",
     "start_time": "2023-11-02T11:29:12.402036800Z"
    }
   },
   "id": "e396a8799af88321"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Subject-wise or leave-one-subject-out (LOSO) cross-validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25d46039db7b7165"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Leave-One-Subject-Out Cross-Validation (LOSO CV):\n",
    "- For each fold of the cross-validation, data from N-1 participants are used for training, and the data from the remaining participant is used for testing.\n",
    "- This process is repeated N times (for each participant), ensuring that each participant's data is used as a test set exactly once.\n",
    "- This method ensures that the model generalizes well across different participants."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "accfd74af5ba431"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GE44' 'FY25' 'MN37' ... 'BO03' 'ZN05' 'GN10']\n"
     ]
    }
   ],
   "source": [
    "series_id_df = pd.read_pickle(os.path.join(config.classification_resource_dir, \"pairwise_sessions_series_id_df.pkl\"))\n",
    "\n",
    "# remove the corresponding rows from y_train\n",
    "series_id_df = series_id_df.loc[series_id_df.index.isin(features_df.index)]\n",
    "\n",
    "# Create a list of unique subject IDs\n",
    "subject_ids = series_id_df[config.SUBJECT].unique()\n",
    "\n",
    "# Order the list of subject IDs alphabetically\n",
    "subject_ids = np.sort(subject_ids)\n",
    "\n",
    "# Create groups of subject IDs\n",
    "groups = series_id_df[config.SUBJECT].values\n",
    "\n",
    "# Print the groups\n",
    "print(groups)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.837750200Z",
     "start_time": "2023-11-02T11:29:12.411034900Z"
    }
   },
   "id": "b00d1170f51a31c0"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.839749700Z",
     "start_time": "2023-11-02T11:29:12.426040400Z"
    }
   },
   "id": "a01b0291073eaf6d"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def logistic_regression_model_searcher():\n",
    "    # Define the range of values for each hyperparameter\n",
    "    C = np.linspace(0.01, 1, 15)\n",
    "    PENALTY = ['l1', 'l2']\n",
    "    SOLVER = ['liblinear', 'saga']\n",
    "    \n",
    "    LR_PARAM_GRID  = {\n",
    "        'C': C,\n",
    "        'penalty': PENALTY,\n",
    "        'solver': SOLVER\n",
    "    }\n",
    "    \n",
    "    return GridSearchCV(estimator=LogisticRegression(), param_grid=LR_PARAM_GRID, verbose=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.840749500Z",
     "start_time": "2023-11-02T11:29:12.441009400Z"
    }
   },
   "id": "14786f3ec0aff569"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Gradient Boosting:\n",
    "\n",
    "def gradient_boosting_model_searcher():\n",
    "    # Define the range of values for each hyperparameter\n",
    "    LEARNING_RATE = np.linspace(0.05, 0.5, 5)\n",
    "    MAX_DEPTH = range(2, 4)\n",
    "    N_ESTIMATORS = range(100, 150, 5)\n",
    "    \n",
    "    GB_PARAM_GRID  = {\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'max_depth': MAX_DEPTH,\n",
    "        'n_estimators': N_ESTIMATORS\n",
    "    }\n",
    "    \n",
    "    return GridSearchCV(estimator=GradientBoostingClassifier(), param_grid=GB_PARAM_GRID, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.853749600Z",
     "start_time": "2023-11-02T11:29:12.455992900Z"
    }
   },
   "id": "d4c7e2a8356ddb34"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# SVM:\n",
    "\n",
    "def svm_model_searcher():\n",
    "    # Define the range of values for each hyperparameter\n",
    "    C = np.linspace(0.01, 1, 10)\n",
    "    KERNEL = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    GAMMA = ['scale', 'auto']\n",
    "    \n",
    "    SVM_PARAM_GRID  = {\n",
    "        'C': C,\n",
    "        'kernel': KERNEL,\n",
    "        'gamma': GAMMA\n",
    "    }\n",
    "    \n",
    "    return GridSearchCV(estimator=SVC(), param_grid=SVM_PARAM_GRID, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.854758200Z",
     "start_time": "2023-11-02T11:29:12.472997500Z"
    }
   },
   "id": "87147fda5f93f6fd"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Random Forest:\n",
    "\n",
    "def random_forest_model_searcher():\n",
    "    # Define the range of values for each hyperparameter\n",
    "    N_ESTIMATORS = range(50, 140, 10)\n",
    "    MAX_DEPTH = range(2, 5)\n",
    "    MIN_SAMPLES_SPLIT = range(2, 4)\n",
    "    MIN_SAMPLES_LEAF = range(1, 3)\n",
    "    \n",
    "    RF_PARAM_GRID  = {\n",
    "        'n_estimators': N_ESTIMATORS,\n",
    "        'max_depth': MAX_DEPTH,\n",
    "        'min_samples_split': MIN_SAMPLES_SPLIT,\n",
    "        'min_samples_leaf': MIN_SAMPLES_LEAF\n",
    "    }\n",
    "    \n",
    "    return GridSearchCV(estimator=RandomForestClassifier(), param_grid=RF_PARAM_GRID, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.854758200Z",
     "start_time": "2023-11-02T11:29:12.490010100Z"
    }
   },
   "id": "8f034f95c753d8d9"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# XGBoost model\n",
    "\n",
    "def xgboost_model_searcher():\n",
    "    # Define the range of values for each hyperparameter\n",
    "    LEARNING_RATE = np.linspace(0.05, 0.5, 5)\n",
    "    MAX_DEPTH = range(2, 4)\n",
    "    N_ESTIMATORS = range(100, 150, 5)\n",
    "    \n",
    "    XGB_PARAM_GRID  = {\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'max_depth': MAX_DEPTH,\n",
    "        'n_estimators': N_ESTIMATORS\n",
    "    }\n",
    "    \n",
    "    return GridSearchCV(estimator=XGBClassifier(), param_grid=XGB_PARAM_GRID, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.854758200Z",
     "start_time": "2023-11-02T11:29:12.503869Z"
    }
   },
   "id": "ab4223a8bb4e06b"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'SVM': svm_model_searcher(),\n",
    "    'Gradient Boosting': gradient_boosting_model_searcher(),\n",
    "    'Random Forest': random_forest_model_searcher(),\n",
    "    'Logistic Regression': logistic_regression_model_searcher(),\n",
    "    'XGBoost': xgboost_model_searcher()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.854758200Z",
     "start_time": "2023-11-02T11:29:12.518882400Z"
    }
   },
   "id": "f2b0e16b3549634f"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model_name, y_true, y_pred):\n",
    "    # Evaluate the model using various metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    print(model_name)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", round(accuracy, 2))\n",
    "    print(\"Precision:\", round(precision, 2))\n",
    "    print(\"Recall:\", round(recall, 2))\n",
    "    print(\"F1-score:\", round(f1, 2))\n",
    "    print(\"ROC-AUC score:\", round(roc_auc, 2))\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Create a heatmap visualization of the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    sns.heatmap(confusion_mat, annot=True, cmap=\"Blues\", fmt=\"d\", ax=ax)\n",
    "\n",
    "    # Set the axis labels and title\n",
    "    ax.set_xlabel(\"Predicted Labels\")\n",
    "    ax.set_ylabel(\"True Labels\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    return confusion_mat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.854758200Z",
     "start_time": "2023-11-02T11:29:12.536422800Z"
    }
   },
   "id": "fce6879d296a15ed"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import LeaveOneGroupOut\n",
    "# \n",
    "# # Initialize LeaveOneSubjectOut cross-validator\n",
    "# logo = LeaveOneGroupOut()\n",
    "# \n",
    "# # Function to perform LOSO CV and return average accuracy\n",
    "# def evaluate_classifier(model_searcher, X, y, groups, name):\n",
    "#     tabnet_accuracies = {}\n",
    "#     tabnet_confusion_matricies = {}\n",
    "#     tabnet_confidence_intervals = {}\n",
    "#     tabnet_models = {}\n",
    "#     \n",
    "#     for train_index, test_index in logo.split(X, y, groups):\n",
    "#         # Extract indices for training and testing data for each participant\n",
    "#         X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#         y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "#         \n",
    "#         # fill inf values with the mean of the column\n",
    "#         X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "#         X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "#         X_train = X_train.fillna(X_train.mean()) # fill missing values with the mean of the column or zero ? features_df.mean()\n",
    "#         X_test = X_test.fillna(X_train.mean())\n",
    "#         \n",
    "#         # Scale the data\n",
    "#         # Create separate StandardScaler instances\n",
    "#         scaler_x = StandardScaler()\n",
    "#         # Fit on Training Data (!)\n",
    "#         scaler_x.fit(X_train.values)\n",
    "#         # Transform both training and testing data\n",
    "#         X_train_scaled = scaler_x.transform(X_train.values)\n",
    "#         X_test_scaled = scaler_x.transform(X_test.values)\n",
    "#         y_train = y_train.values.reshape(-1, 1).flatten()\n",
    "#         y_test = y_test.values.reshape(-1, 1).flatten()\n",
    "#         X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "#         X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "#         \n",
    "#         model_searcher.fit(X_train_scaled, y_train)\n",
    "#         clf = model_searcher.best_estimator_\n",
    "#         \n",
    "#         # Fit the classifier\n",
    "#         clf.fit(X_train_scaled, y_train)\n",
    "#         y_pred = clf.predict(X_test_scaled)\n",
    "#         \n",
    "#         acc = accuracy_score(y_test, y_pred)\n",
    "#         accuracies.append(acc)\n",
    "#         conf_mat = evaluate_model(f\"Eval {name}\", y_test, y_pred)\n",
    "#         confusion_matricies.append(conf_mat)\n",
    "#         \n",
    "#     # return the average accuracy, average confusion matrix\n",
    "#     avg_confusion_matrix = np.mean(confusion_matricies, axis=0)\n",
    "#     return np.mean(accuracies), avg_confusion_matrix\n",
    "# \n",
    "# # Evaluate each classifier\n",
    "# results = {}\n",
    "# for name, clf in classifiers.items():\n",
    "#     avg_acc, avg_confusion_matrix = evaluate_classifier(clf, features_df, labels_df, groups, name)\n",
    "#     results[name] = avg_acc, avg_confusion_matrix\n",
    "#     print(f\"Average accuracy of {name}: {avg_acc:.4f}\")\n",
    "#     print(f\"Average confusion matrix of {name}: {avg_confusion_matrix}\")\n",
    "# \n",
    "# # Decision-making (choose the classifier with the highest average accuracy)\n",
    "# best_classifier_name = max(results, key=lambda k: results[k][0])\n",
    "# print(f\"\\nThe best classifier is: {best_classifier_name} with accuracy: {results[best_classifier_name][0]:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:12.854758200Z",
     "start_time": "2023-11-02T11:29:12.551152400Z"
    }
   },
   "id": "38aa660c534b5698"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-tabnet in c:\\users\\user\\anaconda3\\lib\\site-packages (4.0)\n",
      "Requirement already satisfied: torch<2.0,>=1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (1.13.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (1.24.3)\n",
      "Requirement already satisfied: scikit_learn>0.21 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (1.2.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytorch-tabnet) (4.62.3)\n",
      "Requirement already satisfied: scipy>1.4 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from pytorch-tabnet) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.36->pytorch-tabnet) (0.4.4)\n",
      "Requirement already satisfied: optuna in c:\\users\\user\\anaconda3\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (0.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (4.62.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (1.10.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: colorlog in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (1.4.22)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\user\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "# TabNetClassifier with automatic hyperparameters tuning\n",
    "!pip install pytorch-tabnet\n",
    "!pip install optuna"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T11:29:18.288578600Z",
     "start_time": "2023-11-02T11:29:12.567154900Z"
    }
   },
   "id": "3f696eb21974c16b"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 13:29:18,317]\u001B[0m A new study created in memory with name: no-name-b402bd07-c40d-414f-bff3-0162dfabed48\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.55639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:29:29,771]\u001B[0m Trial 0 finished with value: 0.5563888888888888 and parameters: {'n_d': 11, 'n_a': 22, 'n_steps': 15, 'gamma': 0.6283374562449269, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.07596052631330448}. Best is trial 0 with value: 0.5563888888888888.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.58056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:30:08,774]\u001B[0m Trial 1 finished with value: 0.5805555555555556 and parameters: {'n_d': 52, 'n_a': 60, 'n_steps': 14, 'gamma': 1.722360598882185, 'n_independent': 2, 'n_shared': 9, 'lambda_sparse': 0.02894904023287173}. Best is trial 1 with value: 0.5805555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.6025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:30:26,709]\u001B[0m Trial 2 finished with value: 0.6025 and parameters: {'n_d': 37, 'n_a': 46, 'n_steps': 5, 'gamma': 0.4115312921380325, 'n_independent': 10, 'n_shared': 4, 'lambda_sparse': 0.014625603519107728}. Best is trial 2 with value: 0.6025.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.62861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:30:45,274]\u001B[0m Trial 3 finished with value: 0.6286111111111111 and parameters: {'n_d': 35, 'n_a': 59, 'n_steps': 4, 'gamma': 1.8165356359494884, 'n_independent': 8, 'n_shared': 5, 'lambda_sparse': 0.0003515674976533883}. Best is trial 3 with value: 0.6286111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.58722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:31:30,676]\u001B[0m Trial 4 finished with value: 0.5872222222222222 and parameters: {'n_d': 44, 'n_a': 53, 'n_steps': 11, 'gamma': 0.7511586521204885, 'n_independent': 6, 'n_shared': 3, 'lambda_sparse': 0.08525727841190056}. Best is trial 3 with value: 0.6286111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.57208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:32:00,532]\u001B[0m Trial 5 finished with value: 0.5720833333333333 and parameters: {'n_d': 17, 'n_a': 29, 'n_steps': 18, 'gamma': 1.9906402441619526, 'n_independent': 5, 'n_shared': 6, 'lambda_sparse': 0.03541836006421171}. Best is trial 3 with value: 0.6286111111111111.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:32:06,519]\u001B[0m Trial 6 finished with value: 0.6122222222222221 and parameters: {'n_d': 38, 'n_a': 12, 'n_steps': 2, 'gamma': 0.45734554843547237, 'n_independent': 4, 'n_shared': 10, 'lambda_sparse': 0.001665172567387016}. Best is trial 3 with value: 0.6286111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.61222\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.63681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:32:50,144]\u001B[0m Trial 7 finished with value: 0.6368055555555556 and parameters: {'n_d': 42, 'n_a': 25, 'n_steps': 13, 'gamma': 1.452206817555564, 'n_independent': 7, 'n_shared': 7, 'lambda_sparse': 0.09352791868487659}. Best is trial 7 with value: 0.6368055555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.56222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:32:57,439]\u001B[0m Trial 8 finished with value: 0.5622222222222223 and parameters: {'n_d': 40, 'n_a': 62, 'n_steps': 7, 'gamma': 0.9186631241990793, 'n_independent': 3, 'n_shared': 4, 'lambda_sparse': 0.015386676642576168}. Best is trial 7 with value: 0.6368055555555556.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:33:01,060]\u001B[0m Trial 9 finished with value: 0.5852777777777778 and parameters: {'n_d': 35, 'n_a': 12, 'n_steps': 3, 'gamma': 0.3893677181913304, 'n_independent': 2, 'n_shared': 6, 'lambda_sparse': 0.06133499599543893}. Best is trial 7 with value: 0.6368055555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.58528\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.64056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:33:32,506]\u001B[0m Trial 10 finished with value: 0.6405555555555555 and parameters: {'n_d': 63, 'n_a': 38, 'n_steps': 10, 'gamma': 1.3135955769368444, 'n_independent': 8, 'n_shared': 8, 'lambda_sparse': 0.09595774224663126}. Best is trial 10 with value: 0.6405555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.62111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:33:58,109]\u001B[0m Trial 11 finished with value: 0.6211111111111112 and parameters: {'n_d': 61, 'n_a': 38, 'n_steps': 10, 'gamma': 1.3325386303567028, 'n_independent': 8, 'n_shared': 8, 'lambda_sparse': 0.09134427150199873}. Best is trial 10 with value: 0.6405555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.56806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:34:48,099]\u001B[0m Trial 12 finished with value: 0.5680555555555555 and parameters: {'n_d': 60, 'n_a': 36, 'n_steps': 10, 'gamma': 1.2125132822811369, 'n_independent': 8, 'n_shared': 8, 'lambda_sparse': 0.09934701184008364}. Best is trial 10 with value: 0.6405555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.59278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:35:16,225]\u001B[0m Trial 13 finished with value: 0.5927777777777777 and parameters: {'n_d': 25, 'n_a': 25, 'n_steps': 14, 'gamma': 1.403351395640993, 'n_independent': 10, 'n_shared': 7, 'lambda_sparse': 0.07126355219637402}. Best is trial 10 with value: 0.6405555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.64181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:35:43,390]\u001B[0m Trial 14 finished with value: 0.6418055555555556 and parameters: {'n_d': 52, 'n_a': 45, 'n_steps': 8, 'gamma': 1.056160504319582, 'n_independent': 7, 'n_shared': 10, 'lambda_sparse': 0.09446334796888102}. Best is trial 14 with value: 0.6418055555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.61778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:36:46,814]\u001B[0m Trial 15 finished with value: 0.6177777777777778 and parameters: {'n_d': 51, 'n_a': 45, 'n_steps': 7, 'gamma': 1.0692490358201574, 'n_independent': 9, 'n_shared': 10, 'lambda_sparse': 0.0798995565189679}. Best is trial 14 with value: 0.6418055555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.59194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:37:06,628]\u001B[0m Trial 16 finished with value: 0.5919444444444444 and parameters: {'n_d': 53, 'n_a': 45, 'n_steps': 7, 'gamma': 0.9864493950141987, 'n_independent': 7, 'n_shared': 9, 'lambda_sparse': 0.0626558238196846}. Best is trial 14 with value: 0.6418055555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.56458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:37:28,292]\u001B[0m Trial 17 finished with value: 0.5645833333333333 and parameters: {'n_d': 62, 'n_a': 38, 'n_steps': 9, 'gamma': 0.12492844567702577, 'n_independent': 5, 'n_shared': 9, 'lambda_sparse': 0.09966024141091138}. Best is trial 14 with value: 0.6418055555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.56806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:38:34,720]\u001B[0m Trial 18 finished with value: 0.5680555555555554 and parameters: {'n_d': 56, 'n_a': 34, 'n_steps': 17, 'gamma': 1.1697577654803348, 'n_independent': 7, 'n_shared': 10, 'lambda_sparse': 0.0839959661067734}. Best is trial 14 with value: 0.6418055555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:39:21,972]\u001B[0m Trial 19 finished with value: 0.5850000000000001 and parameters: {'n_d': 48, 'n_a': 52, 'n_steps': 12, 'gamma': 1.525104300817687, 'n_independent': 9, 'n_shared': 8, 'lambda_sparse': 0.06952306578936329}. Best is trial 14 with value: 0.6418055555555556.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.97933 |  0:00:01s\n",
      "epoch 1  | loss: 1.95768 |  0:00:03s\n",
      "epoch 2  | loss: 1.82172 |  0:00:05s\n",
      "epoch 3  | loss: 1.51033 |  0:00:06s\n",
      "epoch 4  | loss: 1.32521 |  0:00:08s\n",
      "epoch 5  | loss: 1.51382 |  0:00:10s\n",
      "epoch 6  | loss: 1.20887 |  0:00:12s\n",
      "epoch 7  | loss: 1.09219 |  0:00:14s\n",
      "epoch 8  | loss: 1.07312 |  0:00:15s\n",
      "epoch 9  | loss: 1.07654 |  0:00:17s\n",
      "epoch 10 | loss: 1.61633 |  0:00:19s\n",
      "epoch 11 | loss: 1.2382  |  0:00:21s\n",
      "epoch 12 | loss: 0.97732 |  0:00:23s\n",
      "epoch 13 | loss: 0.92094 |  0:00:24s\n",
      "epoch 14 | loss: 0.83347 |  0:00:26s\n",
      "epoch 15 | loss: 0.86905 |  0:00:28s\n",
      "epoch 16 | loss: 0.86111 |  0:00:29s\n",
      "epoch 17 | loss: 1.18729 |  0:00:31s\n",
      "epoch 18 | loss: 1.18799 |  0:00:33s\n",
      "epoch 19 | loss: 0.78034 |  0:00:35s\n",
      "epoch 20 | loss: 0.82861 |  0:00:36s\n",
      "epoch 21 | loss: 0.89078 |  0:00:38s\n",
      "epoch 22 | loss: 0.799   |  0:00:40s\n",
      "epoch 23 | loss: 0.73426 |  0:00:42s\n",
      "epoch 24 | loss: 0.71984 |  0:00:43s\n",
      "epoch 25 | loss: 0.6808  |  0:00:45s\n",
      "epoch 26 | loss: 0.6848  |  0:00:47s\n",
      "epoch 27 | loss: 0.68393 |  0:00:49s\n",
      "epoch 28 | loss: 0.67283 |  0:00:50s\n",
      "epoch 29 | loss: 0.6668  |  0:00:52s\n",
      "epoch 30 | loss: 0.66891 |  0:00:54s\n",
      "epoch 31 | loss: 0.65377 |  0:00:56s\n",
      "epoch 32 | loss: 0.66638 |  0:00:57s\n",
      "epoch 33 | loss: 0.66517 |  0:00:59s\n",
      "epoch 34 | loss: 0.68519 |  0:01:01s\n",
      "epoch 35 | loss: 0.73309 |  0:01:03s\n",
      "epoch 36 | loss: 0.70851 |  0:01:04s\n",
      "epoch 37 | loss: 0.67791 |  0:01:06s\n",
      "epoch 38 | loss: 0.66528 |  0:01:08s\n",
      "epoch 39 | loss: 0.65708 |  0:01:09s\n",
      "epoch 40 | loss: 0.66789 |  0:01:11s\n",
      "epoch 41 | loss: 0.6548  |  0:01:13s\n",
      "epoch 42 | loss: 0.65812 |  0:01:15s\n",
      "epoch 43 | loss: 0.66162 |  0:01:17s\n",
      "epoch 44 | loss: 0.6633  |  0:01:19s\n",
      "epoch 45 | loss: 0.67947 |  0:01:21s\n",
      "epoch 46 | loss: 0.75696 |  0:01:23s\n",
      "epoch 47 | loss: 0.68077 |  0:01:25s\n",
      "epoch 48 | loss: 0.66075 |  0:01:27s\n",
      "epoch 49 | loss: 0.65129 |  0:01:28s\n",
      "epoch 50 | loss: 0.6415  |  0:01:30s\n",
      "epoch 51 | loss: 0.64235 |  0:01:32s\n",
      "epoch 52 | loss: 0.63396 |  0:01:34s\n",
      "epoch 53 | loss: 0.64598 |  0:01:35s\n",
      "epoch 54 | loss: 0.64378 |  0:01:37s\n",
      "epoch 55 | loss: 0.63785 |  0:01:39s\n",
      "epoch 56 | loss: 0.62943 |  0:01:41s\n",
      "epoch 57 | loss: 0.62085 |  0:01:42s\n",
      "epoch 58 | loss: 0.62657 |  0:01:44s\n",
      "epoch 59 | loss: 0.62202 |  0:01:46s\n",
      "epoch 60 | loss: 0.61925 |  0:01:48s\n",
      "epoch 61 | loss: 0.61321 |  0:01:49s\n",
      "epoch 62 | loss: 0.6194  |  0:01:51s\n",
      "epoch 63 | loss: 0.61363 |  0:01:53s\n",
      "epoch 64 | loss: 0.62169 |  0:01:55s\n",
      "epoch 65 | loss: 0.62024 |  0:01:56s\n",
      "epoch 66 | loss: 0.61882 |  0:01:58s\n",
      "epoch 67 | loss: 0.61789 |  0:02:00s\n",
      "epoch 68 | loss: 0.61333 |  0:02:02s\n",
      "epoch 69 | loss: 0.60638 |  0:02:03s\n",
      "epoch 70 | loss: 0.60927 |  0:02:05s\n",
      "epoch 71 | loss: 0.61985 |  0:02:07s\n",
      "epoch 72 | loss: 0.61664 |  0:02:08s\n",
      "epoch 73 | loss: 0.61222 |  0:02:10s\n",
      "epoch 74 | loss: 0.61539 |  0:02:12s\n",
      "epoch 75 | loss: 0.6257  |  0:02:14s\n",
      "epoch 76 | loss: 0.62327 |  0:02:15s\n",
      "epoch 77 | loss: 0.64845 |  0:02:17s\n",
      "epoch 78 | loss: 0.62235 |  0:02:19s\n",
      "epoch 79 | loss: 0.62353 |  0:02:21s\n",
      "epoch 80 | loss: 0.61528 |  0:02:22s\n",
      "epoch 81 | loss: 0.61509 |  0:02:24s\n",
      "epoch 82 | loss: 0.61768 |  0:02:26s\n",
      "epoch 83 | loss: 0.62524 |  0:02:28s\n",
      "epoch 84 | loss: 0.62401 |  0:02:29s\n",
      "epoch 85 | loss: 0.61957 |  0:02:31s\n",
      "epoch 86 | loss: 0.61388 |  0:02:33s\n",
      "epoch 87 | loss: 0.61974 |  0:02:34s\n",
      "epoch 88 | loss: 0.61955 |  0:02:36s\n",
      "epoch 89 | loss: 0.62017 |  0:02:38s\n",
      "epoch 90 | loss: 0.62501 |  0:02:40s\n",
      "epoch 91 | loss: 0.60849 |  0:02:41s\n",
      "epoch 92 | loss: 0.61302 |  0:02:43s\n",
      "epoch 93 | loss: 0.60939 |  0:02:45s\n",
      "epoch 94 | loss: 0.61241 |  0:02:47s\n",
      "epoch 95 | loss: 0.61163 |  0:02:48s\n",
      "epoch 96 | loss: 0.60426 |  0:02:50s\n",
      "epoch 97 | loss: 0.60932 |  0:02:52s\n",
      "epoch 98 | loss: 0.60669 |  0:02:53s\n",
      "epoch 99 | loss: 0.6076  |  0:02:55s\n",
      "Eval TABNET\n",
      "Accuracy: 0.52\n",
      "Precision: 0.51\n",
      "Recall: 0.58\n",
      "F1-score: 0.55\n",
      "ROC-AUC score: 0.52\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 13:42:19,127]\u001B[0m A new study created in memory with name: no-name-73ab0a46-3d28-4ae7-8b01-212bf4f18f31\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.70917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:42:42,877]\u001B[0m Trial 0 finished with value: 0.7091666666666667 and parameters: {'n_d': 11, 'n_a': 60, 'n_steps': 7, 'gamma': 1.2733640799405064, 'n_independent': 7, 'n_shared': 3, 'lambda_sparse': 0.0761230179335766}. Best is trial 0 with value: 0.7091666666666667.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:42:48,270]\u001B[0m Trial 1 finished with value: 0.6775 and parameters: {'n_d': 32, 'n_a': 22, 'n_steps': 7, 'gamma': 1.5536993541807536, 'n_independent': 3, 'n_shared': 1, 'lambda_sparse': 0.0077499311848387}. Best is trial 0 with value: 0.7091666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.6775\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.7425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:45:23,261]\u001B[0m Trial 2 finished with value: 0.7424999999999999 and parameters: {'n_d': 62, 'n_a': 17, 'n_steps': 16, 'gamma': 0.2846519941136938, 'n_independent': 9, 'n_shared': 10, 'lambda_sparse': 0.004739537829159746}. Best is trial 2 with value: 0.7424999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.69694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:46:55,322]\u001B[0m Trial 3 finished with value: 0.6969444444444444 and parameters: {'n_d': 16, 'n_a': 45, 'n_steps': 19, 'gamma': 1.4641772790366832, 'n_independent': 8, 'n_shared': 4, 'lambda_sparse': 0.08376535613598998}. Best is trial 2 with value: 0.7424999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.54472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:47:24,226]\u001B[0m Trial 4 finished with value: 0.5447222222222222 and parameters: {'n_d': 22, 'n_a': 42, 'n_steps': 18, 'gamma': 1.4187658362731461, 'n_independent': 3, 'n_shared': 10, 'lambda_sparse': 0.022251278009496014}. Best is trial 2 with value: 0.7424999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.70361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:47:40,589]\u001B[0m Trial 5 finished with value: 0.703611111111111 and parameters: {'n_d': 41, 'n_a': 28, 'n_steps': 2, 'gamma': 1.562079334778711, 'n_independent': 10, 'n_shared': 6, 'lambda_sparse': 0.07832025383571006}. Best is trial 2 with value: 0.7424999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.69472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:47:53,677]\u001B[0m Trial 6 finished with value: 0.6947222222222222 and parameters: {'n_d': 28, 'n_a': 54, 'n_steps': 6, 'gamma': 1.2559758912883443, 'n_independent': 3, 'n_shared': 2, 'lambda_sparse': 0.09634282252045097}. Best is trial 2 with value: 0.7424999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.72722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:48:26,677]\u001B[0m Trial 7 finished with value: 0.7272222222222222 and parameters: {'n_d': 54, 'n_a': 53, 'n_steps': 15, 'gamma': 0.6478513303796353, 'n_independent': 3, 'n_shared': 3, 'lambda_sparse': 0.02353311631905449}. Best is trial 2 with value: 0.7424999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_auc = 0.72167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:49:49,269]\u001B[0m Trial 8 finished with value: 0.7216666666666667 and parameters: {'n_d': 47, 'n_a': 27, 'n_steps': 18, 'gamma': 0.9521874292620505, 'n_independent': 2, 'n_shared': 5, 'lambda_sparse': 0.014377646699057217}. Best is trial 2 with value: 0.7424999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.71306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:50:21,070]\u001B[0m Trial 9 finished with value: 0.7130555555555556 and parameters: {'n_d': 61, 'n_a': 34, 'n_steps': 5, 'gamma': 1.0819913851183347, 'n_independent': 7, 'n_shared': 2, 'lambda_sparse': 0.08523285202809283}. Best is trial 2 with value: 0.7424999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.73194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:51:37,968]\u001B[0m Trial 10 finished with value: 0.7319444444444445 and parameters: {'n_d': 64, 'n_a': 9, 'n_steps': 13, 'gamma': 0.1696250773933745, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.03994474271197909}. Best is trial 2 with value: 0.7424999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.69361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:53:07,764]\u001B[0m Trial 11 finished with value: 0.6936111111111111 and parameters: {'n_d': 62, 'n_a': 8, 'n_steps': 12, 'gamma': 0.2445362324011559, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.043307455493402744}. Best is trial 2 with value: 0.7424999999999999.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.05696 |  0:00:03s\n",
      "epoch 1  | loss: 1.55716 |  0:00:06s\n",
      "epoch 2  | loss: 2.3023  |  0:00:09s\n",
      "epoch 3  | loss: 1.69516 |  0:00:12s\n",
      "epoch 4  | loss: 2.85325 |  0:00:15s\n",
      "epoch 5  | loss: 1.8527  |  0:00:19s\n",
      "epoch 6  | loss: 2.41731 |  0:00:22s\n",
      "epoch 7  | loss: 1.30015 |  0:00:25s\n",
      "epoch 8  | loss: 1.25831 |  0:00:28s\n",
      "epoch 9  | loss: 1.0889  |  0:00:31s\n",
      "epoch 10 | loss: 1.11267 |  0:00:35s\n",
      "epoch 11 | loss: 0.88035 |  0:00:38s\n",
      "epoch 12 | loss: 0.8853  |  0:00:41s\n",
      "epoch 13 | loss: 0.85387 |  0:00:44s\n",
      "epoch 14 | loss: 0.80771 |  0:00:47s\n",
      "epoch 15 | loss: 0.73209 |  0:00:50s\n",
      "epoch 16 | loss: 0.68492 |  0:00:54s\n",
      "epoch 17 | loss: 0.65782 |  0:00:57s\n",
      "epoch 18 | loss: 0.64646 |  0:01:00s\n",
      "epoch 19 | loss: 0.6268  |  0:01:03s\n",
      "epoch 20 | loss: 0.66358 |  0:01:06s\n",
      "epoch 21 | loss: 0.62072 |  0:01:10s\n",
      "epoch 22 | loss: 0.61177 |  0:01:13s\n",
      "epoch 23 | loss: 0.61157 |  0:01:16s\n",
      "epoch 24 | loss: 0.59281 |  0:01:19s\n",
      "epoch 25 | loss: 0.58504 |  0:01:23s\n",
      "epoch 26 | loss: 0.58502 |  0:01:26s\n",
      "epoch 27 | loss: 0.59466 |  0:01:29s\n",
      "epoch 28 | loss: 0.59247 |  0:01:32s\n",
      "epoch 29 | loss: 0.5796  |  0:01:36s\n",
      "epoch 30 | loss: 0.57683 |  0:01:39s\n",
      "epoch 31 | loss: 0.58224 |  0:01:42s\n",
      "epoch 32 | loss: 0.57536 |  0:01:46s\n",
      "epoch 33 | loss: 0.56863 |  0:01:49s\n",
      "epoch 34 | loss: 0.56217 |  0:01:52s\n",
      "epoch 35 | loss: 0.55599 |  0:01:55s\n",
      "epoch 36 | loss: 0.56238 |  0:01:59s\n",
      "epoch 37 | loss: 0.55082 |  0:02:02s\n",
      "epoch 38 | loss: 0.55501 |  0:02:05s\n",
      "epoch 39 | loss: 0.54456 |  0:02:08s\n",
      "epoch 40 | loss: 0.5506  |  0:02:12s\n",
      "epoch 41 | loss: 0.53879 |  0:02:15s\n",
      "epoch 42 | loss: 0.54073 |  0:02:18s\n",
      "epoch 43 | loss: 0.54198 |  0:02:21s\n",
      "epoch 44 | loss: 0.53694 |  0:02:25s\n",
      "epoch 45 | loss: 0.53497 |  0:02:28s\n",
      "epoch 46 | loss: 0.53067 |  0:02:31s\n",
      "epoch 47 | loss: 0.53096 |  0:02:34s\n",
      "epoch 48 | loss: 0.52465 |  0:02:37s\n",
      "epoch 49 | loss: 0.52486 |  0:02:41s\n",
      "epoch 50 | loss: 0.51616 |  0:02:44s\n",
      "epoch 51 | loss: 0.51335 |  0:02:47s\n",
      "epoch 52 | loss: 0.51204 |  0:02:51s\n",
      "epoch 53 | loss: 0.50374 |  0:02:54s\n",
      "epoch 54 | loss: 0.50111 |  0:02:57s\n",
      "epoch 55 | loss: 0.49384 |  0:03:00s\n",
      "epoch 56 | loss: 0.48685 |  0:03:04s\n",
      "epoch 57 | loss: 0.48758 |  0:03:07s\n",
      "epoch 58 | loss: 0.47761 |  0:03:10s\n",
      "epoch 59 | loss: 0.49325 |  0:03:14s\n",
      "epoch 60 | loss: 0.47756 |  0:03:17s\n",
      "epoch 61 | loss: 0.46957 |  0:03:20s\n",
      "epoch 62 | loss: 0.46689 |  0:03:24s\n",
      "epoch 63 | loss: 0.46596 |  0:03:27s\n",
      "epoch 64 | loss: 0.44436 |  0:03:31s\n",
      "epoch 65 | loss: 0.451   |  0:03:34s\n",
      "epoch 66 | loss: 0.44985 |  0:03:37s\n",
      "epoch 67 | loss: 0.44646 |  0:03:40s\n",
      "epoch 68 | loss: 0.43342 |  0:03:44s\n",
      "epoch 69 | loss: 0.44543 |  0:03:47s\n",
      "epoch 70 | loss: 0.44214 |  0:03:51s\n",
      "epoch 71 | loss: 0.40752 |  0:03:54s\n",
      "epoch 72 | loss: 0.42385 |  0:03:57s\n",
      "epoch 73 | loss: 0.41379 |  0:04:01s\n",
      "epoch 74 | loss: 0.39486 |  0:04:04s\n",
      "epoch 75 | loss: 0.3916  |  0:04:07s\n",
      "epoch 76 | loss: 0.40229 |  0:04:11s\n",
      "epoch 77 | loss: 0.41029 |  0:04:14s\n",
      "epoch 78 | loss: 0.38929 |  0:04:17s\n",
      "epoch 79 | loss: 0.38219 |  0:04:21s\n",
      "epoch 80 | loss: 0.38048 |  0:04:24s\n",
      "epoch 81 | loss: 0.36148 |  0:04:27s\n",
      "epoch 82 | loss: 0.37374 |  0:04:31s\n",
      "epoch 83 | loss: 0.3563  |  0:04:34s\n",
      "epoch 84 | loss: 0.34824 |  0:04:37s\n",
      "epoch 85 | loss: 0.34334 |  0:04:41s\n",
      "epoch 86 | loss: 0.31569 |  0:04:44s\n",
      "epoch 87 | loss: 0.32961 |  0:04:47s\n",
      "epoch 88 | loss: 0.3184  |  0:04:51s\n",
      "epoch 89 | loss: 0.33141 |  0:04:54s\n",
      "epoch 90 | loss: 0.3439  |  0:04:58s\n",
      "epoch 91 | loss: 0.33189 |  0:05:01s\n",
      "epoch 92 | loss: 0.31705 |  0:05:04s\n",
      "epoch 93 | loss: 0.32532 |  0:05:08s\n",
      "epoch 94 | loss: 0.34335 |  0:05:11s\n",
      "epoch 95 | loss: 0.3012  |  0:05:14s\n",
      "epoch 96 | loss: 0.31144 |  0:05:18s\n",
      "epoch 97 | loss: 0.30941 |  0:05:21s\n",
      "epoch 98 | loss: 0.29781 |  0:05:24s\n",
      "epoch 99 | loss: 0.27452 |  0:05:28s\n",
      "Eval TABNET\n",
      "Accuracy: 0.61\n",
      "Precision: 0.6\n",
      "Recall: 0.65\n",
      "F1-score: 0.62\n",
      "ROC-AUC score: 0.61\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 13:58:38,735]\u001B[0m A new study created in memory with name: no-name-07392007-521e-484d-9c34-d295891ff18d\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.89333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:59:31,893]\u001B[0m Trial 0 finished with value: 0.8933333333333334 and parameters: {'n_d': 60, 'n_a': 42, 'n_steps': 16, 'gamma': 0.694900008001287, 'n_independent': 6, 'n_shared': 6, 'lambda_sparse': 0.02260018935869962}. Best is trial 0 with value: 0.8933333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.87278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 13:59:58,181]\u001B[0m Trial 1 finished with value: 0.8727777777777778 and parameters: {'n_d': 55, 'n_a': 37, 'n_steps': 16, 'gamma': 0.4288720008730137, 'n_independent': 1, 'n_shared': 7, 'lambda_sparse': 0.011514149565815344}. Best is trial 0 with value: 0.8933333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.89028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:01:08,724]\u001B[0m Trial 2 finished with value: 0.8902777777777777 and parameters: {'n_d': 56, 'n_a': 52, 'n_steps': 8, 'gamma': 0.7397148827533447, 'n_independent': 9, 'n_shared': 9, 'lambda_sparse': 0.04785607225455433}. Best is trial 0 with value: 0.8933333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.80278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:02:14,754]\u001B[0m Trial 3 finished with value: 0.8027777777777778 and parameters: {'n_d': 62, 'n_a': 39, 'n_steps': 10, 'gamma': 1.2218002351189878, 'n_independent': 9, 'n_shared': 10, 'lambda_sparse': 0.04534706329027002}. Best is trial 0 with value: 0.8933333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.92083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:02:57,406]\u001B[0m Trial 4 finished with value: 0.9208333333333333 and parameters: {'n_d': 64, 'n_a': 58, 'n_steps': 12, 'gamma': 1.8597738316855905, 'n_independent': 3, 'n_shared': 2, 'lambda_sparse': 0.04539821192200142}. Best is trial 4 with value: 0.9208333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.87194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:03:30,473]\u001B[0m Trial 5 finished with value: 0.8719444444444444 and parameters: {'n_d': 10, 'n_a': 28, 'n_steps': 8, 'gamma': 1.4608044971242695, 'n_independent': 10, 'n_shared': 5, 'lambda_sparse': 0.09838099669480777}. Best is trial 4 with value: 0.9208333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.88472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:03:48,263]\u001B[0m Trial 6 finished with value: 0.8847222222222222 and parameters: {'n_d': 58, 'n_a': 32, 'n_steps': 8, 'gamma': 0.33705149644407256, 'n_independent': 2, 'n_shared': 5, 'lambda_sparse': 0.09028366118766022}. Best is trial 4 with value: 0.9208333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.89806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:04:50,495]\u001B[0m Trial 7 finished with value: 0.8980555555555555 and parameters: {'n_d': 31, 'n_a': 46, 'n_steps': 11, 'gamma': 0.37947356067405424, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.0649535086610869}. Best is trial 4 with value: 0.9208333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.88167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:05:24,519]\u001B[0m Trial 8 finished with value: 0.8816666666666667 and parameters: {'n_d': 49, 'n_a': 17, 'n_steps': 6, 'gamma': 1.647516852244406, 'n_independent': 5, 'n_shared': 10, 'lambda_sparse': 0.033131522007504584}. Best is trial 4 with value: 0.9208333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_auc = 0.9025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:06:14,862]\u001B[0m Trial 9 finished with value: 0.9025 and parameters: {'n_d': 37, 'n_a': 46, 'n_steps': 6, 'gamma': 1.3970516131582984, 'n_independent': 6, 'n_shared': 9, 'lambda_sparse': 0.08141535914136185}. Best is trial 4 with value: 0.9208333333333333.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:06:18,777]\u001B[0m Trial 10 finished with value: 0.9 and parameters: {'n_d': 41, 'n_a': 62, 'n_steps': 2, 'gamma': 1.9536716805130925, 'n_independent': 3, 'n_shared': 1, 'lambda_sparse': 0.00374278010791617}. Best is trial 4 with value: 0.9208333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.9\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 31 and best_val_0_auc = 0.91722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:07:01,290]\u001B[0m Trial 11 finished with value: 0.9172222222222223 and parameters: {'n_d': 25, 'n_a': 64, 'n_steps': 13, 'gamma': 1.9354941059276483, 'n_independent': 4, 'n_shared': 2, 'lambda_sparse': 0.0732721294728284}. Best is trial 4 with value: 0.9208333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.88556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:07:26,128]\u001B[0m Trial 12 finished with value: 0.8855555555555555 and parameters: {'n_d': 23, 'n_a': 64, 'n_steps': 13, 'gamma': 1.9673481042417407, 'n_independent': 4, 'n_shared': 1, 'lambda_sparse': 0.06044016074354553}. Best is trial 4 with value: 0.9208333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.91556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:08:18,639]\u001B[0m Trial 13 finished with value: 0.9155555555555555 and parameters: {'n_d': 21, 'n_a': 56, 'n_steps': 19, 'gamma': 1.7105795937394115, 'n_independent': 3, 'n_shared': 3, 'lambda_sparse': 0.07029488466795636}. Best is trial 4 with value: 0.9208333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.86889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:08:41,217]\u001B[0m Trial 14 finished with value: 0.8688888888888889 and parameters: {'n_d': 27, 'n_a': 55, 'n_steps': 14, 'gamma': 1.740196230606434, 'n_independent': 4, 'n_shared': 3, 'lambda_sparse': 0.07630521451255834}. Best is trial 4 with value: 0.9208333333333333.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.62917 |  0:00:00s\n",
      "epoch 1  | loss: 1.61364 |  0:00:01s\n",
      "epoch 2  | loss: 2.23917 |  0:00:02s\n",
      "epoch 3  | loss: 1.81148 |  0:00:03s\n",
      "epoch 4  | loss: 1.18811 |  0:00:04s\n",
      "epoch 5  | loss: 1.20041 |  0:00:05s\n",
      "epoch 6  | loss: 1.169   |  0:00:06s\n",
      "epoch 7  | loss: 1.52665 |  0:00:07s\n",
      "epoch 8  | loss: 2.1707  |  0:00:08s\n",
      "epoch 9  | loss: 1.42948 |  0:00:09s\n",
      "epoch 10 | loss: 1.14351 |  0:00:10s\n",
      "epoch 11 | loss: 0.96696 |  0:00:11s\n",
      "epoch 12 | loss: 1.43045 |  0:00:12s\n",
      "epoch 13 | loss: 0.84875 |  0:00:13s\n",
      "epoch 14 | loss: 0.87531 |  0:00:14s\n",
      "epoch 15 | loss: 0.84677 |  0:00:14s\n",
      "epoch 16 | loss: 0.73541 |  0:00:15s\n",
      "epoch 17 | loss: 0.6909  |  0:00:16s\n",
      "epoch 18 | loss: 0.69241 |  0:00:17s\n",
      "epoch 19 | loss: 0.73012 |  0:00:18s\n",
      "epoch 20 | loss: 0.828   |  0:00:19s\n",
      "epoch 21 | loss: 0.91035 |  0:00:20s\n",
      "epoch 22 | loss: 0.82701 |  0:00:21s\n",
      "epoch 23 | loss: 0.99672 |  0:00:22s\n",
      "epoch 24 | loss: 0.78961 |  0:00:23s\n",
      "epoch 25 | loss: 0.66966 |  0:00:24s\n",
      "epoch 26 | loss: 0.66695 |  0:00:24s\n",
      "epoch 27 | loss: 0.75469 |  0:00:25s\n",
      "epoch 28 | loss: 0.65393 |  0:00:26s\n",
      "epoch 29 | loss: 0.65085 |  0:00:27s\n",
      "epoch 30 | loss: 0.86453 |  0:00:28s\n",
      "epoch 31 | loss: 0.71225 |  0:00:29s\n",
      "epoch 32 | loss: 0.82009 |  0:00:30s\n",
      "epoch 33 | loss: 0.73274 |  0:00:31s\n",
      "epoch 34 | loss: 1.06734 |  0:00:32s\n",
      "epoch 35 | loss: 1.01038 |  0:00:33s\n",
      "epoch 36 | loss: 0.70562 |  0:00:33s\n",
      "epoch 37 | loss: 0.75051 |  0:00:34s\n",
      "epoch 38 | loss: 0.81713 |  0:00:35s\n",
      "epoch 39 | loss: 0.65933 |  0:00:36s\n",
      "epoch 40 | loss: 0.69306 |  0:00:37s\n",
      "epoch 41 | loss: 0.65024 |  0:00:38s\n",
      "epoch 42 | loss: 0.63816 |  0:00:39s\n",
      "epoch 43 | loss: 0.63624 |  0:00:40s\n",
      "epoch 44 | loss: 0.61517 |  0:00:41s\n",
      "epoch 45 | loss: 0.64276 |  0:00:42s\n",
      "epoch 46 | loss: 0.62114 |  0:00:42s\n",
      "epoch 47 | loss: 0.63816 |  0:00:43s\n",
      "epoch 48 | loss: 0.62101 |  0:00:44s\n",
      "epoch 49 | loss: 0.62127 |  0:00:45s\n",
      "epoch 50 | loss: 0.60672 |  0:00:46s\n",
      "epoch 51 | loss: 0.60374 |  0:00:47s\n",
      "epoch 52 | loss: 0.60643 |  0:00:48s\n",
      "epoch 53 | loss: 0.60957 |  0:00:49s\n",
      "epoch 54 | loss: 0.59769 |  0:00:50s\n",
      "epoch 55 | loss: 0.59903 |  0:00:50s\n",
      "epoch 56 | loss: 0.60868 |  0:00:51s\n",
      "epoch 57 | loss: 0.62803 |  0:00:52s\n",
      "epoch 58 | loss: 0.62767 |  0:00:53s\n",
      "epoch 59 | loss: 0.61913 |  0:00:54s\n",
      "epoch 60 | loss: 0.62592 |  0:00:55s\n",
      "epoch 61 | loss: 0.6319  |  0:00:56s\n",
      "epoch 62 | loss: 0.62962 |  0:00:57s\n",
      "epoch 63 | loss: 0.61103 |  0:00:57s\n",
      "epoch 64 | loss: 0.60997 |  0:00:58s\n",
      "epoch 65 | loss: 0.6065  |  0:00:59s\n",
      "epoch 66 | loss: 0.62571 |  0:01:00s\n",
      "epoch 67 | loss: 0.60565 |  0:01:01s\n",
      "epoch 68 | loss: 0.6136  |  0:01:02s\n",
      "epoch 69 | loss: 0.62381 |  0:01:03s\n",
      "epoch 70 | loss: 0.6017  |  0:01:04s\n",
      "epoch 71 | loss: 0.60238 |  0:01:04s\n",
      "epoch 72 | loss: 0.60393 |  0:01:05s\n",
      "epoch 73 | loss: 0.60166 |  0:01:06s\n",
      "epoch 74 | loss: 0.60639 |  0:01:07s\n",
      "epoch 75 | loss: 0.60378 |  0:01:08s\n",
      "epoch 76 | loss: 0.60703 |  0:01:09s\n",
      "epoch 77 | loss: 0.59907 |  0:01:10s\n",
      "epoch 78 | loss: 0.59608 |  0:01:11s\n",
      "epoch 79 | loss: 0.60089 |  0:01:11s\n",
      "epoch 80 | loss: 0.59772 |  0:01:12s\n",
      "epoch 81 | loss: 0.60713 |  0:01:13s\n",
      "epoch 82 | loss: 0.60954 |  0:01:14s\n",
      "epoch 83 | loss: 0.59914 |  0:01:15s\n",
      "epoch 84 | loss: 0.60483 |  0:01:16s\n",
      "epoch 85 | loss: 0.61224 |  0:01:17s\n",
      "epoch 86 | loss: 0.59694 |  0:01:18s\n",
      "epoch 87 | loss: 0.60381 |  0:01:19s\n",
      "epoch 88 | loss: 0.60673 |  0:01:19s\n",
      "epoch 89 | loss: 0.61341 |  0:01:20s\n",
      "epoch 90 | loss: 0.60264 |  0:01:21s\n",
      "epoch 91 | loss: 0.60758 |  0:01:22s\n",
      "epoch 92 | loss: 0.6092  |  0:01:23s\n",
      "epoch 93 | loss: 0.59927 |  0:01:24s\n",
      "epoch 94 | loss: 0.60042 |  0:01:25s\n",
      "epoch 95 | loss: 0.60117 |  0:01:26s\n",
      "epoch 96 | loss: 0.59401 |  0:01:27s\n",
      "epoch 97 | loss: 0.59577 |  0:01:28s\n",
      "epoch 98 | loss: 0.59829 |  0:01:28s\n",
      "epoch 99 | loss: 0.60028 |  0:01:29s\n",
      "Eval TABNET\n",
      "Accuracy: 0.78\n",
      "Precision: 0.77\n",
      "Recall: 0.82\n",
      "F1-score: 0.79\n",
      "ROC-AUC score: 0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 14:10:11,759]\u001B[0m A new study created in memory with name: no-name-9251d006-9ac1-47e0-a16e-927e167f89d1\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 40 and best_val_0_auc = 0.87806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:11:07,347]\u001B[0m Trial 0 finished with value: 0.8780555555555556 and parameters: {'n_d': 12, 'n_a': 41, 'n_steps': 15, 'gamma': 1.913731751265177, 'n_independent': 6, 'n_shared': 2, 'lambda_sparse': 0.058983342133018354}. Best is trial 0 with value: 0.8780555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.88056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:11:24,163]\u001B[0m Trial 1 finished with value: 0.8805555555555554 and parameters: {'n_d': 31, 'n_a': 36, 'n_steps': 18, 'gamma': 0.6552683644413292, 'n_independent': 5, 'n_shared': 1, 'lambda_sparse': 0.09583284039246369}. Best is trial 1 with value: 0.8805555555555554.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.64333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:12:01,657]\u001B[0m Trial 2 finished with value: 0.6433333333333333 and parameters: {'n_d': 28, 'n_a': 14, 'n_steps': 18, 'gamma': 1.4902877763663258, 'n_independent': 9, 'n_shared': 9, 'lambda_sparse': 0.03700932489694623}. Best is trial 1 with value: 0.8805555555555554.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:12:20,770]\u001B[0m Trial 3 finished with value: 0.8775000000000001 and parameters: {'n_d': 37, 'n_a': 34, 'n_steps': 8, 'gamma': 0.25360058525860124, 'n_independent': 1, 'n_shared': 10, 'lambda_sparse': 0.09422545713657111}. Best is trial 1 with value: 0.8805555555555554.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.89639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:12:58,296]\u001B[0m Trial 4 finished with value: 0.8963888888888889 and parameters: {'n_d': 40, 'n_a': 55, 'n_steps': 13, 'gamma': 0.6593112858560309, 'n_independent': 8, 'n_shared': 1, 'lambda_sparse': 0.0223727789649947}. Best is trial 4 with value: 0.8963888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.88278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:13:41,974]\u001B[0m Trial 5 finished with value: 0.8827777777777778 and parameters: {'n_d': 28, 'n_a': 46, 'n_steps': 11, 'gamma': 0.9315670585078807, 'n_independent': 8, 'n_shared': 2, 'lambda_sparse': 0.09518130966790905}. Best is trial 4 with value: 0.8963888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.79028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:13:54,595]\u001B[0m Trial 6 finished with value: 0.7902777777777777 and parameters: {'n_d': 59, 'n_a': 21, 'n_steps': 6, 'gamma': 1.9680238418850284, 'n_independent': 6, 'n_shared': 4, 'lambda_sparse': 0.04124426526276965}. Best is trial 4 with value: 0.8963888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.7475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:14:34,445]\u001B[0m Trial 7 finished with value: 0.7475 and parameters: {'n_d': 51, 'n_a': 23, 'n_steps': 11, 'gamma': 1.3141810544141999, 'n_independent': 8, 'n_shared': 5, 'lambda_sparse': 0.031563665114998675}. Best is trial 4 with value: 0.8963888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:15:01,981]\u001B[0m Trial 8 finished with value: 0.8524999999999999 and parameters: {'n_d': 59, 'n_a': 60, 'n_steps': 9, 'gamma': 1.9766228525290703, 'n_independent': 5, 'n_shared': 2, 'lambda_sparse': 0.079166028424165}. Best is trial 4 with value: 0.8963888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.84278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:16:07,003]\u001B[0m Trial 9 finished with value: 0.8427777777777777 and parameters: {'n_d': 10, 'n_a': 52, 'n_steps': 18, 'gamma': 0.6620510696144314, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.06664474282563121}. Best is trial 4 with value: 0.8963888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.89889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:16:13,162]\u001B[0m Trial 10 finished with value: 0.8988888888888888 and parameters: {'n_d': 44, 'n_a': 61, 'n_steps': 1, 'gamma': 0.2835398753626088, 'n_independent': 10, 'n_shared': 6, 'lambda_sparse': 0.006662291447218364}. Best is trial 10 with value: 0.8988888888888888.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.91389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:16:28,575]\u001B[0m Trial 11 finished with value: 0.913888888888889 and parameters: {'n_d': 44, 'n_a': 62, 'n_steps': 1, 'gamma': 0.14578432753093976, 'n_independent': 10, 'n_shared': 7, 'lambda_sparse': 0.0053840398433246655}. Best is trial 11 with value: 0.913888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_auc = 0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:16:49,494]\u001B[0m Trial 12 finished with value: 0.9125000000000001 and parameters: {'n_d': 46, 'n_a': 64, 'n_steps': 1, 'gamma': 0.1574227749281731, 'n_independent': 10, 'n_shared': 7, 'lambda_sparse': 0.0003160732843100894}. Best is trial 11 with value: 0.913888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.89917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:17:00,133]\u001B[0m Trial 13 finished with value: 0.8991666666666667 and parameters: {'n_d': 49, 'n_a': 64, 'n_steps': 1, 'gamma': 0.10560741307452644, 'n_independent': 10, 'n_shared': 7, 'lambda_sparse': 0.0021498955901689512}. Best is trial 11 with value: 0.913888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.88028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:17:16,759]\u001B[0m Trial 14 finished with value: 0.8802777777777778 and parameters: {'n_d': 64, 'n_a': 52, 'n_steps': 4, 'gamma': 0.3998707859835764, 'n_independent': 3, 'n_shared': 7, 'lambda_sparse': 0.01572913004414405}. Best is trial 11 with value: 0.913888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.91167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:17:43,642]\u001B[0m Trial 15 finished with value: 0.9116666666666666 and parameters: {'n_d': 49, 'n_a': 46, 'n_steps': 4, 'gamma': 0.43654504405346806, 'n_independent': 10, 'n_shared': 8, 'lambda_sparse': 0.013925502104913702}. Best is trial 11 with value: 0.913888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.90694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:17:57,395]\u001B[0m Trial 16 finished with value: 0.9069444444444444 and parameters: {'n_d': 20, 'n_a': 56, 'n_steps': 3, 'gamma': 0.14138305183875383, 'n_independent': 9, 'n_shared': 4, 'lambda_sparse': 0.00021210578408228237}. Best is trial 11 with value: 0.913888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.91528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:18:40,728]\u001B[0m Trial 17 finished with value: 0.9152777777777777 and parameters: {'n_d': 43, 'n_a': 64, 'n_steps': 6, 'gamma': 0.4729259944736566, 'n_independent': 7, 'n_shared': 8, 'lambda_sparse': 0.02236727466746976}. Best is trial 17 with value: 0.9152777777777777.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.89944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:19:24,672]\u001B[0m Trial 18 finished with value: 0.8994444444444445 and parameters: {'n_d': 34, 'n_a': 47, 'n_steps': 7, 'gamma': 0.4710679413818941, 'n_independent': 7, 'n_shared': 8, 'lambda_sparse': 0.02608890677519754}. Best is trial 17 with value: 0.9152777777777777.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.91944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:20:00,987]\u001B[0m Trial 19 finished with value: 0.9194444444444444 and parameters: {'n_d': 21, 'n_a': 31, 'n_steps': 6, 'gamma': 0.9129639801326506, 'n_independent': 4, 'n_shared': 9, 'lambda_sparse': 0.01442445640341393}. Best is trial 19 with value: 0.9194444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 41 and best_val_0_auc = 0.90194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:20:33,144]\u001B[0m Trial 20 finished with value: 0.9019444444444444 and parameters: {'n_d': 20, 'n_a': 28, 'n_steps': 6, 'gamma': 0.8674058403448949, 'n_independent': 3, 'n_shared': 9, 'lambda_sparse': 0.04384442822234829}. Best is trial 19 with value: 0.9194444444444444.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.08831 |  0:00:00s\n",
      "epoch 1  | loss: 0.88216 |  0:00:01s\n",
      "epoch 2  | loss: 0.80618 |  0:00:01s\n",
      "epoch 3  | loss: 0.77942 |  0:00:02s\n",
      "epoch 4  | loss: 0.73622 |  0:00:03s\n",
      "epoch 5  | loss: 0.73597 |  0:00:03s\n",
      "epoch 6  | loss: 0.75639 |  0:00:04s\n",
      "epoch 7  | loss: 0.72589 |  0:00:05s\n",
      "epoch 8  | loss: 0.71696 |  0:00:05s\n",
      "epoch 9  | loss: 0.71671 |  0:00:06s\n",
      "epoch 10 | loss: 0.69873 |  0:00:07s\n",
      "epoch 11 | loss: 0.67826 |  0:00:07s\n",
      "epoch 12 | loss: 0.67046 |  0:00:08s\n",
      "epoch 13 | loss: 0.65459 |  0:00:09s\n",
      "epoch 14 | loss: 0.64415 |  0:00:09s\n",
      "epoch 15 | loss: 0.63495 |  0:00:10s\n",
      "epoch 16 | loss: 0.63463 |  0:00:11s\n",
      "epoch 17 | loss: 0.63421 |  0:00:12s\n",
      "epoch 18 | loss: 0.64578 |  0:00:12s\n",
      "epoch 19 | loss: 0.62844 |  0:00:13s\n",
      "epoch 20 | loss: 0.6353  |  0:00:14s\n",
      "epoch 21 | loss: 0.62346 |  0:00:14s\n",
      "epoch 22 | loss: 0.6277  |  0:00:15s\n",
      "epoch 23 | loss: 0.61779 |  0:00:16s\n",
      "epoch 24 | loss: 0.61499 |  0:00:17s\n",
      "epoch 25 | loss: 0.61124 |  0:00:17s\n",
      "epoch 26 | loss: 0.59933 |  0:00:18s\n",
      "epoch 27 | loss: 0.60942 |  0:00:19s\n",
      "epoch 28 | loss: 0.6099  |  0:00:19s\n",
      "epoch 29 | loss: 0.60765 |  0:00:20s\n",
      "epoch 30 | loss: 0.60246 |  0:00:21s\n",
      "epoch 31 | loss: 0.60176 |  0:00:22s\n",
      "epoch 32 | loss: 0.60208 |  0:00:22s\n",
      "epoch 33 | loss: 0.59795 |  0:00:23s\n",
      "epoch 34 | loss: 0.59222 |  0:00:24s\n",
      "epoch 35 | loss: 0.59581 |  0:00:24s\n",
      "epoch 36 | loss: 0.6077  |  0:00:25s\n",
      "epoch 37 | loss: 0.60599 |  0:00:26s\n",
      "epoch 38 | loss: 0.59905 |  0:00:26s\n",
      "epoch 39 | loss: 0.59677 |  0:00:27s\n",
      "epoch 40 | loss: 0.59295 |  0:00:28s\n",
      "epoch 41 | loss: 0.59826 |  0:00:29s\n",
      "epoch 42 | loss: 0.59496 |  0:00:29s\n",
      "epoch 43 | loss: 0.59305 |  0:00:30s\n",
      "epoch 44 | loss: 0.59485 |  0:00:31s\n",
      "epoch 45 | loss: 0.59579 |  0:00:31s\n",
      "epoch 46 | loss: 0.59561 |  0:00:32s\n",
      "epoch 47 | loss: 0.60084 |  0:00:33s\n",
      "epoch 48 | loss: 0.59223 |  0:00:34s\n",
      "epoch 49 | loss: 0.58434 |  0:00:34s\n",
      "epoch 50 | loss: 0.59336 |  0:00:35s\n",
      "epoch 51 | loss: 0.5966  |  0:00:36s\n",
      "epoch 52 | loss: 0.59082 |  0:00:36s\n",
      "epoch 53 | loss: 0.59781 |  0:00:37s\n",
      "epoch 54 | loss: 0.58959 |  0:00:38s\n",
      "epoch 55 | loss: 0.58646 |  0:00:38s\n",
      "epoch 56 | loss: 0.58635 |  0:00:39s\n",
      "epoch 57 | loss: 0.58846 |  0:00:40s\n",
      "epoch 58 | loss: 0.5903  |  0:00:41s\n",
      "epoch 59 | loss: 0.57854 |  0:00:41s\n",
      "epoch 60 | loss: 0.5816  |  0:00:42s\n",
      "epoch 61 | loss: 0.58908 |  0:00:43s\n",
      "epoch 62 | loss: 0.5885  |  0:00:43s\n",
      "epoch 63 | loss: 0.5771  |  0:00:44s\n",
      "epoch 64 | loss: 0.58455 |  0:00:45s\n",
      "epoch 65 | loss: 0.58287 |  0:00:45s\n",
      "epoch 66 | loss: 0.58483 |  0:00:46s\n",
      "epoch 67 | loss: 0.58496 |  0:00:47s\n",
      "epoch 68 | loss: 0.58129 |  0:00:48s\n",
      "epoch 69 | loss: 0.57773 |  0:00:48s\n",
      "epoch 70 | loss: 0.58919 |  0:00:49s\n",
      "epoch 71 | loss: 0.58056 |  0:00:50s\n",
      "epoch 72 | loss: 0.58166 |  0:00:50s\n",
      "epoch 73 | loss: 0.58056 |  0:00:51s\n",
      "epoch 74 | loss: 0.58544 |  0:00:52s\n",
      "epoch 75 | loss: 0.58096 |  0:00:53s\n",
      "epoch 76 | loss: 0.58893 |  0:00:53s\n",
      "epoch 77 | loss: 0.58408 |  0:00:54s\n",
      "epoch 78 | loss: 0.58333 |  0:00:55s\n",
      "epoch 79 | loss: 0.5781  |  0:00:55s\n",
      "epoch 80 | loss: 0.58856 |  0:00:56s\n",
      "epoch 81 | loss: 0.58054 |  0:00:57s\n",
      "epoch 82 | loss: 0.57398 |  0:00:57s\n",
      "epoch 83 | loss: 0.58231 |  0:00:58s\n",
      "epoch 84 | loss: 0.5887  |  0:00:59s\n",
      "epoch 85 | loss: 0.58806 |  0:01:00s\n",
      "epoch 86 | loss: 0.57965 |  0:01:00s\n",
      "epoch 87 | loss: 0.58767 |  0:01:01s\n",
      "epoch 88 | loss: 0.57722 |  0:01:02s\n",
      "epoch 89 | loss: 0.58153 |  0:01:02s\n",
      "epoch 90 | loss: 0.57668 |  0:01:03s\n",
      "epoch 91 | loss: 0.58551 |  0:01:04s\n",
      "epoch 92 | loss: 0.58119 |  0:01:05s\n",
      "epoch 93 | loss: 0.58359 |  0:01:05s\n",
      "epoch 94 | loss: 0.59166 |  0:01:06s\n",
      "epoch 95 | loss: 0.5813  |  0:01:07s\n",
      "epoch 96 | loss: 0.58763 |  0:01:07s\n",
      "epoch 97 | loss: 0.58997 |  0:01:08s\n",
      "epoch 98 | loss: 0.58201 |  0:01:09s\n",
      "epoch 99 | loss: 0.58587 |  0:01:10s\n",
      "Eval TABNET\n",
      "Accuracy: 0.85\n",
      "Precision: 0.84\n",
      "Recall: 0.87\n",
      "F1-score: 0.85\n",
      "ROC-AUC score: 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 14:21:43,808]\u001B[0m A new study created in memory with name: no-name-71b87b26-203f-4ccd-bb6c-17d747d8869d\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.55653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:22:28,955]\u001B[0m Trial 0 finished with value: 0.5565277777777778 and parameters: {'n_d': 43, 'n_a': 10, 'n_steps': 14, 'gamma': 1.5479760322434937, 'n_independent': 9, 'n_shared': 8, 'lambda_sparse': 0.08301559636143996}. Best is trial 0 with value: 0.5565277777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.58861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:22:52,904]\u001B[0m Trial 1 finished with value: 0.5886111111111111 and parameters: {'n_d': 59, 'n_a': 58, 'n_steps': 10, 'gamma': 1.6989059282498395, 'n_independent': 6, 'n_shared': 4, 'lambda_sparse': 0.07614297280180539}. Best is trial 1 with value: 0.5886111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.62278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:23:06,913]\u001B[0m Trial 2 finished with value: 0.6227777777777778 and parameters: {'n_d': 60, 'n_a': 38, 'n_steps': 8, 'gamma': 1.141164307004235, 'n_independent': 2, 'n_shared': 6, 'lambda_sparse': 0.012629810464368755}. Best is trial 2 with value: 0.6227777777777778.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:23:08,427]\u001B[0m Trial 3 finished with value: 0.5588888888888889 and parameters: {'n_d': 30, 'n_a': 48, 'n_steps': 1, 'gamma': 0.4723068485191164, 'n_independent': 1, 'n_shared': 5, 'lambda_sparse': 0.08018281458341567}. Best is trial 2 with value: 0.6227777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.55889\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.59194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:23:22,456]\u001B[0m Trial 4 finished with value: 0.5919444444444445 and parameters: {'n_d': 50, 'n_a': 61, 'n_steps': 7, 'gamma': 0.9271710668640625, 'n_independent': 1, 'n_shared': 8, 'lambda_sparse': 0.0007937005827661957}. Best is trial 2 with value: 0.6227777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.59611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:23:51,127]\u001B[0m Trial 5 finished with value: 0.596111111111111 and parameters: {'n_d': 39, 'n_a': 38, 'n_steps': 19, 'gamma': 1.457618972037831, 'n_independent': 6, 'n_shared': 2, 'lambda_sparse': 0.03062396871462813}. Best is trial 2 with value: 0.6227777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.55083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:23:59,912]\u001B[0m Trial 6 finished with value: 0.5508333333333334 and parameters: {'n_d': 14, 'n_a': 23, 'n_steps': 4, 'gamma': 0.84639470214656, 'n_independent': 5, 'n_shared': 8, 'lambda_sparse': 0.08556448691133388}. Best is trial 2 with value: 0.6227777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.55056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:24:05,858]\u001B[0m Trial 7 finished with value: 0.5505555555555556 and parameters: {'n_d': 8, 'n_a': 36, 'n_steps': 5, 'gamma': 1.273479022523896, 'n_independent': 3, 'n_shared': 4, 'lambda_sparse': 0.024284061400746775}. Best is trial 2 with value: 0.6227777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.48083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:24:30,033]\u001B[0m Trial 8 finished with value: 0.48083333333333333 and parameters: {'n_d': 17, 'n_a': 54, 'n_steps': 18, 'gamma': 0.2713234024671485, 'n_independent': 5, 'n_shared': 5, 'lambda_sparse': 0.07726368587492019}. Best is trial 2 with value: 0.6227777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.57417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:24:42,934]\u001B[0m Trial 9 finished with value: 0.5741666666666667 and parameters: {'n_d': 31, 'n_a': 56, 'n_steps': 7, 'gamma': 1.1842338786809463, 'n_independent': 3, 'n_shared': 6, 'lambda_sparse': 0.05821575065945252}. Best is trial 2 with value: 0.6227777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.65389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:26:54,111]\u001B[0m Trial 10 finished with value: 0.653888888888889 and parameters: {'n_d': 64, 'n_a': 30, 'n_steps': 13, 'gamma': 1.9947292473768574, 'n_independent': 9, 'n_shared': 10, 'lambda_sparse': 0.00022151987265479553}. Best is trial 10 with value: 0.653888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.60083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:28:10,033]\u001B[0m Trial 11 finished with value: 0.6008333333333333 and parameters: {'n_d': 64, 'n_a': 31, 'n_steps': 14, 'gamma': 1.9709643212343813, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.0020372260754438778}. Best is trial 10 with value: 0.653888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.6525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:29:05,227]\u001B[0m Trial 12 finished with value: 0.6525 and parameters: {'n_d': 54, 'n_a': 23, 'n_steps': 12, 'gamma': 1.998572419915002, 'n_independent': 8, 'n_shared': 10, 'lambda_sparse': 0.013399899541367891}. Best is trial 10 with value: 0.653888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.59694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:29:40,712]\u001B[0m Trial 13 finished with value: 0.5969444444444444 and parameters: {'n_d': 52, 'n_a': 20, 'n_steps': 14, 'gamma': 1.9931016236099424, 'n_independent': 8, 'n_shared': 10, 'lambda_sparse': 0.02934799540541746}. Best is trial 10 with value: 0.653888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.59042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:30:18,326]\u001B[0m Trial 14 finished with value: 0.5904166666666667 and parameters: {'n_d': 51, 'n_a': 21, 'n_steps': 12, 'gamma': 1.7960292122926407, 'n_independent': 8, 'n_shared': 10, 'lambda_sparse': 0.015538433475584342}. Best is trial 10 with value: 0.653888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.59444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:31:33,429]\u001B[0m Trial 15 finished with value: 0.5944444444444444 and parameters: {'n_d': 56, 'n_a': 12, 'n_steps': 16, 'gamma': 1.7596144033390524, 'n_independent': 8, 'n_shared': 9, 'lambda_sparse': 0.04026063606110524}. Best is trial 10 with value: 0.653888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.62972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:32:25,022]\u001B[0m Trial 16 finished with value: 0.6297222222222222 and parameters: {'n_d': 46, 'n_a': 27, 'n_steps': 11, 'gamma': 1.9983833872276793, 'n_independent': 10, 'n_shared': 7, 'lambda_sparse': 0.010337659801256227}. Best is trial 10 with value: 0.653888888888889.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.93469 |  0:00:03s\n",
      "epoch 1  | loss: 3.11446 |  0:00:06s\n",
      "epoch 2  | loss: 3.00209 |  0:00:09s\n",
      "epoch 3  | loss: 2.94936 |  0:00:12s\n",
      "epoch 4  | loss: 2.30956 |  0:00:15s\n",
      "epoch 5  | loss: 1.97622 |  0:00:18s\n",
      "epoch 6  | loss: 1.88738 |  0:00:21s\n",
      "epoch 7  | loss: 1.41527 |  0:00:24s\n",
      "epoch 8  | loss: 2.90325 |  0:00:27s\n",
      "epoch 9  | loss: 1.66813 |  0:00:30s\n",
      "epoch 10 | loss: 1.35781 |  0:00:33s\n",
      "epoch 11 | loss: 1.4807  |  0:00:36s\n",
      "epoch 12 | loss: 1.30166 |  0:00:39s\n",
      "epoch 13 | loss: 1.20674 |  0:00:42s\n",
      "epoch 14 | loss: 1.3806  |  0:00:45s\n",
      "epoch 15 | loss: 2.47021 |  0:00:48s\n",
      "epoch 16 | loss: 1.46392 |  0:00:51s\n",
      "epoch 17 | loss: 1.23653 |  0:00:54s\n",
      "epoch 18 | loss: 1.12711 |  0:00:57s\n",
      "epoch 19 | loss: 1.09677 |  0:01:00s\n",
      "epoch 20 | loss: 1.08498 |  0:01:03s\n",
      "epoch 21 | loss: 1.3472  |  0:01:06s\n",
      "epoch 22 | loss: 1.16447 |  0:01:09s\n",
      "epoch 23 | loss: 0.85634 |  0:01:13s\n",
      "epoch 24 | loss: 0.81579 |  0:01:16s\n",
      "epoch 25 | loss: 0.92999 |  0:01:19s\n",
      "epoch 26 | loss: 1.05472 |  0:01:22s\n",
      "epoch 27 | loss: 0.88533 |  0:01:25s\n",
      "epoch 28 | loss: 0.97734 |  0:01:28s\n",
      "epoch 29 | loss: 1.12814 |  0:01:31s\n",
      "epoch 30 | loss: 1.26371 |  0:01:34s\n",
      "epoch 31 | loss: 0.92123 |  0:01:37s\n",
      "epoch 32 | loss: 0.8022  |  0:01:40s\n",
      "epoch 33 | loss: 0.76733 |  0:01:43s\n",
      "epoch 34 | loss: 0.68632 |  0:01:46s\n",
      "epoch 35 | loss: 0.71389 |  0:01:50s\n",
      "epoch 36 | loss: 0.66872 |  0:01:52s\n",
      "epoch 37 | loss: 0.68003 |  0:01:56s\n",
      "epoch 38 | loss: 0.72015 |  0:01:59s\n",
      "epoch 39 | loss: 0.66875 |  0:02:02s\n",
      "epoch 40 | loss: 0.64709 |  0:02:05s\n",
      "epoch 41 | loss: 0.64084 |  0:02:08s\n",
      "epoch 42 | loss: 0.651   |  0:02:11s\n",
      "epoch 43 | loss: 0.62395 |  0:02:14s\n",
      "epoch 44 | loss: 0.62021 |  0:02:17s\n",
      "epoch 45 | loss: 0.62464 |  0:02:20s\n",
      "epoch 46 | loss: 0.63688 |  0:02:23s\n",
      "epoch 47 | loss: 0.63301 |  0:02:26s\n",
      "epoch 48 | loss: 0.67259 |  0:02:29s\n",
      "epoch 49 | loss: 0.6356  |  0:02:33s\n",
      "epoch 50 | loss: 0.6175  |  0:02:36s\n",
      "epoch 51 | loss: 0.62722 |  0:02:39s\n",
      "epoch 52 | loss: 0.62758 |  0:02:42s\n",
      "epoch 53 | loss: 0.6246  |  0:02:45s\n",
      "epoch 54 | loss: 0.64662 |  0:02:48s\n",
      "epoch 55 | loss: 0.63368 |  0:02:51s\n",
      "epoch 56 | loss: 0.62896 |  0:02:54s\n",
      "epoch 57 | loss: 0.62074 |  0:02:57s\n",
      "epoch 58 | loss: 0.62619 |  0:03:00s\n",
      "epoch 59 | loss: 0.63244 |  0:03:03s\n",
      "epoch 60 | loss: 0.63204 |  0:03:06s\n",
      "epoch 61 | loss: 0.62063 |  0:03:09s\n",
      "epoch 62 | loss: 0.62704 |  0:03:12s\n",
      "epoch 63 | loss: 0.67466 |  0:03:15s\n",
      "epoch 64 | loss: 0.65776 |  0:03:18s\n",
      "epoch 65 | loss: 0.62689 |  0:03:21s\n",
      "epoch 66 | loss: 0.62565 |  0:03:24s\n",
      "epoch 67 | loss: 0.6203  |  0:03:27s\n",
      "epoch 68 | loss: 0.617   |  0:03:31s\n",
      "epoch 69 | loss: 0.61328 |  0:03:34s\n",
      "epoch 70 | loss: 0.61535 |  0:03:37s\n",
      "epoch 71 | loss: 0.62151 |  0:03:40s\n",
      "epoch 72 | loss: 0.62195 |  0:03:43s\n",
      "epoch 73 | loss: 0.61546 |  0:03:46s\n",
      "epoch 74 | loss: 0.60503 |  0:03:49s\n",
      "epoch 75 | loss: 0.61047 |  0:03:52s\n",
      "epoch 76 | loss: 0.61138 |  0:03:55s\n",
      "epoch 77 | loss: 0.60878 |  0:03:58s\n",
      "epoch 78 | loss: 0.61317 |  0:04:01s\n",
      "epoch 79 | loss: 0.62635 |  0:04:04s\n",
      "epoch 80 | loss: 0.65563 |  0:04:07s\n",
      "epoch 81 | loss: 0.63831 |  0:04:10s\n",
      "epoch 82 | loss: 0.61591 |  0:04:13s\n",
      "epoch 83 | loss: 0.63637 |  0:04:16s\n",
      "epoch 84 | loss: 0.61    |  0:04:20s\n",
      "epoch 85 | loss: 0.63238 |  0:04:23s\n",
      "epoch 86 | loss: 0.62814 |  0:04:26s\n",
      "epoch 87 | loss: 0.62486 |  0:04:29s\n",
      "epoch 88 | loss: 0.62827 |  0:04:32s\n",
      "epoch 89 | loss: 0.61371 |  0:04:35s\n",
      "epoch 90 | loss: 0.62159 |  0:04:38s\n",
      "epoch 91 | loss: 0.62244 |  0:04:41s\n",
      "epoch 92 | loss: 0.60811 |  0:04:44s\n",
      "epoch 93 | loss: 0.61627 |  0:04:47s\n",
      "epoch 94 | loss: 0.6134  |  0:04:50s\n",
      "epoch 95 | loss: 0.61259 |  0:04:53s\n",
      "epoch 96 | loss: 0.62149 |  0:04:56s\n",
      "epoch 97 | loss: 0.61603 |  0:05:00s\n",
      "epoch 98 | loss: 0.61604 |  0:05:03s\n",
      "epoch 99 | loss: 0.61493 |  0:05:06s\n",
      "Eval TABNET\n",
      "Accuracy: 0.48\n",
      "Precision: 0.49\n",
      "Recall: 0.55\n",
      "F1-score: 0.52\n",
      "ROC-AUC score: 0.48\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 14:37:33,402]\u001B[0m A new study created in memory with name: no-name-16046d9e-4d15-4588-9947-cce44e346077\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:37:36,721]\u001B[0m Trial 0 finished with value: 0.6008333333333333 and parameters: {'n_d': 54, 'n_a': 12, 'n_steps': 4, 'gamma': 1.6820155427449082, 'n_independent': 1, 'n_shared': 5, 'lambda_sparse': 0.060481401895069516}. Best is trial 0 with value: 0.6008333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.60083\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.65222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:38:05,571]\u001B[0m Trial 1 finished with value: 0.6522222222222221 and parameters: {'n_d': 56, 'n_a': 28, 'n_steps': 15, 'gamma': 0.849929243735286, 'n_independent': 6, 'n_shared': 6, 'lambda_sparse': 0.09473247210679847}. Best is trial 1 with value: 0.6522222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.63944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:38:56,735]\u001B[0m Trial 2 finished with value: 0.6394444444444445 and parameters: {'n_d': 30, 'n_a': 42, 'n_steps': 18, 'gamma': 0.6640367607138176, 'n_independent': 8, 'n_shared': 5, 'lambda_sparse': 0.003849654194343867}. Best is trial 1 with value: 0.6522222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.62889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:40:21,094]\u001B[0m Trial 3 finished with value: 0.6288888888888888 and parameters: {'n_d': 13, 'n_a': 40, 'n_steps': 13, 'gamma': 0.14870413380098207, 'n_independent': 8, 'n_shared': 7, 'lambda_sparse': 0.07124813456281827}. Best is trial 1 with value: 0.6522222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.59444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:40:59,450]\u001B[0m Trial 4 finished with value: 0.5944444444444443 and parameters: {'n_d': 33, 'n_a': 34, 'n_steps': 12, 'gamma': 1.1865639721329164, 'n_independent': 8, 'n_shared': 2, 'lambda_sparse': 0.01631136924401604}. Best is trial 1 with value: 0.6522222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.62917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:41:28,134]\u001B[0m Trial 5 finished with value: 0.6291666666666667 and parameters: {'n_d': 23, 'n_a': 30, 'n_steps': 9, 'gamma': 1.0434771241212926, 'n_independent': 10, 'n_shared': 5, 'lambda_sparse': 0.08309352722986939}. Best is trial 1 with value: 0.6522222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.56556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:41:33,125]\u001B[0m Trial 6 finished with value: 0.5655555555555556 and parameters: {'n_d': 23, 'n_a': 18, 'n_steps': 18, 'gamma': 0.9679997111136373, 'n_independent': 1, 'n_shared': 1, 'lambda_sparse': 0.04935054638162432}. Best is trial 1 with value: 0.6522222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.63667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:42:20,098]\u001B[0m Trial 7 finished with value: 0.6366666666666667 and parameters: {'n_d': 62, 'n_a': 34, 'n_steps': 19, 'gamma': 0.5724846496754433, 'n_independent': 7, 'n_shared': 1, 'lambda_sparse': 0.03822529278878295}. Best is trial 1 with value: 0.6522222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.63861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:42:36,475]\u001B[0m Trial 8 finished with value: 0.638611111111111 and parameters: {'n_d': 15, 'n_a': 22, 'n_steps': 9, 'gamma': 1.4200925497339183, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.002947063620340308}. Best is trial 1 with value: 0.6522222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.66722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:43:01,981]\u001B[0m Trial 9 finished with value: 0.6672222222222223 and parameters: {'n_d': 46, 'n_a': 33, 'n_steps': 17, 'gamma': 0.6416852519011474, 'n_independent': 5, 'n_shared': 4, 'lambda_sparse': 0.0709879321632246}. Best is trial 9 with value: 0.6672222222222223.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:43:05,598]\u001B[0m Trial 10 finished with value: 0.55125 and parameters: {'n_d': 44, 'n_a': 53, 'n_steps': 1, 'gamma': 1.9407498940494405, 'n_independent': 4, 'n_shared': 10, 'lambda_sparse': 0.09551465682835152}. Best is trial 9 with value: 0.6672222222222223.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.55125\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.60417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:44:16,359]\u001B[0m Trial 11 finished with value: 0.6041666666666666 and parameters: {'n_d': 47, 'n_a': 62, 'n_steps': 15, 'gamma': 0.5791130639499458, 'n_independent': 4, 'n_shared': 8, 'lambda_sparse': 0.09771567842045562}. Best is trial 9 with value: 0.6672222222222223.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.55028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:44:49,810]\u001B[0m Trial 12 finished with value: 0.5502777777777778 and parameters: {'n_d': 64, 'n_a': 24, 'n_steps': 15, 'gamma': 0.8239297582030809, 'n_independent': 5, 'n_shared': 3, 'lambda_sparse': 0.07783300009836955}. Best is trial 9 with value: 0.6672222222222223.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.61667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:45:04,924]\u001B[0m Trial 13 finished with value: 0.6166666666666667 and parameters: {'n_d': 44, 'n_a': 48, 'n_steps': 15, 'gamma': 0.3623894438163088, 'n_independent': 3, 'n_shared': 3, 'lambda_sparse': 0.08664412642855279}. Best is trial 9 with value: 0.6672222222222223.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.58958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:45:21,064]\u001B[0m Trial 14 finished with value: 0.5895833333333333 and parameters: {'n_d': 54, 'n_a': 28, 'n_steps': 6, 'gamma': 0.8367834855036145, 'n_independent': 6, 'n_shared': 8, 'lambda_sparse': 0.07220602250594763}. Best is trial 9 with value: 0.6672222222222223.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.62639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:45:33,223]\u001B[0m Trial 15 finished with value: 0.6263888888888889 and parameters: {'n_d': 52, 'n_a': 9, 'n_steps': 12, 'gamma': 1.1618136011841467, 'n_independent': 3, 'n_shared': 4, 'lambda_sparse': 0.09949978967933029}. Best is trial 9 with value: 0.6672222222222223.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.57194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:46:23,155]\u001B[0m Trial 16 finished with value: 0.5719444444444445 and parameters: {'n_d': 37, 'n_a': 43, 'n_steps': 16, 'gamma': 0.33061978027042493, 'n_independent': 10, 'n_shared': 7, 'lambda_sparse': 0.06279009424412484}. Best is trial 9 with value: 0.6672222222222223.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.59583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:47:42,078]\u001B[0m Trial 17 finished with value: 0.5958333333333333 and parameters: {'n_d': 58, 'n_a': 16, 'n_steps': 17, 'gamma': 0.746773157995055, 'n_independent': 5, 'n_shared': 10, 'lambda_sparse': 0.08441287739634452}. Best is trial 9 with value: 0.6672222222222223.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.09346 |  0:00:01s\n",
      "epoch 1  | loss: 2.1907  |  0:00:03s\n",
      "epoch 2  | loss: 1.86605 |  0:00:05s\n",
      "epoch 3  | loss: 1.18164 |  0:00:06s\n",
      "epoch 4  | loss: 1.59999 |  0:00:08s\n",
      "epoch 5  | loss: 2.67612 |  0:00:10s\n",
      "epoch 6  | loss: 1.32266 |  0:00:11s\n",
      "epoch 7  | loss: 1.50316 |  0:00:13s\n",
      "epoch 8  | loss: 1.14627 |  0:00:15s\n",
      "epoch 9  | loss: 1.03459 |  0:00:16s\n",
      "epoch 10 | loss: 0.89922 |  0:00:18s\n",
      "epoch 11 | loss: 0.85748 |  0:00:20s\n",
      "epoch 12 | loss: 0.96902 |  0:00:21s\n",
      "epoch 13 | loss: 0.87912 |  0:00:23s\n",
      "epoch 14 | loss: 0.84753 |  0:00:25s\n",
      "epoch 15 | loss: 0.79454 |  0:00:26s\n",
      "epoch 16 | loss: 0.76695 |  0:00:28s\n",
      "epoch 17 | loss: 0.76952 |  0:00:30s\n",
      "epoch 18 | loss: 0.76565 |  0:00:31s\n",
      "epoch 19 | loss: 0.73401 |  0:00:33s\n",
      "epoch 20 | loss: 0.72292 |  0:00:35s\n",
      "epoch 21 | loss: 0.72335 |  0:00:36s\n",
      "epoch 22 | loss: 0.71526 |  0:00:38s\n",
      "epoch 23 | loss: 0.70722 |  0:00:40s\n",
      "epoch 24 | loss: 0.70611 |  0:00:41s\n",
      "epoch 25 | loss: 0.69755 |  0:00:43s\n",
      "epoch 26 | loss: 0.69182 |  0:00:44s\n",
      "epoch 27 | loss: 0.69706 |  0:00:46s\n",
      "epoch 28 | loss: 0.68315 |  0:00:48s\n",
      "epoch 29 | loss: 0.67675 |  0:00:49s\n",
      "epoch 30 | loss: 0.67689 |  0:00:51s\n",
      "epoch 31 | loss: 0.68604 |  0:00:53s\n",
      "epoch 32 | loss: 0.67488 |  0:00:54s\n",
      "epoch 33 | loss: 0.67263 |  0:00:56s\n",
      "epoch 34 | loss: 0.66477 |  0:00:58s\n",
      "epoch 35 | loss: 0.66674 |  0:01:00s\n",
      "epoch 36 | loss: 0.66465 |  0:01:01s\n",
      "epoch 37 | loss: 0.64515 |  0:01:03s\n",
      "epoch 38 | loss: 0.63833 |  0:01:05s\n",
      "epoch 39 | loss: 0.62184 |  0:01:06s\n",
      "epoch 40 | loss: 0.61033 |  0:01:08s\n",
      "epoch 41 | loss: 0.60534 |  0:01:10s\n",
      "epoch 42 | loss: 0.60122 |  0:01:12s\n",
      "epoch 43 | loss: 0.58467 |  0:01:13s\n",
      "epoch 44 | loss: 0.58477 |  0:01:15s\n",
      "epoch 45 | loss: 0.55003 |  0:01:17s\n",
      "epoch 46 | loss: 0.55598 |  0:01:18s\n",
      "epoch 47 | loss: 0.56236 |  0:01:20s\n",
      "epoch 48 | loss: 0.54598 |  0:01:22s\n",
      "epoch 49 | loss: 0.5392  |  0:01:23s\n",
      "epoch 50 | loss: 0.53493 |  0:01:25s\n",
      "epoch 51 | loss: 0.53353 |  0:01:27s\n",
      "epoch 52 | loss: 0.51498 |  0:01:28s\n",
      "epoch 53 | loss: 0.50409 |  0:01:30s\n",
      "epoch 54 | loss: 0.50501 |  0:01:32s\n",
      "epoch 55 | loss: 0.50269 |  0:01:33s\n",
      "epoch 56 | loss: 0.49147 |  0:01:35s\n",
      "epoch 57 | loss: 0.48931 |  0:01:37s\n",
      "epoch 58 | loss: 0.49336 |  0:01:39s\n",
      "epoch 59 | loss: 0.45962 |  0:01:40s\n",
      "epoch 60 | loss: 0.47022 |  0:01:42s\n",
      "epoch 61 | loss: 0.44713 |  0:01:44s\n",
      "epoch 62 | loss: 0.43484 |  0:01:45s\n",
      "epoch 63 | loss: 0.45528 |  0:01:47s\n",
      "epoch 64 | loss: 0.4359  |  0:01:49s\n",
      "epoch 65 | loss: 0.43549 |  0:01:50s\n",
      "epoch 66 | loss: 0.41733 |  0:01:52s\n",
      "epoch 67 | loss: 0.42289 |  0:01:54s\n",
      "epoch 68 | loss: 0.42507 |  0:01:56s\n",
      "epoch 69 | loss: 0.41242 |  0:01:57s\n",
      "epoch 70 | loss: 0.39016 |  0:01:59s\n",
      "epoch 71 | loss: 0.39387 |  0:02:01s\n",
      "epoch 72 | loss: 0.3782  |  0:02:02s\n",
      "epoch 73 | loss: 0.37879 |  0:02:04s\n",
      "epoch 74 | loss: 0.38184 |  0:02:06s\n",
      "epoch 75 | loss: 0.41484 |  0:02:07s\n",
      "epoch 76 | loss: 0.40139 |  0:02:09s\n",
      "epoch 77 | loss: 0.41324 |  0:02:11s\n",
      "epoch 78 | loss: 0.39259 |  0:02:13s\n",
      "epoch 79 | loss: 0.39203 |  0:02:14s\n",
      "epoch 80 | loss: 0.4041  |  0:02:16s\n",
      "epoch 81 | loss: 0.39541 |  0:02:18s\n",
      "epoch 82 | loss: 0.36477 |  0:02:19s\n",
      "epoch 83 | loss: 0.33564 |  0:02:21s\n",
      "epoch 84 | loss: 0.33801 |  0:02:23s\n",
      "epoch 85 | loss: 0.34441 |  0:02:25s\n",
      "epoch 86 | loss: 0.3304  |  0:02:26s\n",
      "epoch 87 | loss: 0.30957 |  0:02:28s\n",
      "epoch 88 | loss: 0.33262 |  0:02:30s\n",
      "epoch 89 | loss: 0.30974 |  0:02:31s\n",
      "epoch 90 | loss: 0.30844 |  0:02:33s\n",
      "epoch 91 | loss: 0.29939 |  0:02:35s\n",
      "epoch 92 | loss: 0.28573 |  0:02:37s\n",
      "epoch 93 | loss: 0.29713 |  0:02:38s\n",
      "epoch 94 | loss: 0.28605 |  0:02:40s\n",
      "epoch 95 | loss: 0.29603 |  0:02:42s\n",
      "epoch 96 | loss: 0.28063 |  0:02:43s\n",
      "epoch 97 | loss: 0.28289 |  0:02:45s\n",
      "epoch 98 | loss: 0.28555 |  0:02:47s\n",
      "epoch 99 | loss: 0.27128 |  0:02:48s\n",
      "Eval TABNET\n",
      "Accuracy: 0.53\n",
      "Precision: 0.53\n",
      "Recall: 0.53\n",
      "F1-score: 0.53\n",
      "ROC-AUC score: 0.53\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 14:50:32,261]\u001B[0m A new study created in memory with name: no-name-b4721241-35c3-45ac-8b8c-a6b75669ea6f\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.75542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:50:51,625]\u001B[0m Trial 0 finished with value: 0.7554166666666666 and parameters: {'n_d': 33, 'n_a': 60, 'n_steps': 18, 'gamma': 1.9588982966172743, 'n_independent': 5, 'n_shared': 1, 'lambda_sparse': 0.05196554969043064}. Best is trial 0 with value: 0.7554166666666666.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.77389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:52:29,719]\u001B[0m Trial 1 finished with value: 0.773888888888889 and parameters: {'n_d': 30, 'n_a': 39, 'n_steps': 16, 'gamma': 1.166620400554982, 'n_independent': 6, 'n_shared': 6, 'lambda_sparse': 0.05807439484824125}. Best is trial 1 with value: 0.773888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.76306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:52:42,640]\u001B[0m Trial 2 finished with value: 0.7630555555555556 and parameters: {'n_d': 9, 'n_a': 50, 'n_steps': 4, 'gamma': 0.7960808910403991, 'n_independent': 6, 'n_shared': 9, 'lambda_sparse': 0.08245319698321826}. Best is trial 1 with value: 0.773888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.79944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:53:02,864]\u001B[0m Trial 3 finished with value: 0.7994444444444445 and parameters: {'n_d': 58, 'n_a': 55, 'n_steps': 11, 'gamma': 0.4918787779918582, 'n_independent': 2, 'n_shared': 6, 'lambda_sparse': 0.07788595433136783}. Best is trial 3 with value: 0.7994444444444445.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:53:05,079]\u001B[0m Trial 4 finished with value: 0.7858333333333333 and parameters: {'n_d': 47, 'n_a': 58, 'n_steps': 2, 'gamma': 1.6992350032041468, 'n_independent': 4, 'n_shared': 1, 'lambda_sparse': 0.007947109816980701}. Best is trial 3 with value: 0.7994444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.78583\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.77056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:53:50,220]\u001B[0m Trial 5 finished with value: 0.7705555555555557 and parameters: {'n_d': 34, 'n_a': 40, 'n_steps': 5, 'gamma': 1.9929462583136563, 'n_independent': 10, 'n_shared': 9, 'lambda_sparse': 0.055919908407282594}. Best is trial 3 with value: 0.7994444444444445.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:53:55,634]\u001B[0m Trial 6 finished with value: 0.7438888888888888 and parameters: {'n_d': 44, 'n_a': 29, 'n_steps': 2, 'gamma': 0.8313543313171985, 'n_independent': 1, 'n_shared': 7, 'lambda_sparse': 0.017764210256502926}. Best is trial 3 with value: 0.7994444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.74389\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.74028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:54:10,135]\u001B[0m Trial 7 finished with value: 0.7402777777777778 and parameters: {'n_d': 51, 'n_a': 41, 'n_steps': 8, 'gamma': 0.49902337100860183, 'n_independent': 4, 'n_shared': 2, 'lambda_sparse': 0.033110152198400744}. Best is trial 3 with value: 0.7994444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.77639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:55:05,644]\u001B[0m Trial 8 finished with value: 0.7763888888888889 and parameters: {'n_d': 55, 'n_a': 8, 'n_steps': 14, 'gamma': 1.3824824309659869, 'n_independent': 4, 'n_shared': 7, 'lambda_sparse': 0.02625800775147872}. Best is trial 3 with value: 0.7994444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.74583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:55:25,236]\u001B[0m Trial 9 finished with value: 0.7458333333333333 and parameters: {'n_d': 8, 'n_a': 34, 'n_steps': 11, 'gamma': 1.5005840325862463, 'n_independent': 4, 'n_shared': 2, 'lambda_sparse': 0.07008497324377758}. Best is trial 3 with value: 0.7994444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.74972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:55:46,265]\u001B[0m Trial 10 finished with value: 0.7497222222222222 and parameters: {'n_d': 64, 'n_a': 21, 'n_steps': 11, 'gamma': 0.19545717733241585, 'n_independent': 1, 'n_shared': 4, 'lambda_sparse': 0.0979938944328087}. Best is trial 3 with value: 0.7994444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.75611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:56:03,114]\u001B[0m Trial 11 finished with value: 0.7561111111111111 and parameters: {'n_d': 64, 'n_a': 62, 'n_steps': 8, 'gamma': 0.12913411889892445, 'n_independent': 2, 'n_shared': 4, 'lambda_sparse': 0.0005302424638421047}. Best is trial 3 with value: 0.7994444444444445.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:56:08,686]\u001B[0m Trial 12 finished with value: 0.7569444444444444 and parameters: {'n_d': 46, 'n_a': 53, 'n_steps': 1, 'gamma': 0.5180762013163724, 'n_independent': 8, 'n_shared': 4, 'lambda_sparse': 0.03690575991405121}. Best is trial 3 with value: 0.7994444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.75694\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.74361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:56:31,526]\u001B[0m Trial 13 finished with value: 0.7436111111111111 and parameters: {'n_d': 56, 'n_a': 52, 'n_steps': 13, 'gamma': 1.6289501872372982, 'n_independent': 3, 'n_shared': 5, 'lambda_sparse': 0.0036756552379426212}. Best is trial 3 with value: 0.7994444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.75139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:56:55,864]\u001B[0m Trial 14 finished with value: 0.7513888888888888 and parameters: {'n_d': 41, 'n_a': 64, 'n_steps': 7, 'gamma': 1.0877804313910144, 'n_independent': 2, 'n_shared': 10, 'lambda_sparse': 0.04285589472516291}. Best is trial 3 with value: 0.7994444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.80472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:57:23,496]\u001B[0m Trial 15 finished with value: 0.8047222222222222 and parameters: {'n_d': 27, 'n_a': 47, 'n_steps': 5, 'gamma': 1.6748814089181507, 'n_independent': 7, 'n_shared': 7, 'lambda_sparse': 0.06918533416642773}. Best is trial 15 with value: 0.8047222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.77917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:57:48,110]\u001B[0m Trial 16 finished with value: 0.7791666666666667 and parameters: {'n_d': 25, 'n_a': 46, 'n_steps': 5, 'gamma': 1.2382087481453752, 'n_independent': 8, 'n_shared': 7, 'lambda_sparse': 0.07237039881396189}. Best is trial 15 with value: 0.8047222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.79778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:58:52,062]\u001B[0m Trial 17 finished with value: 0.7977777777777778 and parameters: {'n_d': 20, 'n_a': 46, 'n_steps': 9, 'gamma': 0.9211936953508636, 'n_independent': 8, 'n_shared': 8, 'lambda_sparse': 0.08821631839340321}. Best is trial 15 with value: 0.8047222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.79694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 14:59:54,952]\u001B[0m Trial 18 finished with value: 0.7969444444444445 and parameters: {'n_d': 16, 'n_a': 29, 'n_steps': 13, 'gamma': 1.2599319793581376, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.0688661350147628}. Best is trial 15 with value: 0.8047222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.77583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:00:25,242]\u001B[0m Trial 19 finished with value: 0.7758333333333333 and parameters: {'n_d': 39, 'n_a': 56, 'n_steps': 6, 'gamma': 0.9936189950635489, 'n_independent': 10, 'n_shared': 5, 'lambda_sparse': 0.061760095050254996}. Best is trial 15 with value: 0.8047222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.76694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:01:10,302]\u001B[0m Trial 20 finished with value: 0.7669444444444445 and parameters: {'n_d': 28, 'n_a': 47, 'n_steps': 10, 'gamma': 0.6702319177105215, 'n_independent': 7, 'n_shared': 9, 'lambda_sparse': 0.07950302548269951}. Best is trial 15 with value: 0.8047222222222222.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.1058  |  0:00:00s\n",
      "epoch 1  | loss: 0.86668 |  0:00:01s\n",
      "epoch 2  | loss: 0.83157 |  0:00:02s\n",
      "epoch 3  | loss: 0.79871 |  0:00:03s\n",
      "epoch 4  | loss: 0.76773 |  0:00:03s\n",
      "epoch 5  | loss: 0.77237 |  0:00:04s\n",
      "epoch 6  | loss: 0.75745 |  0:00:05s\n",
      "epoch 7  | loss: 0.70862 |  0:00:06s\n",
      "epoch 8  | loss: 0.70529 |  0:00:07s\n",
      "epoch 9  | loss: 0.69216 |  0:00:07s\n",
      "epoch 10 | loss: 0.67715 |  0:00:08s\n",
      "epoch 11 | loss: 0.66548 |  0:00:09s\n",
      "epoch 12 | loss: 0.6715  |  0:00:10s\n",
      "epoch 13 | loss: 0.66305 |  0:00:11s\n",
      "epoch 14 | loss: 0.66714 |  0:00:11s\n",
      "epoch 15 | loss: 0.66389 |  0:00:12s\n",
      "epoch 16 | loss: 0.65425 |  0:00:13s\n",
      "epoch 17 | loss: 0.657   |  0:00:14s\n",
      "epoch 18 | loss: 0.65679 |  0:00:15s\n",
      "epoch 19 | loss: 0.64549 |  0:00:15s\n",
      "epoch 20 | loss: 0.6489  |  0:00:16s\n",
      "epoch 21 | loss: 0.63247 |  0:00:17s\n",
      "epoch 22 | loss: 0.64592 |  0:00:18s\n",
      "epoch 23 | loss: 0.63215 |  0:00:19s\n",
      "epoch 24 | loss: 0.62558 |  0:00:19s\n",
      "epoch 25 | loss: 0.63361 |  0:00:20s\n",
      "epoch 26 | loss: 0.63079 |  0:00:21s\n",
      "epoch 27 | loss: 0.62618 |  0:00:22s\n",
      "epoch 28 | loss: 0.62476 |  0:00:22s\n",
      "epoch 29 | loss: 0.62193 |  0:00:23s\n",
      "epoch 30 | loss: 0.61979 |  0:00:24s\n",
      "epoch 31 | loss: 0.6263  |  0:00:25s\n",
      "epoch 32 | loss: 0.62496 |  0:00:26s\n",
      "epoch 33 | loss: 0.6309  |  0:00:26s\n",
      "epoch 34 | loss: 0.62786 |  0:00:27s\n",
      "epoch 35 | loss: 0.6377  |  0:00:28s\n",
      "epoch 36 | loss: 0.63147 |  0:00:29s\n",
      "epoch 37 | loss: 0.62979 |  0:00:30s\n",
      "epoch 38 | loss: 0.62218 |  0:00:30s\n",
      "epoch 39 | loss: 0.625   |  0:00:31s\n",
      "epoch 40 | loss: 0.62472 |  0:00:32s\n",
      "epoch 41 | loss: 0.62535 |  0:00:33s\n",
      "epoch 42 | loss: 0.6186  |  0:00:33s\n",
      "epoch 43 | loss: 0.62046 |  0:00:34s\n",
      "epoch 44 | loss: 0.61809 |  0:00:35s\n",
      "epoch 45 | loss: 0.61958 |  0:00:36s\n",
      "epoch 46 | loss: 0.62194 |  0:00:37s\n",
      "epoch 47 | loss: 0.62717 |  0:00:37s\n",
      "epoch 48 | loss: 0.6137  |  0:00:38s\n",
      "epoch 49 | loss: 0.62304 |  0:00:39s\n",
      "epoch 50 | loss: 0.63041 |  0:00:40s\n",
      "epoch 51 | loss: 0.6353  |  0:00:41s\n",
      "epoch 52 | loss: 0.62249 |  0:00:41s\n",
      "epoch 53 | loss: 0.62486 |  0:00:42s\n",
      "epoch 54 | loss: 0.6151  |  0:00:43s\n",
      "epoch 55 | loss: 0.60998 |  0:00:44s\n",
      "epoch 56 | loss: 0.62037 |  0:00:45s\n",
      "epoch 57 | loss: 0.60735 |  0:00:45s\n",
      "epoch 58 | loss: 0.60785 |  0:00:46s\n",
      "epoch 59 | loss: 0.60792 |  0:00:47s\n",
      "epoch 60 | loss: 0.60982 |  0:00:48s\n",
      "epoch 61 | loss: 0.60693 |  0:00:49s\n",
      "epoch 62 | loss: 0.616   |  0:00:49s\n",
      "epoch 63 | loss: 0.61309 |  0:00:50s\n",
      "epoch 64 | loss: 0.60097 |  0:00:51s\n",
      "epoch 65 | loss: 0.60232 |  0:00:52s\n",
      "epoch 66 | loss: 0.60502 |  0:00:52s\n",
      "epoch 67 | loss: 0.60797 |  0:00:53s\n",
      "epoch 68 | loss: 0.60234 |  0:00:54s\n",
      "epoch 69 | loss: 0.59751 |  0:00:55s\n",
      "epoch 70 | loss: 0.60213 |  0:00:56s\n",
      "epoch 71 | loss: 0.60053 |  0:00:56s\n",
      "epoch 72 | loss: 0.60097 |  0:00:57s\n",
      "epoch 73 | loss: 0.59523 |  0:00:58s\n",
      "epoch 74 | loss: 0.59887 |  0:00:59s\n",
      "epoch 75 | loss: 0.6     |  0:01:00s\n",
      "epoch 76 | loss: 0.59631 |  0:01:00s\n",
      "epoch 77 | loss: 0.59336 |  0:01:01s\n",
      "epoch 78 | loss: 0.59833 |  0:01:02s\n",
      "epoch 79 | loss: 0.60398 |  0:01:03s\n",
      "epoch 80 | loss: 0.59386 |  0:01:04s\n",
      "epoch 81 | loss: 0.58631 |  0:01:04s\n",
      "epoch 82 | loss: 0.59864 |  0:01:05s\n",
      "epoch 83 | loss: 0.59491 |  0:01:06s\n",
      "epoch 84 | loss: 0.59052 |  0:01:07s\n",
      "epoch 85 | loss: 0.59404 |  0:01:08s\n",
      "epoch 86 | loss: 0.59652 |  0:01:08s\n",
      "epoch 87 | loss: 0.59098 |  0:01:09s\n",
      "epoch 88 | loss: 0.59461 |  0:01:10s\n",
      "epoch 89 | loss: 0.59326 |  0:01:11s\n",
      "epoch 90 | loss: 0.59418 |  0:01:12s\n",
      "epoch 91 | loss: 0.59859 |  0:01:12s\n",
      "epoch 92 | loss: 0.59081 |  0:01:13s\n",
      "epoch 93 | loss: 0.59251 |  0:01:14s\n",
      "epoch 94 | loss: 0.60197 |  0:01:15s\n",
      "epoch 95 | loss: 0.59289 |  0:01:15s\n",
      "epoch 96 | loss: 0.58955 |  0:01:16s\n",
      "epoch 97 | loss: 0.59228 |  0:01:17s\n",
      "epoch 98 | loss: 0.59144 |  0:01:18s\n",
      "epoch 99 | loss: 0.59006 |  0:01:19s\n",
      "Eval TABNET\n",
      "Accuracy: 0.65\n",
      "Precision: 0.64\n",
      "Recall: 0.68\n",
      "F1-score: 0.66\n",
      "ROC-AUC score: 0.65\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdcAAAHsCAYAAACAOeevAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvZ0lEQVR4nO3de3RU5b3/8c8wIRcSINAAomAMRayVS0y9Vm4qMYhwuAhMuMRq8AJiY0BMSAgS5ZLQWLCAgqC2HpBmjtSD1Av+gIKpFrEHTRUV8WBEmmAEQUgCZBJmfn94nJoKmQF28sDO+9U1a2Vn9n6e76Rr+eXz7Ms4fD6fTwAAwDLNTBcAAIDd0FwBALAYzRUAAIvRXAEAsBjNFQAAi9FcAQCwGM0V540TJ07o97//vUaMGKGhQ4dq0KBBKigokMfjOasxJ02apKSkJK1ateq0j//www+VlpZ2xvP/u5tuuknx8fGqqqqq8/uXXnpJl112mdavX1/v8RUVFbrjjjtO+f7QoUN15MgRS2oFcGohpgsAgpWbm6vDhw/r+eefV8uWLXX06FFNmzZNM2bMUEFBwRmNWV5errfeekvFxcVyOp2nfXyPHj20aNGiM5r7VNq0aaMNGzZo2LBh/t+tXbtWMTExAY89fPiwPvzww1O+//LLL1tRIoAASK44L/zzn//Un//8Z82bN08tW7aUJLVo0UKPPvqoBgwYIOm71DZt2jQNHjxYQ4YM0W9+8xvV1tZK+q4JLl68WMnJybrpppu0evVqVVZW6u6771Ztba1GjBihL7/8UpdddpkOHjzon/f77aqqKqWlpWno0KEaPny4cnJy5PV6tW3bNg0ePPiM5j+V//iP/9C6dev826WlpTp69Ki6dOni/92aNWs0atQoDRs2TDfeeKN/vKysLB0/flxDhw7ViRMn1L17dz344INKSkrShx9+6P88S5YsUXJysk6cOKH9+/erd+/eeuedd6z4vwqAaK44T3z00Ufq2rWroqKi6vy+Xbt2SkpKkiTNmTNH0dHR+vOf/6w//elP+vTTT/Xcc89Jkjwej9q0aaPCwkItWrRIeXl5at68uZYvX67w8HC9/PLLuvjii085/4YNG1RVVaWXX35Za9askSTt3bu3zj6nO391dfVJ5+rXr5927typr7/+WtJ3afOHKbaqqkovvviili9frrVr12rhwoX+5J6Xl+f/PE6nUzU1Nbrxxhv1xhtvqEePHv4xJk2apJCQED377LPKyMjQ+PHjdd111wX8/wFAcGiuOC80a9ZMXq+33n2Kioo0fvx4ORwOhYaGKjk5WUVFRf73b775ZknSFVdcIY/Ho6NHjwY9/y9+8Qv97//+r1JSUrR8+XL96le/UmxsbIPM37x5cyUlJemVV16RJL3++uv+dCxJkZGRWrZsmd5880098cQTWrZsWb2f5aqrrvrR75xOpx5//HGtWLFCPp9P9913X9B/CwCB0VxxXujZs6c+//xzVVZW1vl9eXm57r33Xh0/flxer1cOh8P/ntfr9S/LSlJYWJgk+fcJ9FjtH14o1blzZ23YsEH33nuvKisrddddd+kvf/lLnf2tnH/YsGFat26d3nvvPcXFxSk6Otr/3ldffaVhw4aptLRUv/jFL5Senl7v52jRosVJf19aWqqwsDB9+eWXOnz4cL1jADg9NFecFzp06KAhQ4YoOzvb32ArKyuVm5ur6OhohYeHq3fv3lq1apV8Pp88Ho/+67/+S7/85S9Pa562bdv6Lwj6PjlK0urVq5WVlaXevXvr4YcfVu/evfXxxx/XOdaK+b/Xq1cvHT9+XAsXLtTw4cPrvLdjxw61bdtW999/v3r37q3NmzdL+u7K55CQEJ04cSLgPxyOHDmihx9+WPn5+Ro8eLBmzJhxRnUCODmaK84bs2bNUteuXZWcnKyhQ4dq1KhR6tq1q+bMmSNJysnJ0cGDBzVkyBANGTJEcXFxmjhx4mnNkZOTo8cee0zDhw/X7t271a5dO0nfJckTJ05o0KBBGjFihCoqKpSSkvKjY892/h8aOnSoSkpK1KdPnzq/v+GGG9ShQwcNHDhQt956q/bt26e2bdtqz549ateunXr27KnbbrtNhw4dqvdz9u/fX71799YDDzygvXv36oUXXjjjWgHU5eAr5wAAsBbJFQAAi9FcAQCwGM0VAACL0VwBALAYzRUAAIudcw/uj7mz0HQJgCW2zB0ceCfgHNf9oqjAO52hiCsfsHzMY+8vsXzMM0FyBQDAYudccgUANBEO++Y7misAwIwfPIvbbuz7zwYAAAwhuQIAzLDxsrB9PxkAAIaQXAEAZtj4nCvNFQBgBsvCAAAgWCRXAIAZNl4WJrkCAGAxkisAwAzOuQIAgGCRXAEAZtj4nCvNFQBgBsvCAADYxzfffKN+/fpp9+7d2rNnj8aMGaOxY8dq1qxZ8nq9dfb1er165JFH5HK5lJKSoj179gQcn+YKADDD4bD+FYSamho98sgjCg8PlyTl5eUpPT1dq1evls/n06ZNm+rsv3HjRnk8Hrndbj300EPKz88POAfNFQDQpMyfP1/Jyclq3769JOmjjz7SNddcI0nq27ev/va3v9XZf/v27erTp48kKT4+Xjt27Ag4B80VAGCGo5n1rwBeeukltW3b1t8sJcnn88nxf6k3MjJSFRUVdY6prKxUVFSUf9vpdKq2trbeebigCQBgRgNcLex2u+V2u/3bLpdLLpfLv/2nP/1JDodDW7du1SeffKLMzEwdPHjQ/35VVZVatWpVZ8yoqChVVVX5t71er0JC6m+fNFcAgG38ezP9dy+88IL/55SUFOXm5qqgoEDbtm3Ttddeq6KiIl133XV1jklISNDmzZs1aNAgFRcXq1u3bgHrYFkYAGCGgWXhk8nMzNTixYvlcrlUU1OjpKQkSVJGRobKysqUmJio0NBQJScnKy8vT1lZWYE/ms/n851RNQ0k5s5C0yUAltgyd7DpEoCz1v2iqMA7naGIvrmWj3msyPoxzwTLwgAAM2z8EAmaKwDAjGb2ffyhff/ZAACAISRXAIAZNl4Wtu8nAwDAEJIrAMAMvnIOAACLsSwMAACCRXIFAJhh42VhkisAABYjuQIAzOCcKwAACBbJFQBgho3PudJcAQBmsCwMAACCRXIFAJhh42VhkisAABYjuQIAzLDxOVeaKwDADJaFAQBAsEiuAAAzbLwsbN9PBgCAISRXAIAZNk6uNFcAgBlc0AQAAIJFcgUAmGHjZWH7fjIAAAwhuQIAzOCcKwAACBbJFQBgho3PudJcAQBmsCwMAACCRXIFABjhILkCAIBgkVwBAEbYObnSXAEAZti3t7IsDACA1UiuAAAj7LwsTHIFAMBiJFcAgBF2Tq40VwCAEXZuriwLAwBgMZIrAMAIE8n1xIkTysnJUUlJiZxOp/Ly8rRw4UIdOHBAklRaWqpevXpp4cKFdY4bNmyYWrZsKUnq1KmT8vLy6p2H5goAaDI2b94sSSosLNS2bduUl5enpUuXSpIOHz6sO+64Q1lZWXWOqa6uliStXLky6HlorgAAMwycch0wYID69+8vSSorK1NMTIz/vcWLF2v8+PFq3759nWN27typY8eOKTU1VbW1tZo6dari4+PrnYfmCgCwDbfbLbfb7d92uVxyuVx19gkJCVFmZqY2bNigRYsWSZK++eYbbd269UepVZLCw8M1YcIEjRo1Sl988YXuuecerV+/XiEhp26hNFcAgBENcc71ZM30ZObPn69p06Zp9OjRevXVV7V+/XoNHjxYTqfzR/vGxcUpNjZWDodDcXFxio6O1v79+9WxY8dTjs/VwgAAIxwOh+WvQNauXaunn35akhQRESGHwyGn06mtW7eqb9++Jz1mzZo1ys/PlySVl5ersrJS7dq1q3cemisAoMm45ZZb9PHHH2vcuHGaMGGCsrOzFRYWppKSEnXu3LnOvhkZGSorK9PIkSNVUVGhMWPGaMqUKZo3b169S8KS5PD5fL6G/CCnK+bOQtMlAJbYMnew6RKAs9b9oqgGG7ttymrLxzy4cqzlY54JkisAABbjgiYAgBF2fvwhzRUAYIZ9eyvLwgAAWI3kCgAwws7LwiRXAAAsRnIFABhh5+RKcwUAGGHn5sqyMAAAFiO5AgDMsG9wJbkCAGA1kisAwAjOuQIAgKCRXAEARtg5udJcAQBG2Lm5siwMAIDFSK4AACNIrgAAIGgkVwCAGfYNrjRXAIAZLAsDAICgkVwBAEaQXAEAQNBIrgAAI+ycXGmuAAAz7NtbWRYGAMBqJFcAgBF2XhYmuQIAYDGSKwDACJIrAAAIGsnV5po5HFp419Xq2rGlvF6ffv3Mu5oxsofat46QJHWOidT23Qd0z9KthisF6ldbW6Mnf/OY9peXqcZTo5HjJ+iCizpr2YI58vmkS356qSb8OkNOp9N0qQiSnZMrzdXmkq68UJJ029xNuuFn7TV7TLxSFr0lSWrdornWTr9JOavfN1kiEJSiDa+rZavWejB7tioOf6tp941V3KU/09gJD+iKXglaPH+W/udvb+raPjeZLhVBornivPX6e6X6f8VlkqROP2mh/Ueq/e9lDu+hZzZ+pvLDx02VBwTt+v4DdH2/m/3bzZwheji3QE6nUzU1Nfr24Ddq3eYnBisE/qVBz7l6vd6GHB5BOuH1acnd1yp//C+07u97JUkxLcPU9+cd9Me/lhiuDghOREQLRbSI1LGjVSp4NENjUyfJ6XTq66/2KT11lCoOf6uLOseaLhOnw9EAr3OE5c117969uv/++9W3b18NGDBA/fv317333quSEv4jbtIDz2zTtdNf1cK7rlaLUKeGXN1Zf3pnj7w+n+nSgKAd+PorzZp6n/ol3qY+N98qSWp/QUc9uXKtbhlyu/6wdIHhCoHvWN5cZ8yYofvuu09FRUX6y1/+oi1btuj+++9XVlaW1VMhCKN+eYkevO1ySdLR6lp5fT6d8PnU7+cdtOmDfYarA4L37cFv9FjGZI2/N0033zpUkpQ3Y4rK/vmlJCmiRaQcDm6AOJ84HA7LX+cKy8+5ejwe9erVq87v4uPjrZ4GQXr1f/Zq0d3X6s9ZNynE2Uw5q99XdY1XXTu20hf7K02XBwTtT6ufU1VFhdasfEZrVj4jSRo74X4tmZ+rkOYhCgsL1/3TZhquEqfjXGqGVnP4fNauC86aNUsej0d9+vRRy5YtVVVVpTfffFOhoaF69NFHAx4fc2ehleUAxmyZO9h0CcBZ635RVION/dOHXrd8zN2/vdXyMc+E5ck1NzdXGzdu1Pbt21VZWamoqCjdeOONSkxMtHoqAMB5zMbB1frm6nA4lJiYSDMFADRZ3OcKADDCzudcaa4AACNM9NYTJ04oJydHJSUlcjqdysvLU0VFhSZOnKhLLrlEkjRmzBgNGjTIf4zX61Vubq4+/fRThYaGas6cOYqNrf+eaporAKDJ2Lx5sySpsLBQ27ZtU15enm666SbdddddSk1NPekxGzdulMfjkdvtVnFxsfLz87V06dJ656G5AgCMMLEs/P3DjSSprKxMMTEx2rFjh0pKSrRp0ybFxsYqOztbUVH/ukp6+/bt6tOnj6Tvbi3dsWNHwHm44xoA0KSEhIQoMzNTs2fPVlJSknr27KmMjAy98MIL6ty5s5588sk6+39/58v3nE6namtr652D5goAMMLhsP7ldrs1YsQI/8vtdp907vnz5+uNN97QzJkz1bt3b3Xv3l2SlJiYqI8//rjOvlFRUaqqqvJve71ehYTUv/DLsjAAwDZcLpdcLtcp31+7dq3Ky8t13333KSIiQg6HQw888IBmzpypnj17auvWrbriiivqHJOQkKDNmzdr0KBBKi4uVrdu3QLWQXMFABjRrFnjn3O95ZZblJWVpXHjxqm2tlbZ2dnq2LGjZs+erebNmysmJkazZ8+WJGVkZCg9PV2JiYl6++23lZycLJ/Pp3nz5gWcx/LHH54tHn8Iu+Dxh7CDhnz84RUz/p/lY3409xbLxzwTnHMFAMBiLAsDAIyw8xOaSK4AAFiM5AoAMMLGwZXmCgAwg2VhAAAQNJIrAMAIkisAAAgayRUAYISNgyvNFQBgBsvCAAAgaCRXAIARNg6uJFcAAKxGcgUAGME5VwAAEDSSKwDACBsHV5orAMAMloUBAEDQSK4AACNsHFxJrgAAWI3kCgAwws7nXGmuAAAjbNxbWRYGAMBqJFcAgBF2XhYmuQIAYDGSKwDACBsHV5orAMAMloUBAEDQSK4AACNsHFxJrgAAWI3kCgAwgnOuAAAgaCRXAIARdk6uNFcAgBE27q0sCwMAYDWSKwDACDsvC5NcAQCwGMkVAGCEjYMrzRUAYAbLwgAAIGgkVwCAETYOriRXAACsRnIFABjRzEB0PXHihHJyclRSUiKn06m8vDxVVVVp9uzZcjqdCg0N1fz58xUTE1PnuGHDhqlly5aSpE6dOikvL6/eeWiuAAAjTCwLb968WZJUWFiobdu2KS8vTxUVFZo5c6Yuv/xyFRYWasWKFcrKyvIfU11dLUlauXJl0PPQXAEATcaAAQPUv39/SVJZWZliYmL06KOPqn379pK+S7ZhYWF1jtm5c6eOHTum1NRU1dbWaurUqYqPj693HporAMCIhrgVx+12y+12+7ddLpdcLledfUJCQpSZmakNGzZo0aJF/sb63nvvadWqVXrhhRfq7B8eHq4JEyZo1KhR+uKLL3TPPfdo/fr1Cgk5dQuluQIAbONkzfRk5s+fr2nTpmn06NF69dVXtWXLFi1dulTLly9X27Zt6+wbFxen2NhYORwOxcXFKTo6Wvv371fHjh1POT5XCwMAjGjmsP4VyNq1a/X0009LkiIiIuRwOLRhwwatWrVKK1euVOfOnX90zJo1a5Sfny9JKi8vV2Vlpdq1a1f/Zzv9PwcAAGfP4XBY/grklltu0ccff6xx48ZpwoQJys7O1ty5c1VVVaVf//rXSklJ0aJFiyRJGRkZKisr08iRI1VRUaExY8ZoypQpmjdvXr1LwpLk8Pl8Pkv+ShaJubPQdAmAJbbMHWy6BOCsdb8oqsHGHrTsXcvHfG3iNZaPeSY45woAMIInNAEAgKCRXAEARjhk3+hKcgUAwGIkVwCAEcHcOnO+orkCAIzgy9IBAEDQSK4AACNsHFxJrgAAWI3kCgAwwsSXpTcWmisAwAgb91aWhQEAsBrJFQBgBLfiAACAoJFcAQBG2Di40lwBAGbY+WphloUBALAYyRUAYIR9cyvJFQAAy51WcvV6vWrWjH4MADh7TfpWnNdff12vvvqq/vu//1s33HCDnn322caoCwCA81bA5vrcc8/pl7/8pdatW6c333xTmzdvboy6AAA218xh/etcEXBZOCwsTJIUGRmp0NBQVVVVNXhRAAD7a9LLwp06ddLtt9+u22+/XUuWLFHPnj0boy4AAM5bAZNrfn6+qqqqFBkZqR49eigmJqYx6gIA2JyNg+upm+vUqVNPGdl/+9vfNlhBAACc707ZXJOTkxuzDgBAE2Pnc66nbK7XXHONJKmyslIrVqzQ/v371b9/f1122WWNVhwAwL7Opat7rRbwgqbs7Gx17txZX3zxhWJiYjRjxozGqAsAgPNWwOb67bffauTIkQoJCVFCQoJ8Pl9j1AUAsDmHw2H561wR1LMMd+/eLUn66quvePwhAAABBLwVJycnR9nZ2dq9e7fS0tI0a9asxqgLAGBz507OtF7A5tqtWzctXbpUpaWlio2NVatWrRqjLgCAzTXpL0tfs2aNxo4dq6effloul0uvvfZaY9QFAMB5K2ByLSws1Msvv6ywsDAdPXpUv/rVrzRo0KDGqA0AYGM2Dq6Bk2t0dLRCQr7rweHh4SwLAwAQQMDHHx48eFAjRoxQr1699PHHHys8PLwx6wMA2NS5dOuM1U7r8YeDBw9u0GIAALCDgI8//Pbbb/XWW2+ptrZWPp9PX3/9tf89AADOlI2Da+ALmtLS0nTJJZdo165dCgsLU0RERGPUBQCwuSZ9K44kPfbYY4qLi9Pvf/97HT58uKFrAgDgvBYwuUpSdXW1jh07JofDoaNHjzZ0TQCAJsBEcD1x4oRycnJUUlIip9OpvLw8+Xw+TZ8+XQ6HQ5deeqlmzZpV51G/Xq9Xubm5+vTTTxUaGqo5c+YoNja23nkCJtdx48bp+eef1w033KB+/fqpS5cuZ//pAAAwYPPmzZK+e4ZDWlqa8vLylJeXp/T0dK1evVo+n0+bNm2qc8zGjRvl8Xjkdrv10EMPKT8/P+A8AZNrUlKS/+dbb71VBw4cON3PAgDAj5i4FWfAgAHq37+/JKmsrEwxMTHasmWL/0Ldvn376u2331ZiYqL/mO3bt6tPnz6SpPj4eO3YsSPgPEEtC38vKipKd955p9asWXM6h52Wfz7z41uAgPNRm6sfMF0CcNaOvb+kwcZuiO9Yc7vdcrvd/m2XyyWXy1Vnn5CQEGVmZmrDhg1atGiRNm/e7G/0kZGRqqioqLN/ZWWloqKi/NtOp1O1tbX+ByydzGk1V0l8nysA4Jx1smZ6MvPnz9e0adM0evRoVVdX+39fVVX1oycRRkVFqaqqyr/t9XrrbazSGfzDwc5P1AAANB4TX5a+du1aPf3005KkiIgIORwOde/eXdu2bZMkFRUV6aqrrqpzTEJCgoqKiiRJxcXF6tatW8B5Aj7+8Id8Pp/27t0bcFAAAM5Ft9xyi7KysjRu3DjV1tYqOztbP/3pTzVz5kwtWLBAXbp08V9rlJGRofT0dCUmJurtt99WcnKyfD6f5s2bF3Aeh+8U67zvvvvuKQ9qyCc0Ha9tsKGBRsU5V9hBQ55zTX95p+VjPjH0Z5aPeSYCPv4QAICG0MzGZxkb4mItAACatNO+WhgAACvY+QLZgM21vLxcBQUFOnTokJKSknTZZZepV69ejVEbAADnpYDLwjNnztTtt98uj8ejq666SnPnzm2MugAANtfMYf3rXBGwuVZXV+v666+Xw+FQly5dFBYW1hh1AQBw3gq4LBwaGqq//vWv8nq9Ki4uVmhoaGPUBQCwORufcg2cXGfPnq2XXnpJhw4d0nPPPafc3NxGKAsAYHfNHA7LX+eKgMn1ggsu0MKFCxujFgAAbCFgc+3du7f/52+//VadO3fW66+/3qBFAQDsz84PWgjYXN966y3/z6WlpVqypOEehQUAgB2c1kMkLrroIn3++ecNVQsAoAk5h06RWi5gc/3ht+N8/fXX+slPftLgRQEA7O9cugDJagGb66BBg/xfHBsWFqbu3bs3eFEAAJzPAjbXZ599Vn/84x8boxYAQBNi4+AauLm2bt1azz//vOLi4tSs2XfXdv3wCmIAAFBXwObapk0b7dy5Uzt3/utLbWmuAICzdS49C9hqp2yu6enpeuKJJ5SXl9eY9QAAmgg7X9B0ynt4Dx482Jh1AABgG6dMrnv37tWCBQtO+t7UqVMbrCAAQNNg4+B66uYaHh6uuLi4xqwFAABbOGVzjYmJ0fDhwxuzFgBAE2LnC5pOec6Vh0UAAHBmTplcMzMzG7MOAEAT45B9o+tpPbgfAACrNMllYQAAcGZIrgAAI0iuAAAgaCRXAIARDhs/RYLmCgAwgmVhAAAQNJIrAMAIG68Kk1wBALAayRUAYISdv8+V5goAMIILmgAAQNBIrgAAI2y8KkxyBQDAaiRXAIARzWz8lXMkVwAALEZyBQAYYedzrjRXAIARdr4Vh+YKAGgyampqlJ2drdLSUnk8Hk2aNEmvvPKKDhw4IEkqLS1Vr169tHDhwjrHDRs2TC1btpQkderUSXl5efXOQ3MFABhh4glN69atU3R0tAoKCnTo0CENHz5cW7ZskSQdPnxYd9xxh7KysuocU11dLUlauXJl0PPQXAEATcbAgQOVlJTk33Y6nf6fFy9erPHjx6t9+/Z1jtm5c6eOHTum1NRU1dbWaurUqYqPj693HporAMCIhgiubrdbbrfbv+1yueRyufzbkZGRkqTKykqlpaUpPT1dkvTNN99o69atP0qtkhQeHq4JEyZo1KhR+uKLL3TPPfdo/fr1Cgk5dQuluQIAjGiIZeF/b6Yns2/fPk2ePFljx47VkCFDJEnr16/X4MGD6yTZ78XFxSk2NlYOh0NxcXGKjo7W/v371bFjx1POwX2uAIAm48CBA0pNTdXDDz+skSNH+n+/detW9e3b96THrFmzRvn5+ZKk8vJyVVZWql27dvXOQ3MFABjhcFj/CmTZsmU6cuSInnrqKaWkpCglJUXHjx9XSUmJOnfuXGffjIwMlZWVaeTIkaqoqNCYMWM0ZcoUzZs3r94lYUly+Hw+39n8cax2vNZ0BYA12lz9gOkSgLN27P0lDTb2c3//0vIxU6++2PIxzwTnXAEARth56ZTmCgAwwmHj5x/a+R8OAAAYQXIFABhh39xKcgUAwHIkVwCAESaeLdxYSK4AAFiM5AoAMMK+uZXmCgAwxMarwiwLAwBgNZIrAMAIHiIBAACCRnIFABhh53RHcwUAGMGyMAAACBrJFQBghH1zK8kVAADLkVwBAEbY+ZwrzRUAYISdl07t/NkAADCC5AoAMMLOy8IkVwAALEZyBQAYYd/cSnIFAMByJFcAgBE2PuVKcwUAmNHMxgvDLAsDAGAxkisAwAg7LwuTXAEAsBjJFQBghMPG51xprgAAI1gWBgAAQSO5AgCM4FYcAAAQNJIrAMAIO59zpbkCAIywc3NlWRgAAIuRXAEARtj5PleSKwAAFiO5AgCMaGbf4EpzBQCYYedlYZorAKDJqKmpUXZ2tkpLS+XxeDRp0iRdcMEFmjhxoi655BJJ0pgxYzRo0CD/MV6vV7m5ufr0008VGhqqOXPmKDY2tt55aK4AACNM3Iqzbt06RUdHq6CgQIcOHdLw4cM1efJk3XXXXUpNTT3pMRs3bpTH45Hb7VZxcbHy8/O1dOnSeuehuQIAmoyBAwcqKSnJv+10OrVjxw6VlJRo06ZNio2NVXZ2tqKiovz7bN++XX369JEkxcfHa8eOHQHnobkCAIxoiHOubrdbbrfbv+1yueRyufzbkZGRkqTKykqlpaUpPT1dHo9Ho0aNUvfu3bV06VI9+eSTyszM9B9TWVlZp9k6nU7V1tYqJOTULZTmCgCwjX9vpiezb98+TZ48WWPHjtWQIUN05MgRtWrVSpKUmJio2bNn19k/KipKVVVV/m2v11tvY5W4zxUAYEgzh/WvQA4cOKDU1FQ9/PDDGjlypCRpwoQJ+uCDDyRJW7du1RVXXFHnmISEBBUVFUmSiouL1a1bt4DzkFwBAEaYuBVn2bJlOnLkiJ566ik99dRTkqTp06dr3rx5at68uWJiYvzJNSMjQ+np6UpMTNTbb7+t5ORk+Xw+zZs3L+A8Dp/P52vQT3KajteargCwRpurHzBdAnDWjr2/pMHG/uuuQ5aP2adbG8vHPBMkVwCAEXwrDs57H3zwD024M0WS9MnHH2msa6TuTBmrvLmz5fV6DVcHBK9dmyh99vpsdbukg/93v3lohO4e2dtgVUBdNNcm4PfPrtCjj+SourpakvRY7kxlTM/WH1auVsuoKL326p8NVwgEJySkmZbkjNGx6hpJUkybKK1dMkm39ethuDKcCUcDvM4VNNcmoHPni7Xgd4v92+VflSv+ygRJUnxCgt5/b7up0oDTkj9luFaseUv79h+WJEVGhGnuste0+tW/G64MZ6KZw2H561xBc20CBtySVOeerE6dO+t//v6uJOnNzZt17NgxU6UBQRs/5FrtP1SpjVs/8f9uT9k3+vuOPQarAk6O5toEPTZnnp5d8bQemHSv2v7kJ2oTfW5cXQfU51fDrtfN1/1Mb6x4UD0vu0jPzk5Rh5+0NF0WzoKdl4Utv1o4JSVFNTU1dX7n8/nkcDhUWFho9XQ4A0VvvqlH58xT+/YdlDd3tnr36Wu6JCCgxAlP+H9+Y8WD+vXcQpV/U2GuIKAeljfXadOmKScnR08++aScTqfVw8MCF8fG6oGJ9yo8IkJXX3Ot+vTtZ7okAE3RuRQ1LdYgD5F45plnFBsbq8TExNM+lodIwC54iATsoCEfIrFt92HLx7z2p60tH/NMNMhDJO6+++6GGBYAgPMCT2gCABhxDt05YzmuFgYAwGIkVwCAETYOriRXAACsRnIFAJhh4+hKcwUAGGHiy9IbC8vCAABYjOQKADCCW3EAAEDQSK4AACNsHFxprgAAQ2zcXVkWBgDAYiRXAIAR3IoDAACCRnIFABhh51txaK4AACNs3FtZFgYAwGokVwCAGTaOriRXAAAsRnIFABjBrTgAACBoJFcAgBHcigMAgMVs3FtZFgYAwGokVwCAGTaOriRXAAAsRnIFABhh51txaK4AACPsfLUwy8IAAFiM5AoAMMLGwZXkCgCA1UiuAAAzDETXmpoaZWdnq7S0VB6PR5MmTdKFF16o2bNny+l0KjQ0VPPnz1dMTEyd44YNG6aWLVtKkjp16qS8vLx656G5AgCMMHG18Lp16xQdHa2CggIdOnRIw4cPV6dOnTRz5kxdfvnlKiws1IoVK5SVleU/prq6WpK0cuXKoOehuQIAmoyBAwcqKSnJv+10OrVgwQK1b99eknTixAmFhYXVOWbnzp06duyYUlNTVVtbq6lTpyo+Pr7eeWiuAAAjTNyKExkZKUmqrKxUWlqa0tPT/Y31vffe06pVq/TCCy/UOSY8PFwTJkzQqFGj9MUXX+iee+7R+vXrFRJy6hZKcwUA2Ibb7Zbb7fZvu1wuuVyuOvvs27dPkydP1tixYzVkyBBJ0muvvaalS5dq+fLlatu2bZ394+LiFBsbK4fDobi4OEVHR2v//v3q2LHjKeuguQIAjGiI4HqyZvpDBw4cUGpqqh555BFdf/31kqSXX35ZbrdbK1euVHR09I+OWbNmjXbt2qXc3FyVl5ersrJS7dq1q7cOh8/n853VJ7HY8VrTFQDWaHP1A6ZLAM7asfeXNNjYu746avmY3S5oUe/7c+bM0euvv64uXbpI+u4c62effaYLL7xQrVq1kiRdffXVSktLU0ZGhtLT0xUTE6OsrCyVlZXJ4XBo2rRpSkhIqHcemivQQGiusIMGba7lDdBcO9TfXBsLy8IAACPs/OB+ntAEAIDFSK4AACP4VhwAABA0kisAwAgbB1eaKwDAEBt3V5aFAQCwGMkVAGAEt+IAAICgkVwBAEbY+VYcmisAwAgb91aWhQEAsBrJFQBgho2jK8kVAACLkVwBAEZwKw4AAAgayRUAYAS34gAAYDEb91aWhQEAsBrJFQBghJ2XhUmuAABYjOQKADDEvtGV5goAMIJlYQAAEDSSKwDACBsHV5IrAABWI7kCAIyw8zlXmisAwAge3A8AAIJGcgUAmGHf4EpyBQDAaiRXAIARNg6uJFcAAKxGcgUAGMGtOAAAWIxbcQAAQNBIrgAAM+wbXEmuAABYjeQKADDCxsGV5goAMMPOVwuzLAwAgMVIrgAAI+x8Kw7NFQDQZNTU1Cg7O1ulpaXyeDyaNGmSunbtqunTp8vhcOjSSy/VrFmz1KzZvxZ2vV6vcnNz9emnnyo0NFRz5sxRbGxsvfOwLAwAMMLhsP4VyLp16xQdHa3Vq1drxYoVmj17tvLy8pSenq7Vq1fL5/Np06ZNdY7ZuHGjPB6P3G63HnroIeXn5wech+YKAGgyBg4cqAcffNC/7XQ69dFHH+maa66RJPXt21d/+9vf6hyzfft29enTR5IUHx+vHTt2BJyH5goAsA23260RI0b4X263u877kZGRioqKUmVlpdLS0pSeni6fzyfH/8XeyMhIVVRU1DmmsrJSUVFR/m2n06na2tp66+CcKwDAiIa4FcflcsnlctW7z759+zR58mSNHTtWQ4YMUUFBgf+9qqoqtWrVqs7+UVFRqqqq8m97vV6FhNTfPkmuAIAm48CBA0pNTdXDDz+skSNHSpJ+/vOfa9u2bZKkoqIiXXXVVXWOSUhIUFFRkSSpuLhY3bp1CzgPzRUAYISjAf4XyLJly3TkyBE99dRTSklJUUpKitLT07V48WK5XC7V1NQoKSlJkpSRkaGysjIlJiYqNDRUycnJysvLU1ZWVuDP5vP5fGf9F7LQ8fqXsYHzRpurHzBdAnDWjr2/pMHGPnzMa/mYrSPOjczIOVcAgBF2fvwhzRUAYISNeyvnXAEAsBrJFQBgho2jK8kVAACLkVwBAEbwrTgAAFjMzlcLsywMAIDFSK4AACNsHFxJrgAAWI3kCgAww8bRleYKADDCzlcLsywMAIDFSK4AACO4FQcAAATtnPs+VwAAznckVwAALEZzBQDAYjRXAAAsRnMFAMBiNFcAACxGcwUAwGI01ybE6/XqkUcekcvlUkpKivbs2WO6JOCM/eMf/1BKSorpMoCT4glNTcjGjRvl8XjkdrtVXFys/Px8LV261HRZwGlbsWKF1q1bp4iICNOlACdFcm1Ctm/frj59+kiS4uPjtWPHDsMVAWfm4osv1uLFi02XAZwSzbUJqaysVFRUlH/b6XSqtrbWYEXAmUlKSlJICAtvOHfRXJuQqKgoVVVV+be9Xi//gQKABkBzbUISEhJUVFQkSSouLla3bt0MVwQA9kRsaUISExP19ttvKzk5WT6fT/PmzTNdEgDYEt+KAwCAxVgWBgDAYjRXAAAsRnMFAMBiNFcAACxGcwUAwGI0V5z3tm3bpuuvv14pKSlKSUnR6NGjtXLlyjMa6/HHH9dLL72kTz75REuWLDnlfhs2bFB5eXlQYxYVFWn69Ol1fvfPf/5To0ePDur4htoXQMPhPlfYwnXXXaeFCxdKkjwejwYOHKihQ4eqVatWZzTe5Zdfrssvv/yU7//nf/6ncnNz1aFDhzMaH4C90VxhO5WVlWrWrJmcTqdSUlLUpk0bHTlyRMuXL1dubq727Nkjr9er9PR0XXvttXrjjTe0dOlStW3bVjU1NerSpYu2bdumwsJCLVy4UC+++KL++Mc/yuv16uabb1aPHj30ySefKDMzU6tXr5bb7dYrr7wih8OhQYMG6Y477tDu3buVnZ2tiIgIRUREqHXr1kHV/u677/oT8/HjxzV//nw1b95cBw8e1MSJE3Xw4EH169dPkydP1r59+zRz5kxVV1crLCxMs2fPrjPWwoUL9c4778jr9eq2227TnXfeafWfGsAp0FxhC++8845SUlLkcDjUvHlzzZw5U5GRkZKkIUOGKDExUatXr1abNm00b948HTp0SOPHj9err76qgoICvfjii4qOjta9995bZ9xvvvnG//VmoaGhys/P19VXX63LL79cubm5+vLLL/Xaa69p9erVcjgcuvPOO9W7d2/97ne/U1pamm644QYtX75cn3/+eVCf47PPPlNBQYE6dOigZcuWaf369RoyZIiOHj2qgoICtWjRQuPGjdPNN9+sZcuWKSUlRf369dPWrVv1+OOPa8qUKf6x1q5dq1WrVqlDhw566aWXrPtjAwiI5gpb+OGy8L+Li4uTJO3atUvbt2/XBx98IEmqra3VgQMHFBUVpTZt2kiSrrzyyjrH7t27V5deeqnCw8MlSdnZ2XXe37Vrl8rKyvyp8PDhw/ryyy/12WefqWfPnpK+e6ZzsM21Q4cOmjt3rlq0aKHy8nIlJCRIkn72s5+pZcuWkqQePXqopKREu3bt0tNPP61nnnlGPp9PzZs3rzPWggULtGDBAh04cMD/VYMAGgfNFbbncDgkSV26dNEFF1ygiRMn6vjx41q6dKlatWqliooKHTx4UG3bttWHH36oCy64wH/sxRdfrM8//1wej0ehoaFKS0vTjBkz5HA45PP51KVLF3Xt2lXPPPOMHA6H/vCHP6hbt27q0qWL3n//ffXt2/e0vjc3JydHGzduVFRUlDIzM/X900l3796tqqoqhYWF6YMPPpDL5VKXLl2UmpqqhIQE7d69W3//+9/943g8Hq1fv14LFiyQz+fTbbfdpttuu00XXXSRRX9VAPWhuaLJSE5OVk5OjsaPH6/KykqNHTtWoaGhysvL04QJE9S6desffQVf27Ztdc8992j8+PFyOBy68cYb1aFDB1155ZXKyMjQc889p+uvv15jxoyRx+NRz5491aFDB82aNUtTpkzRs88+q7Zt2yosLOxH9Xz22WcaMWKEf3v69OkaOnSoRo8erVatWikmJkZff/21JKl169aaMmWKDh48qEGDBqlr167KzMxUbm6uqqurdfz4cc2YMcM/VmhoqFq3bq2hQ4eqdevWuuGGG3ThhRc20F8WwL/jwf0AAFiM+1wBALAYzRUAAIvRXAEAsBjNFQAAi9FcAQCwGM0VAACL0VwBALAYzRUAAIv9f9B3WaS20gqRAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 15:02:30,016]\u001B[0m A new study created in memory with name: no-name-dfad9c73-6967-49a2-8d45-fb67a602f1df\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.86139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:03:31,898]\u001B[0m Trial 0 finished with value: 0.8613888888888889 and parameters: {'n_d': 30, 'n_a': 41, 'n_steps': 14, 'gamma': 1.81115184161773, 'n_independent': 9, 'n_shared': 5, 'lambda_sparse': 0.03178446363054603}. Best is trial 0 with value: 0.8613888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.86639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:04:44,100]\u001B[0m Trial 1 finished with value: 0.8663888888888889 and parameters: {'n_d': 36, 'n_a': 59, 'n_steps': 16, 'gamma': 1.503256671275458, 'n_independent': 9, 'n_shared': 1, 'lambda_sparse': 0.04111947207359846}. Best is trial 1 with value: 0.8663888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.90528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:04:57,395]\u001B[0m Trial 2 finished with value: 0.9052777777777777 and parameters: {'n_d': 33, 'n_a': 21, 'n_steps': 6, 'gamma': 1.5183911973795745, 'n_independent': 6, 'n_shared': 3, 'lambda_sparse': 0.006012398414861672}. Best is trial 2 with value: 0.9052777777777777.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:05:07,279]\u001B[0m Trial 3 finished with value: 0.9291666666666667 and parameters: {'n_d': 46, 'n_a': 12, 'n_steps': 2, 'gamma': 0.4834818554249982, 'n_independent': 4, 'n_shared': 8, 'lambda_sparse': 0.0052566210304513614}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.92917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:05:15,342]\u001B[0m Trial 4 finished with value: 0.9030555555555556 and parameters: {'n_d': 36, 'n_a': 49, 'n_steps': 4, 'gamma': 0.32943881715203116, 'n_independent': 2, 'n_shared': 3, 'lambda_sparse': 0.012750425690367644}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.90306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:05:19,256]\u001B[0m Trial 5 finished with value: 0.9044444444444444 and parameters: {'n_d': 27, 'n_a': 63, 'n_steps': 5, 'gamma': 1.721995897276172, 'n_independent': 1, 'n_shared': 1, 'lambda_sparse': 0.09833671901250456}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.90444\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.90833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:06:13,922]\u001B[0m Trial 6 finished with value: 0.9083333333333333 and parameters: {'n_d': 14, 'n_a': 56, 'n_steps': 14, 'gamma': 1.078074384171645, 'n_independent': 4, 'n_shared': 4, 'lambda_sparse': 0.011575193268249621}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.86556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:07:08,099]\u001B[0m Trial 7 finished with value: 0.8655555555555556 and parameters: {'n_d': 31, 'n_a': 59, 'n_steps': 19, 'gamma': 1.621628142598701, 'n_independent': 4, 'n_shared': 5, 'lambda_sparse': 0.027850709424900665}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.90444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:07:40,614]\u001B[0m Trial 8 finished with value: 0.9044444444444445 and parameters: {'n_d': 37, 'n_a': 61, 'n_steps': 6, 'gamma': 1.7728043182197881, 'n_independent': 6, 'n_shared': 6, 'lambda_sparse': 0.03902127123174916}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.86806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:07:51,784]\u001B[0m Trial 9 finished with value: 0.8680555555555556 and parameters: {'n_d': 35, 'n_a': 34, 'n_steps': 8, 'gamma': 0.6670998786356274, 'n_independent': 8, 'n_shared': 1, 'lambda_sparse': 0.0012018870481133564}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:08:00,561]\u001B[0m Trial 10 finished with value: 0.9038888888888889 and parameters: {'n_d': 61, 'n_a': 8, 'n_steps': 1, 'gamma': 0.10993943817620633, 'n_independent': 3, 'n_shared': 9, 'lambda_sparse': 0.062387967216257695}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.90389\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.88056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:08:37,816]\u001B[0m Trial 11 finished with value: 0.8805555555555555 and parameters: {'n_d': 9, 'n_a': 26, 'n_steps': 12, 'gamma': 1.0703040292418962, 'n_independent': 4, 'n_shared': 9, 'lambda_sparse': 0.017420323450629247}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.90389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:09:06,772]\u001B[0m Trial 12 finished with value: 0.903888888888889 and parameters: {'n_d': 52, 'n_a': 8, 'n_steps': 10, 'gamma': 0.9384852108890531, 'n_independent': 5, 'n_shared': 7, 'lambda_sparse': 0.0017106885893082954}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.9025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:09:55,841]\u001B[0m Trial 13 finished with value: 0.9025 and parameters: {'n_d': 8, 'n_a': 48, 'n_steps': 16, 'gamma': 0.6120188950246612, 'n_independent': 7, 'n_shared': 7, 'lambda_sparse': 0.020094685741518396}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:10:00,239]\u001B[0m Trial 14 finished with value: 0.9233333333333333 and parameters: {'n_d': 19, 'n_a': 18, 'n_steps': 1, 'gamma': 1.1636310233621998, 'n_independent': 3, 'n_shared': 10, 'lambda_sparse': 0.02084180422876787}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.92333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:10:04,198]\u001B[0m Trial 15 finished with value: 0.898611111111111 and parameters: {'n_d': 47, 'n_a': 19, 'n_steps': 1, 'gamma': 1.3147287363859081, 'n_independent': 1, 'n_shared': 10, 'lambda_sparse': 0.02377847687577086}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.89861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:10:19,345]\u001B[0m Trial 16 finished with value: 0.9252777777777776 and parameters: {'n_d': 22, 'n_a': 16, 'n_steps': 3, 'gamma': 0.8369927361859302, 'n_independent': 3, 'n_shared': 10, 'lambda_sparse': 0.0007922629928102179}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.92528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:10:27,537]\u001B[0m Trial 17 finished with value: 0.9275 and parameters: {'n_d': 22, 'n_a': 29, 'n_steps': 3, 'gamma': 0.7878405813306446, 'n_independent': 2, 'n_shared': 8, 'lambda_sparse': 0.0025028891423220546}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.9275\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.91222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:10:50,943]\u001B[0m Trial 18 finished with value: 0.9122222222222223 and parameters: {'n_d': 47, 'n_a': 31, 'n_steps': 9, 'gamma': 0.716487672592311, 'n_independent': 2, 'n_shared': 8, 'lambda_sparse': 0.05525248918893992}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.90167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:11:00,611]\u001B[0m Trial 19 finished with value: 0.9016666666666667 and parameters: {'n_d': 44, 'n_a': 27, 'n_steps': 3, 'gamma': 0.45795314181885516, 'n_independent': 5, 'n_shared': 8, 'lambda_sparse': 0.010452876950664675}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.85333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:11:12,451]\u001B[0m Trial 20 finished with value: 0.8533333333333333 and parameters: {'n_d': 62, 'n_a': 40, 'n_steps': 7, 'gamma': 0.8506515023334266, 'n_independent': 2, 'n_shared': 7, 'lambda_sparse': 0.011986515653005167}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:11:22,983]\u001B[0m Trial 21 finished with value: 0.9247222222222222 and parameters: {'n_d': 23, 'n_a': 13, 'n_steps': 2, 'gamma': 0.8682048807035543, 'n_independent': 3, 'n_shared': 9, 'lambda_sparse': 0.0016204529752197815}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.92472\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.90528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:11:32,437]\u001B[0m Trial 22 finished with value: 0.9052777777777777 and parameters: {'n_d': 21, 'n_a': 14, 'n_steps': 3, 'gamma': 0.505256218926606, 'n_independent': 3, 'n_shared': 10, 'lambda_sparse': 0.0008810376253984989}. Best is trial 3 with value: 0.9291666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.93167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:11:39,317]\u001B[0m Trial 23 finished with value: 0.9316666666666665 and parameters: {'n_d': 16, 'n_a': 24, 'n_steps': 4, 'gamma': 0.8107271148680673, 'n_independent': 1, 'n_shared': 8, 'lambda_sparse': 0.010426266134098765}. Best is trial 23 with value: 0.9316666666666665.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.91806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:11:51,303]\u001B[0m Trial 24 finished with value: 0.9180555555555555 and parameters: {'n_d': 17, 'n_a': 24, 'n_steps': 5, 'gamma': 0.7235430807148588, 'n_independent': 1, 'n_shared': 8, 'lambda_sparse': 0.013613920621567516}. Best is trial 23 with value: 0.9316666666666665.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:11:56,874]\u001B[0m Trial 25 finished with value: 0.895 and parameters: {'n_d': 14, 'n_a': 32, 'n_steps': 4, 'gamma': 0.3685306299109797, 'n_independent': 2, 'n_shared': 7, 'lambda_sparse': 0.019635368922527343}. Best is trial 23 with value: 0.9316666666666665.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.91333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:12:12,874]\u001B[0m Trial 26 finished with value: 0.9133333333333333 and parameters: {'n_d': 40, 'n_a': 38, 'n_steps': 7, 'gamma': 0.5773161266455382, 'n_independent': 1, 'n_shared': 6, 'lambda_sparse': 0.007321885861186571}. Best is trial 23 with value: 0.9316666666666665.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.88083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:12:24,527]\u001B[0m Trial 27 finished with value: 0.8808333333333334 and parameters: {'n_d': 56, 'n_a': 29, 'n_steps': 2, 'gamma': 0.9661689576706304, 'n_independent': 4, 'n_shared': 8, 'lambda_sparse': 0.029545486550546923}. Best is trial 23 with value: 0.9316666666666665.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.89472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:12:56,989]\u001B[0m Trial 28 finished with value: 0.8947222222222223 and parameters: {'n_d': 27, 'n_a': 23, 'n_steps': 10, 'gamma': 0.7796208757303672, 'n_independent': 2, 'n_shared': 9, 'lambda_sparse': 0.008120898696683906}. Best is trial 23 with value: 0.9316666666666665.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.82714 |  0:00:00s\n",
      "epoch 1  | loss: 0.70636 |  0:00:00s\n",
      "epoch 2  | loss: 0.69524 |  0:00:01s\n",
      "epoch 3  | loss: 0.6892  |  0:00:01s\n",
      "epoch 4  | loss: 0.66498 |  0:00:01s\n",
      "epoch 5  | loss: 0.65154 |  0:00:02s\n",
      "epoch 6  | loss: 0.64996 |  0:00:02s\n",
      "epoch 7  | loss: 0.62769 |  0:00:02s\n",
      "epoch 8  | loss: 0.62535 |  0:00:03s\n",
      "epoch 9  | loss: 0.63561 |  0:00:03s\n",
      "epoch 10 | loss: 0.62426 |  0:00:03s\n",
      "epoch 11 | loss: 0.62003 |  0:00:03s\n",
      "epoch 12 | loss: 0.61954 |  0:00:04s\n",
      "epoch 13 | loss: 0.61482 |  0:00:04s\n",
      "epoch 14 | loss: 0.61051 |  0:00:04s\n",
      "epoch 15 | loss: 0.60774 |  0:00:05s\n",
      "epoch 16 | loss: 0.60625 |  0:00:05s\n",
      "epoch 17 | loss: 0.6031  |  0:00:05s\n",
      "epoch 18 | loss: 0.61518 |  0:00:06s\n",
      "epoch 19 | loss: 0.60842 |  0:00:06s\n",
      "epoch 20 | loss: 0.60894 |  0:00:06s\n",
      "epoch 21 | loss: 0.60911 |  0:00:07s\n",
      "epoch 22 | loss: 0.60761 |  0:00:07s\n",
      "epoch 23 | loss: 0.60241 |  0:00:07s\n",
      "epoch 24 | loss: 0.60578 |  0:00:08s\n",
      "epoch 25 | loss: 0.59482 |  0:00:08s\n",
      "epoch 26 | loss: 0.59465 |  0:00:08s\n",
      "epoch 27 | loss: 0.61119 |  0:00:09s\n",
      "epoch 28 | loss: 0.60157 |  0:00:09s\n",
      "epoch 29 | loss: 0.60254 |  0:00:09s\n",
      "epoch 30 | loss: 0.59912 |  0:00:10s\n",
      "epoch 31 | loss: 0.593   |  0:00:10s\n",
      "epoch 32 | loss: 0.59579 |  0:00:10s\n",
      "epoch 33 | loss: 0.59248 |  0:00:11s\n",
      "epoch 34 | loss: 0.58942 |  0:00:11s\n",
      "epoch 35 | loss: 0.60079 |  0:00:11s\n",
      "epoch 36 | loss: 0.59463 |  0:00:11s\n",
      "epoch 37 | loss: 0.60245 |  0:00:12s\n",
      "epoch 38 | loss: 0.60092 |  0:00:12s\n",
      "epoch 39 | loss: 0.58953 |  0:00:12s\n",
      "epoch 40 | loss: 0.59341 |  0:00:13s\n",
      "epoch 41 | loss: 0.59231 |  0:00:13s\n",
      "epoch 42 | loss: 0.59609 |  0:00:13s\n",
      "epoch 43 | loss: 0.5941  |  0:00:14s\n",
      "epoch 44 | loss: 0.58263 |  0:00:14s\n",
      "epoch 45 | loss: 0.58956 |  0:00:14s\n",
      "epoch 46 | loss: 0.58527 |  0:00:15s\n",
      "epoch 47 | loss: 0.58168 |  0:00:15s\n",
      "epoch 48 | loss: 0.5818  |  0:00:15s\n",
      "epoch 49 | loss: 0.58903 |  0:00:16s\n",
      "epoch 50 | loss: 0.57835 |  0:00:16s\n",
      "epoch 51 | loss: 0.58609 |  0:00:16s\n",
      "epoch 52 | loss: 0.58077 |  0:00:17s\n",
      "epoch 53 | loss: 0.58241 |  0:00:17s\n",
      "epoch 54 | loss: 0.58307 |  0:00:17s\n",
      "epoch 55 | loss: 0.57992 |  0:00:18s\n",
      "epoch 56 | loss: 0.5815  |  0:00:18s\n",
      "epoch 57 | loss: 0.58245 |  0:00:18s\n",
      "epoch 58 | loss: 0.59059 |  0:00:19s\n",
      "epoch 59 | loss: 0.59043 |  0:00:19s\n",
      "epoch 60 | loss: 0.58393 |  0:00:19s\n",
      "epoch 61 | loss: 0.58862 |  0:00:20s\n",
      "epoch 62 | loss: 0.58306 |  0:00:20s\n",
      "epoch 63 | loss: 0.58806 |  0:00:20s\n",
      "epoch 64 | loss: 0.58465 |  0:00:21s\n",
      "epoch 65 | loss: 0.58293 |  0:00:21s\n",
      "epoch 66 | loss: 0.58778 |  0:00:21s\n",
      "epoch 67 | loss: 0.58523 |  0:00:22s\n",
      "epoch 68 | loss: 0.58276 |  0:00:22s\n",
      "epoch 69 | loss: 0.58234 |  0:00:22s\n",
      "epoch 70 | loss: 0.57827 |  0:00:22s\n",
      "epoch 71 | loss: 0.57848 |  0:00:23s\n",
      "epoch 72 | loss: 0.59116 |  0:00:23s\n",
      "epoch 73 | loss: 0.58261 |  0:00:23s\n",
      "epoch 74 | loss: 0.58497 |  0:00:24s\n",
      "epoch 75 | loss: 0.58095 |  0:00:24s\n",
      "epoch 76 | loss: 0.57593 |  0:00:24s\n",
      "epoch 77 | loss: 0.57941 |  0:00:25s\n",
      "epoch 78 | loss: 0.57737 |  0:00:25s\n",
      "epoch 79 | loss: 0.57294 |  0:00:25s\n",
      "epoch 80 | loss: 0.5782  |  0:00:26s\n",
      "epoch 81 | loss: 0.58181 |  0:00:26s\n",
      "epoch 82 | loss: 0.58494 |  0:00:26s\n",
      "epoch 83 | loss: 0.57272 |  0:00:27s\n",
      "epoch 84 | loss: 0.58182 |  0:00:27s\n",
      "epoch 85 | loss: 0.57591 |  0:00:27s\n",
      "epoch 86 | loss: 0.57382 |  0:00:28s\n",
      "epoch 87 | loss: 0.57571 |  0:00:28s\n",
      "epoch 88 | loss: 0.57301 |  0:00:28s\n",
      "epoch 89 | loss: 0.57896 |  0:00:29s\n",
      "epoch 90 | loss: 0.57806 |  0:00:29s\n",
      "epoch 91 | loss: 0.57222 |  0:00:29s\n",
      "epoch 92 | loss: 0.58389 |  0:00:30s\n",
      "epoch 93 | loss: 0.57642 |  0:00:30s\n",
      "epoch 94 | loss: 0.58504 |  0:00:30s\n",
      "epoch 95 | loss: 0.57804 |  0:00:31s\n",
      "epoch 96 | loss: 0.5836  |  0:00:31s\n",
      "epoch 97 | loss: 0.58704 |  0:00:31s\n",
      "epoch 98 | loss: 0.58197 |  0:00:32s\n",
      "epoch 99 | loss: 0.58279 |  0:00:32s\n",
      "Eval TABNET\n",
      "Accuracy: 0.8\n",
      "Precision: 0.8\n",
      "Recall: 0.8\n",
      "F1-score: 0.8\n",
      "ROC-AUC score: 0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 15:13:29,761]\u001B[0m A new study created in memory with name: no-name-cfcafc36-e098-4acc-83ad-4d112c1025f2\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.77806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:14:20,824]\u001B[0m Trial 0 finished with value: 0.7780555555555555 and parameters: {'n_d': 8, 'n_a': 46, 'n_steps': 15, 'gamma': 1.2098272226995497, 'n_independent': 3, 'n_shared': 10, 'lambda_sparse': 0.09889255605405638}. Best is trial 0 with value: 0.7780555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.84611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:14:29,384]\u001B[0m Trial 1 finished with value: 0.8461111111111111 and parameters: {'n_d': 47, 'n_a': 42, 'n_steps': 2, 'gamma': 0.9128471000555436, 'n_independent': 8, 'n_shared': 3, 'lambda_sparse': 0.0766981676166407}. Best is trial 1 with value: 0.8461111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.78556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:15:12,612]\u001B[0m Trial 2 finished with value: 0.7855555555555556 and parameters: {'n_d': 53, 'n_a': 29, 'n_steps': 17, 'gamma': 1.7313954852914706, 'n_independent': 4, 'n_shared': 6, 'lambda_sparse': 0.09715512077484142}. Best is trial 1 with value: 0.8461111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.85222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:15:54,719]\u001B[0m Trial 3 finished with value: 0.8522222222222221 and parameters: {'n_d': 62, 'n_a': 30, 'n_steps': 8, 'gamma': 0.37342402289490995, 'n_independent': 4, 'n_shared': 9, 'lambda_sparse': 0.029637794116743332}. Best is trial 3 with value: 0.8522222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.8075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:16:12,947]\u001B[0m Trial 4 finished with value: 0.8075 and parameters: {'n_d': 18, 'n_a': 16, 'n_steps': 18, 'gamma': 1.265903989165061, 'n_independent': 3, 'n_shared': 1, 'lambda_sparse': 0.045423566226215614}. Best is trial 3 with value: 0.8522222222222221.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:16:20,482]\u001B[0m Trial 5 finished with value: 0.82 and parameters: {'n_d': 10, 'n_a': 10, 'n_steps': 3, 'gamma': 1.066757288990242, 'n_independent': 10, 'n_shared': 5, 'lambda_sparse': 0.021638912206916102}. Best is trial 3 with value: 0.8522222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.82\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.80944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:16:58,018]\u001B[0m Trial 6 finished with value: 0.8094444444444443 and parameters: {'n_d': 62, 'n_a': 27, 'n_steps': 11, 'gamma': 1.6596107921369767, 'n_independent': 3, 'n_shared': 4, 'lambda_sparse': 0.012639327465202542}. Best is trial 3 with value: 0.8522222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.86583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:17:50,079]\u001B[0m Trial 7 finished with value: 0.8658333333333332 and parameters: {'n_d': 33, 'n_a': 35, 'n_steps': 13, 'gamma': 0.31122261310739796, 'n_independent': 7, 'n_shared': 7, 'lambda_sparse': 0.025496230874314733}. Best is trial 7 with value: 0.8658333333333332.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.85694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:18:08,088]\u001B[0m Trial 8 finished with value: 0.8569444444444444 and parameters: {'n_d': 53, 'n_a': 27, 'n_steps': 2, 'gamma': 0.17620434921785794, 'n_independent': 7, 'n_shared': 10, 'lambda_sparse': 0.04888180733147219}. Best is trial 7 with value: 0.8658333333333332.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.77167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:19:21,521]\u001B[0m Trial 9 finished with value: 0.7716666666666666 and parameters: {'n_d': 36, 'n_a': 13, 'n_steps': 17, 'gamma': 1.5086207033897132, 'n_independent': 5, 'n_shared': 8, 'lambda_sparse': 0.08824386627248984}. Best is trial 7 with value: 0.8658333333333332.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.83778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:19:54,798]\u001B[0m Trial 10 finished with value: 0.8377777777777777 and parameters: {'n_d': 31, 'n_a': 61, 'n_steps': 12, 'gamma': 0.5830744012465348, 'n_independent': 1, 'n_shared': 7, 'lambda_sparse': 0.004877232314051582}. Best is trial 7 with value: 0.8658333333333332.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.85778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:20:22,787]\u001B[0m Trial 11 finished with value: 0.8577777777777778 and parameters: {'n_d': 27, 'n_a': 49, 'n_steps': 6, 'gamma': 0.13059749265225573, 'n_independent': 7, 'n_shared': 10, 'lambda_sparse': 0.04464134627979781}. Best is trial 7 with value: 0.8658333333333332.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.87611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:20:51,959]\u001B[0m Trial 12 finished with value: 0.8761111111111112 and parameters: {'n_d': 26, 'n_a': 55, 'n_steps': 7, 'gamma': 0.1081897919866816, 'n_independent': 7, 'n_shared': 8, 'lambda_sparse': 0.033587721287472734}. Best is trial 12 with value: 0.8761111111111112.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.85139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:22:23,501]\u001B[0m Trial 13 finished with value: 0.8513888888888889 and parameters: {'n_d': 23, 'n_a': 64, 'n_steps': 13, 'gamma': 0.5851632741514265, 'n_independent': 9, 'n_shared': 7, 'lambda_sparse': 0.02909659393347692}. Best is trial 12 with value: 0.8761111111111112.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.84917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:22:57,577]\u001B[0m Trial 14 finished with value: 0.8491666666666666 and parameters: {'n_d': 42, 'n_a': 53, 'n_steps': 8, 'gamma': 0.11083072242735645, 'n_independent': 6, 'n_shared': 8, 'lambda_sparse': 0.0012934051924887273}. Best is trial 12 with value: 0.8761111111111112.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.84806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:23:13,827]\u001B[0m Trial 15 finished with value: 0.8480555555555556 and parameters: {'n_d': 19, 'n_a': 38, 'n_steps': 6, 'gamma': 0.4440110668139874, 'n_independent': 8, 'n_shared': 6, 'lambda_sparse': 0.06339707253398212}. Best is trial 12 with value: 0.8761111111111112.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.7975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:25:08,646]\u001B[0m Trial 16 finished with value: 0.7975 and parameters: {'n_d': 35, 'n_a': 57, 'n_steps': 14, 'gamma': 1.9873716566048891, 'n_independent': 6, 'n_shared': 8, 'lambda_sparse': 0.03496890368015544}. Best is trial 12 with value: 0.8761111111111112.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.19699 |  0:00:01s\n",
      "epoch 1  | loss: 0.91004 |  0:00:02s\n",
      "epoch 2  | loss: 0.91456 |  0:00:03s\n",
      "epoch 3  | loss: 0.83511 |  0:00:04s\n",
      "epoch 4  | loss: 0.78789 |  0:00:06s\n",
      "epoch 5  | loss: 0.72695 |  0:00:07s\n",
      "epoch 6  | loss: 0.75389 |  0:00:08s\n",
      "epoch 7  | loss: 0.7139  |  0:00:10s\n",
      "epoch 8  | loss: 0.69709 |  0:00:11s\n",
      "epoch 9  | loss: 0.69385 |  0:00:12s\n",
      "epoch 10 | loss: 0.71036 |  0:00:13s\n",
      "epoch 11 | loss: 0.67407 |  0:00:15s\n",
      "epoch 12 | loss: 0.66849 |  0:00:16s\n",
      "epoch 13 | loss: 0.65459 |  0:00:17s\n",
      "epoch 14 | loss: 0.65018 |  0:00:18s\n",
      "epoch 15 | loss: 0.64376 |  0:00:20s\n",
      "epoch 16 | loss: 0.63893 |  0:00:21s\n",
      "epoch 17 | loss: 0.64768 |  0:00:22s\n",
      "epoch 18 | loss: 0.6372  |  0:00:23s\n",
      "epoch 19 | loss: 0.62998 |  0:00:24s\n",
      "epoch 20 | loss: 0.62633 |  0:00:26s\n",
      "epoch 21 | loss: 0.6261  |  0:00:27s\n",
      "epoch 22 | loss: 0.61689 |  0:00:28s\n",
      "epoch 23 | loss: 0.62345 |  0:00:29s\n",
      "epoch 24 | loss: 0.62378 |  0:00:31s\n",
      "epoch 25 | loss: 0.61744 |  0:00:32s\n",
      "epoch 26 | loss: 0.60934 |  0:00:33s\n",
      "epoch 27 | loss: 0.59983 |  0:00:34s\n",
      "epoch 28 | loss: 0.60825 |  0:00:35s\n",
      "epoch 29 | loss: 0.60168 |  0:00:37s\n",
      "epoch 30 | loss: 0.59859 |  0:00:38s\n",
      "epoch 31 | loss: 0.59659 |  0:00:39s\n",
      "epoch 32 | loss: 0.59664 |  0:00:40s\n",
      "epoch 33 | loss: 0.58946 |  0:00:42s\n",
      "epoch 34 | loss: 0.57992 |  0:00:43s\n",
      "epoch 35 | loss: 0.58695 |  0:00:44s\n",
      "epoch 36 | loss: 0.58952 |  0:00:45s\n",
      "epoch 37 | loss: 0.58279 |  0:00:46s\n",
      "epoch 38 | loss: 0.58142 |  0:00:48s\n",
      "epoch 39 | loss: 0.5818  |  0:00:49s\n",
      "epoch 40 | loss: 0.56379 |  0:00:50s\n",
      "epoch 41 | loss: 0.55301 |  0:00:51s\n",
      "epoch 42 | loss: 0.55774 |  0:00:53s\n",
      "epoch 43 | loss: 0.54763 |  0:00:54s\n",
      "epoch 44 | loss: 0.53814 |  0:00:55s\n",
      "epoch 45 | loss: 0.53367 |  0:00:56s\n",
      "epoch 46 | loss: 0.52965 |  0:00:58s\n",
      "epoch 47 | loss: 0.52423 |  0:00:59s\n",
      "epoch 48 | loss: 0.52767 |  0:01:00s\n",
      "epoch 49 | loss: 0.51883 |  0:01:01s\n",
      "epoch 50 | loss: 0.50627 |  0:01:03s\n",
      "epoch 51 | loss: 0.50489 |  0:01:04s\n",
      "epoch 52 | loss: 0.50601 |  0:01:05s\n",
      "epoch 53 | loss: 0.50414 |  0:01:06s\n",
      "epoch 54 | loss: 0.51136 |  0:01:07s\n",
      "epoch 55 | loss: 0.49477 |  0:01:09s\n",
      "epoch 56 | loss: 0.47573 |  0:01:10s\n",
      "epoch 57 | loss: 0.46765 |  0:01:11s\n",
      "epoch 58 | loss: 0.47701 |  0:01:12s\n",
      "epoch 59 | loss: 0.44557 |  0:01:14s\n",
      "epoch 60 | loss: 0.4742  |  0:01:15s\n",
      "epoch 61 | loss: 0.45097 |  0:01:16s\n",
      "epoch 62 | loss: 0.46743 |  0:01:17s\n",
      "epoch 63 | loss: 0.43682 |  0:01:19s\n",
      "epoch 64 | loss: 0.46195 |  0:01:20s\n",
      "epoch 65 | loss: 0.44184 |  0:01:21s\n",
      "epoch 66 | loss: 0.43522 |  0:01:22s\n",
      "epoch 67 | loss: 0.41822 |  0:01:23s\n",
      "epoch 68 | loss: 0.41047 |  0:01:25s\n",
      "epoch 69 | loss: 0.41426 |  0:01:26s\n",
      "epoch 70 | loss: 0.41734 |  0:01:27s\n",
      "epoch 71 | loss: 0.40283 |  0:01:28s\n",
      "epoch 72 | loss: 0.40194 |  0:01:30s\n",
      "epoch 73 | loss: 0.40584 |  0:01:31s\n",
      "epoch 74 | loss: 0.41007 |  0:01:32s\n",
      "epoch 75 | loss: 0.39986 |  0:01:33s\n",
      "epoch 76 | loss: 0.3836  |  0:01:35s\n",
      "epoch 77 | loss: 0.36883 |  0:01:36s\n",
      "epoch 78 | loss: 0.3647  |  0:01:37s\n",
      "epoch 79 | loss: 0.36427 |  0:01:38s\n",
      "epoch 80 | loss: 0.34339 |  0:01:39s\n",
      "epoch 81 | loss: 0.35073 |  0:01:41s\n",
      "epoch 82 | loss: 0.35356 |  0:01:42s\n",
      "epoch 83 | loss: 0.35792 |  0:01:43s\n",
      "epoch 84 | loss: 0.36349 |  0:01:44s\n",
      "epoch 85 | loss: 0.36186 |  0:01:46s\n",
      "epoch 86 | loss: 0.35341 |  0:01:47s\n",
      "epoch 87 | loss: 0.33859 |  0:01:48s\n",
      "epoch 88 | loss: 0.33712 |  0:01:49s\n",
      "epoch 89 | loss: 0.33868 |  0:01:51s\n",
      "epoch 90 | loss: 0.31838 |  0:01:52s\n",
      "epoch 91 | loss: 0.32979 |  0:01:53s\n",
      "epoch 92 | loss: 0.30272 |  0:01:54s\n",
      "epoch 93 | loss: 0.29774 |  0:01:55s\n",
      "epoch 94 | loss: 0.29825 |  0:01:57s\n",
      "epoch 95 | loss: 0.28355 |  0:01:58s\n",
      "epoch 96 | loss: 0.30524 |  0:01:59s\n",
      "epoch 97 | loss: 0.28155 |  0:02:00s\n",
      "epoch 98 | loss: 0.28743 |  0:02:02s\n",
      "epoch 99 | loss: 0.27447 |  0:02:03s\n",
      "Eval TABNET\n",
      "Accuracy: 0.58\n",
      "Precision: 0.58\n",
      "Recall: 0.63\n",
      "F1-score: 0.6\n",
      "ROC-AUC score: 0.58\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 15:27:12,925]\u001B[0m A new study created in memory with name: no-name-3bc946c0-e457-4394-b806-f9c9206c3d22\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.76542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:28:50,139]\u001B[0m Trial 0 finished with value: 0.7654166666666666 and parameters: {'n_d': 39, 'n_a': 53, 'n_steps': 19, 'gamma': 1.27071684148336, 'n_independent': 6, 'n_shared': 6, 'lambda_sparse': 0.0628546350361743}. Best is trial 0 with value: 0.7654166666666666.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.83083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:29:49,433]\u001B[0m Trial 1 finished with value: 0.8308333333333333 and parameters: {'n_d': 53, 'n_a': 42, 'n_steps': 14, 'gamma': 0.48387813854643535, 'n_independent': 3, 'n_shared': 5, 'lambda_sparse': 0.09711215049138788}. Best is trial 1 with value: 0.8308333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.85639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:30:47,712]\u001B[0m Trial 2 finished with value: 0.8563888888888889 and parameters: {'n_d': 54, 'n_a': 8, 'n_steps': 18, 'gamma': 0.20033914544045742, 'n_independent': 1, 'n_shared': 9, 'lambda_sparse': 0.05377690642704428}. Best is trial 2 with value: 0.8563888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.74139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:31:21,947]\u001B[0m Trial 3 finished with value: 0.7413888888888889 and parameters: {'n_d': 12, 'n_a': 36, 'n_steps': 14, 'gamma': 1.4536150953296112, 'n_independent': 3, 'n_shared': 8, 'lambda_sparse': 0.039464005454840224}. Best is trial 2 with value: 0.8563888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.75222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:31:29,767]\u001B[0m Trial 4 finished with value: 0.7522222222222221 and parameters: {'n_d': 12, 'n_a': 55, 'n_steps': 6, 'gamma': 1.5020453887202398, 'n_independent': 3, 'n_shared': 3, 'lambda_sparse': 0.06325842890092356}. Best is trial 2 with value: 0.8563888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:33:25,197]\u001B[0m Trial 5 finished with value: 0.8275 and parameters: {'n_d': 60, 'n_a': 30, 'n_steps': 11, 'gamma': 0.2950210563046922, 'n_independent': 8, 'n_shared': 9, 'lambda_sparse': 0.029702523309692214}. Best is trial 2 with value: 0.8563888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.56167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:33:48,874]\u001B[0m Trial 6 finished with value: 0.5616666666666666 and parameters: {'n_d': 12, 'n_a': 45, 'n_steps': 12, 'gamma': 0.8022621712713185, 'n_independent': 10, 'n_shared': 6, 'lambda_sparse': 0.09229530006494464}. Best is trial 2 with value: 0.8563888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.81944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:35:08,848]\u001B[0m Trial 7 finished with value: 0.8194444444444444 and parameters: {'n_d': 49, 'n_a': 47, 'n_steps': 14, 'gamma': 0.38185980076944115, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.02618060338522408}. Best is trial 2 with value: 0.8563888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 61 with best_epoch = 51 and best_val_0_auc = 0.79722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:36:32,733]\u001B[0m Trial 8 finished with value: 0.7972222222222222 and parameters: {'n_d': 30, 'n_a': 64, 'n_steps': 5, 'gamma': 1.4043796309121552, 'n_independent': 9, 'n_shared': 10, 'lambda_sparse': 0.018565070431182266}. Best is trial 2 with value: 0.8563888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.81333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:37:05,557]\u001B[0m Trial 9 finished with value: 0.8133333333333332 and parameters: {'n_d': 54, 'n_a': 29, 'n_steps': 10, 'gamma': 0.7618444190182034, 'n_independent': 10, 'n_shared': 1, 'lambda_sparse': 0.0013577100468641161}. Best is trial 2 with value: 0.8563888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.83389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:37:46,857]\u001B[0m Trial 10 finished with value: 0.8338888888888888 and parameters: {'n_d': 38, 'n_a': 10, 'n_steps': 19, 'gamma': 0.15908581806650202, 'n_independent': 1, 'n_shared': 8, 'lambda_sparse': 0.04824179280170976}. Best is trial 2 with value: 0.8563888888888889.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.05131 |  0:00:01s\n",
      "epoch 1  | loss: 2.05389 |  0:00:03s\n",
      "epoch 2  | loss: 1.3784  |  0:00:05s\n",
      "epoch 3  | loss: 1.20952 |  0:00:06s\n",
      "epoch 4  | loss: 1.238   |  0:00:08s\n",
      "epoch 5  | loss: 1.30999 |  0:00:10s\n",
      "epoch 6  | loss: 1.08838 |  0:00:12s\n",
      "epoch 7  | loss: 1.02786 |  0:00:13s\n",
      "epoch 8  | loss: 0.99822 |  0:00:15s\n",
      "epoch 9  | loss: 0.90372 |  0:00:17s\n",
      "epoch 10 | loss: 0.83908 |  0:00:18s\n",
      "epoch 11 | loss: 0.79801 |  0:00:20s\n",
      "epoch 12 | loss: 0.7732  |  0:00:22s\n",
      "epoch 13 | loss: 0.79298 |  0:00:24s\n",
      "epoch 14 | loss: 0.74085 |  0:00:26s\n",
      "epoch 15 | loss: 0.7716  |  0:00:27s\n",
      "epoch 16 | loss: 0.79619 |  0:00:29s\n",
      "epoch 17 | loss: 0.73933 |  0:00:31s\n",
      "epoch 18 | loss: 0.72247 |  0:00:33s\n",
      "epoch 19 | loss: 0.71592 |  0:00:34s\n",
      "epoch 20 | loss: 0.69754 |  0:00:36s\n",
      "epoch 21 | loss: 0.72841 |  0:00:38s\n",
      "epoch 22 | loss: 0.70659 |  0:00:40s\n",
      "epoch 23 | loss: 0.6958  |  0:00:41s\n",
      "epoch 24 | loss: 0.6877  |  0:00:43s\n",
      "epoch 25 | loss: 0.67919 |  0:00:45s\n",
      "epoch 26 | loss: 0.6715  |  0:00:47s\n",
      "epoch 27 | loss: 0.67414 |  0:00:48s\n",
      "epoch 28 | loss: 0.68611 |  0:00:50s\n",
      "epoch 29 | loss: 0.67735 |  0:00:52s\n",
      "epoch 30 | loss: 0.67101 |  0:00:53s\n",
      "epoch 31 | loss: 0.66133 |  0:00:55s\n",
      "epoch 32 | loss: 0.64779 |  0:00:57s\n",
      "epoch 33 | loss: 0.66235 |  0:00:59s\n",
      "epoch 34 | loss: 0.65433 |  0:01:00s\n",
      "epoch 35 | loss: 0.62956 |  0:01:02s\n",
      "epoch 36 | loss: 0.62304 |  0:01:04s\n",
      "epoch 37 | loss: 0.61283 |  0:01:06s\n",
      "epoch 38 | loss: 0.62168 |  0:01:07s\n",
      "epoch 39 | loss: 0.61885 |  0:01:09s\n",
      "epoch 40 | loss: 0.62263 |  0:01:11s\n",
      "epoch 41 | loss: 0.61218 |  0:01:13s\n",
      "epoch 42 | loss: 0.60419 |  0:01:14s\n",
      "epoch 43 | loss: 0.6097  |  0:01:16s\n",
      "epoch 44 | loss: 0.60343 |  0:01:18s\n",
      "epoch 45 | loss: 0.58708 |  0:01:20s\n",
      "epoch 46 | loss: 0.5747  |  0:01:21s\n",
      "epoch 47 | loss: 0.56743 |  0:01:23s\n",
      "epoch 48 | loss: 0.57539 |  0:01:25s\n",
      "epoch 49 | loss: 0.56161 |  0:01:27s\n",
      "epoch 50 | loss: 0.5663  |  0:01:28s\n",
      "epoch 51 | loss: 0.5496  |  0:01:30s\n",
      "epoch 52 | loss: 0.55117 |  0:01:32s\n",
      "epoch 53 | loss: 0.54097 |  0:01:34s\n",
      "epoch 54 | loss: 0.54017 |  0:01:35s\n",
      "epoch 55 | loss: 0.53033 |  0:01:37s\n",
      "epoch 56 | loss: 0.51675 |  0:01:39s\n",
      "epoch 57 | loss: 0.52343 |  0:01:40s\n",
      "epoch 58 | loss: 0.51644 |  0:01:42s\n",
      "epoch 59 | loss: 0.52004 |  0:01:44s\n",
      "epoch 60 | loss: 0.51115 |  0:01:46s\n",
      "epoch 61 | loss: 0.52458 |  0:01:47s\n",
      "epoch 62 | loss: 0.50611 |  0:01:49s\n",
      "epoch 63 | loss: 0.50528 |  0:01:51s\n",
      "epoch 64 | loss: 0.51174 |  0:01:53s\n",
      "epoch 65 | loss: 0.48827 |  0:01:54s\n",
      "epoch 66 | loss: 0.48232 |  0:01:56s\n",
      "epoch 67 | loss: 0.4603  |  0:01:58s\n",
      "epoch 68 | loss: 0.46264 |  0:02:00s\n",
      "epoch 69 | loss: 0.46282 |  0:02:01s\n",
      "epoch 70 | loss: 0.45918 |  0:02:03s\n",
      "epoch 71 | loss: 0.45294 |  0:02:05s\n",
      "epoch 72 | loss: 0.44635 |  0:02:07s\n",
      "epoch 73 | loss: 0.44443 |  0:02:08s\n",
      "epoch 74 | loss: 0.42285 |  0:02:10s\n",
      "epoch 75 | loss: 0.40497 |  0:02:12s\n",
      "epoch 76 | loss: 0.39146 |  0:02:14s\n",
      "epoch 77 | loss: 0.39973 |  0:02:15s\n",
      "epoch 78 | loss: 0.38541 |  0:02:17s\n",
      "epoch 79 | loss: 0.39815 |  0:02:19s\n",
      "epoch 80 | loss: 0.37617 |  0:02:21s\n",
      "epoch 81 | loss: 0.38551 |  0:02:23s\n",
      "epoch 82 | loss: 0.36343 |  0:02:24s\n",
      "epoch 83 | loss: 0.35922 |  0:02:26s\n",
      "epoch 84 | loss: 0.36458 |  0:02:28s\n",
      "epoch 85 | loss: 0.36184 |  0:02:29s\n",
      "epoch 86 | loss: 0.34398 |  0:02:31s\n",
      "epoch 87 | loss: 0.34521 |  0:02:33s\n",
      "epoch 88 | loss: 0.33349 |  0:02:35s\n",
      "epoch 89 | loss: 0.34814 |  0:02:36s\n",
      "epoch 90 | loss: 0.3481  |  0:02:38s\n",
      "epoch 91 | loss: 0.33547 |  0:02:40s\n",
      "epoch 92 | loss: 0.33939 |  0:02:42s\n",
      "epoch 93 | loss: 0.32254 |  0:02:43s\n",
      "epoch 94 | loss: 0.33435 |  0:02:45s\n",
      "epoch 95 | loss: 0.3185  |  0:02:47s\n",
      "epoch 96 | loss: 0.31048 |  0:02:49s\n",
      "epoch 97 | loss: 0.31079 |  0:02:50s\n",
      "epoch 98 | loss: 0.31864 |  0:02:52s\n",
      "epoch 99 | loss: 0.29622 |  0:02:54s\n",
      "Eval TABNET\n",
      "Accuracy: 0.68\n",
      "Precision: 0.64\n",
      "Recall: 0.78\n",
      "F1-score: 0.71\n",
      "ROC-AUC score: 0.68\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc4AAAHsCAYAAABbgk2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnOUlEQVR4nO3de1SVdd738c/mjCAKYXjXeCLTGhXLTDMxNSUKZVArNx6o1O5G04esUVFEZaJCB0crTc1T05QOTOaoldZjjuVYZvfTZB4bG3TM1DTDRPDAad9/9MyerDhcuuHnxX6/Wnst9uH6XV90Lb99vtdhO1wul0sAAKBGfEwXAACAndA4AQCwgMYJAIAFNE4AACygcQIAYAGNEwAAC2icsI3y8nK99NJLGjRokJKSkpSQkKCcnByVlJRc1ppjxoxRfHy8Xn31Vcvb79q1S6mpqZe8/x+78847ddNNN6m4uPii11evXq22bdvq7bffrnL7M2fO6IEHHqj0/aSkJBUWFnqkVsBb+ZkuAKipzMxMnT59Wi+//LIaNmyos2fPasKECZo6dapycnIuac3jx49r69at2rFjh3x9fS1v36FDBz3//POXtO/KhIeHa+PGjRowYID7tTVr1igyMrLabU+fPq1du3ZV+v7atWs9USLg1UicsIWvvvpKb7zxhp555hk1bNhQktSgQQP99re/Vd++fSV9n7YmTJig/v37KzExUb/73e9UVlYm6fsGN2/ePCUnJ+vOO+/UypUrVVRUpIcfflhlZWUaNGiQvvzyS7Vt21YFBQXu/f77eXFxsVJTU5WUlKSBAwcqIyNDFRUV2r59u/r3739J+6/Mr371K61bt879/MiRIzp79qyio6Pdr61atUr333+/BgwYoN69e7vXmzJlis6fP6+kpCSVl5erffv2euyxxxQfH69du3a5f5/58+crOTlZ5eXl+uabbxQbG6uPPvrIE39VQL1H44Qt7NmzR61bt1ZoaOhFrzdp0kTx8fGSpKeeekqNGzfWG2+8oddff13/+Mc/tHz5cklSSUmJwsPDlZubq+eff17Z2dny9/fX4sWLFRQUpLVr16p58+aV7n/jxo0qLi7W2rVrtWrVKknS4cOHL/qM1f1fuHDhZ/fVs2dPff755zpx4oSk71PiD9NncXGxXnvtNS1evFhr1qzR3Llz3Yk7Ozvb/fv4+vqqtLRUvXv31jvvvKMOHTq41xgzZoz8/Py0bNkyTZo0ScOHD9dtt91W7d8DABonbMLHx0cVFRVVfmbLli0aPny4HA6HAgIClJycrC1btrjf79OnjySpXbt2Kikp0dmzZ2u8/1tuuUX//Oc/lZKSosWLF+vBBx9UixYtamX//v7+io+P15tvvilJ2rBhgzvVSlJISIgWLVqk999/X88++6wWLVpU5e/SuXPnn7zm6+ur2bNna8mSJXK5XPr1r39d4z8LwNvROGELMTExOnDggIqKii56/fjx43rkkUd0/vx5VVRUyOFwuN+rqKhwj0olKTAwUJLcn6nuNs0/POmoWbNm2rhxox555BEVFRVpxIgR+utf/3rR5z25/wEDBmjdunX6+9//rlatWqlx48bu977++msNGDBAR44c0S233KLx48dX+Xs0aNDgZ18/cuSIAgMD9eWXX+r06dNVrgHgP2icsIWoqCglJiYqPT3d3TyLioqUmZmpxo0bKygoSLGxsXr11VflcrlUUlKiP//5z7r99tst7SciIsJ9cs2/E58krVy5UlOmTFFsbKwmTpyo2NhY7d2796JtPbH/f+vYsaPOnz+vuXPnauDAgRe9t3v3bkVEROjRRx9VbGysNm/eLOn7M4T9/PxUXl5e7f8UFBYWauLEiZo5c6b69++vqVOnXlKdgDeiccI2ZsyYodatWys5OVlJSUm6//771bp1az311FOSpIyMDBUUFCgxMVGJiYlq1aqVRo8ebWkfGRkZevLJJzVw4EDl5+erSZMmkr5PgOXl5UpISNCgQYN05swZpaSk/GTby93/DyUlJengwYPq0aPHRa93795dUVFRuvvuu3XPPffo2LFjioiI0KFDh9SkSRPFxMSoX79+OnXqVJW/Z69evRQbG6tx48bp8OHDWrFixSXXCngTB18rBgBAzZE4AQCwgMYJAIAFNE4AACygcQIAYAGNEwAAC664m7zHzed+magfkrtcY7oE4LKN6lL5rSgvV/DN4zy+5rlP53t8zR8jcQIAYMEVlzgBAF7CYc/sRuMEAJjxg3s724k92z0AAIaQOAEAZth0VGvPqgEAMITECQAww6bHOGmcAAAzGNUCAFD/kTgBAGbYdFRL4gQAwAISJwDADI5xAgBQ/5E4AQBm2PQYJ40TAGAGo1oAAOo/EicAwAybjmpJnAAAWEDiBACYYdNjnDROAIAZjGoBAKj/aJwAADMcPp5/1NC3336rnj17Kj8/X3v27FGPHj2UkpKilJQUrV+/vsptGdUCALxKaWmppk+frqCgIEnS3r17NWLECI0cObJG25M4AQBmGEqcs2bNUnJysq6++mpJ0u7du/Xee+9p2LBhSk9PV1FRUZXb0zgBAGb4ODz/qMbq1asVERGhHj16uF+LiYnRpEmTtGLFCjVr1kwvvPBClWswqgUA1Bt5eXnKy8tzP3c6nXI6ne7nr7/+uhwOh7Zt26Z9+/YpLS1NCxcuVJMmTSRJcXFxysrKqnIfNE4AgBm1cB3njxvlj61YscL9c0pKijIzM/Xoo49q2rRpiomJ0bZt29SuXbsq90HjBAB4tczMTGVlZcnf31+RkZEkTgDAFcrwDRBeeeUV98+5ubk13o7GCQAww6a33LNn1QAAGELiBACYwb1qAQCo/0icAAAzOMYJAED9R+IEAJhh02OcNE4AgBmMagEAqP9InAAAM2w6qiVxAgBgAYkTAGCGTY9x0jgBAGYwqgUAoP4jcQIAzLDpqNaeVQMAYAiJEwBghk0TJ40TAGAGJwcBAFD/kTgBAGbYdFRrz6oBADCExAkAMINjnAAA1H8kTgCAGTY9xknjBACYwagWAID6j8QJADDCQeIEAKD+I3ECAIywa+KkcQIAzLBn32RUCwCAFSROAIARdh3VkjgBALCAxAkAMMKuiZPGCQAwwq6Nk1EtAAAWkDgBAEaQOAEA8AIkTgCAGfYMnCROAACsIHECAIyw6zFOGicAwAi7Nk5GtQAAWEDiBAAYQeIEAMALkDgBAEbYNXHSOAEAZtizbzKqBQDAChInAMAIu45qSZwAAFhA4gQAGGHXxEnjBAAYYdfGyagWAAALSJwAADPsGThJnAAAWEHiBAAYwTFOAABs4ttvv1XPnj2Vn5+vQ4cOaciQIRo6dKhmzJihioqKKrelcQIAjHA4HB5/1ERpaammT5+uoKAgSVJ2drbGjx+vlStXyuVyadOmTVVuT+MEABhhqnHOmjVLycnJuvrqqyVJe/bsUZcuXSRJd9xxhz788MMqt6dxAgDqjby8PA0aNMj9yMvLu+j91atXKyIiQj169HC/5nK53E03JCREZ86cqXIfnBwEADCiNk4Ocjqdcjqdlb7/+uuvy+FwaNu2bdq3b5/S0tJUUFDgfr+4uFhhYWFV7oPGCQDwGitWrHD/nJKSoszMTOXk5Gj79u3q2rWrtmzZottuu63KNRjVAgDMcNTC4xKkpaVp3rx5cjqdKi0tVXx8fJWfJ3ECAIwwfR3nK6+84v751VdfrfF2JE4AACwgcQIAjDCdOC8ViRMAAAtInAAAI+yaOGmcAAAz7Nk3GdUCAGAFiRMAYIRdR7UkTgAALCBxAgCMIHECAOAFSJz1nI9Derx3tJqFB6u8wqXZm/J1rPCCJKl3m6s0IKapHlu1x3CVQPXKy8q0YelsFX5zXGVlpeqWNFTXXHej3lk+V+eLi+SqKFfCr9MUHnWN6VJRQ3ZNnDTOeu62luGSpPGv71HMtWEaHdtCM9bv13WRDXTPjVfb9WxweKG9H76r4NAw9R89WefOFOoP00arxY036Ze399ENXXvq0N4dKjh2mMZpI3ZtnIxq67kPD57S3M0HJElRDQN06lypGgb5aVS35lqw9V9miwMsaNulp2Lvfcj93MfHV199sUdnCr5R3sxJ2vvhJjW7IcZcgfAatdo4KyoqanN51FCFS5rY9zqNvaOltuYX6Dd3RmvR1n/pXAl/P7CPgKBgBQY30IVzZ7Vm3pPqcd8IFZ48rqCQUDkn/05hV12t7W/lmS4TVlwhXytmlcdHtYcPH1Z2drZ2794tPz8/VVRUqE2bNpoyZYpatWrl6d2hhnLezdfSBv565YGbVXC2RKm9ohXg61DziGCNiW2hhVsPmS4RqFbhtyf0l+cydXOfX+mXt9+pzSsXqfXNt0uSWt/cTX97bbnhCuENPN44p06dqt/85jfq2LGj+7UdO3ZoypQpys3N9fTuUI2+bSMVGRqg3E+O6kJphQrOlmjUis9UWu5SVMNATY1vTdOELRSfPqU//26y4h4YpxbtOkmSrm3TXgc+2652sXE6/I+duuoXLc0WCUvseozT442zpKTkoqYpSTfddJOnd4Ma2ppfoAl9rtPvB/5Sfr4OLfzbIZWWu0yXBVj20bqVulBcpA/XrNCHa1ZIkhJ+PUlvL52jTze9qcAGIUp8dIrhKmGFXRunw+VyefRf0RkzZqikpEQ9evRQw4YNVVxcrPfff18BAQH67W9/W+32cfM/8mQ5gDHJXTi7E/Y3qkvzWlv7ut9s8Pia+b+/x+Nr/pjHE2dmZqbeffddffLJJyoqKlJoaKh69+6tuLg4T+8KAGBjNg2cnm+cDodDcXFxNEoAQL3EDRAAAEbY9RgnjRMAYIRN+yZ3DgIAwAoSJwDACLuOakmcAABYQOIEABhh08BJ4gQAwAoSJwDACB8fe0ZOGicAwAhGtQAAeAESJwDACC5HAQDAC5A4AQBG2DRw0jgBAGYwqgUAwAuQOAEARpA4AQDwAiROAIARNg2cNE4AgBmMagEA8AIkTgCAETYNnCROAACsIHECAIzgGCcAAF6AxAkAMMKmgZPGCQAwg1EtAABegMQJADDCpoGTxAkAgBUkTgCAEXY9xknjBAAYYdO+yagWAAArSJwAACPsOqolcQIAYAGJEwBghE0DJ40TAGCGXUe1NE4AgNcoLy9XRkaGDh48KF9fX2VnZ+vMmTMaPXq0WrZsKUkaMmSIEhISKl2DxgkAMMJE4Ny8ebMkKTc3V9u3b1d2drbuvPNOjRgxQiNHjqzRGjROAIDX6Nu3r3r16iVJOnr0qCIjI7V7924dPHhQmzZtUosWLZSenq7Q0NBK16BxAgCMqI1jnHl5ecrLy3M/dzqdcjqdF33Gz89PaWlp2rhxo55//nkdP35c999/v9q3b6+FCxfqhRdeUFpaWqX7oHECAOqNn2uUP2fWrFmaMGGCBg8erNzcXEVFRUmS4uLilJWVVeW2XMcJADDC4XB4/FGdNWvW6MUXX5QkBQcHy+FwaNy4cdq5c6ckadu2bWrXrl2Va5A4AQBGmDg56K677tKUKVM0bNgwlZWVKT09Xf/1X/+lrKws+fv7KzIystrESeMEAHiNBg0a6LnnnvvJ67m5uTVeg8YJADDCrjdA4BgnAAAWkDgBAEbYNHDSOAEAZjCqBQDAC5A4AQBG2DRwkjgBALCCxAkAMMLHppGTxgkAMMKmfZNRLQAAVpA4AQBGcDkKAABegMQJADDCx56Bk8YJADCDUS0AAF6AxAkAMMKmgZPECQCAFSROAIARDtkzcpI4AQCwgMQJADCCy1EAALCAy1EAAPACJE4AgBE2DZwkTgAArCBxAgCM4IusAQCwwKZ9k1EtAABWkDgBAEZwOQoAAF6AxAkAMMKmgZPGCQAww65n1TKqBQDAAhInAMAIe+ZNEicAAJZYSpwVFRXy8aHXAgAuX729HGXDhg1666239Je//EXdu3fXsmXL6qIuAACuSNU2zuXLl+v222/XunXr9P7772vz5s11URcAoJ7zcXj+UReqHdUGBgZKkkJCQhQQEKDi4uJaLwoAUP/V21HtL37xC91777269957NX/+fMXExNRFXQAAXJGqTZwzZ85UcXGxQkJC1KFDB0VGRtZFXQCAes6mgbPyxvnEE09UGqN///vf11pBAABcySptnMnJyXVZBwDAy9j1GGeljbNLly6SpKKiIi1ZskTffPONevXqpbZt29ZZcQCA+quuzoL1tGpPDkpPT1ezZs30r3/9S5GRkZo6dWpd1AUAwBWp2sb53Xff6b777pOfn586deokl8tVF3UBAOo5h8Ph8UddqNH98/Lz8yVJX3/9NbfcAwB4tWovR8nIyFB6erry8/OVmpqqGTNm1EVdAIB6zqaHOKtvnG3atNHChQt15MgRtWjRQmFhYXVRFwCgnqu3X2S9atUqDR06VC+++KKcTqfWr19fF3UBAHBFqjZx5ubmau3atQoMDNTZs2f14IMPKiEhoS5qAwDUYzYNnNUnzsaNG8vP7/v+GhQUxKgWAODVqr3lXkFBgQYNGqSOHTtq7969CgoKqsv6AAD1VL27c9DP3XKvf//+tVoMAABXumpvuffdd99p69atKisrk8vl0okTJ9zvAQBwqWwaOKs/OSg1NVUtW7bU/v37FRgYqODg4LqoCwBQz9Xby1Ek6cknn1SrVq300ksv6fTp07VdEwAAV6xqE6ckXbhwQefOnZPD4dDZs2druyYAgBcwETjLy8uVkZGhgwcPytfXV9nZ2XK5XJo8ebIcDoeuv/56zZgxo8rby1abOIcNG6aXX35Z3bt3V8+ePRUdHe3RXwIAgLqyefNmSd/foyA1NVXZ2dnKzs7W+PHjtXLlSrlcLm3atKnKNapNnPHx8e6f77nnHp08efIyywYAwMzlKH379lWvXr0kSUePHlVkZKTee+8990mvd9xxhz744APFxcVVukaNRrX/FhoaqoceekirVq269Kqr8cbo22ptbaAuhd86znQJwGUb9en8Wlu7Nr5rKy8vT3l5ee7nTqdTTqfzos/4+fkpLS1NGzdu1PPPP6/Nmze7m3hISIjOnDlT5T4sNU5JfB8nAOCK9XON8ufMmjVLEyZM0ODBg3XhwgX368XFxdXeIc9yw7frnR4AAFcWE19kvWbNGr344ouSpODgYDkcDrVv317bt2+XJG3ZskWdO3euco1qb7n3Qy6XS4cPH662MAAArkR33XWXpkyZomHDhqmsrEzp6em67rrrNG3aNM2ZM0fR0dEXndvzcxyuSmavH3/8caUb1eadg86X1drSQJ3iGCfqg3O1eIxz/NrPPb7ms0k3eHzNH6v2lnsAANQGH5se+auNk5oAAKi3LJ9VCwCAJ9j1ZNNqG+fx48eVk5OjU6dOKT4+Xm3btlXHjh3rojYAAK441Y5qp02bpnvvvVclJSXq3Lmznn766bqoCwBQz/k4PP+ok7qr+8CFCxfUrVs3ORwORUdHKzAwsC7qAgDgilTtqDYgIEB/+9vfVFFRoR07diggIKAu6gIA1HM2PcRZfeLMysrS6tWrderUKS1fvlyZmZl1UBYAoL7zcTg8/qgL1SbOpk2bau7cuXVRCwAAV7xqG2dsbKz75++++07NmjXThg0barUoAED9Z9cbCVTbOLdu3er++ciRI5o/v/ZuvwQAwJXO0g0Qrr32Wh04cKC2agEAeBG7nhxUbeP84beknDhxQldddVWtFwUAqP/q6mQeT6u2cSYkJLi/1DMwMFDt27ev9aIAALhSVds4ly1bpj/96U91UQsAwIvYNHBW3zgbNWqkl19+Wa1atZKPz/fnQP3wTFsAALxJtY0zPDxcn3/+uT7//D9fOErjBABcLrt+H2eljXP8+PF69tlnlZ2dXZf1AAC8hF1PDqr0+tOCgoK6rAMAAFuoNHEePnxYc+bM+dn3nnjiiVorCADgHWwaOCtvnEFBQWrVqlVd1gIAwBWv0sYZGRmpgQMH1mUtAAAvYteTgyo9xsmNDgAA+KlKE2daWlpd1gEA8DIO2TNyWrrJOwAAnlLvRrUAAOCnSJwAACNInAAAeAESJwDACIdN74BA4wQAGMGoFgAAL0DiBAAYYdNJLYkTAAArSJwAACPs+n2cNE4AgBGcHAQAgBcgcQIAjLDppJbECQCAFSROAIARPjb9WjESJwAAFpA4AQBG2PUYJ40TAGAEl6MAAOAFSJwAACPseucgEicAABaQOAEARtg0cNI4AQBmMKoFAMALkDgBAEbYNHCSOAEAsILECQAwwq7JjcYJADDCYdNZrV0bPgAARpA4AQBG2DNvkjgBALCExAkAMMKuN0CgcQIAvEZpaanS09N15MgRlZSUaMyYMWratKlGjx6tli1bSpKGDBmihISEStegcQIAjDCRN9etW6fGjRsrJydHp06d0sCBAzV27FiNGDFCI0eOrNEaNE4AgBEmJrV333234uPj3c99fX21e/duHTx4UJs2bVKLFi2Unp6u0NDQStdwuFwuV10UW1Pny0xXAHhG+K3jTJcAXLZzn86vtbVX/v0rj6/p+8UHysvLcz93Op1yOp0/+VxRUZHGjBmjwYMHq6SkRG3btlX79u21cOFCFRYWKi0trdJ9kDgBAEbUxg0QKmuUP3Ts2DGNHTtWQ4cOVWJiogoLCxUWFiZJiouLU1ZWVpXbczkKAMBrnDx5UiNHjtTEiRN13333SZJGjRqlnTt3SpK2bdumdu3aVbkGiRMAYISJ5LZo0SIVFhZqwYIFWrBggSRp8uTJeuaZZ+Tv76/IyMhqEyfHOIFawjFO1Ae1eYzzzzuOenzNwTdd4/E1f4xRLQAAFjCqBQAYYc/7BpE4AQCwhMQJADDCrt/HSeMEABhh15GnXesGAMAIEicAwAi7jmpJnAAAWEDiBAAYYc+8SeIEAMASEicAwAibHuKkcQIAzPCx6bCWUS0AABaQOAEARth1VEviBADAAhInAMAIh02PcdI4AQBGMKoFAMALkDgBAEZwOQoAAF6AxAkAMMKuxzhpnAAAI+zaOBnVAgBgAYkTAGCEXa/jJHECAGABiRMAYISPPQMnjRMAYAajWgAAvACJEwBgBJejAADgBUicAAAjOMYJAIAXIHECAIzgchQAACxgVAsAgBcgcQIAjLDr5Sg0Ti+xc+dnem7ObC37wyvK/+c/9WTmNMnlUpu2N2jy1Gny9fU1XSJQI03CQ/XhyjT1GzNfGaMTFHVVmCSpxTUR+njXv/TA5JcMV4j6jsbpBV5atkRvvrFOwcHBkqR5z81R6vgndEvnWzUtfbLe2/xX9ekbZ7hKoHp+fj6anzFE5y6USpK7STZuGKy3lzymSbNfN1keLLJp4OQYpzdo1qy55jw3z/3898/O0y2db1VpSYlOnvxGV111lcHqgJqb+fhALVm1Vce+OX3R69PG9NPC3Pf19clCQ5XhUvg4HB5/1EnddbIXGNX3rnj5+f1nuODr66ujR49oUFJ/fffdKbVs1cpgdUDNDE/sqm9OFendbfsuer1JeKh6dWmrV9Z9ZKgyeBsap5e65ppr9caG/6v7Bw/R7FkzTZcDVOvBAd3U57Yb9M6SxxTT9loty0pR1FUNNbDvzcrb8P9UUeEyXSIsctTCoy54/BhnSkqKSktLL3rN5XLJ4XAoNzfX07vDJUgdO1q/mTRZLVq0VIOQEDl8+P8nXPniRj3r/vmdJY/p/zydq+PfntGdXdtq5tK3zRUGr+PxxjlhwgRlZGTohRde4EzNK9TIhx/R9PTJ8vP3V3BwsGY8+ZTpkoBLdn3LKB386lvTZeBS2PTsIIfL5fL4fGPp0qVq0aKF4uKsn6l5vszT1QBmhN86znQJwGU79+n8Wlt7e/7p6j9kUdfrGnl8zR+rlctRHn744dpYFgAA47iOEwBghF3vHMRZIQAAWEDiBAAYYdPASeIEAMAKEicAwAybRk4aJwDACL7IGgAAL0DiBAAYweUoAAB4ARInAMAImwZOGicAwBCbdk4aJwDAa5SWlio9PV1HjhxRSUmJxowZo9atW2vy5MlyOBy6/vrrNWPGDPlU8XWLNE4AgBEmLkdZt26dGjdurJycHJ06dUoDBw7UDTfcoPHjx6tr166aPn26Nm3aVOW3e3FyEADAa9x999167LHH3M99fX21Z88edenSRZJ0xx136MMPP6xyDRonAMAIh8Pzj7y8PA0aNMj9yMvLu2ifISEhCg0NVVFRkVJTUzV+/Hi5XC45/v+1MSEhITpz5kyVdTOqBQAYURuDWqfTKafTWeVnjh07prFjx2ro0KFKTExUTk6O+73i4mKFhYVVuT2JEwDgNU6ePKmRI0dq4sSJuu+++yRJv/zlL7V9+3ZJ0pYtW9S5c+cq1yBxAgDMMHA5yqJFi1RYWKgFCxZowYIFkqSpU6fqqaee0pw5cxQdHa34+Pgq13C4XC5XXRRbU+fLTFcAeEb4reNMlwBctnOfzq+1tT87XPWxxEvRsVlDj6/5YyROAIARfDsKAABegMQJADDCrt+OQuMEABhh077JqBYAACtInAAAM2waOUmcAABYQOIEABhh18tRaJwAACPselYto1oAACwgcQIAjLBp4CRxAgBgBYkTAGCGTSMnjRMAYIRdz6plVAsAgAUkTgCAEVyOAgCAFyBxAgCMsGngJHECAGAFiRMAYIZNIyeNEwBgBJejAADgBUicAAAjuBwFAAAvQOIEABhh08BJ4wQAGGLTzsmoFgAAC0icAAAjuBwFAAAvQOIEABhh18tRaJwAACNs2jcZ1QIAYAWJEwBghk0jJ4kTAAALSJwAACO4HAUAAC9A4gQAGMHlKAAAWGDTvsmoFgAAK0icAAAj7DqqJXECAGABiRMAYIg9IyeNEwBgBKNaAAC8AIkTAGCETQMniRMAACtInAAAI+x6jJPGCQAwgpu8AwDgBUicAAAz7Bk4SZwAAFhB4gQAGGHTwEniBADAChInAMAILkcBAMACLkcBAMAL0DgBAGY4auFRQ5999plSUlIkSXv27FGPHj2UkpKilJQUrV+/vsptGdUCALzKkiVLtG7dOgUHB0uS9u7dqxEjRmjkyJE12p7ECQAwwlTgbN68uebNm+d+vnv3br333nsaNmyY0tPTVVRUVOX2NE4AgBEOh+cfeXl5GjRokPuRl5f3k/3Gx8fLz+8/A9eYmBhNmjRJK1asULNmzfTCCy9UWTejWgBAveF0OuV0Oi1tExcXp7CwMPfPWVlZVX6exAkAMMJRC/9dilGjRmnnzp2SpG3btqldu3ZVfp7ECQDwapmZmcrKypK/v78iIyOrTZwOl8vlqqPaauR8mekKAM8Iv3Wc6RKAy3bu0/m1tvaps+UeXzO8ga/H1/wxRrUAAFhA4wQAwAKOcQIAjLDrTd5JnAAAWEDiBAAYwbejAADgBUicAAAj7HqMk8YJADDCpn2TUS0AAFaQOAEAZtg0cpI4AQCwgMQJADDCrpej0DgBAEbY9axaRrUAAFhA4gQAGGHTwEniBADAChInAMAMm0ZOGicAwAi7nlXLqBYAAAtInAAAI7gcBQAAL+BwuVwu00UAAGAXJE4AACygcQIAYAGNEwAAC2icAABYQOMEAMACGicAABbQOL1IRUWFpk+fLqfTqZSUFB06dMh0ScAl++yzz5SSkmK6DHgh7hzkRd59912VlJQoLy9PO3bs0MyZM7Vw4ULTZQGWLVmyROvWrVNwcLDpUuCFSJxe5JNPPlGPHj0kSTfddJN2795tuCLg0jRv3lzz5s0zXQa8FI3TixQVFSk0NNT93NfXV2VlZQYrAi5NfHy8/PwYmMEMGqcXCQ0NVXFxsft5RUUF//gAgEU0Ti/SqVMnbdmyRZK0Y8cOtWnTxnBFAGA/xA0vEhcXpw8++EDJyclyuVx65plnTJcEALbDt6MAAGABo1oAACygcQIAYAGNEwAAC2icAABYQOMEAMACGidsb/v27erWrZtSUlKUkpKiwYMH65VXXrmktWbPnq3Vq1dr3759mj9/fqWf27hxo44fP16jNbds2aLJkydf9NpXX32lwYMH12j72vosgEvDdZyoF2677TbNnTtXklRSUqK7775bSUlJCgsLu6T1brzxRt14442Vvv/HP/5RmZmZioqKuqT1AdgXjRP1TlFRkXx8fOTr66uUlBSFh4ersLBQixcvVmZmpg4dOqSKigqNHz9eXbt21TvvvKOFCxcqIiJCpaWlio6O1vbt25Wbm6u5c+fqtdde05/+9CdVVFSoT58+6tChg/bt26e0tDStXLlSeXl5evPNN+VwOJSQkKAHHnhA+fn5Sk9PV3BwsIKDg9WoUaMa1f7xxx+7k+758+c1a9Ys+fv7q6CgQKNHj1ZBQYF69uypsWPH6tixY5o2bZouXLigwMBAZWVlXbTW3Llz9dFHH6miokL9+vXTQw895Ok/asAr0ThRL3z00UdKSUmRw+GQv7+/pk2bppCQEElSYmKi4uLitHLlSoWHh+uZZ57RqVOnNHz4cL311lvKycnRa6+9psaNG+uRRx65aN1vv/3W/RVWAQEBmjlzpm699VbdeOONyszM1Jdffqn169dr5cqVcjgceuihhxQbG6vnnntOqamp6t69uxYvXqwDBw7U6Pf44osvlJOTo6ioKC1atEhvv/22EhMTdfbsWeXk5KhBgwYaNmyY+vTpo0WLFiklJUU9e/bUtm3bNHv2bD3++OPutdasWaNXX31VUVFRWr16tef+sAEvR+NEvfDDUe2PtWrVSpK0f/9+ffLJJ9q5c6ckqaysTCdPnlRoaKjCw8MlSTfffPNF2x4+fFjXX3+9goKCJEnp6ekXvb9//34dPXrUneZOnz6tL7/8Ul988YViYmIkfX+P4Jo2zqioKD399NNq0KCBjh8/rk6dOkmSbrjhBjVs2FCS1KFDBx08eFD79+/Xiy++qKVLl8rlcsnf3/+itebMmaM5c+bo5MmT7q+TA3D5aJyo9xwOhyQpOjpaTZs21ejRo3X+/HktXLhQYWFhOnPmjAoKChQREaFdu3apadOm7m2bN2+uAwcOqKSkRAEBAUpNTdXUqVPlcDjkcrkUHR2t1q1ba+nSpXI4HPrDH/6gNm3aKDo6Wp9++qnuuOMOS997mpGRoXfffVehoaFKS0vTv++ImZ+fr+LiYgUGBmrnzp1yOp2Kjo7WyJEj1alTJ+Xn5+t//ud/3OuUlJTo7bff1pw5c+RyudSvXz/169dP1157rYf+VAHvReOE10hOTlZGRoaGDx+uoqIiDR06VAEBAcrOztaoUaPUqFGjn3zNWkREhP77v/9bw4cPl8PhUO/evRUVFaWbb75ZkyZN0vLly9WtWzcNGTJEJSUliomJUVRUlGbMmKHHH39cy5YtU0REhAIDA39SzxdffKFBgwa5n0+ePFlJSUkaPHiwwsLCFBkZqRMnTkiSGjVqpMcff1wFBQVKSEhQ69atlZaWpszMTF24cEHnz5/X1KlT3WsFBASoUaNGSkpKUqNGjdS9e3ddc801tfQnC3gXbvIOAIAFXMcJAIAFNE4AACygcQIAYAGNEwAAC2icAABYQOMEAMACGicAABbQOAEAsOB/Acpudc9c29AOAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 15:40:42,785]\u001B[0m A new study created in memory with name: no-name-14a6b67a-da24-4f15-b12e-d3ea2f450dd1\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.71722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:42:53,640]\u001B[0m Trial 0 finished with value: 0.7172222222222222 and parameters: {'n_d': 56, 'n_a': 9, 'n_steps': 19, 'gamma': 0.20841737832540652, 'n_independent': 9, 'n_shared': 10, 'lambda_sparse': 0.06672542530855098}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.67806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:43:03,209]\u001B[0m Trial 1 finished with value: 0.6780555555555555 and parameters: {'n_d': 12, 'n_a': 39, 'n_steps': 2, 'gamma': 1.608274014294965, 'n_independent': 10, 'n_shared': 6, 'lambda_sparse': 0.049327103566461264}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.69528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:43:26,493]\u001B[0m Trial 2 finished with value: 0.6952777777777778 and parameters: {'n_d': 18, 'n_a': 31, 'n_steps': 13, 'gamma': 0.26057493444271906, 'n_independent': 9, 'n_shared': 1, 'lambda_sparse': 0.06576859755806898}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.55639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:43:58,953]\u001B[0m Trial 3 finished with value: 0.5563888888888888 and parameters: {'n_d': 33, 'n_a': 22, 'n_steps': 17, 'gamma': 1.3338485481994098, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.0832073527254345}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.7075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:44:17,740]\u001B[0m Trial 4 finished with value: 0.7075 and parameters: {'n_d': 55, 'n_a': 51, 'n_steps': 9, 'gamma': 0.14566534107304105, 'n_independent': 3, 'n_shared': 5, 'lambda_sparse': 0.0974129985931965}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.69667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:44:38,377]\u001B[0m Trial 5 finished with value: 0.6966666666666665 and parameters: {'n_d': 55, 'n_a': 46, 'n_steps': 18, 'gamma': 1.9661723342424329, 'n_independent': 2, 'n_shared': 3, 'lambda_sparse': 0.001909427200602377}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.63889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:44:52,902]\u001B[0m Trial 6 finished with value: 0.638888888888889 and parameters: {'n_d': 9, 'n_a': 59, 'n_steps': 5, 'gamma': 1.2693010069428246, 'n_independent': 10, 'n_shared': 8, 'lambda_sparse': 0.06818087807817218}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.64556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:45:41,237]\u001B[0m Trial 7 finished with value: 0.6455555555555554 and parameters: {'n_d': 59, 'n_a': 38, 'n_steps': 11, 'gamma': 1.221080588508279, 'n_independent': 5, 'n_shared': 6, 'lambda_sparse': 0.07430386810138898}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.71222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:46:06,537]\u001B[0m Trial 8 finished with value: 0.7122222222222222 and parameters: {'n_d': 58, 'n_a': 27, 'n_steps': 10, 'gamma': 0.5034769874468781, 'n_independent': 1, 'n_shared': 8, 'lambda_sparse': 0.0717477848311028}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.70583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:46:19,616]\u001B[0m Trial 9 finished with value: 0.7058333333333334 and parameters: {'n_d': 45, 'n_a': 51, 'n_steps': 2, 'gamma': 1.8902022712559843, 'n_independent': 6, 'n_shared': 5, 'lambda_sparse': 0.008156209923062053}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.68667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:47:42,634]\u001B[0m Trial 10 finished with value: 0.6866666666666665 and parameters: {'n_d': 38, 'n_a': 9, 'n_steps': 15, 'gamma': 0.7282667627886696, 'n_independent': 8, 'n_shared': 10, 'lambda_sparse': 0.04279307911161168}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.67389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:47:52,714]\u001B[0m Trial 11 finished with value: 0.6738888888888889 and parameters: {'n_d': 64, 'n_a': 11, 'n_steps': 7, 'gamma': 0.5548333058222046, 'n_independent': 1, 'n_shared': 8, 'lambda_sparse': 0.054062486979664225}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.68625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:48:30,145]\u001B[0m Trial 12 finished with value: 0.68625 and parameters: {'n_d': 47, 'n_a': 20, 'n_steps': 12, 'gamma': 0.4939955217239288, 'n_independent': 4, 'n_shared': 8, 'lambda_sparse': 0.08904609868217826}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.59917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:49:48,458]\u001B[0m Trial 13 finished with value: 0.5991666666666667 and parameters: {'n_d': 49, 'n_a': 22, 'n_steps': 19, 'gamma': 0.8896574446537147, 'n_independent': 7, 'n_shared': 9, 'lambda_sparse': 0.07772656331920808}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.68444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:50:04,019]\u001B[0m Trial 14 finished with value: 0.6844444444444444 and parameters: {'n_d': 29, 'n_a': 29, 'n_steps': 8, 'gamma': 0.10724256252229691, 'n_independent': 1, 'n_shared': 10, 'lambda_sparse': 0.09934769288892734}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.70083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:51:37,842]\u001B[0m Trial 15 finished with value: 0.7008333333333333 and parameters: {'n_d': 64, 'n_a': 15, 'n_steps': 15, 'gamma': 0.4262547117508436, 'n_independent': 8, 'n_shared': 7, 'lambda_sparse': 0.061915303949579156}. Best is trial 0 with value: 0.7172222222222222.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.98911 |  0:00:03s\n",
      "epoch 1  | loss: 4.41913 |  0:00:07s\n",
      "epoch 2  | loss: 4.4627  |  0:00:10s\n",
      "epoch 3  | loss: 3.60715 |  0:00:14s\n",
      "epoch 4  | loss: 2.5083  |  0:00:18s\n",
      "epoch 5  | loss: 3.45602 |  0:00:21s\n",
      "epoch 6  | loss: 2.23641 |  0:00:25s\n",
      "epoch 7  | loss: 1.50738 |  0:00:28s\n",
      "epoch 8  | loss: 1.36654 |  0:00:32s\n",
      "epoch 9  | loss: 1.52753 |  0:00:36s\n",
      "epoch 10 | loss: 1.26099 |  0:00:39s\n",
      "epoch 11 | loss: 1.28156 |  0:00:43s\n",
      "epoch 12 | loss: 1.22035 |  0:00:47s\n",
      "epoch 13 | loss: 1.00991 |  0:00:50s\n",
      "epoch 14 | loss: 0.91661 |  0:00:54s\n",
      "epoch 15 | loss: 0.88155 |  0:00:58s\n",
      "epoch 16 | loss: 0.81715 |  0:01:01s\n",
      "epoch 17 | loss: 0.80033 |  0:01:05s\n",
      "epoch 18 | loss: 0.80676 |  0:01:09s\n",
      "epoch 19 | loss: 0.7451  |  0:01:13s\n",
      "epoch 20 | loss: 0.74374 |  0:01:16s\n",
      "epoch 21 | loss: 0.75493 |  0:01:20s\n",
      "epoch 22 | loss: 0.74767 |  0:01:24s\n",
      "epoch 23 | loss: 0.73605 |  0:01:27s\n",
      "epoch 24 | loss: 0.73564 |  0:01:31s\n",
      "epoch 25 | loss: 0.738   |  0:01:35s\n",
      "epoch 26 | loss: 0.72216 |  0:01:38s\n",
      "epoch 27 | loss: 0.7185  |  0:01:42s\n",
      "epoch 28 | loss: 0.72252 |  0:01:45s\n",
      "epoch 29 | loss: 0.7356  |  0:01:49s\n",
      "epoch 30 | loss: 0.70786 |  0:01:53s\n",
      "epoch 31 | loss: 0.7206  |  0:01:56s\n",
      "epoch 32 | loss: 0.71299 |  0:02:00s\n",
      "epoch 33 | loss: 0.70972 |  0:02:04s\n",
      "epoch 34 | loss: 0.70593 |  0:02:08s\n",
      "epoch 35 | loss: 0.69491 |  0:02:11s\n",
      "epoch 36 | loss: 0.69614 |  0:02:15s\n",
      "epoch 37 | loss: 0.70277 |  0:02:19s\n",
      "epoch 38 | loss: 0.69612 |  0:02:22s\n",
      "epoch 39 | loss: 0.69145 |  0:02:26s\n",
      "epoch 40 | loss: 0.6905  |  0:02:30s\n",
      "epoch 41 | loss: 0.68503 |  0:02:33s\n",
      "epoch 42 | loss: 0.6872  |  0:02:37s\n",
      "epoch 43 | loss: 0.70657 |  0:02:41s\n",
      "epoch 44 | loss: 0.6994  |  0:02:44s\n",
      "epoch 45 | loss: 0.6821  |  0:02:48s\n",
      "epoch 46 | loss: 0.68153 |  0:02:52s\n",
      "epoch 47 | loss: 0.66755 |  0:02:55s\n",
      "epoch 48 | loss: 0.67146 |  0:02:59s\n",
      "epoch 49 | loss: 0.66521 |  0:03:03s\n",
      "epoch 50 | loss: 0.65209 |  0:03:06s\n",
      "epoch 51 | loss: 0.64503 |  0:03:10s\n",
      "epoch 52 | loss: 0.64019 |  0:03:14s\n",
      "epoch 53 | loss: 0.63058 |  0:03:17s\n",
      "epoch 54 | loss: 0.63555 |  0:03:21s\n",
      "epoch 55 | loss: 0.62555 |  0:03:25s\n",
      "epoch 56 | loss: 0.61291 |  0:03:28s\n",
      "epoch 57 | loss: 0.59821 |  0:03:32s\n",
      "epoch 58 | loss: 0.59532 |  0:03:36s\n",
      "epoch 59 | loss: 0.58796 |  0:03:39s\n",
      "epoch 60 | loss: 0.59311 |  0:03:43s\n",
      "epoch 61 | loss: 0.59099 |  0:03:47s\n",
      "epoch 62 | loss: 0.57599 |  0:03:50s\n",
      "epoch 63 | loss: 0.56774 |  0:03:54s\n",
      "epoch 64 | loss: 0.56609 |  0:03:58s\n",
      "epoch 65 | loss: 0.56293 |  0:04:01s\n",
      "epoch 66 | loss: 0.58421 |  0:04:05s\n",
      "epoch 67 | loss: 0.55285 |  0:04:09s\n",
      "epoch 68 | loss: 0.55522 |  0:04:12s\n",
      "epoch 69 | loss: 0.56125 |  0:04:16s\n",
      "epoch 70 | loss: 0.53939 |  0:04:20s\n",
      "epoch 71 | loss: 0.52804 |  0:04:24s\n",
      "epoch 72 | loss: 0.53465 |  0:04:27s\n",
      "epoch 73 | loss: 0.53067 |  0:04:31s\n",
      "epoch 74 | loss: 0.53027 |  0:04:35s\n",
      "epoch 75 | loss: 0.51314 |  0:04:38s\n",
      "epoch 76 | loss: 0.52754 |  0:04:42s\n",
      "epoch 77 | loss: 0.51268 |  0:04:46s\n",
      "epoch 78 | loss: 0.502   |  0:04:49s\n",
      "epoch 79 | loss: 0.53266 |  0:04:53s\n",
      "epoch 80 | loss: 0.52371 |  0:04:57s\n",
      "epoch 81 | loss: 0.50517 |  0:05:00s\n",
      "epoch 82 | loss: 0.50717 |  0:05:04s\n",
      "epoch 83 | loss: 0.48369 |  0:05:07s\n",
      "epoch 84 | loss: 0.46892 |  0:05:11s\n",
      "epoch 85 | loss: 0.46273 |  0:05:15s\n",
      "epoch 86 | loss: 0.44534 |  0:05:18s\n",
      "epoch 87 | loss: 0.43436 |  0:05:22s\n",
      "epoch 88 | loss: 0.42063 |  0:05:26s\n",
      "epoch 89 | loss: 0.44428 |  0:05:29s\n",
      "epoch 90 | loss: 0.43732 |  0:05:33s\n",
      "epoch 91 | loss: 0.4448  |  0:05:37s\n",
      "epoch 92 | loss: 0.42989 |  0:05:40s\n",
      "epoch 93 | loss: 0.43849 |  0:05:44s\n",
      "epoch 94 | loss: 0.42333 |  0:05:48s\n",
      "epoch 95 | loss: 0.43885 |  0:05:51s\n",
      "epoch 96 | loss: 0.44375 |  0:05:55s\n",
      "epoch 97 | loss: 0.42906 |  0:05:59s\n",
      "epoch 98 | loss: 0.42668 |  0:06:02s\n",
      "epoch 99 | loss: 0.40385 |  0:06:06s\n",
      "Eval TABNET\n",
      "Accuracy: 0.57\n",
      "Precision: 0.58\n",
      "Recall: 0.55\n",
      "F1-score: 0.56\n",
      "ROC-AUC score: 0.57\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc4AAAHsCAYAAABbgk2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnz0lEQVR4nO3deXRV9bn/8c9JQmZISKNRqSgRoVxlcKoiUZApCKZhUE4MxKptVYqNIGDMAERRggaJUGQUxIqYKEUGEb3RIlxdQvlJUbhglaECERlMICRIxvP7w+W5oiYnG5J82ee8X2tlLc703U9w6ePn2fu7j8PlcrkEAAAaxM90AQAA2AmNEwAAC2icAABYQOMEAMACGicAABbQOAEAsIDGCduoqanRSy+9pKFDhyoxMVEDBw5Ubm6uKisrz2nNUaNGKT4+XkuXLrX8+e3btys1NfWsj/9TvXv3Vrdu3VReXn7G8ytWrFDHjh31zjvv1Pv5kydP6p577qnz9cTERJWWljZKrYCvCjBdANBQ2dnZOnHihF5++WW1bNlSp06d0vjx45WZmanc3NyzWvPw4cP68MMPtW3bNvn7+1v+fOfOnTVr1qyzOnZdWrdurcLCQg0ePNj93MqVKxUdHe3xsydOnND27dvrfH3VqlWNUSLg00icsIWDBw9qzZo1mjp1qlq2bClJCg0N1RNPPKG+fftK+j5tjR8/XnfccYcSEhL07LPPqrq6WtL3De6vf/2rkpKS1Lt3by1btkxlZWX64x//qOrqag0dOlT79+9Xx44dVVxc7D7uD4/Ly8uVmpqqxMREDRkyRFlZWaqtrdXmzZt1xx13nNXx6/K73/1Oq1evdj8uKirSqVOnFBsb635u+fLluuuuuzR48GDddttt7vXS09N1+vRpJSYmqqamRldffbUeeeQRxcfHa/v27e7fZ/bs2UpKSlJNTY2OHj2quLg4bdq0qTH+UQFej8YJW/jf//1ftW/fXuHh4Wc8f8EFFyg+Pl6S9NRTTykyMlJr1qzR3//+d/373//W4sWLJUmVlZVq3bq18vPzNWvWLOXk5KhFixZasGCBgoODtWrVKrVt27bO4xcWFqq8vFyrVq3S8uXLJUkHDhw44z1Wj19RUfGLx+rZs6c+//xzHTlyRNL3KfHH6bO8vFxvvPGGFixYoJUrVyovL8+duHNycty/j7+/v6qqqnTbbbfp3XffVefOnd1rjBo1SgEBAVq0aJEee+wxjRw5UjfddJPHfw4AaJywCT8/P9XW1tb7no0bN2rkyJFyOBwKDAxUUlKSNm7c6H69T58+kqSrrrpKlZWVOnXqVIOPf91112n37t1KSUnRggUL9Pvf/16XXXZZkxy/RYsWio+P11tvvSVJWrdunTvVSlJYWJjmzZunDRs26Pnnn9e8efPq/V2uv/76nz3n7++v6dOna+HChXK5XHrwwQcb/HcB+DoaJ2yhS5cu2rt3r8rKys54/vDhw3rggQd0+vRp1dbWyuFwuF+rra11j0olKSgoSJLc7/F0m+YfX3R06aWXqrCwUA888IDKysp033336R//+McZ72/M4w8ePFirV6/W1q1b1a5dO0VGRrpf++abbzR48GAVFRXpuuuu05gxY+r9PUJDQ3/x+aKiIgUFBWn//v06ceJEvWsA+D80TthCTEyMEhISlJGR4W6eZWVlys7OVmRkpIKDgxUXF6elS5fK5XKpsrJSr7/+um6++WZLx4mKinJfXPND4pOkZcuWKT09XXFxcZowYYLi4uK0c+fOMz7bGMf/QdeuXXX69Gnl5eVpyJAhZ7y2Y8cORUVF6c9//rPi4uK0fv16Sd9fIRwQEKCamhqP/1NQWlqqCRMmaNq0abrjjjuUmZl5VnUCvojGCduYPHmy2rdvr6SkJCUmJuquu+5S+/bt9dRTT0mSsrKyVFxcrISEBCUkJKhdu3Z66KGHLB0jKytLTz75pIYMGaI9e/boggsukPR9AqypqdHAgQM1dOhQnTx5UikpKT/77Lke/8cSExO1b98+3XLLLWc836NHD8XExGjAgAG6/fbbdejQIUVFRemrr77SBRdcoC5dumjQoEEqKSmp9/fs1auX4uLi9PDDD+vAgQN69dVXz7pWwJc4+FoxAAAajsQJAIAFNE4AACzgzkEAAJ9RU1OjrKws7du3T/7+/srJyVFYWJiysrJUWlqqmpoaPfvss/Xu66ZxAgB8xg9Xoefn52vz5s3KyclRRESEEhISNHDgQG3atEl79+6tt3FycRAAwKdUV1crICBAb775prZu3arNmzfr7rvv1oYNG9SmTRtlZmbWuf9ZOg8TZ8g1D5suAWgUJVtmmy4BOGfBTdglmuK/90sev0UFBQXux06nU06n84z3BAQEKC0tTYWFhZo1a5ZWrFihVq1aacmSJZo9e7YWLlyoRx55pM5jnHeJk8YJb0HjhDewW+P87l8N//fu6NGjGj58uL777jutW7dOrVu31s6dO5WXl6eFCxfW+TmuqgUAmOHwa/wfD1auXKn58+dLkkJCQuRwOPTb3/5WGzZskCRt2bJF7du3r3eN825UCwDwET+6t3Nz6d+/v9LT0zVixAhVV1crIyNDnTp1UlZWlvLz8xUeHq7nnnuu3jVonAAAnxEaGqqZM2f+7PmXXnqpwWvQOAEAZjRgtHo+smfVAAAYQuIEAJhh4BxnY6BxAgDMYFQLAID3I3ECAMyw6aiWxAkAgAUkTgCAGZzjBADA+5E4AQBm2PQcJ40TAGAGo1oAALwfiRMAYIZNR7UkTgAALCBxAgDMsOk5ThonAMAMRrUAAHg/EicAwAybjmrtWTUAAIaQOAEAZtg0cdI4AQBm+HFxEAAAXo/ECQAww6ajWntWDQCAISROAIAZNr0BAo0TAGAGo1oAALwfiRMAYIZNR7UkTgAALCBxAgDM4BwnAADej8QJADDDpuc4aZwAADMY1QIA4P1InAAAM2w6qiVxAgBgAYkTAGCGTc9x0jgBAGYwqgUAwPuROAEAZth0VGvPqgEAMITECQAww6aJk8YJADCDi4MAAPB+JE4AgBk2HdXas2oAAAwhcQIAzOAcJwAA3o/ECQAww6bnOGmcAAAzGNUCAOD9SJwAACMcJE4AALwfiRMAYIRdEyeNEwBghj37JqNaAACsIHECAIyw66iWxAkAgAUkTgCAEXZNnDROAIARdm2cjGoBALCAxAkAMILECQCADyBxAgDMsGfgJHECAHxHTU2N0tPTlZSUpBEjRmj//v3u19asWSOn0+lxDRonAMAIh8PR6D+erF+/XpKUn5+v1NRU5eTkSJJ27dql5cuXy+VyeVyDxgkAMMJE4+zbt6+mTJkiSfr6668VHR2tkpISTZ8+XRkZGQ2qm3OcAACvUVBQoIKCAvdjp9P5s/FrQECA0tLSVFhYqJkzZyozM1MZGRkKCgpq0DEcrobk0mYUcs3DpksAGkXJltmmSwDOWXATxquolGWNvmbxK8kNfu/Ro0fVp08fRUdHq02bNqqoqNDu3bs1bNgwZWZm1vk5EicAwGesXLlShw8f1oMPPqiQkBBFR0dr3bp1CgoK0sGDB/Xoo4/W2zQlGicAwBATN0Do37+/0tPTNWLECFVXV1sa0f6AxgkAMMPAPs7Q0FDNnDnzF1/79a9/rddff93jGlxVCwCABSROAIAR3KsWAAAfQOIEABhh18RJ4wQAGGHXxsmoFgAAC0icAAAz7Bk4SZwAAFhB4gQAGME5TgAAfACJEwBghF0TJ40TAGCEXRsno1oAACwgcQIAjCBxAgDgA0icAAAz7Bk4aZwAADMY1QIA4ANInAAAI0icAAD4ABInAMAIuyZOGicAwAx79k1GtQAAWEHiBAAYYddRLYkTAAALSJwAACNInAAA+AASp5fz83NozsRkdbj8QtXUuvTA5KUqKz+tFyYlq3WrUPn7OfSHia9o38FjpksF6lVVVaXJEzP0dVGRKisr9cCDo9Srdx9J0ttvrdFry5bqlWUFhquEFXZNnDROLzfo1s6SpN735emW667UM+OG6njpKRW8vUV/L/yXbr3+SnW8PIbGifPe2rdWKzIiUlOn5er48RI5hw1Rr9599PmuXXpzxXK5XC7TJcIiuzZORrVebs0Hn2n0U69JktpeEqUj355U926xahPTWmvnPaykgTdo4//70nCVgGf9+w/Q6NRH3I/9A/x1/HiJZuZN12OPZxisDL6mSRtnbW1tUy6PBqqpqdXCJ1M047E79eZ7/9JlF/9KJaWnNOih2TrwTbHG3dfPdImAR6FhYQoLC1d5eZnGjUnV6L88ouyJmZqQlqHQsDDT5eFsOJrgpxk0+qj2wIEDysnJ0Y4dOxQQEKDa2lp16NBB6enpateuXWMfDg30p0mvKOtXLbXxlQk6XnZKazdslyS9vWGHsh9OMFwd0DDfHDqksY+M1vCkZLVte7m++uorPT0lWxUVFdq7Z7eezXlaj6Vnmi4TXq7RG2dmZqbGjRunrl27up/btm2b0tPTlZ+f39iHgwd3D7pBbWJaa/ri/9ap01Wqra3Vh5/sVnzcf+m1tVsUd2177dpzyHSZgEffHjumhx64X+mZk3TjTd0lSW+uXitJKio6qLTxj9I0bcau5zgbvXFWVlae0TQlqVu3bo19GDTQqvc/1YInRqpw0Ri1CPDXhOl/12f/Pqg5k0bogbtu0Ymy73Rv+hLTZQIevbhwnkpPlGrBvDlaMG+OJOmFeQsVHBxsuDKcLbs2ToerkS9Fmzx5siorK3XLLbeoZcuWKi8v14YNGxQYGKgnnnjC4+dDrnm4McsBjCnZMtt0CcA5C27CvRdXjFvX6Gvuee72Rl/zpxr9ryQ7O1vvvfeePvnkE5WVlSk8PFy33Xab+vXjAhQAwP+xaeBs/MbpcDjUr18/GiUAwCtxAwQAgBF2PcdJ4wQAGGHTvsmdgwAAsILECQAwwq6jWhInAAAWkDgBAEbYNHCSOAEAsILECQAwws/PnpGTxgkAMIJRLQAAPoDECQAwgu0oAAD4ABInAMAImwZOGicAwAxGtQAA+AASJwDACBInAAA+gMQJADDCpoGTxgkAMINRLQAAPoDECQAwwqaBk8QJAIAVJE4AgBGc4wQAwAeQOAEARtg0cNI4AQBmMKoFAMAHkDgBAEbYNHDSOAEAvqOmpkZZWVnat2+f/P39lZOTo/Lyck2ZMkX+/v4KDAzUM888o+jo6DrXoHECAIwwcY5z/fr1kqT8/Hxt3rxZOTk5OnnypCZOnKhOnTopPz9fCxcuVHp6ep1r0DgBAEaYGNX27dtXvXr1kiR9/fXXio6O1hNPPKELL7xQ0veJNCgoqN41aJwAAK9RUFCggoIC92On0ymn03nGewICApSWlqbCwkLNmjXL3TS3bt2qpUuX6tVXX633GA6Xy+Vq/NLPXsg1D5suAWgUJVtmmy4BOGfBTRivuj+zsdHX/Djt1ga/9+jRoxo+fLjWrl2rDz74QHPnztWcOXN06aWX1vs5tqMAAHzGypUrNX/+fElSSEiIHA6HCgsLtXTpUr3yyisem6bEqBYAYIiJc5z9+/dXenq6RowYoerqamVkZCgjI0MXX3yx/vKXv0iSbrjhBqWmpta5Bo0TAGCEiatqQ0NDNXPmzDOe69u3r6U1GNUCAGABiRMAYIRd7xxE4gQAwAISJwDACL4dBQAAH0DiBAAYYdfESeMEABhh077JqBYAACtInAAAI+w6qiVxAgBgAYkTAGCETQMnjRMAYAajWgAAfACJEwBghE0DJ4kTAAArSJwAACP8bBo5aZwAACNs2jcZ1QIAYAWJEwBgBNtRAADwASROAIARfvYMnDROAIAZjGoBAPABJE4AgBE2DZwkTgAArCBxAgCMcMiekZPECQCABSROAIARbEcBAMACtqMAAOADSJwAACNsGjhJnAAAWEHiBAAYwRdZAwBggU37JqNaAACsIHECAIxgOwoAAD6AxAkAMMKmgZPGCQAww65X1TKqBQDAAhInAMAIe+ZNEicAAJZYSpy1tbXy86PXAgDOndduR1m3bp3Wrl2rN998Uz169NCiRYuaoy4AAM5LHhvn4sWLdfPNN2v16tXasGGD1q9f3xx1AQC8nJ+j8X+ag8dRbVBQkCQpLCxMgYGBKi8vb/KiAADez2tHtb/+9a81bNgwDRs2TLNnz1aXLl2aoy4AAM5LHhPntGnTVF5errCwMHXu3FnR0dHNURcAwMvZNHDW3TgfffTROmP0c88912QFAQBwPquzcSYlJTVnHQAAH2PXc5x1Ns7f/va3kqSysjItXLhQR48eVa9evdSxY8dmKw4A4L2a6yrYxubx4qCMjAxdeuml+s9//qPo6GhlZmY2R10AAJyXPDbO48eP684771RAQICuvfZauVyu5qgLAODlHA5Ho/80hwbdP2/Pnj2SpG+++YZb7gEAfJrH7ShZWVnKyMjQnj17lJqaqsmTJzdHXQAAL2fTU5yeG2eHDh00d+5cFRUV6bLLLlOrVq2aoy4AgJfz2i+yXr58uZKTkzV//nw5nU69/fbbzVEXAADnJY+JMz8/X6tWrVJQUJBOnTql3//+9xo4cGBz1AYA8GI2DZyeE2dkZKQCAr7vr8HBwYxqAQA+zeMt94qLizV06FB17dpVO3fuVHBwcHPWBwDwUl5356BfuuXeHXfc0aTFAABwvvN4y73jx4/rww8/VHV1tVwul44cOeJ+DQCAs2XTwOn54qDU1FRdfvnl+uKLLxQUFKSQkJDmqAsA4OW8djuKJD355JNq166dXnrpJZ04caKpawIA4LzlMXFKUkVFhb777js5HA6dOnWqqWsCAPgAE4GzpqZGWVlZ2rdvn/z9/ZWTkyOXy6XHH39cDodDV155pSZPnlzv7WU9Js4RI0bo5ZdfVo8ePdSzZ0/FxsY26i8BAEBzWb9+vaTv71GQmpqqnJwc5eTkaMyYMVq2bJlcLpfef//9etfwmDjj4+Pdf7799tt17NixcywbAAAz21H69u2rXr16SZK+/vprRUdH64MPPnBf9Hrrrbfqo48+Ur9+/epco0Gj2h+Eh4fr3nvv1fLly8++ag/+8cZTTbY20Jw6TVhrugTgnO3LG9RkazfFd20VFBSooKDA/djpdMrpdJ7xnoCAAKWlpamwsFCzZs3S+vXr3U08LCxMJ0+erPcYlhqnJL6PEwBw3vqlRvlLnnnmGY0fP17Dhw9XRUWF+/ny8nKPd8iz3PDteqcHAMD5xcQXWa9cuVLz58+XJIWEhMjhcOjqq6/W5s2bJUkbN27U9ddfX+8aHm+592Mul0sHDhzwWBgAAOej/v37Kz09XSNGjFB1dbUyMjJ0xRVXaOLEiZoxY4ZiY2PPuLbnl1i65V59zwMAYIWfgQFmaGioZs6c+bPnly5d2uA1PN5yDwCApmCicTaGprioCQAAr2X5qloAABqDXS829dg4Dx8+rNzcXJWUlCg+Pl4dO3ZU165dm6M2AADOOx5HtRMnTtSwYcNUWVmp66+/Xk8//XRz1AUA8HJ+jsb/aZa6Pb2hoqJC3bt3l8PhUGxsrIKCgpqjLgAAzkseR7WBgYH6n//5H9XW1mrbtm0KDAxsjroAAF7Opqc4PSfOKVOmaMWKFSopKdHixYuVnZ3dDGUBALydn8PR6D/NwWPivOiii5SXl9cctQAAcN7z2Djj4uLcfz5+/LguvfRSrVu3rkmLAgB4P7veSMBj4/zwww/dfy4qKtLs2bObtCAAAM5nlm6A0KZNG+3du7epagEA+BC7XhzksXH++FtSjhw5ol/96ldNXhQAwPs118U8jc1j4xw4cKD7Sz2DgoJ09dVXN3lRAACcrzw2zkWLFum1115rjloAAD7EpoHTc+OMiIjQyy+/rHbt2snP7/troH58pS0AAL7EY+Ns3bq1Pv/8c33++efu52icAIBzZdfv46yzcY4ZM0bPP/+8cnJymrMeAICPsOvFQXXuPy0uLm7OOgAAsIU6E+eBAwc0Y8aMX3zt0UcfbbKCAAC+waaBs+7GGRwcrHbt2jVnLQAAnPfqbJzR0dEaMmRIc9YCAPAhdr04qM5znNzoAACAn6szcaalpTVnHQAAH+OQPSOnpZu8AwDQWLxuVAsAAH6OxAkAMILECQCADyBxAgCMcNj0Dgg0TgCAEYxqAQDwASROAIARNp3UkjgBALCCxAkAMMKu38dJ4wQAGMHFQQAA+AASJwDACJtOakmcAABYQeIEABjhZ9OvFSNxAgBgAYkTAGCEXc9x0jgBAEawHQUAAB9A4gQAGGHXOweROAEAsIDECQAwwqaBk8YJADCDUS0AAD6AxAkAMMKmgZPECQCAFSROAIARdk1uNE4AgBEOm85q7drwAQAwgsQJADDCnnmTxAkAgCUkTgCAEdwAAQAAH0DiBAAYYc+8SeMEABhi00kto1oAAKwgcQIAjOAGCAAA+AASJwDACLsmNxonAMAIRrUAAPgAEicAwAgTebOqqkoZGRkqKipSZWWlRo0apUsuuUSTJ0+Wv7+/Lr/8cj399NPy86s7V9I4AQA+Y/Xq1YqMjFRubq5KSko0ZMgQXXXVVRo9erR69uypcePG6YMPPlDv3r3rXIPGCQAwwsQ5zgEDBig+Pt792N/fX506ddLx48flcrlUXl6ugID6WyONEwBgRFNcZFNQUKCCggL3Y6fTKafT6X4cFhYmSSorK1NqaqrGjBkjh8OhJ598UnPnzlXLli1144031nsMGicAwGv8tFH+kkOHDmn06NFKTk5WQkKCunfvrldffVVXXnmlXn31VU2bNk2TJ0+u8/M0TgCAESZGtceOHdP999+vSZMmqXv37pKkiIgIhYeHS5IuvPBCbd26td41aJwAAJ8xb948lZaWas6cOZozZ44k6amnntLYsWMVEBCgFi1aaMqUKfWu4XC5XK7mKLahPt593HQJQKNIfuEj0yUA52xf3qAmW3vlZ980+pqDu1zU6Gv+FDdAAADAAka1AAAjbHrHPRonAMAMPyP3Djp3jGoBALCAxAkAMMKuo1oSJwAAFpA4AQBGOGx6jpPGCQAwglEtAAA+gMQJADCC7SgAAPgAEicAwAi7nuOkcQIAjLBr42RUCwCABSROAIARdt3HSeIEAMACEicAwAg/ewZOGicAwAxGtQAA+AASJwDACLajAADgA0icAAAjOMcJAIAPIHECAIxgOwoAABYwqgUAwAeQOAEARth1OwqN08tVV1dr0fNT9O2RQ6qqqtLvnPfp4w3v6kRJsSTp2OFDuuI3V+nPaU8brhSon59DynF2UeyFYaqtdWnCa58pMMBPU4d3lsMh7So6qewVO1TrMl0pvB2N08t9vH6dwltF6MHxT6is9IQmpaZoxpLVkqTyk6Walv5nJf9prOEqAc/6XBUjSbpr1se68YooZSV2kkvS9LX/1j/3Fiv37i7qe3WM/nv7YbOFosFsGjhpnN7uhrg+ur5Hb/djfz9/95/ffHWh+iYMV2RUtInSAEsKdxzWP3YekSS1iQrRsbJKZb2xXbUuqYW/Qxe0DNKxk5WGq4QVfjad1XJxkJcLDglVSGiYvjtVrtlTH9fQex6SJJUeL9bOT7folr6DDFcINFxNrUvTk7sqe+hVWvfpIdW6pDatQ/RuWk+1Dg/U3iNlpkuED6Bx+oBvjx7WM+l/1s29b1f3XvGSpC0f/kM39YyXn7+/h08D55fxyz5V76kblDO8s0IC/VVU8p16T/1Ayz7ar6zB/2W6PFjgaIKf5tDoo9qUlBRVVVWd8ZzL5ZLD4VB+fn5jHw4enCj5VtOzUpUyarz+q9sN7ud3btuihKT7DFYGWDPk+ja6KCJYc9/fo9OVNap1SfPvv06Tlu/Qf46dUllFtWq5MgjNoNEb5/jx45WVlaUXXnhB/qQZ4956fYnKy0q1Kn+xVuUvliSNeyJPh4q+0gUXtTFcHdBw73z2jXLv7qKCh29SgL+fpqzcqW/LKpWb3FVV1S59V1Wjxws+M10mrLDnKU45XC5Xo/8v2osvvqjLLrtM/fr1s/zZj3cfb+xyACOSX/jIdAnAOduX13TXQWzec6LR17zxiohGX/OnmuSq2j/+8Y9NsSwAAMaxHQUAYIRNd6NwVS0AAFaQOAEARtg0cJI4AQCwgsQJADDDppGTxgkAMIIvsgYAwAeQOAEARrAdBQAAH0DiBAAYYdPASeMEABhi087JqBYAAAtInAAAI9iOAgCADyBxAgCMsOt2FBonAMAIm/ZNRrUAAFhB4gQAmGHTyEniBADAAhInAMAItqMAAOADSJwAACPYjgIAgAU27ZuMagEAsILECQAww6aRk8QJAIAFJE4AgBF23Y5C4wQAGMFVtQAAnOeqqqqUkZGhoqIiVVZWatSoUerWrZuysrJUWlqqmpoaPfvss2rbtm2da9A4AQBGmAicq1evVmRkpHJzc1VSUqIhQ4bopptuUkJCggYOHKhNmzZp7969NE4AACRpwIABio+Pdz/29/fX1q1b1bFjR917771q06aNMjMz612Dq2oBAGY4Gv+noKBAQ4cOdf8UFBSccciwsDCFh4errKxMqampGjNmjIqKitSqVSstWbJEF198sRYuXFhv2SROAIARTXFVrdPplNPprPc9hw4d0ujRo5WcnKyEhARNmzZNvXv3liT17t1beXl59X6exAkA8BnHjh3T/fffrwkTJujOO++UJF133XXasGGDJGnLli1q3759vWuQOAEARpjYjjJv3jyVlpZqzpw5mjNnjiRp2rRpysrKUn5+vsLDw/Xcc8/Vu4bD5XK5mqPYhvp493HTJQCNIvmFj0yXAJyzfXmDmmztf39zqtHX7HhRaKOv+VMkTgCAETa9/wHnOAEAsILECQAww6aRk8YJADDCrjd5Z1QLAIAFJE4AgBF2/XYUEicAABaQOAEARtg0cNI4AQCG2LRzMqoFAMACEicAwAi2owAA4ANInAAAI+y6HYXGCQAwwqZ9k1EtAABWkDgBAGbYNHKSOAEAsIDECQAwgu0oAAD4ABInAMAItqMAAGCBTfsmo1oAAKwgcQIAjLDrqJbECQCABSROAIAh9oycNE4AgBGMagEA8AEkTgCAETYNnCROAACsIHECAIyw6zlOGicAwAhu8g4AgA8gcQIAzLBn4CRxAgBgBYkTAGCETQMniRMAACtInAAAI9iOAgCABWxHAQDAB5A4AQBm2DNwkjgBALCCxAkAMMKmgZPGCQAww65X1TKqBQDAAhInAMAItqMAAOADSJwAACM4xwkAgA+gcQIAYAGjWgCAEYxqAQDwASROAIARbEcBAMAHkDgBAEbY9RwnjRMAYIRN+yajWgAArCBxAgDMsGnkJHECAGABiRMAYIRdt6PQOAEARtj1qlpGtQAAWEDiBAAYYdPASeIEAMAKEicAwAybRk4aJwDACLteVcuoFgDgM6qqqjRhwgQlJyfrzjvv1Pvvv+9+bc2aNXI6nR7XIHECAIwwsR1l9erVioyMVG5urkpKSjRkyBD16dNHu3bt0vLly+VyuTyuQeIEAPiMAQMG6JFHHnE/9vf3V0lJiaZPn66MjIwGreFwNaS9AgBgAwUFBSooKHA/djqdvzh+LSsr06hRo3TXXXfpnXfe0bhx4xQUFKRHH31Ur7/+er3HoHECAHzKoUOHNHr0aCUnJ6tDhw5KT09XVFSUKioqtHv3bg0bNkyZmZl1fp7GCQDwGceOHVNKSoomTZqk7t27n/HawYMHG5Q4OccJAPAZ8+bNU2lpqebMmaOUlBSlpKTo9OnTltYgcQIAYAGJEwAAC2icAABYQOP0IbW1tZo0aZKcTqdSUlL01VdfmS4JOGuffvqpUlJSTJcBH8Sdg3zIe++9p8rKShUUFGjbtm2aNm2a5s6da7oswLKFCxdq9erVCgkJMV0KfBCJ04d88sknuuWWWyRJ3bp1044dOwxXBJydtm3b6q9//avpMuCjaJw+pKysTOHh4e7H/v7+qq6uNlgRcHbi4+MVEMDADGbQOH1IeHi4ysvL3Y9ra2v5jw8AWETj9CHXXnutNm7cKEnatm2bOnToYLgiALAf4oYP6devnz766CMlJSXJ5XJp6tSppksCANvhzkEAAFjAqBYAAAtonAAAWEDjBADAAhonAAAW0DgBALCAxgnb27x5s7p37+7+Utrhw4frlVdeOau1pk+frhUrVmjXrl2aPXt2ne8rLCzU4cOHG7Tmxo0b9fjjj5/x3MGDBzV8+PAGfb6p3gvg7LCPE17hpptuUl5eniSpsrJSAwYMUGJiolq1anVW63Xq1EmdOnWq8/W//e1vys7OVkxMzFmtD8C+aJzwOmVlZfLz85O/v79SUlLUunVrlZaWasGCBcrOztZXX32l2tpajRkzRjfeeKPeffddzZ07V1FRUaqqqlJsbKw2b96s/Px85eXl6Y033tBrr72m2tpa9enTR507d9auXbuUlpamZcuWqaCgQG+99ZYcDocGDhyoe+65R3v27FFGRoZCQkIUEhKiiIiIBtX+z3/+0510T58+rWeeeUYtWrRQcXGxHnroIRUXF6tnz54aPXq0Dh06pIkTJ6qiokJBQUGaMmXKGWvl5eVp06ZNqq2t1aBBg3Tvvfc29l814JNonPAKmzZtUkpKihwOh1q0aKGJEycqLCxMkpSQkKB+/fpp2bJlat26taZOnaqSkhKNHDlSa9euVW5urt544w1FRkbqgQceOGPdb7/91v0VVoGBgZo2bZpuuOEGderUSdnZ2dq/f7/efvttLVu2TA6HQ/fee6/i4uI0c+ZMpaamqkePHlqwYIH27t3boN/jyy+/VG5urmJiYjRv3jy98847SkhI0KlTp5Sbm6vQ0FCNGDFCffr00bx585SSkqKePXvq448/1vTp0zV27Fj3WitXrtTSpUsVExOjFStWNN5fNuDjaJzwCj8e1f5Uu3btJElffPGFPvnkE3322WeSpOrqah07dkzh4eFq3bq1JOmaa64547MHDhzQlVdeqeDgYElSRkbGGa9/8cUX+vrrr91p7sSJE9q/f7++/PJLdenSRdL39whuaOOMiYnR008/rdDQUB0+fFjXXnutJOk3v/mNWrZsKUnq3Lmz9u3bpy+++ELz58/Xiy++KJfLpRYtWpyx1owZMzRjxgwdO3bM/XVyAM4djRNez+FwSJJiY2N10UUX6aGHHtLp06c1d+5ctWrVSidPnlRxcbGioqK0fft2XXTRRe7Ptm3bVnv37lVlZaUCAwOVmpqqzMxMORwOuVwuxcbGqn379nrxxRflcDi0ZMkSdejQQbGxsfrXv/6lW2+91dL3nmZlZem9995TeHi40tLS9MMdMffs2aPy8nIFBQXps88+k9PpVGxsrO6//35de+212rNnj7Zs2eJep7KyUu+8845mzJghl8ulQYMGadCgQWrTpk0j/a0CvovGCZ+RlJSkrKwsjRw5UmVlZUpOTlZgYKBycnL0hz/8QRERET/7mrWoqCj96U9/0siRI+VwOHTbbbcpJiZG11xzjR577DEtXrxY3bt31913363Kykp16dJFMTExmjx5ssaOHatFixYpKipKQUFBP6vnyy+/1NChQ92PH3/8cSUmJmr48OFq1aqVoqOjdeTIEUlSRESExo4dq+LiYg0cOFDt27dXWlqasrOzVVFRodOnTyszM9O9VmBgoCIiIpSYmKiIiAj16NFDl1xySRP9zQK+hZu8AwBgAfs4AQCwgMYJAIAFNE4AACygcQIAYAGNEwAAC2icAABYQOMEAMACGicAABb8f0AzFYW+ipJzAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 15:57:46,910]\u001B[0m A new study created in memory with name: no-name-a01726fe-0e82-4702-9f6d-86cbf8207868\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.83611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:58:48,564]\u001B[0m Trial 0 finished with value: 0.836111111111111 and parameters: {'n_d': 21, 'n_a': 41, 'n_steps': 16, 'gamma': 0.28606101043240867, 'n_independent': 9, 'n_shared': 4, 'lambda_sparse': 0.07891478572476011}. Best is trial 0 with value: 0.836111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.51125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:59:27,834]\u001B[0m Trial 1 finished with value: 0.51125 and parameters: {'n_d': 25, 'n_a': 10, 'n_steps': 19, 'gamma': 1.098684669418074, 'n_independent': 10, 'n_shared': 8, 'lambda_sparse': 0.09566438214466134}. Best is trial 0 with value: 0.836111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.77472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 15:59:49,664]\u001B[0m Trial 2 finished with value: 0.7747222222222222 and parameters: {'n_d': 59, 'n_a': 9, 'n_steps': 12, 'gamma': 1.5421833255652253, 'n_independent': 5, 'n_shared': 2, 'lambda_sparse': 0.001754283128126297}. Best is trial 0 with value: 0.836111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.83111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:00:21,609]\u001B[0m Trial 3 finished with value: 0.8311111111111111 and parameters: {'n_d': 46, 'n_a': 46, 'n_steps': 4, 'gamma': 0.5676593899336834, 'n_independent': 9, 'n_shared': 10, 'lambda_sparse': 0.054264305815857256}. Best is trial 0 with value: 0.836111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.68625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:01:33,650]\u001B[0m Trial 4 finished with value: 0.6862499999999999 and parameters: {'n_d': 30, 'n_a': 33, 'n_steps': 14, 'gamma': 1.132639306240273, 'n_independent': 8, 'n_shared': 8, 'lambda_sparse': 0.007768161881505563}. Best is trial 0 with value: 0.836111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.81639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:01:52,642]\u001B[0m Trial 5 finished with value: 0.8163888888888888 and parameters: {'n_d': 26, 'n_a': 45, 'n_steps': 5, 'gamma': 1.2211169377938018, 'n_independent': 2, 'n_shared': 10, 'lambda_sparse': 0.0161721839514923}. Best is trial 0 with value: 0.836111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.78028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:02:08,987]\u001B[0m Trial 6 finished with value: 0.7802777777777777 and parameters: {'n_d': 37, 'n_a': 33, 'n_steps': 19, 'gamma': 1.2823298057265609, 'n_independent': 1, 'n_shared': 1, 'lambda_sparse': 0.03378703209702228}. Best is trial 0 with value: 0.836111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.77222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:02:18,498]\u001B[0m Trial 7 finished with value: 0.7722222222222221 and parameters: {'n_d': 61, 'n_a': 25, 'n_steps': 5, 'gamma': 1.5318673551487292, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.05433505103146323}. Best is trial 0 with value: 0.836111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.73972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:04:45,683]\u001B[0m Trial 8 finished with value: 0.7397222222222222 and parameters: {'n_d': 38, 'n_a': 18, 'n_steps': 15, 'gamma': 1.1463920277871076, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.04394513461743365}. Best is trial 0 with value: 0.836111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.82361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:04:59,121]\u001B[0m Trial 9 finished with value: 0.8236111111111111 and parameters: {'n_d': 31, 'n_a': 43, 'n_steps': 12, 'gamma': 0.3136792413930119, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.009318472487096932}. Best is trial 0 with value: 0.836111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.86389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:05:10,469]\u001B[0m Trial 10 finished with value: 0.8638888888888889 and parameters: {'n_d': 8, 'n_a': 64, 'n_steps': 8, 'gamma': 0.1520394495941363, 'n_independent': 4, 'n_shared': 4, 'lambda_sparse': 0.08657790243831177}. Best is trial 10 with value: 0.8638888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:05:23,018]\u001B[0m Trial 11 finished with value: 0.8499999999999999 and parameters: {'n_d': 8, 'n_a': 63, 'n_steps': 8, 'gamma': 0.10392343810383561, 'n_independent': 4, 'n_shared': 4, 'lambda_sparse': 0.08553378766052151}. Best is trial 10 with value: 0.8638888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.82806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:05:37,481]\u001B[0m Trial 12 finished with value: 0.8280555555555555 and parameters: {'n_d': 8, 'n_a': 64, 'n_steps': 8, 'gamma': 0.12681349948901366, 'n_independent': 4, 'n_shared': 5, 'lambda_sparse': 0.0989699779037281}. Best is trial 10 with value: 0.8638888888888889.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:05:41,606]\u001B[0m Trial 13 finished with value: 0.8183333333333334 and parameters: {'n_d': 12, 'n_a': 64, 'n_steps': 1, 'gamma': 0.4832278166704169, 'n_independent': 3, 'n_shared': 4, 'lambda_sparse': 0.07832036628663486}. Best is trial 10 with value: 0.8638888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.81833\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.82278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:05:59,278]\u001B[0m Trial 14 finished with value: 0.8227777777777777 and parameters: {'n_d': 15, 'n_a': 55, 'n_steps': 8, 'gamma': 0.7417148062612279, 'n_independent': 4, 'n_shared': 3, 'lambda_sparse': 0.07567296780102237}. Best is trial 10 with value: 0.8638888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.84694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:06:37,046]\u001B[0m Trial 15 finished with value: 0.8469444444444445 and parameters: {'n_d': 17, 'n_a': 55, 'n_steps': 9, 'gamma': 0.12745227678090562, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.06915253205611806}. Best is trial 10 with value: 0.8638888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.82778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:06:56,581]\u001B[0m Trial 16 finished with value: 0.8277777777777778 and parameters: {'n_d': 8, 'n_a': 56, 'n_steps': 11, 'gamma': 0.8279149873409511, 'n_independent': 3, 'n_shared': 6, 'lambda_sparse': 0.08886686281364786}. Best is trial 10 with value: 0.8638888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.79556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:07:26,483]\u001B[0m Trial 17 finished with value: 0.7955555555555556 and parameters: {'n_d': 47, 'n_a': 59, 'n_steps': 7, 'gamma': 1.980180944702211, 'n_independent': 5, 'n_shared': 3, 'lambda_sparse': 0.08673973491588693}. Best is trial 10 with value: 0.8638888888888889.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:07:35,680]\u001B[0m Trial 18 finished with value: 0.8236111111111112 and parameters: {'n_d': 19, 'n_a': 51, 'n_steps': 2, 'gamma': 0.4175330247271663, 'n_independent': 1, 'n_shared': 7, 'lambda_sparse': 0.0682493385594719}. Best is trial 10 with value: 0.8638888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.82361\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.86028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:07:44,138]\u001B[0m Trial 19 finished with value: 0.8602777777777777 and parameters: {'n_d': 13, 'n_a': 49, 'n_steps': 6, 'gamma': 0.10625444021006258, 'n_independent': 3, 'n_shared': 5, 'lambda_sparse': 0.09906521884764151}. Best is trial 10 with value: 0.8638888888888889.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:07:51,302]\u001B[0m Trial 20 finished with value: 0.8241666666666666 and parameters: {'n_d': 23, 'n_a': 51, 'n_steps': 3, 'gamma': 0.6362372003840716, 'n_independent': 2, 'n_shared': 5, 'lambda_sparse': 0.09793860963035166}. Best is trial 10 with value: 0.8638888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.82417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.3982  |  0:00:00s\n",
      "epoch 1  | loss: 0.92491 |  0:00:01s\n",
      "epoch 2  | loss: 0.85917 |  0:00:02s\n",
      "epoch 3  | loss: 0.83069 |  0:00:02s\n",
      "epoch 4  | loss: 0.80004 |  0:00:03s\n",
      "epoch 5  | loss: 0.78032 |  0:00:04s\n",
      "epoch 6  | loss: 0.77227 |  0:00:04s\n",
      "epoch 7  | loss: 0.75367 |  0:00:05s\n",
      "epoch 8  | loss: 0.74621 |  0:00:06s\n",
      "epoch 9  | loss: 0.74479 |  0:00:06s\n",
      "epoch 10 | loss: 0.72201 |  0:00:07s\n",
      "epoch 11 | loss: 0.72815 |  0:00:08s\n",
      "epoch 12 | loss: 0.70688 |  0:00:09s\n",
      "epoch 13 | loss: 0.6974  |  0:00:09s\n",
      "epoch 14 | loss: 0.69152 |  0:00:10s\n",
      "epoch 15 | loss: 0.6768  |  0:00:11s\n",
      "epoch 16 | loss: 0.68554 |  0:00:11s\n",
      "epoch 17 | loss: 0.67236 |  0:00:12s\n",
      "epoch 18 | loss: 0.66728 |  0:00:13s\n",
      "epoch 19 | loss: 0.66248 |  0:00:13s\n",
      "epoch 20 | loss: 0.64597 |  0:00:14s\n",
      "epoch 21 | loss: 0.63984 |  0:00:15s\n",
      "epoch 22 | loss: 0.63083 |  0:00:16s\n",
      "epoch 23 | loss: 0.61685 |  0:00:16s\n",
      "epoch 24 | loss: 0.60936 |  0:00:17s\n",
      "epoch 25 | loss: 0.59837 |  0:00:18s\n",
      "epoch 26 | loss: 0.58321 |  0:00:18s\n",
      "epoch 27 | loss: 0.57895 |  0:00:19s\n",
      "epoch 28 | loss: 0.5799  |  0:00:20s\n",
      "epoch 29 | loss: 0.56998 |  0:00:20s\n",
      "epoch 30 | loss: 0.56457 |  0:00:21s\n",
      "epoch 31 | loss: 0.54715 |  0:00:22s\n",
      "epoch 32 | loss: 0.54959 |  0:00:22s\n",
      "epoch 33 | loss: 0.54306 |  0:00:23s\n",
      "epoch 34 | loss: 0.52328 |  0:00:24s\n",
      "epoch 35 | loss: 0.52251 |  0:00:25s\n",
      "epoch 36 | loss: 0.50978 |  0:00:25s\n",
      "epoch 37 | loss: 0.51211 |  0:00:26s\n",
      "epoch 38 | loss: 0.49973 |  0:00:27s\n",
      "epoch 39 | loss: 0.48634 |  0:00:27s\n",
      "epoch 40 | loss: 0.47627 |  0:00:28s\n",
      "epoch 41 | loss: 0.46997 |  0:00:29s\n",
      "epoch 42 | loss: 0.4601  |  0:00:29s\n",
      "epoch 43 | loss: 0.46229 |  0:00:30s\n",
      "epoch 44 | loss: 0.4423  |  0:00:31s\n",
      "epoch 45 | loss: 0.4606  |  0:00:32s\n",
      "epoch 46 | loss: 0.44242 |  0:00:32s\n",
      "epoch 47 | loss: 0.45645 |  0:00:33s\n",
      "epoch 48 | loss: 0.43576 |  0:00:34s\n",
      "epoch 49 | loss: 0.42621 |  0:00:34s\n",
      "epoch 50 | loss: 0.43573 |  0:00:35s\n",
      "epoch 51 | loss: 0.42516 |  0:00:36s\n",
      "epoch 52 | loss: 0.41981 |  0:00:36s\n",
      "epoch 53 | loss: 0.41693 |  0:00:37s\n",
      "epoch 54 | loss: 0.40722 |  0:00:38s\n",
      "epoch 55 | loss: 0.39812 |  0:00:38s\n",
      "epoch 56 | loss: 0.39622 |  0:00:39s\n",
      "epoch 57 | loss: 0.3876  |  0:00:40s\n",
      "epoch 58 | loss: 0.3832  |  0:00:41s\n",
      "epoch 59 | loss: 0.37546 |  0:00:41s\n",
      "epoch 60 | loss: 0.37904 |  0:00:42s\n",
      "epoch 61 | loss: 0.35873 |  0:00:43s\n",
      "epoch 62 | loss: 0.36449 |  0:00:43s\n",
      "epoch 63 | loss: 0.3452  |  0:00:44s\n",
      "epoch 64 | loss: 0.34723 |  0:00:45s\n",
      "epoch 65 | loss: 0.33702 |  0:00:45s\n",
      "epoch 66 | loss: 0.32906 |  0:00:46s\n",
      "epoch 67 | loss: 0.32932 |  0:00:47s\n",
      "epoch 68 | loss: 0.33185 |  0:00:47s\n",
      "epoch 69 | loss: 0.33085 |  0:00:48s\n",
      "epoch 70 | loss: 0.34103 |  0:00:49s\n",
      "epoch 71 | loss: 0.33701 |  0:00:49s\n",
      "epoch 72 | loss: 0.32703 |  0:00:50s\n",
      "epoch 73 | loss: 0.32227 |  0:00:51s\n",
      "epoch 74 | loss: 0.33036 |  0:00:51s\n",
      "epoch 75 | loss: 0.31602 |  0:00:52s\n",
      "epoch 76 | loss: 0.3289  |  0:00:53s\n",
      "epoch 77 | loss: 0.3186  |  0:00:54s\n",
      "epoch 78 | loss: 0.32591 |  0:00:54s\n",
      "epoch 79 | loss: 0.31615 |  0:00:55s\n",
      "epoch 80 | loss: 0.30224 |  0:00:56s\n",
      "epoch 81 | loss: 0.31086 |  0:00:56s\n",
      "epoch 82 | loss: 0.30796 |  0:00:57s\n",
      "epoch 83 | loss: 0.29063 |  0:00:58s\n",
      "epoch 84 | loss: 0.29372 |  0:00:58s\n",
      "epoch 85 | loss: 0.27533 |  0:00:59s\n",
      "epoch 86 | loss: 0.27138 |  0:01:00s\n",
      "epoch 87 | loss: 0.27894 |  0:01:00s\n",
      "epoch 88 | loss: 0.26162 |  0:01:01s\n",
      "epoch 89 | loss: 0.26854 |  0:01:02s\n",
      "epoch 90 | loss: 0.27063 |  0:01:03s\n",
      "epoch 91 | loss: 0.26258 |  0:01:03s\n",
      "epoch 92 | loss: 0.26654 |  0:01:04s\n",
      "epoch 93 | loss: 0.26205 |  0:01:05s\n",
      "epoch 94 | loss: 0.25419 |  0:01:05s\n",
      "epoch 95 | loss: 0.2633  |  0:01:06s\n",
      "epoch 96 | loss: 0.27028 |  0:01:07s\n",
      "epoch 97 | loss: 0.2733  |  0:01:07s\n",
      "epoch 98 | loss: 0.27403 |  0:01:08s\n",
      "epoch 99 | loss: 0.27002 |  0:01:09s\n",
      "Eval TABNET\n",
      "Accuracy: 0.55\n",
      "Precision: 0.54\n",
      "Recall: 0.62\n",
      "F1-score: 0.58\n",
      "ROC-AUC score: 0.55\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc4AAAHsCAYAAABbgk2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoFUlEQVR4nO3deXSU9b3H8c9kshASSIjRqAhIBFKqIOKKgCBbEEjDogwFYpFahYuNgCBkQRDUgEEQpazuIiZKlUXEFi1L9RT0qlS41aKAAgFZJBASzDpz//B2rqjJ5IFJfnky79c5cw6z/Z5vwjl8+XyfzeHxeDwCAADVEmS6AAAA7ITGCQCABTROAAAsoHECAGABjRMAAAtonAAAWEDjhG1UVFTo+eef1+DBg5WcnKx+/fopOztbpaWl57Xm2LFjlZiYqBUrVlj+/s6dO5WamnrO2/+pHj16qEOHDioqKjrr9TfeeEMJCQl65513qvz+6dOndeedd1b6fnJysgoKCvxSKxCogk0XAFTXjBkzdOrUKb344otq1KiRzpw5o0mTJikjI0PZ2dnntOaRI0f0/vvva8eOHXI6nZa/365dOz311FPntO3KNGnSRBs3btTAgQO9r61evVqxsbE+v3vq1Cnt3Lmz0vfXrFnjjxKBgEbihC0cPHhQ69at02OPPaZGjRpJkho2bKiHH35YvXr1kvRD2po0aZIGDBigpKQkPf744yovL5f0Q4N7+umnNWzYMPXo0UMrV65UYWGh7r77bpWXl2vw4MHav3+/EhISdOLECe92//O8qKhIqampSk5O1qBBg5SZmSm3263t27drwIAB57T9yvzmN7/R2rVrvc/z8vJ05swZxcfHe19btWqV7rjjDg0cOFC33nqrd720tDQVFxcrOTlZFRUVuuqqq3T//fcrMTFRO3fu9P48Cxcu1LBhw1RRUaFjx46pS5cu2rZtmz/+qoB6j8YJW/if//kftWrVSpGRkWe9fuGFFyoxMVGS9Mgjjyg6Olrr1q3Tn//8Z/373//Wc889J0kqLS1VkyZNlJOTo6eeekpZWVkKCQnRsmXL1KBBA61Zs0bNmzevdPsbN25UUVGR1qxZo1WrVkmSDhw4cNZnrG6/pKTkF7fVrVs3ffHFFzp69KikH1Lij9NnUVGRXn/9dS1btkyrV6/W/PnzvYk7KyvL+/M4nU6VlZXp1ltv1V/+8he1a9fOu8bYsWMVHBysZ599Vg8++KBGjhypm266yeffAwAaJ2wiKChIbre7ys9s3bpVI0eOlMPhUGhoqIYNG6atW7d63+/Zs6ck6corr1RpaanOnDlT7e1fe+21+uqrr5SSkqJly5bpd7/7nVq0aFEj2w8JCVFiYqLeeustSdKGDRu8qVaSIiIitGTJEm3ZskVPPvmklixZUuXPct111/3sNafTqblz52r58uXyeDy69957q/27AAIdjRO20L59e+3du1eFhYVnvX7kyBHdc889Ki4ultvtlsPh8L7ndru9o1JJCgsLkyTvZ3xdpvnHBx01a9ZMGzdu1D333KPCwkLddddd+tvf/nbW5/25/YEDB2rt2rX65JNP1LJlS0VHR3vf+/bbbzVw4EDl5eXp2muv1fjx46v8ORo2bPiLr+fl5SksLEz79+/XqVOnqlwDwP+jccIW4uLilJSUpPT0dG/zLCws1IwZMxQdHa0GDRqoS5cuWrFihTwej0pLS/Xaa6/p5ptvtrSdmJgY78E1/0l8krRy5UqlpaWpS5cumjx5srp06aJ//etfZ33XH9v/j6uvvlrFxcWaP3++Bg0adNZ7u3btUkxMjP7rv/5LXbp00aZNmyT9cIRwcHCwKioqfP6noKCgQJMnT9bs2bM1YMAAZWRknFOdQCCiccI2pk+frlatWmnYsGFKTk7WHXfcoVatWumRRx6RJGVmZurEiRNKSkpSUlKSWrZsqTFjxljaRmZmpmbOnKlBgwZpz549uvDCCyX9kAArKirUr18/DR48WKdPn1ZKSsrPvnu+2/+x5ORk7du3T127dj3r9c6dOysuLk59+/bVbbfdpsOHDysmJkbffPONLrzwQrVv3179+/dXfn5+lT9n9+7d1aVLF9133306cOCAXnnllXOuFQgkDm4rBgBA9ZE4AQCwgMYJAIAFNE4AACygcQIAYAGNEwAAC+rcRd4f37THdAmAX3z4NRcVgP2tuqtjja0dfs19fl/z+08X+n3NnyJxAgBgQZ1LnACAAOGwZ3ajcQIAzPjRtZ3txJ7tHgAAQ0icAAAzbDqqtWfVAAAYQuIEAJhh032cNE4AgBmMagEAqP9InAAAM2w6qiVxAgBgAYkTAGAG+zgBAKj/SJwAADNsuo+TxgkAMINRLQAA9R+JEwBghk1HtSROAAAsIHECAMyw6T5OGicAwAxGtQAA1H8kTgCAGTYd1dqzagAADCFxAgDMsGnipHECAMwI4uAgAADqPRInAMAMRrUAANRtFRUVyszM1L59++R0OpWVlaWIiAhlZmaqoKBAFRUVevzxx9W8efNK16BxAgDMMHABhE2bNkmScnJytH37dmVlZSkqKkpJSUnq16+ftm3bpr1799I4AQB1kIFRba9evdS9e3dJ0qFDhxQbG6vt27crISFBo0aNUtOmTZWRkVHlGvYcMAMA8Atyc3M1ePBg7yM3N/dnnwkODtaUKVM0a9YsJSYmKi8vT40bN9YLL7ygSy65RMuXL69yGyROAIAZNTCqdblccrlcPj83Z84cTZo0SUOHDlWjRo3Uo0cPSVKPHj00f/78Kr9L4gQABIzVq1dr6dKlkqTw8HA5HA7dcMMN2rJliyTpo48+UqtWrapcg8QJADDDwD7OPn36KC0tTSNGjFB5ebnS09PVtm1bZWZmKicnR5GRkXriiSeqXIPGCQAIGA0bNtSCBQt+9vrzzz9f7TVonAAAM2x6P04aJwDADJteOcieVQMAYAiJEwBghk1HtSROAAAsIHECAMyw6T5OGicAwAxGtQAA1H8kTgCAGTYd1dqzagAADCFxAgDMsGnipHECAMzg4CAAAOo/EicAwAybjmrtWTUAAIaQOAEAZrCPEwCA+o/ECQAww6b7OGmcAAAzGNUCAFD/kTgBAEY4SJwAANR/JE4AgBF2TZw0TgCAGfbsm4xqAQCwgsQJADDCrqNaEicAABaQOAEARtg1cdI4AQBG2LVxMqoFAMACEicAwAgSJwAAAYDECQAww56Bk8QJAIAVJE4AgBF23cdJ4wQAGGHXxsmoFgAAC0icAAAjSJwAAAQAEicAwAi7Jk4aJwDADHv2TUa1AABYQeIEABhh11EtiRMAAAtInAAAI+yaOGmcAAAj7No4GdUCAGABiRMAYIY9AyeJEwAAK0icAAAj2McJAEAAIHECAIywa+KkcQIAjLBr42RUCwCABTROAIARDofD7w9fKioqlJaWpmHDhmnEiBHav3+/971169bJ5XL5XIPGCQAIGJs2bZIk5eTkKDU1VVlZWZKkzz//XKtWrZLH4/G5Bo0TAGCGowYePvTq1UuzZs2SJB06dEixsbHKz8/X3LlzlZ6eXq2yOTgIAGBETRwclJubq9zcXO9zl8v1s/FrcHCwpkyZoo0bN2rBggXKyMhQenq6wsLCqrUNh6c6ubQWPb5pj+kSAL/48OtTpksAztuquzrW2NpNx77p9zXzFg+q9mePHTumnj17KjY2Vk2bNlVJSYm++uorDRkyRBkZGZV+j8QJADDCxOkoq1ev1pEjR3TvvfcqPDxcsbGx2rBhg8LCwnTw4EFNnDixyqYp0TgBAAGkT58+SktL04gRI1ReXm5pRPsfNE4AgBEmEmfDhg21YMGCX3zvsssu02uvveZzDRonAMAMe144iNNRAACwgsQJADCCa9UCABAASJwAACNInAAABAASZz3nrijX1pfmq/C7o6ooK1OHfsMU0SRWH7yyUM6QEF1wWbxuGnqvHEH8Hwp1W5BDGnNzc10a1UBuj0d/ev8bHTldKkkadUNTHTpVor/++7jhKmGFXRMnjbOe+2r739QgorG63zVZxYUFWv3oHxXeKEo3ucYo7opf67/XvKg9H21Wqxt7mC4VqNK1zaIkSZlv79aVF0dq1A2XafH7+/XHW1roksYNtPbUEcMVwioaJ+qklh276vKOXbzPg5xOFZ38TnFX/FqSFHfFr7X/n9tonKjzPtp/Sh8f+OH6v7GRoTr5fbkahATptU8P65rLogxXh0BSo/M5t9tdk8ujGkIahCu0QUOVFp/R35Y9pmt/k6JGsRfr8O6dkqT9n32ostJiw1UC1eP2SPd1baHf39hM277O19HCUn15/IzpsnCuDNxWzB/8njgPHDigrKws7dq1S8HBwXK73WrTpo3S0tLUsmVLf28O1VB44pjeWzJLbbsN0BU33KoLmrfWtteW6rO/rtKFLVrLGRxiukSg2hb+/RtFh+cpa0CCxr/5uUrK+Q86apffG2dGRoYeeOABXX311d7XduzYobS0NOXk5Ph7c/Dh+4J8vfNUpm4eNlaX/qqDJOnArg/V9c7xioi+QP/IWazLrrzObJFANdxyRYwuaBiiN3ceUUm5W26P5K5bd0WERezj/D+lpaVnNU1J6tChg783g2rasSFXpWcK9en6V/Xp+lclSe16D9ZfF05XcGiYLmnTXs3aXW+4SsC37d+c1LguLTTzttZyBjn0wocHVVZB47QzGuf/SUhIUFpamrp27apGjRqpqKhIW7ZsUUJCgr83hWro5BqjTq4xP3u9efsbDVQDnLuScrfmbd73i++9tuNwLVeDQOb3xjljxgy9++67+vjjj1VYWKjIyEjdeuut6t27t783BQCwMZsGTv83TofDod69e9MoAQD1EudxAgCMYB8nAAAW2LRvcpF3AACsIHECAIyw66iWxAkAgAUkTgCAETYNnCROAACsIHECAIwICrJn5KRxAgCMYFQLAEAAIHECAIzgdBQAAAIAiRMAYIRNAyeNEwBgBqNaAAACAIkTAGAEiRMAgABA4gQAGGHTwEnjBACYwagWAIAAQOIEABhh08BJ4gQAwAoSJwDACPZxAgAQAEicAAAjbBo4aZwAADMY1QIAEABInAAAI2waOEmcAABYQeIEABhh132cNE4AgBE27ZuMagEAsILECQAwwq6jWhInAAAWkDgBAEbYNHDSOAEAZjCqBQAgAJA4AQBG2DRw0jgBAIGjoqJCmZmZ2rdvn5xOp7KyslRUVKRZs2bJ6XQqNDRUc+bMUWxsbKVr0DgBAEaY2Me5adMmSVJOTo62b9+urKwsnT59WtOmTVPbtm2Vk5Oj5cuXKy0trdI1aJwAgIDRq1cvde/eXZJ06NAhxcbG6uGHH9ZFF10k6YdEGhYWVuUaNE4AgBE1kThzc3OVm5vrfe5yueRyuc76THBwsKZMmaKNGzfqqaee8jbNTz75RCtWrNArr7xSdd0ej8fj98rPw+Ob9pguAfCLD78+ZboE4Lytuqtjja3dbf4Hfl9zy4TO1f7ssWPHNHToUK1fv16bN2/W4sWLtWjRIjVr1qzK73E6CgAgYKxevVpLly6VJIWHh8vhcGjjxo1asWKFXn75ZZ9NU2JUCwAwxMTBQX369FFaWppGjBih8vJypaenKz09XZdccon++Mc/SpKuv/56paamVroGjRMAEDAaNmyoBQsWnPVar169LK1B4wQAGMEFEAAAsIBr1QIAEABInAAAI2waOEmcAABYQeIEABgRZNPISeMEABhh077JqBYAACtInAAAIzgdBQCAAEDiBAAYEWTPwEnjBACYwagWAIAAQOIEABhh08BJ4gQAwAoSJwDACIfsGTlJnAAAWEDiBAAYwekoAABYwOkoAAAEABInAMAImwZOEicAAFaQOAEARnAjawAALLBp32RUCwCAFSROAIARnI4CAEAAIHECAIywaeCkcQIAzLDrUbWMagEAsIDECQAwwp55k8QJAIAllhKn2+1WUBC9FgBw/urt6SgbNmzQ+vXr9eabb6pz58569tlna6MuAADqJJ+N87nnntPNN9+stWvXasuWLdq0aVNt1AUAqOeCHP5/1Aafo9qwsDBJUkREhEJDQ1VUVFTjRQEA6r96O6q97LLLNGTIEA0ZMkQLFy5U+/bta6MuAADqJJ+Jc/bs2SoqKlJERITatWun2NjY2qgLAFDP2TRwVt44J06cWGmMfuKJJ2qsIAAA6rJKG+ewYcNqsw4AQICx6z7OShvnDTfcIEkqLCzU8uXLdezYMXXv3l0JCQm1VhwAoP6qraNg/c3nwUHp6elq1qyZvv76a8XGxiojI6M26gIAoE7y2ThPnjyp22+/XcHBwerYsaM8Hk9t1AUAqOccDoffH7WhWtfP27NnjyTp22+/5ZJ7AICA5vN0lMzMTKWnp2vPnj1KTU3V9OnTa6MuAEA9Z9NdnL4bZ5s2bbR48WLl5eWpRYsWaty4cW3UBQCo5+rtjaxXrVql4cOHa+nSpXK5XHr77bdroy4AAOokn4kzJydHa9asUVhYmM6cOaPf/e536tevX23UBgCox2waOH0nzujoaAUH/9BfGzRowKgWABDQfF5y78SJExo8eLCuvvpq/etf/1KDBg1qsz4AQD1V764c9EuX3BswYECNFgMAQF3n85J7J0+e1Pvvv6/y8nJ5PB4dPXrU+x4AAOfKpoHT98FBqampuvzyy7V7926FhYUpPDy8NuoCANRz9fZ0FEmaOXOmWrZsqeeff16nTp2q6ZoAAKizfCZOSSopKdH3338vh8OhM2fO1HRNAIAAYCJwVlRUKDMzU/v27ZPT6VRWVpY8Ho+mTp0qh8Oh1q1ba/r06VVeXtZn4hwxYoRefPFFde7cWd26dVN8fLxffwgAAGrLpk2bJP1wjYLU1FRlZWUpKytL48eP18qVK+XxePTee+9VuYbPxJmYmOj982233abjx4+fZ9kAAJg5HaVXr17q3r27JOnQoUOKjY3V5s2bvQe93nLLLfrggw/Uu3fvSteo1qj2PyIjIzVq1CitWrXq3Kv2IbXrFTW2NlCbmky8z3QJwPm7q2ONLV0T99rKzc1Vbm6u97nL5ZLL5TrrM8HBwZoyZYo2btyop556Sps2bfI28YiICJ0+fbrKbVhqnJK4HycAoM76pUb5S+bMmaNJkyZp6NChKikp8b5eVFTk8wp5lhu+Xa/0AACoW0zcyHr16tVaunSpJCk8PFwOh0NXXXWVtm/fLknaunWrrrvuuirX8HnJvR/zeDw6cOCAz8IAAKiL+vTpo7S0NI0YMULl5eVKT0/XFVdcoWnTpmnevHmKj48/69ieX+LwVDJ7/fDDDyv9Uk1eOai4vMaWBmpVk+vZxwn7+/7ThTW29vg1X/h9zSeTf+X3NX/K5yX3AACoCUE23fNXEwc1AQBQb1k+qhYAAH+w68GmPhvnkSNHlJ2drfz8fCUmJiohIUFXX311bdQGAECd43NUO23aNA0ZMkSlpaW67rrr9Oijj9ZGXQCAei7I4f9HrdTt6wMlJSXq1KmTHA6H4uPjFRYWVht1AQBQJ/kc1YaGhurvf/+73G63duzYodDQ0NqoCwBQz9l0F6fvxDlr1iy98cYbys/P13PPPacZM2bUQlkAgPouyOHw+6M2+EycF198sebPn18btQAAUOf5bJxdunTx/vnkyZNq1qyZNmzYUKNFAQDqP7teSMBn43z//fe9f87Ly9PChTV3+SUAAOo6SxdAaNq0qfbu3VtTtQAAAohdDw7y2Th/fJeUo0eP6oILLqjxogAA9V9tHczjbz4bZ79+/bw39QwLC9NVV11V40UBAFBX+Wyczz77rF599dXaqAUAEEBsGjh9N86oqCi9+OKLatmypYKCfjgG6sdH2gIAEEh8Ns4mTZroiy++0Bdf/P8NR2mcAIDzZdf7cVbaOMePH68nn3xSWVlZtVkPACBA2PXgoErPPz1x4kRt1gEAgC1UmjgPHDigefPm/eJ7EydOrLGCAACBwaaBs/LG2aBBA7Vs2bI2awEAoM6rtHHGxsZq0KBBtVkLACCA2PXgoEr3cXKhAwAAfq7SxDllypTarAMAEGAcsmfktHSRdwAA/KXejWoBAMDPkTgBAEaQOAEACAAkTgCAEQ6bXgGBxgkAMIJRLQAAAYDECQAwwqaTWhInAABWkDgBAEbY9X6cNE4AgBEcHAQAQAAgcQIAjLDppJbECQCAFSROAIARQTa9rRiJEwAAC0icAAAj7LqPk8YJADCC01EAAAgAJE4AgBF2vXIQiRMAAAtInAAAI2waOGmcAAAzGNUCABAASJwAACNsGjhJnAAAWEHiBAAYYdfkRuMEABjhsOms1q4NHwAAI0icAAAj7Jk3aZwAgABSVlam9PR05eXlqbS0VGPHjtWll16q6dOny+l06vLLL9ejjz6qoKDKB7I0TgCAESYugLB27VpFR0crOztb+fn5GjRokK688kqNGzdO3bp10wMPPKDNmzerR48ela5B4wQABIy+ffsqMTHR+9zpdKpt27Y6efKkPB6PioqKFBxcdWukcQIAjKiJvJmbm6vc3Fzvc5fLJZfL5X0eEREhSSosLFRqaqrGjx8vh8OhmTNnavHixWrUqJFuvPHGquv2eDyeGqj9nBWXm64A8I8m199nugTgvH3/6cIaW3vlJwf9vubwjpf5/Mzhw4c1btw4DR8+XLfffrs6deqkl156Sa1bt9Yrr7yir776StOnT6/0+5yOAgAIGMePH9fo0aM1efJk3X777ZKkqKgoRUZGSpIuuugiFRQUVLkGo1oAgBEmLoCwZMkSFRQUaNGiRVq0aJEk6ZFHHtGECRMUHByskJAQzZo1q8o1GNUCNYRRLeqDmhzVvvppnt/X/O01Tf2+5k+ROAEARth1XyGNEwBgBNeqBQAgAJA4AQBG2DNvkjgBALCExAkAMMKu+zhpnAAAI+w68rRr3QAAGEHiBAAYYddRLYkTAAALSJwAACPsmTdJnAAAWELiBAAYYdNdnDROAIAZQTYd1jKqBQDAAhInAMAIu45qSZwAAFhA4gQAGOGw6T5OGicAwAhGtQAABAASJwDACE5HAQAgAJA4AQBG2HUfJ40TAGCEXRsno1oAACwgcQIAjLDreZwkTgAALCBxAgCMCLJn4KRxAgDMYFQLAEAAIHECAIzgdBQAAAIAiRMAYAT7OAEACAAkTgCAEZyOAgCABYxqAQAIACROAIARdj0dhcZZz5WVlWn6tHQdystTaWmp7rl3rJo1b6GZM6ZJHo/aJPxKUzOmyel0mi4VqFJQkEOLpg1Xm8svUoXbo3umr9DD9yUp7oLGkqQWl8bow51f686pzxuuFPUdjbOeW//WWkVHReux2dk6eTJfriGD1PbXv1bq+Im69rrrNS19qjZv+pt69uptulSgSv1vaSdJ6nHXfHW9trXmPDBYQycskyRFNwrXO8vv14Nz/2yyRFhk08BJ46zv+vTpq959Er3PncFOPfHk03I6nSorLdXx48d0wQUXGKwQqJ51mz/T23/fJUlqfmmMjn532vvetLH9tThni749XmCqPJyDIJvOajk4qJ5rGBGhiIhIFRUV6oHxqbrvj+PldDp16FCeBicP0MmT+bq8ZUvTZQLVUlHh1vKZKZr34O16891PJUkXNolU9xsS9PLabYarQ6CgcQaAbw8f1t133akBv0lWvwFJkqRLL22qdRv+qjuG/lZz58w2XCFQfX946GW1HzhTix4aroYNQjWo1zXK3fDfcrs9pkuDRY4aeNQGv49qU1JSVFZWdtZrHo9HDodDOTk5/t4cfPju+HGNuWe00jIe0o03dZIkpY4bowcenKoWLS5Xw4gIOYL4/xPqvt/2v15N45po7nN/1ZniMrndblW43epxY4JmP/OO6fIQQPzeOCdNmqTMzEz96U9/4kjNOuCZ5UtUcKpAy5Ys0rIliyRJ96WO10PpUxUcEqLw8HBNn/mI4SoB39a8908te3ikNj47XiHBTk2e+2eVlJar9eVx2nfwO9Pl4VzYcxenHB6Px+/zjWeeeUYtWrRQ797Wj9QsLvd3NYAZTa6/z3QJwHn7/tOFNbb29j2n/L7mjVdE+X3Nn6qRo2rvvvvumlgWAADjOB0FAGCETc9G4ahaAACsIHECAIywaeAkcQIAYAWJEwBghk0jJ40TAGAEN7IGACAAkDgBAEaYOB2lrKxM6enpyvu/exSPHTtWHTp0UGZmpgoKClRRUaHHH39czZs3r3QNGicAIGCsXbtW0dHRys7OVn5+vgYNGqSbbrpJSUlJ6tevn7Zt26a9e/fSOAEAdY+JPZx9+/ZVYuKP7lHsdOqTTz5RQkKCRo0apaZNmyojI6PKNdjHCQAww8B9xSIiIhQZGanCwkKlpqZq/PjxysvLU+PGjfXCCy/okksu0fLly6tcg8YJAKg3cnNzNXjwYO8jNzf3Z585fPiw7rzzTiUnJyspKUnR0dHq0aOHJKlHjx7atWtXldtgVAsAMKImTkdxuVxyuVyVvn/8+HGNHj1aDz30kDp1+uEexddee622bNmigQMH6qOPPlKrVq2q3AaNEwAQMJYsWaKCggItWrRIixb9cI/i2bNnKzMzUzk5OYqMjNQTTzxR5Ro1cj/O88H9OFFfcD9O1Ac1eT/OHftP+33NDs0b+X3NnyJxAgCMsOd1gzg4CAAAS0icAAAzbBo5SZwAAFhA4gQAGMHdUQAACAAkTgCAESbujuIPNE4AgBE27ZuMagEAsILECQAww6aRk8QJAIAFJE4AgBF2PR2FxgkAMMKuR9UyqgUAwAISJwDACJsGThInAABWkDgBAGbYNHLSOAEARtj1qFpGtQAAWEDiBAAYwekoAAAEABInAMAImwZOEicAAFaQOAEAZtg0ctI4AQBGcDoKAAABgMQJADCC01EAAAgAJE4AgBE2DZw0TgCAITbtnIxqAQCwgMQJADCC01EAAAgAJE4AgBF2PR2FxgkAMMKmfZNRLQAAVpA4AQBm2DRykjgBALCAxAkAMILTUQAACAAkTgCAEZyOAgCABTbtm4xqAQCwgsQJADDCrqNaEicAABaQOAEAhtgzctI4AQBGMKoFACAAkDgBAEbYNHCSOAEAsILECQAwwq77OGmcAAAjuMg7AAABgMQJADDDnoGTxAkAgBU0TgCAEY4aePhSVlamyZMna/jw4br99tv13nvved9bt26dXC6XzzUY1QIAAsbatWsVHR2t7Oxs5efna9CgQerZs6c+//xzrVq1Sh6Px+caJE4AgBEOh/8fvvTt21f333+/97nT6VR+fr7mzp2r9PT0atVN4gQAGFETp6Pk5uYqNzfX+9zlcp01fo2IiJAkFRYWKjU1Vffff78yMjKUnp6usLCwam3D4alOLq1FxeWmKwD8o8n195kuAThv33+6sMbWPnba///gX9jIdx48fPiwxo0bp+HDh6tNmzZKS0tTTEyMSkpK9NVXX2nIkCHKyMio9PskTgCAGQZORzl+/LhGjx6thx56SJ06dZIkrV+/XpJ08OBBTZw4scqmKbGPEwAQQJYsWaKCggItWrRIKSkpSklJUXFxsaU1GNUCNYRRLeqDmhzVHi/0/z/4sZE1P0hlVAsAMMKuF3lnVAsAgAUkTgCAEdwdBQCAAEDiBAAYwT5OAAACAI0TAAALGNUCAIxgVAsAQAAgcQIAjOB0FAAAAgCJEwBghF33cdI4AQBG2LRvMqoFAMAKEicAwAybRk4SJwAAFpA4AQBG2PV0FBonAMAIux5Vy6gWAAALSJwAACNsGjhJnAAAWEHiBACYYdPISeMEABhh16NqGdUCAGABiRMAYASnowAAEAAcHo/HY7oIAADsgsQJAIAFNE4AACygcQIAYAGNEwAAC2icAABYQOMEAMACGmcAcbvdeuihh+RyuZSSkqJvvvnGdEnAOfvnP/+plJQU02UgAHHloADy7rvvqrS0VLm5udqxY4dmz56txYsXmy4LsGz58uVau3atwsPDTZeCAETiDCAff/yxunbtKknq0KGDdu3aZbgi4Nw0b95cTz/9tOkyEKBonAGksLBQkZGR3udOp1Pl5eUGKwLOTWJiooKDGZjBDBpnAImMjFRRUZH3udvt5h8fALCIxhlAOnbsqK1bt0qSduzYoTZt2hiuCADsh7gRQHr37q0PPvhAw4YNk8fj0WOPPWa6JACwHe6OAgCABYxqAQCwgMYJAIAFNE4AACygcQIAYAGNEwAAC2icsL3t27erU6dOSklJUUpKioYOHaqXX375nNaaO3eu3njjDX3++edauHBhpZ/buHGjjhw5Uq01t27dqqlTp5712sGDBzV06NBqfb+mPgvg3HAeJ+qFm266SfPnz5cklZaWqm/fvkpOTlbjxo3Pab22bduqbdu2lb7/0ksvacaMGYqLizun9QHYF40T9U5hYaGCgoLkdDqVkpKiJk2aqKCgQMuWLdOMGTP0zTffyO12a/z48brxxhv1l7/8RYsXL1ZMTIzKysoUHx+v7du3KycnR/Pnz9frr7+uV199VW63Wz179lS7du30+eefa8qUKVq5cqVyc3P11ltvyeFwqF+/frrzzju1Z88epaenKzw8XOHh4YqKiqpW7R9++KE36RYXF2vOnDkKCQnRiRMnNGbMGJ04cULdunXTuHHjdPjwYU2bNk0lJSUKCwvTrFmzzlpr/vz52rZtm9xut/r3769Ro0b5+1cNBCQaJ+qFbdu2KSUlRQ6HQyEhIZo2bZoiIiIkSUlJSerdu7dWrlypJk2a6LHHHlN+fr5Gjhyp9evXKzs7W6+//rqio6N1zz33nLXud999572FVWhoqGbPnq3rr79ebdu21YwZM7R//369/fbbWrlypRwOh0aNGqUuXbpowYIFSk1NVefOnbVs2TLt3bu3Wj/Hl19+qezsbMXFxWnJkiV65513lJSUpDNnzig7O1sNGzbUiBEj1LNnTy1ZskQpKSnq1q2b/vGPf2ju3LmaMGGCd63Vq1drxYoViouL0xtvvOG/XzYQ4GicqBd+PKr9qZYtW0qSdu/erY8//lifffaZJKm8vFzHjx9XZGSkmjRpIkm65pprzvrugQMH1Lp1azVo0ECSlJ6eftb7u3fv1qFDh7xp7tSpU9q/f7++/PJLtW/fXtIP1wiubuOMi4vTo48+qoYNG+rIkSPq2LGjJOlXv/qVGjVqJElq166d9u3bp927d2vp0qV65pln5PF4FBISctZa8+bN07x583T8+HHv7eQAnD8aJ+o9h8MhSYqPj9fFF1+sMWPGqLi4WIsXL1bjxo11+vRpnThxQjExMdq5c6cuvvhi73ebN2+uvXv3qrS0VKGhoUpNTVVGRoYcDoc8Ho/i4+PVqlUrPfPMM3I4HHrhhRfUpk0bxcfH69NPP9Utt9xi6b6nmZmZevfddxUZGakpU6boP1fE3LNnj4qKihQWFqbPPvtMLpdL8fHxGj16tDp27Kg9e/boo48+8q5TWlqqd955R/PmzZPH41H//v3Vv39/NW3a1E+/VSBw0TgRMIYNG6bMzEyNHDlShYWFGj58uEJDQ5WVlaXf//73ioqK+tlt1mJiYvSHP/xBI0eOlMPh0K233qq4uDhdc801evDBB/Xcc8+pU6dO+u1vf6vS0lK1b99ecXFxmj59uiZMmKBnn31WMTExCgsL+1k9X375pQYPHux9PnXqVCUnJ2vo0KFq3LixYmNjdfToUUlSVFSUJkyYoBMnTqhfv35q1aqVpkyZohkzZqikpETFxcXKyMjwrhUaGqqoqCglJycrKipKnTt31qWXXlpDv1kgsHCRdwAALOA8TgAALKBxAgBgAY0TAAALaJwAAFhA4wQAwAIaJwAAFtA4AQCwgMYJAIAF/wtWbeQ2KrMOjwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 16:09:01,148]\u001B[0m A new study created in memory with name: no-name-90aeee10-2023-4981-bbb0-eeab5cb8f416\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.72694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:09:50,809]\u001B[0m Trial 0 finished with value: 0.7269444444444445 and parameters: {'n_d': 12, 'n_a': 28, 'n_steps': 9, 'gamma': 1.2730523932464748, 'n_independent': 9, 'n_shared': 10, 'lambda_sparse': 0.03393653727446176}. Best is trial 0 with value: 0.7269444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:10:41,859]\u001B[0m Trial 1 finished with value: 0.73 and parameters: {'n_d': 56, 'n_a': 36, 'n_steps': 12, 'gamma': 1.5140099848837174, 'n_independent': 9, 'n_shared': 5, 'lambda_sparse': 0.04173572304005009}. Best is trial 1 with value: 0.73.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:10:58,292]\u001B[0m Trial 2 finished with value: 0.7650000000000001 and parameters: {'n_d': 36, 'n_a': 53, 'n_steps': 8, 'gamma': 0.308366370823949, 'n_independent': 4, 'n_shared': 5, 'lambda_sparse': 0.005873691462789662}. Best is trial 2 with value: 0.7650000000000001.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.75944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:11:34,588]\u001B[0m Trial 3 finished with value: 0.7594444444444445 and parameters: {'n_d': 30, 'n_a': 9, 'n_steps': 12, 'gamma': 0.3062723229383365, 'n_independent': 5, 'n_shared': 8, 'lambda_sparse': 0.08205657606744557}. Best is trial 2 with value: 0.7650000000000001.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.76722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:11:54,226]\u001B[0m Trial 4 finished with value: 0.7672222222222221 and parameters: {'n_d': 48, 'n_a': 39, 'n_steps': 10, 'gamma': 0.9798052683372434, 'n_independent': 4, 'n_shared': 4, 'lambda_sparse': 0.008612084918313771}. Best is trial 4 with value: 0.7672222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:12:13,829]\u001B[0m Trial 5 finished with value: 0.71 and parameters: {'n_d': 58, 'n_a': 36, 'n_steps': 14, 'gamma': 0.7026998091095433, 'n_independent': 2, 'n_shared': 7, 'lambda_sparse': 0.09483942918019923}. Best is trial 4 with value: 0.7672222222222221.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.77278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:12:23,386]\u001B[0m Trial 6 finished with value: 0.7727777777777779 and parameters: {'n_d': 9, 'n_a': 11, 'n_steps': 7, 'gamma': 0.9360003004022073, 'n_independent': 4, 'n_shared': 4, 'lambda_sparse': 0.07123762976688573}. Best is trial 6 with value: 0.7727777777777779.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.59139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:13:03,122]\u001B[0m Trial 7 finished with value: 0.591388888888889 and parameters: {'n_d': 56, 'n_a': 19, 'n_steps': 17, 'gamma': 1.2728910120267247, 'n_independent': 7, 'n_shared': 8, 'lambda_sparse': 0.0699925375835747}. Best is trial 6 with value: 0.7727777777777779.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.76361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:13:14,643]\u001B[0m Trial 8 finished with value: 0.7636111111111111 and parameters: {'n_d': 58, 'n_a': 18, 'n_steps': 7, 'gamma': 0.44544416227282246, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.07735835157581222}. Best is trial 6 with value: 0.7727777777777779.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.76472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:13:40,518]\u001B[0m Trial 9 finished with value: 0.7647222222222222 and parameters: {'n_d': 45, 'n_a': 30, 'n_steps': 6, 'gamma': 1.7367126690532688, 'n_independent': 5, 'n_shared': 7, 'lambda_sparse': 0.03555485236786869}. Best is trial 6 with value: 0.7727777777777779.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:13:42,442]\u001B[0m Trial 10 finished with value: 0.7425 and parameters: {'n_d': 9, 'n_a': 60, 'n_steps': 1, 'gamma': 1.8916653314260614, 'n_independent': 1, 'n_shared': 2, 'lambda_sparse': 0.062231584985283764}. Best is trial 6 with value: 0.7727777777777779.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.7425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:13:46,898]\u001B[0m Trial 11 finished with value: 0.8088888888888889 and parameters: {'n_d': 23, 'n_a': 48, 'n_steps': 3, 'gamma': 0.8503769223827142, 'n_independent': 3, 'n_shared': 3, 'lambda_sparse': 0.003094630561092164}. Best is trial 11 with value: 0.8088888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.80889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:13:51,675]\u001B[0m Trial 12 finished with value: 0.8019444444444443 and parameters: {'n_d': 21, 'n_a': 51, 'n_steps': 3, 'gamma': 0.8626532297664617, 'n_independent': 3, 'n_shared': 3, 'lambda_sparse': 0.05585572179506027}. Best is trial 11 with value: 0.8088888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.80194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:13:55,551]\u001B[0m Trial 13 finished with value: 0.82 and parameters: {'n_d': 22, 'n_a': 50, 'n_steps': 2, 'gamma': 0.7255838912226106, 'n_independent': 2, 'n_shared': 3, 'lambda_sparse': 0.05377629002187749}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:14:01,064]\u001B[0m Trial 14 finished with value: 0.7794444444444445 and parameters: {'n_d': 23, 'n_a': 46, 'n_steps': 4, 'gamma': 0.570941459450254, 'n_independent': 1, 'n_shared': 2, 'lambda_sparse': 0.02411284360224942}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.77944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:14:02,561]\u001B[0m Trial 15 finished with value: 0.7609722222222222 and parameters: {'n_d': 21, 'n_a': 63, 'n_steps': 1, 'gamma': 0.15172912172041764, 'n_independent': 2, 'n_shared': 1, 'lambda_sparse': 0.047911253798425424}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.76097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:14:08,730]\u001B[0m Trial 16 finished with value: 0.7930555555555555 and parameters: {'n_d': 30, 'n_a': 47, 'n_steps': 3, 'gamma': 0.6358861832903445, 'n_independent': 3, 'n_shared': 3, 'lambda_sparse': 0.02252404569861243}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.79306\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.81028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:14:17,918]\u001B[0m Trial 17 finished with value: 0.8102777777777777 and parameters: {'n_d': 15, 'n_a': 55, 'n_steps': 5, 'gamma': 0.7790710341340314, 'n_independent': 7, 'n_shared': 3, 'lambda_sparse': 0.05143787128141523}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.77056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:14:45,694]\u001B[0m Trial 18 finished with value: 0.7705555555555555 and parameters: {'n_d': 14, 'n_a': 57, 'n_steps': 5, 'gamma': 1.0873749293272719, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.055945196015453766}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.77194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:16:23,238]\u001B[0m Trial 19 finished with value: 0.7719444444444444 and parameters: {'n_d': 16, 'n_a': 42, 'n_steps': 18, 'gamma': 0.7144162267345449, 'n_independent': 10, 'n_shared': 4, 'lambda_sparse': 0.0485154370521366}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.78472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:16:28,992]\u001B[0m Trial 20 finished with value: 0.7847222222222222 and parameters: {'n_d': 31, 'n_a': 55, 'n_steps': 1, 'gamma': 1.1174772255731806, 'n_independent': 7, 'n_shared': 2, 'lambda_sparse': 0.06069859124089594}. Best is trial 13 with value: 0.82.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:16:35,388]\u001B[0m Trial 21 finished with value: 0.7805555555555556 and parameters: {'n_d': 25, 'n_a': 47, 'n_steps': 3, 'gamma': 0.7949136767498985, 'n_independent': 2, 'n_shared': 3, 'lambda_sparse': 0.04319366347296691}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.78056\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.75722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:16:47,989]\u001B[0m Trial 22 finished with value: 0.7572222222222221 and parameters: {'n_d': 17, 'n_a': 51, 'n_steps': 5, 'gamma': 0.5126810385000058, 'n_independent': 6, 'n_shared': 4, 'lambda_sparse': 0.002806035970867753}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.80056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:17:01,582]\u001B[0m Trial 23 finished with value: 0.8005555555555556 and parameters: {'n_d': 26, 'n_a': 63, 'n_steps': 3, 'gamma': 0.8670263827215625, 'n_independent': 8, 'n_shared': 3, 'lambda_sparse': 0.01878870489473637}. Best is trial 13 with value: 0.82.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:17:06,234]\u001B[0m Trial 24 finished with value: 0.7725000000000001 and parameters: {'n_d': 40, 'n_a': 43, 'n_steps': 5, 'gamma': 0.7524922429803688, 'n_independent': 3, 'n_shared': 1, 'lambda_sparse': 0.033542176424259516}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.7725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:17:08,799]\u001B[0m Trial 25 finished with value: 0.7861111111111112 and parameters: {'n_d': 17, 'n_a': 59, 'n_steps': 2, 'gamma': 0.6118720773146546, 'n_independent': 1, 'n_shared': 2, 'lambda_sparse': 0.013375282581354099}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.78611\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_auc = 0.81083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:17:47,591]\u001B[0m Trial 26 finished with value: 0.8108333333333333 and parameters: {'n_d': 35, 'n_a': 49, 'n_steps': 6, 'gamma': 0.9904497010671393, 'n_independent': 5, 'n_shared': 5, 'lambda_sparse': 0.05195448824017499}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.78278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:18:38,808]\u001B[0m Trial 27 finished with value: 0.7827777777777778 and parameters: {'n_d': 64, 'n_a': 53, 'n_steps': 7, 'gamma': 1.0505095492928282, 'n_independent': 8, 'n_shared': 5, 'lambda_sparse': 0.052639659153325226}. Best is trial 13 with value: 0.82.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.75722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:19:09,694]\u001B[0m Trial 28 finished with value: 0.7572222222222221 and parameters: {'n_d': 36, 'n_a': 30, 'n_steps': 9, 'gamma': 1.2040984746726067, 'n_independent': 6, 'n_shared': 6, 'lambda_sparse': 0.06362297945859517}. Best is trial 13 with value: 0.82.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.82376 |  0:00:00s\n",
      "epoch 1  | loss: 0.71386 |  0:00:00s\n",
      "epoch 2  | loss: 0.69042 |  0:00:00s\n",
      "epoch 3  | loss: 0.66802 |  0:00:00s\n",
      "epoch 4  | loss: 0.64877 |  0:00:00s\n",
      "epoch 5  | loss: 0.64348 |  0:00:00s\n",
      "epoch 6  | loss: 0.63541 |  0:00:01s\n",
      "epoch 7  | loss: 0.63049 |  0:00:01s\n",
      "epoch 8  | loss: 0.62779 |  0:00:01s\n",
      "epoch 9  | loss: 0.61828 |  0:00:01s\n",
      "epoch 10 | loss: 0.6085  |  0:00:01s\n",
      "epoch 11 | loss: 0.61427 |  0:00:01s\n",
      "epoch 12 | loss: 0.61626 |  0:00:02s\n",
      "epoch 13 | loss: 0.60828 |  0:00:02s\n",
      "epoch 14 | loss: 0.59698 |  0:00:02s\n",
      "epoch 15 | loss: 0.60095 |  0:00:02s\n",
      "epoch 16 | loss: 0.60276 |  0:00:02s\n",
      "epoch 17 | loss: 0.58888 |  0:00:02s\n",
      "epoch 18 | loss: 0.58475 |  0:00:03s\n",
      "epoch 19 | loss: 0.59352 |  0:00:03s\n",
      "epoch 20 | loss: 0.58413 |  0:00:03s\n",
      "epoch 21 | loss: 0.58609 |  0:00:03s\n",
      "epoch 22 | loss: 0.58346 |  0:00:03s\n",
      "epoch 23 | loss: 0.5734  |  0:00:03s\n",
      "epoch 24 | loss: 0.57436 |  0:00:03s\n",
      "epoch 25 | loss: 0.57676 |  0:00:04s\n",
      "epoch 26 | loss: 0.56493 |  0:00:04s\n",
      "epoch 27 | loss: 0.57551 |  0:00:04s\n",
      "epoch 28 | loss: 0.57009 |  0:00:04s\n",
      "epoch 29 | loss: 0.56475 |  0:00:04s\n",
      "epoch 30 | loss: 0.56317 |  0:00:04s\n",
      "epoch 31 | loss: 0.56651 |  0:00:05s\n",
      "epoch 32 | loss: 0.56482 |  0:00:05s\n",
      "epoch 33 | loss: 0.55466 |  0:00:05s\n",
      "epoch 34 | loss: 0.56457 |  0:00:05s\n",
      "epoch 35 | loss: 0.55184 |  0:00:05s\n",
      "epoch 36 | loss: 0.55138 |  0:00:05s\n",
      "epoch 37 | loss: 0.54897 |  0:00:05s\n",
      "epoch 38 | loss: 0.55043 |  0:00:06s\n",
      "epoch 39 | loss: 0.54665 |  0:00:06s\n",
      "epoch 40 | loss: 0.54599 |  0:00:06s\n",
      "epoch 41 | loss: 0.55635 |  0:00:06s\n",
      "epoch 42 | loss: 0.55351 |  0:00:06s\n",
      "epoch 43 | loss: 0.54121 |  0:00:06s\n",
      "epoch 44 | loss: 0.53748 |  0:00:07s\n",
      "epoch 45 | loss: 0.54999 |  0:00:07s\n",
      "epoch 46 | loss: 0.52846 |  0:00:07s\n",
      "epoch 47 | loss: 0.53672 |  0:00:07s\n",
      "epoch 48 | loss: 0.53782 |  0:00:07s\n",
      "epoch 49 | loss: 0.54363 |  0:00:07s\n",
      "epoch 50 | loss: 0.53401 |  0:00:08s\n",
      "epoch 51 | loss: 0.5427  |  0:00:08s\n",
      "epoch 52 | loss: 0.53876 |  0:00:08s\n",
      "epoch 53 | loss: 0.52988 |  0:00:08s\n",
      "epoch 54 | loss: 0.53178 |  0:00:08s\n",
      "epoch 55 | loss: 0.5373  |  0:00:08s\n",
      "epoch 56 | loss: 0.53746 |  0:00:09s\n",
      "epoch 57 | loss: 0.52812 |  0:00:09s\n",
      "epoch 58 | loss: 0.52376 |  0:00:09s\n",
      "epoch 59 | loss: 0.52363 |  0:00:09s\n",
      "epoch 60 | loss: 0.52439 |  0:00:09s\n",
      "epoch 61 | loss: 0.52989 |  0:00:09s\n",
      "epoch 62 | loss: 0.51849 |  0:00:10s\n",
      "epoch 63 | loss: 0.52401 |  0:00:10s\n",
      "epoch 64 | loss: 0.53002 |  0:00:10s\n",
      "epoch 65 | loss: 0.51705 |  0:00:10s\n",
      "epoch 66 | loss: 0.52199 |  0:00:10s\n",
      "epoch 67 | loss: 0.51929 |  0:00:10s\n",
      "epoch 68 | loss: 0.51611 |  0:00:10s\n",
      "epoch 69 | loss: 0.52115 |  0:00:11s\n",
      "epoch 70 | loss: 0.51702 |  0:00:11s\n",
      "epoch 71 | loss: 0.51726 |  0:00:11s\n",
      "epoch 72 | loss: 0.51483 |  0:00:11s\n",
      "epoch 73 | loss: 0.51303 |  0:00:11s\n",
      "epoch 74 | loss: 0.50716 |  0:00:11s\n",
      "epoch 75 | loss: 0.5183  |  0:00:12s\n",
      "epoch 76 | loss: 0.5164  |  0:00:12s\n",
      "epoch 77 | loss: 0.53023 |  0:00:12s\n",
      "epoch 78 | loss: 0.53101 |  0:00:12s\n",
      "epoch 79 | loss: 0.51927 |  0:00:12s\n",
      "epoch 80 | loss: 0.52384 |  0:00:12s\n",
      "epoch 81 | loss: 0.50895 |  0:00:13s\n",
      "epoch 82 | loss: 0.50008 |  0:00:13s\n",
      "epoch 83 | loss: 0.50371 |  0:00:13s\n",
      "epoch 84 | loss: 0.50125 |  0:00:13s\n",
      "epoch 85 | loss: 0.49752 |  0:00:13s\n",
      "epoch 86 | loss: 0.50068 |  0:00:13s\n",
      "epoch 87 | loss: 0.49212 |  0:00:13s\n",
      "epoch 88 | loss: 0.51262 |  0:00:14s\n",
      "epoch 89 | loss: 0.48972 |  0:00:14s\n",
      "epoch 90 | loss: 0.49108 |  0:00:14s\n",
      "epoch 91 | loss: 0.49254 |  0:00:14s\n",
      "epoch 92 | loss: 0.49422 |  0:00:14s\n",
      "epoch 93 | loss: 0.49816 |  0:00:14s\n",
      "epoch 94 | loss: 0.49981 |  0:00:15s\n",
      "epoch 95 | loss: 0.48325 |  0:00:15s\n",
      "epoch 96 | loss: 0.5037  |  0:00:15s\n",
      "epoch 97 | loss: 0.49849 |  0:00:15s\n",
      "epoch 98 | loss: 0.50172 |  0:00:15s\n",
      "epoch 99 | loss: 0.49353 |  0:00:15s\n",
      "Eval TABNET\n",
      "Accuracy: 0.63\n",
      "Precision: 0.65\n",
      "Recall: 0.58\n",
      "F1-score: 0.61\n",
      "ROC-AUC score: 0.63\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 16:19:25,821]\u001B[0m A new study created in memory with name: no-name-cd7d531f-6b54-4be0-b293-3fd7821c7c61\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:19:33,280]\u001B[0m Trial 0 finished with value: 0.7625000000000001 and parameters: {'n_d': 56, 'n_a': 50, 'n_steps': 4, 'gamma': 1.5719530250329778, 'n_independent': 5, 'n_shared': 1, 'lambda_sparse': 0.027289008071395313}. Best is trial 0 with value: 0.7625000000000001.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.78667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:20:06,897]\u001B[0m Trial 1 finished with value: 0.7866666666666666 and parameters: {'n_d': 55, 'n_a': 52, 'n_steps': 15, 'gamma': 1.9727903712432513, 'n_independent': 2, 'n_shared': 3, 'lambda_sparse': 0.06146729243690649}. Best is trial 1 with value: 0.7866666666666666.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:21:16,623]\u001B[0m Trial 2 finished with value: 0.795 and parameters: {'n_d': 31, 'n_a': 29, 'n_steps': 17, 'gamma': 1.0224181650511996, 'n_independent': 2, 'n_shared': 9, 'lambda_sparse': 0.011055063952611867}. Best is trial 2 with value: 0.795.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.73583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:21:34,269]\u001B[0m Trial 3 finished with value: 0.7358333333333333 and parameters: {'n_d': 30, 'n_a': 21, 'n_steps': 10, 'gamma': 1.5910910120543627, 'n_independent': 5, 'n_shared': 7, 'lambda_sparse': 0.0898094667533624}. Best is trial 2 with value: 0.795.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.79722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:21:46,429]\u001B[0m Trial 4 finished with value: 0.7972222222222223 and parameters: {'n_d': 18, 'n_a': 49, 'n_steps': 10, 'gamma': 1.8384411952033803, 'n_independent': 1, 'n_shared': 6, 'lambda_sparse': 0.07049336057979955}. Best is trial 4 with value: 0.7972222222222223.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.80333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:23:36,937]\u001B[0m Trial 5 finished with value: 0.8033333333333333 and parameters: {'n_d': 34, 'n_a': 36, 'n_steps': 16, 'gamma': 0.4088260043555074, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.013339689535963812}. Best is trial 5 with value: 0.8033333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.77611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:24:23,932]\u001B[0m Trial 6 finished with value: 0.7761111111111112 and parameters: {'n_d': 45, 'n_a': 45, 'n_steps': 16, 'gamma': 0.3732880184175872, 'n_independent': 8, 'n_shared': 2, 'lambda_sparse': 0.018170565613332502}. Best is trial 5 with value: 0.8033333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.81167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:24:36,351]\u001B[0m Trial 7 finished with value: 0.8116666666666666 and parameters: {'n_d': 36, 'n_a': 56, 'n_steps': 2, 'gamma': 0.4365622097762818, 'n_independent': 5, 'n_shared': 10, 'lambda_sparse': 0.06212958288019571}. Best is trial 7 with value: 0.8116666666666666.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.79667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:24:48,196]\u001B[0m Trial 8 finished with value: 0.7966666666666666 and parameters: {'n_d': 23, 'n_a': 44, 'n_steps': 5, 'gamma': 1.4215402324583704, 'n_independent': 3, 'n_shared': 6, 'lambda_sparse': 0.09624603903325703}. Best is trial 7 with value: 0.8116666666666666.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.80667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:25:44,412]\u001B[0m Trial 9 finished with value: 0.8066666666666666 and parameters: {'n_d': 56, 'n_a': 62, 'n_steps': 9, 'gamma': 0.5135738658318701, 'n_independent': 8, 'n_shared': 8, 'lambda_sparse': 0.06181633736176191}. Best is trial 7 with value: 0.8116666666666666.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:25:48,651]\u001B[0m Trial 10 finished with value: 0.7616666666666666 and parameters: {'n_d': 9, 'n_a': 64, 'n_steps': 1, 'gamma': 0.15297417527382962, 'n_independent': 7, 'n_shared': 4, 'lambda_sparse': 0.038898362380720586}. Best is trial 7 with value: 0.8116666666666666.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.76167\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.77667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:26:44,287]\u001B[0m Trial 11 finished with value: 0.7766666666666666 and parameters: {'n_d': 43, 'n_a': 64, 'n_steps': 7, 'gamma': 0.7518162888136533, 'n_independent': 7, 'n_shared': 8, 'lambda_sparse': 0.051433201507565425}. Best is trial 7 with value: 0.8116666666666666.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.81306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:26:59,232]\u001B[0m Trial 12 finished with value: 0.8130555555555555 and parameters: {'n_d': 62, 'n_a': 58, 'n_steps': 1, 'gamma': 0.6775656309174569, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.06917919074132374}. Best is trial 12 with value: 0.8130555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.79486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:27:12,859]\u001B[0m Trial 13 finished with value: 0.7948611111111111 and parameters: {'n_d': 64, 'n_a': 11, 'n_steps': 1, 'gamma': 0.8336786635083624, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.07849582261126548}. Best is trial 12 with value: 0.8130555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.78806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:27:25,941]\u001B[0m Trial 14 finished with value: 0.7880555555555555 and parameters: {'n_d': 43, 'n_a': 57, 'n_steps': 4, 'gamma': 0.10592937347474257, 'n_independent': 4, 'n_shared': 10, 'lambda_sparse': 0.046924520305711245}. Best is trial 12 with value: 0.8130555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.80361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:28:16,197]\u001B[0m Trial 15 finished with value: 0.8036111111111112 and parameters: {'n_d': 47, 'n_a': 37, 'n_steps': 13, 'gamma': 0.6652594143387436, 'n_independent': 6, 'n_shared': 8, 'lambda_sparse': 0.08325041760283897}. Best is trial 12 with value: 0.8130555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.76583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:28:23,623]\u001B[0m Trial 16 finished with value: 0.7658333333333334 and parameters: {'n_d': 64, 'n_a': 56, 'n_steps': 2, 'gamma': 1.0078229141608916, 'n_independent': 4, 'n_shared': 5, 'lambda_sparse': 0.07056087216946458}. Best is trial 12 with value: 0.8130555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.78528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:29:09,090]\u001B[0m Trial 17 finished with value: 0.7852777777777777 and parameters: {'n_d': 24, 'n_a': 37, 'n_steps': 7, 'gamma': 0.6056169473679379, 'n_independent': 9, 'n_shared': 9, 'lambda_sparse': 0.07837316893365201}. Best is trial 12 with value: 0.8130555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.53542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:30:00,322]\u001B[0m Trial 18 finished with value: 0.5354166666666667 and parameters: {'n_d': 39, 'n_a': 56, 'n_steps': 19, 'gamma': 0.8686817522309249, 'n_independent': 6, 'n_shared': 9, 'lambda_sparse': 0.09838107489928638}. Best is trial 12 with value: 0.8130555555555555.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.89577 |  0:00:00s\n",
      "epoch 1  | loss: 0.82834 |  0:00:01s\n",
      "epoch 2  | loss: 0.79349 |  0:00:01s\n",
      "epoch 3  | loss: 0.76121 |  0:00:02s\n",
      "epoch 4  | loss: 0.74286 |  0:00:02s\n",
      "epoch 5  | loss: 0.71141 |  0:00:03s\n",
      "epoch 6  | loss: 0.68722 |  0:00:03s\n",
      "epoch 7  | loss: 0.65934 |  0:00:04s\n",
      "epoch 8  | loss: 0.67074 |  0:00:04s\n",
      "epoch 9  | loss: 0.65751 |  0:00:05s\n",
      "epoch 10 | loss: 0.64077 |  0:00:05s\n",
      "epoch 11 | loss: 0.64842 |  0:00:06s\n",
      "epoch 12 | loss: 0.63517 |  0:00:06s\n",
      "epoch 13 | loss: 0.63244 |  0:00:07s\n",
      "epoch 14 | loss: 0.62006 |  0:00:08s\n",
      "epoch 15 | loss: 0.61334 |  0:00:08s\n",
      "epoch 16 | loss: 0.62309 |  0:00:09s\n",
      "epoch 17 | loss: 0.62047 |  0:00:09s\n",
      "epoch 18 | loss: 0.62023 |  0:00:10s\n",
      "epoch 19 | loss: 0.61146 |  0:00:10s\n",
      "epoch 20 | loss: 0.60407 |  0:00:11s\n",
      "epoch 21 | loss: 0.60529 |  0:00:11s\n",
      "epoch 22 | loss: 0.60289 |  0:00:12s\n",
      "epoch 23 | loss: 0.60158 |  0:00:12s\n",
      "epoch 24 | loss: 0.59391 |  0:00:13s\n",
      "epoch 25 | loss: 0.5953  |  0:00:13s\n",
      "epoch 26 | loss: 0.59655 |  0:00:14s\n",
      "epoch 27 | loss: 0.59817 |  0:00:14s\n",
      "epoch 28 | loss: 0.59614 |  0:00:15s\n",
      "epoch 29 | loss: 0.5868  |  0:00:15s\n",
      "epoch 30 | loss: 0.58779 |  0:00:16s\n",
      "epoch 31 | loss: 0.58245 |  0:00:16s\n",
      "epoch 32 | loss: 0.58223 |  0:00:17s\n",
      "epoch 33 | loss: 0.57471 |  0:00:18s\n",
      "epoch 34 | loss: 0.58179 |  0:00:18s\n",
      "epoch 35 | loss: 0.58156 |  0:00:19s\n",
      "epoch 36 | loss: 0.59145 |  0:00:19s\n",
      "epoch 37 | loss: 0.58493 |  0:00:20s\n",
      "epoch 38 | loss: 0.59151 |  0:00:20s\n",
      "epoch 39 | loss: 0.57224 |  0:00:21s\n",
      "epoch 40 | loss: 0.58679 |  0:00:21s\n",
      "epoch 41 | loss: 0.57719 |  0:00:22s\n",
      "epoch 42 | loss: 0.58576 |  0:00:22s\n",
      "epoch 43 | loss: 0.58304 |  0:00:23s\n",
      "epoch 44 | loss: 0.57926 |  0:00:23s\n",
      "epoch 45 | loss: 0.57351 |  0:00:24s\n",
      "epoch 46 | loss: 0.58545 |  0:00:24s\n",
      "epoch 47 | loss: 0.57549 |  0:00:25s\n",
      "epoch 48 | loss: 0.57425 |  0:00:26s\n",
      "epoch 49 | loss: 0.57383 |  0:00:26s\n",
      "epoch 50 | loss: 0.58537 |  0:00:27s\n",
      "epoch 51 | loss: 0.57218 |  0:00:27s\n",
      "epoch 52 | loss: 0.57732 |  0:00:28s\n",
      "epoch 53 | loss: 0.58799 |  0:00:28s\n",
      "epoch 54 | loss: 0.5955  |  0:00:29s\n",
      "epoch 55 | loss: 0.58307 |  0:00:29s\n",
      "epoch 56 | loss: 0.57582 |  0:00:30s\n",
      "epoch 57 | loss: 0.58532 |  0:00:30s\n",
      "epoch 58 | loss: 0.57742 |  0:00:31s\n",
      "epoch 59 | loss: 0.57429 |  0:00:31s\n",
      "epoch 60 | loss: 0.58042 |  0:00:32s\n",
      "epoch 61 | loss: 0.57605 |  0:00:32s\n",
      "epoch 62 | loss: 0.574   |  0:00:33s\n",
      "epoch 63 | loss: 0.58449 |  0:00:34s\n",
      "epoch 64 | loss: 0.58158 |  0:00:34s\n",
      "epoch 65 | loss: 0.5813  |  0:00:35s\n",
      "epoch 66 | loss: 0.58508 |  0:00:35s\n",
      "epoch 67 | loss: 0.58571 |  0:00:36s\n",
      "epoch 68 | loss: 0.57687 |  0:00:36s\n",
      "epoch 69 | loss: 0.57458 |  0:00:37s\n",
      "epoch 70 | loss: 0.56663 |  0:00:37s\n",
      "epoch 71 | loss: 0.57124 |  0:00:38s\n",
      "epoch 72 | loss: 0.57698 |  0:00:38s\n",
      "epoch 73 | loss: 0.56764 |  0:00:39s\n",
      "epoch 74 | loss: 0.57828 |  0:00:39s\n",
      "epoch 75 | loss: 0.56266 |  0:00:40s\n",
      "epoch 76 | loss: 0.57977 |  0:00:40s\n",
      "epoch 77 | loss: 0.57343 |  0:00:41s\n",
      "epoch 78 | loss: 0.57401 |  0:00:41s\n",
      "epoch 79 | loss: 0.57147 |  0:00:42s\n",
      "epoch 80 | loss: 0.57433 |  0:00:42s\n",
      "epoch 81 | loss: 0.57829 |  0:00:43s\n",
      "epoch 82 | loss: 0.5757  |  0:00:43s\n",
      "epoch 83 | loss: 0.57709 |  0:00:44s\n",
      "epoch 84 | loss: 0.56369 |  0:00:44s\n",
      "epoch 85 | loss: 0.57195 |  0:00:45s\n",
      "epoch 86 | loss: 0.56514 |  0:00:45s\n",
      "epoch 87 | loss: 0.5649  |  0:00:46s\n",
      "epoch 88 | loss: 0.56148 |  0:00:46s\n",
      "epoch 89 | loss: 0.55943 |  0:00:47s\n",
      "epoch 90 | loss: 0.54892 |  0:00:47s\n",
      "epoch 91 | loss: 0.56821 |  0:00:48s\n",
      "epoch 92 | loss: 0.56291 |  0:00:48s\n",
      "epoch 93 | loss: 0.56067 |  0:00:49s\n",
      "epoch 94 | loss: 0.55979 |  0:00:49s\n",
      "epoch 95 | loss: 0.57238 |  0:00:50s\n",
      "epoch 96 | loss: 0.56471 |  0:00:50s\n",
      "epoch 97 | loss: 0.55796 |  0:00:51s\n",
      "epoch 98 | loss: 0.55951 |  0:00:51s\n",
      "epoch 99 | loss: 0.55748 |  0:00:52s\n",
      "Eval TABNET\n",
      "Accuracy: 0.7\n",
      "Precision: 0.7\n",
      "Recall: 0.7\n",
      "F1-score: 0.7\n",
      "ROC-AUC score: 0.7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 16:30:52,958]\u001B[0m A new study created in memory with name: no-name-bb876f6c-67f4-4b7c-ae36-15bdd5c2b869\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.7125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:31:18,743]\u001B[0m Trial 0 finished with value: 0.7125 and parameters: {'n_d': 60, 'n_a': 19, 'n_steps': 11, 'gamma': 0.4786525030500779, 'n_independent': 7, 'n_shared': 4, 'lambda_sparse': 0.055494993735953645}. Best is trial 0 with value: 0.7125.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.69222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:31:28,135]\u001B[0m Trial 1 finished with value: 0.6922222222222222 and parameters: {'n_d': 36, 'n_a': 45, 'n_steps': 2, 'gamma': 1.1998641905703877, 'n_independent': 8, 'n_shared': 5, 'lambda_sparse': 0.0041373545509611805}. Best is trial 0 with value: 0.7125.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.59083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:32:04,932]\u001B[0m Trial 2 finished with value: 0.5908333333333333 and parameters: {'n_d': 38, 'n_a': 9, 'n_steps': 14, 'gamma': 1.7342177431325232, 'n_independent': 10, 'n_shared': 9, 'lambda_sparse': 0.06744497564651562}. Best is trial 0 with value: 0.7125.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.69472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:32:12,844]\u001B[0m Trial 3 finished with value: 0.6947222222222222 and parameters: {'n_d': 23, 'n_a': 58, 'n_steps': 5, 'gamma': 1.408738324658028, 'n_independent': 3, 'n_shared': 6, 'lambda_sparse': 0.037842752418960665}. Best is trial 0 with value: 0.7125.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.74833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:32:46,407]\u001B[0m Trial 4 finished with value: 0.7483333333333333 and parameters: {'n_d': 16, 'n_a': 42, 'n_steps': 8, 'gamma': 0.24912824965637023, 'n_independent': 9, 'n_shared': 8, 'lambda_sparse': 0.029592609695851865}. Best is trial 4 with value: 0.7483333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.69958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:34:01,903]\u001B[0m Trial 5 finished with value: 0.6995833333333333 and parameters: {'n_d': 45, 'n_a': 46, 'n_steps': 16, 'gamma': 1.6790756655299184, 'n_independent': 10, 'n_shared': 5, 'lambda_sparse': 0.07274478482550845}. Best is trial 4 with value: 0.7483333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.69153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:35:21,186]\u001B[0m Trial 6 finished with value: 0.6915277777777777 and parameters: {'n_d': 24, 'n_a': 28, 'n_steps': 14, 'gamma': 1.514108794577498, 'n_independent': 10, 'n_shared': 9, 'lambda_sparse': 0.02030809454633252}. Best is trial 4 with value: 0.7483333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 37 and best_val_0_auc = 0.67472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:38:49,413]\u001B[0m Trial 7 finished with value: 0.6747222222222222 and parameters: {'n_d': 39, 'n_a': 19, 'n_steps': 19, 'gamma': 1.9389221590031154, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.050374894299929175}. Best is trial 4 with value: 0.7483333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.67444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:39:35,174]\u001B[0m Trial 8 finished with value: 0.6744444444444444 and parameters: {'n_d': 38, 'n_a': 50, 'n_steps': 15, 'gamma': 1.982749312591188, 'n_independent': 5, 'n_shared': 8, 'lambda_sparse': 0.09617453653761329}. Best is trial 4 with value: 0.7483333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.69889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:41:21,408]\u001B[0m Trial 9 finished with value: 0.6988888888888888 and parameters: {'n_d': 63, 'n_a': 56, 'n_steps': 16, 'gamma': 0.8588660317550576, 'n_independent': 5, 'n_shared': 7, 'lambda_sparse': 0.09567448802736822}. Best is trial 4 with value: 0.7483333333333333.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.5812  |  0:00:01s\n",
      "epoch 1  | loss: 1.31554 |  0:00:02s\n",
      "epoch 2  | loss: 0.98916 |  0:00:04s\n",
      "epoch 3  | loss: 0.88934 |  0:00:05s\n",
      "epoch 4  | loss: 0.88951 |  0:00:06s\n",
      "epoch 5  | loss: 0.81512 |  0:00:08s\n",
      "epoch 6  | loss: 0.79425 |  0:00:09s\n",
      "epoch 7  | loss: 0.77204 |  0:00:10s\n",
      "epoch 8  | loss: 0.73042 |  0:00:12s\n",
      "epoch 9  | loss: 0.75898 |  0:00:13s\n",
      "epoch 10 | loss: 0.70347 |  0:00:14s\n",
      "epoch 11 | loss: 0.69977 |  0:00:16s\n",
      "epoch 12 | loss: 0.69667 |  0:00:17s\n",
      "epoch 13 | loss: 0.67664 |  0:00:18s\n",
      "epoch 14 | loss: 0.65714 |  0:00:20s\n",
      "epoch 15 | loss: 0.64831 |  0:00:21s\n",
      "epoch 16 | loss: 0.64321 |  0:00:22s\n",
      "epoch 17 | loss: 0.63726 |  0:00:24s\n",
      "epoch 18 | loss: 0.63266 |  0:00:25s\n",
      "epoch 19 | loss: 0.63327 |  0:00:26s\n",
      "epoch 20 | loss: 0.62919 |  0:00:28s\n",
      "epoch 21 | loss: 0.6314  |  0:00:29s\n",
      "epoch 22 | loss: 0.62681 |  0:00:30s\n",
      "epoch 23 | loss: 0.61474 |  0:00:32s\n",
      "epoch 24 | loss: 0.61745 |  0:00:33s\n",
      "epoch 25 | loss: 0.61924 |  0:00:34s\n",
      "epoch 26 | loss: 0.60411 |  0:00:36s\n",
      "epoch 27 | loss: 0.60928 |  0:00:37s\n",
      "epoch 28 | loss: 0.6119  |  0:00:38s\n",
      "epoch 29 | loss: 0.59518 |  0:00:40s\n",
      "epoch 30 | loss: 0.59365 |  0:00:41s\n",
      "epoch 31 | loss: 0.59356 |  0:00:42s\n",
      "epoch 32 | loss: 0.5937  |  0:00:44s\n",
      "epoch 33 | loss: 0.58456 |  0:00:45s\n",
      "epoch 34 | loss: 0.58709 |  0:00:46s\n",
      "epoch 35 | loss: 0.58589 |  0:00:48s\n",
      "epoch 36 | loss: 0.57908 |  0:00:49s\n",
      "epoch 37 | loss: 0.58273 |  0:00:50s\n",
      "epoch 38 | loss: 0.57099 |  0:00:52s\n",
      "epoch 39 | loss: 0.5631  |  0:00:53s\n",
      "epoch 40 | loss: 0.56882 |  0:00:54s\n",
      "epoch 41 | loss: 0.55256 |  0:00:56s\n",
      "epoch 42 | loss: 0.55259 |  0:00:57s\n",
      "epoch 43 | loss: 0.55815 |  0:00:58s\n",
      "epoch 44 | loss: 0.54881 |  0:01:00s\n",
      "epoch 45 | loss: 0.53685 |  0:01:01s\n",
      "epoch 46 | loss: 0.53646 |  0:01:02s\n",
      "epoch 47 | loss: 0.52273 |  0:01:04s\n",
      "epoch 48 | loss: 0.52445 |  0:01:05s\n",
      "epoch 49 | loss: 0.52682 |  0:01:06s\n",
      "epoch 50 | loss: 0.51404 |  0:01:08s\n",
      "epoch 51 | loss: 0.51383 |  0:01:09s\n",
      "epoch 52 | loss: 0.51211 |  0:01:10s\n",
      "epoch 53 | loss: 0.48596 |  0:01:12s\n",
      "epoch 54 | loss: 0.49559 |  0:01:13s\n",
      "epoch 55 | loss: 0.50415 |  0:01:14s\n",
      "epoch 56 | loss: 0.48871 |  0:01:16s\n",
      "epoch 57 | loss: 0.47846 |  0:01:17s\n",
      "epoch 58 | loss: 0.47928 |  0:01:18s\n",
      "epoch 59 | loss: 0.46486 |  0:01:20s\n",
      "epoch 60 | loss: 0.45953 |  0:01:21s\n",
      "epoch 61 | loss: 0.45617 |  0:01:22s\n",
      "epoch 62 | loss: 0.45536 |  0:01:24s\n",
      "epoch 63 | loss: 0.45748 |  0:01:25s\n",
      "epoch 64 | loss: 0.44857 |  0:01:26s\n",
      "epoch 65 | loss: 0.43668 |  0:01:28s\n",
      "epoch 66 | loss: 0.43498 |  0:01:29s\n",
      "epoch 67 | loss: 0.42915 |  0:01:30s\n",
      "epoch 68 | loss: 0.42698 |  0:01:32s\n",
      "epoch 69 | loss: 0.42019 |  0:01:33s\n",
      "epoch 70 | loss: 0.41897 |  0:01:34s\n",
      "epoch 71 | loss: 0.41395 |  0:01:36s\n",
      "epoch 72 | loss: 0.41213 |  0:01:37s\n",
      "epoch 73 | loss: 0.40077 |  0:01:38s\n",
      "epoch 74 | loss: 0.40413 |  0:01:40s\n",
      "epoch 75 | loss: 0.398   |  0:01:41s\n",
      "epoch 76 | loss: 0.38649 |  0:01:42s\n",
      "epoch 77 | loss: 0.38974 |  0:01:44s\n",
      "epoch 78 | loss: 0.38737 |  0:01:45s\n",
      "epoch 79 | loss: 0.38096 |  0:01:46s\n",
      "epoch 80 | loss: 0.41826 |  0:01:48s\n",
      "epoch 81 | loss: 0.39685 |  0:01:49s\n",
      "epoch 82 | loss: 0.39462 |  0:01:50s\n",
      "epoch 83 | loss: 0.37857 |  0:01:52s\n",
      "epoch 84 | loss: 0.36593 |  0:01:53s\n",
      "epoch 85 | loss: 0.37712 |  0:01:54s\n",
      "epoch 86 | loss: 0.37509 |  0:01:55s\n",
      "epoch 87 | loss: 0.35305 |  0:01:57s\n",
      "epoch 88 | loss: 0.35993 |  0:01:58s\n",
      "epoch 89 | loss: 0.37727 |  0:01:59s\n",
      "epoch 90 | loss: 0.35479 |  0:02:01s\n",
      "epoch 91 | loss: 0.35744 |  0:02:02s\n",
      "epoch 92 | loss: 0.3576  |  0:02:03s\n",
      "epoch 93 | loss: 0.3422  |  0:02:05s\n",
      "epoch 94 | loss: 0.33576 |  0:02:06s\n",
      "epoch 95 | loss: 0.3535  |  0:02:08s\n",
      "epoch 96 | loss: 0.35067 |  0:02:09s\n",
      "epoch 97 | loss: 0.33721 |  0:02:10s\n",
      "epoch 98 | loss: 0.33297 |  0:02:12s\n",
      "epoch 99 | loss: 0.32792 |  0:02:13s\n",
      "Eval TABNET\n",
      "Accuracy: 0.61\n",
      "Precision: 0.61\n",
      "Recall: 0.58\n",
      "F1-score: 0.6\n",
      "ROC-AUC score: 0.61\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 16:43:35,880]\u001B[0m A new study created in memory with name: no-name-ee25cc60-a0d0-4b62-8f8c-0daf8e4871af\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.98333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:43:46,370]\u001B[0m Trial 0 finished with value: 0.9833333333333334 and parameters: {'n_d': 39, 'n_a': 26, 'n_steps': 3, 'gamma': 0.11059820077025899, 'n_independent': 10, 'n_shared': 1, 'lambda_sparse': 0.04664492346661858}. Best is trial 0 with value: 0.9833333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.93028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:44:08,389]\u001B[0m Trial 1 finished with value: 0.9302777777777778 and parameters: {'n_d': 56, 'n_a': 14, 'n_steps': 11, 'gamma': 1.7980600719626343, 'n_independent': 2, 'n_shared': 5, 'lambda_sparse': 0.08957345043731275}. Best is trial 0 with value: 0.9833333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.98306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:44:30,195]\u001B[0m Trial 2 finished with value: 0.9830555555555556 and parameters: {'n_d': 43, 'n_a': 34, 'n_steps': 3, 'gamma': 1.5442083492285361, 'n_independent': 10, 'n_shared': 9, 'lambda_sparse': 0.003109532620289428}. Best is trial 0 with value: 0.9833333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.98278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:45:08,390]\u001B[0m Trial 3 finished with value: 0.9827777777777778 and parameters: {'n_d': 16, 'n_a': 61, 'n_steps': 12, 'gamma': 0.809577045375274, 'n_independent': 3, 'n_shared': 6, 'lambda_sparse': 0.0072813614673300255}. Best is trial 0 with value: 0.9833333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.96722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:45:37,921]\u001B[0m Trial 4 finished with value: 0.9672222222222222 and parameters: {'n_d': 10, 'n_a': 63, 'n_steps': 9, 'gamma': 0.9471580902453999, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.08784384309608483}. Best is trial 0 with value: 0.9833333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.93306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:46:04,495]\u001B[0m Trial 5 finished with value: 0.9330555555555555 and parameters: {'n_d': 10, 'n_a': 26, 'n_steps': 15, 'gamma': 1.8719112611956206, 'n_independent': 1, 'n_shared': 7, 'lambda_sparse': 0.046503736971439696}. Best is trial 0 with value: 0.9833333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_auc = 0.98806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:46:48,470]\u001B[0m Trial 6 finished with value: 0.9880555555555555 and parameters: {'n_d': 25, 'n_a': 8, 'n_steps': 6, 'gamma': 0.9353882612349917, 'n_independent': 7, 'n_shared': 10, 'lambda_sparse': 0.08563957165471082}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.88306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:47:40,511]\u001B[0m Trial 7 finished with value: 0.8830555555555556 and parameters: {'n_d': 54, 'n_a': 33, 'n_steps': 16, 'gamma': 1.5958751883337752, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.0869777407030971}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_auc = 0.95194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:48:32,446]\u001B[0m Trial 8 finished with value: 0.9519444444444445 and parameters: {'n_d': 53, 'n_a': 50, 'n_steps': 9, 'gamma': 1.5660484599275795, 'n_independent': 1, 'n_shared': 6, 'lambda_sparse': 0.04024067587091411}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.95139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:49:24,782]\u001B[0m Trial 9 finished with value: 0.9513888888888888 and parameters: {'n_d': 61, 'n_a': 51, 'n_steps': 14, 'gamma': 0.2146068332985894, 'n_independent': 9, 'n_shared': 6, 'lambda_sparse': 0.030440567396688645}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.5575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:49:53,534]\u001B[0m Trial 10 finished with value: 0.5575 and parameters: {'n_d': 25, 'n_a': 10, 'n_steps': 19, 'gamma': 1.1739675538210141, 'n_independent': 5, 'n_shared': 10, 'lambda_sparse': 0.06885214353066088}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:49:59,153]\u001B[0m Trial 11 finished with value: 0.9819444444444445 and parameters: {'n_d': 32, 'n_a': 19, 'n_steps': 3, 'gamma': 0.12957826215117796, 'n_independent': 7, 'n_shared': 1, 'lambda_sparse': 0.06404761599435663}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.98194\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.96083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:50:11,725]\u001B[0m Trial 12 finished with value: 0.9608333333333333 and parameters: {'n_d': 40, 'n_a': 22, 'n_steps': 6, 'gamma': 0.49902255554732033, 'n_independent': 8, 'n_shared': 3, 'lambda_sparse': 0.06404469100383059}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:50:16,344]\u001B[0m Trial 13 finished with value: 0.9641666666666666 and parameters: {'n_d': 32, 'n_a': 8, 'n_steps': 1, 'gamma': 0.6706526233765747, 'n_independent': 5, 'n_shared': 4, 'lambda_sparse': 0.09950143015030727}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.96417\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.98722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:50:40,947]\u001B[0m Trial 14 finished with value: 0.9872222222222222 and parameters: {'n_d': 22, 'n_a': 43, 'n_steps': 6, 'gamma': 0.4415086008095346, 'n_independent': 7, 'n_shared': 8, 'lambda_sparse': 0.05582675710733569}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:51:10,780]\u001B[0m Trial 15 finished with value: 0.94 and parameters: {'n_d': 21, 'n_a': 45, 'n_steps': 7, 'gamma': 1.183887740748214, 'n_independent': 6, 'n_shared': 8, 'lambda_sparse': 0.07508569764715105}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:51:42,122]\u001B[0m Trial 16 finished with value: 0.9850000000000001 and parameters: {'n_d': 23, 'n_a': 38, 'n_steps': 6, 'gamma': 0.4882016166743868, 'n_independent': 4, 'n_shared': 10, 'lambda_sparse': 0.05908256831955783}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.97028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:52:32,966]\u001B[0m Trial 17 finished with value: 0.9702777777777778 and parameters: {'n_d': 30, 'n_a': 42, 'n_steps': 7, 'gamma': 1.0692568772547626, 'n_independent': 8, 'n_shared': 8, 'lambda_sparse': 0.07774158473967789}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.98056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:52:59,807]\u001B[0m Trial 18 finished with value: 0.9805555555555556 and parameters: {'n_d': 17, 'n_a': 52, 'n_steps': 5, 'gamma': 0.39931822451838406, 'n_independent': 7, 'n_shared': 9, 'lambda_sparse': 0.05645491223465747}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:53:06,279]\u001B[0m Trial 19 finished with value: 0.9469444444444445 and parameters: {'n_d': 27, 'n_a': 30, 'n_steps': 1, 'gamma': 0.7310880549074805, 'n_independent': 6, 'n_shared': 8, 'lambda_sparse': 0.07568025025284243}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.94694\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.97194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:54:08,492]\u001B[0m Trial 20 finished with value: 0.9719444444444445 and parameters: {'n_d': 48, 'n_a': 58, 'n_steps': 8, 'gamma': 0.349962533541683, 'n_independent': 8, 'n_shared': 9, 'lambda_sparse': 0.05311675156853416}. Best is trial 6 with value: 0.9880555555555555.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.04802 |  0:00:00s\n",
      "epoch 1  | loss: 1.38172 |  0:00:01s\n",
      "epoch 2  | loss: 1.17828 |  0:00:02s\n",
      "epoch 3  | loss: 1.16129 |  0:00:03s\n",
      "epoch 4  | loss: 1.0619  |  0:00:04s\n",
      "epoch 5  | loss: 0.98698 |  0:00:04s\n",
      "epoch 6  | loss: 0.92073 |  0:00:05s\n",
      "epoch 7  | loss: 0.90436 |  0:00:06s\n",
      "epoch 8  | loss: 0.85059 |  0:00:07s\n",
      "epoch 9  | loss: 0.79584 |  0:00:08s\n",
      "epoch 10 | loss: 0.78748 |  0:00:08s\n",
      "epoch 11 | loss: 0.78589 |  0:00:09s\n",
      "epoch 12 | loss: 0.86128 |  0:00:10s\n",
      "epoch 13 | loss: 0.86131 |  0:00:11s\n",
      "epoch 14 | loss: 0.80699 |  0:00:12s\n",
      "epoch 15 | loss: 0.80227 |  0:00:12s\n",
      "epoch 16 | loss: 0.79292 |  0:00:13s\n",
      "epoch 17 | loss: 0.85104 |  0:00:14s\n",
      "epoch 18 | loss: 0.77776 |  0:00:15s\n",
      "epoch 19 | loss: 0.73441 |  0:00:16s\n",
      "epoch 20 | loss: 0.73046 |  0:00:16s\n",
      "epoch 21 | loss: 0.70507 |  0:00:17s\n",
      "epoch 22 | loss: 0.72484 |  0:00:18s\n",
      "epoch 23 | loss: 0.71635 |  0:00:19s\n",
      "epoch 24 | loss: 0.69981 |  0:00:19s\n",
      "epoch 25 | loss: 0.69665 |  0:00:20s\n",
      "epoch 26 | loss: 0.69739 |  0:00:21s\n",
      "epoch 27 | loss: 0.695   |  0:00:22s\n",
      "epoch 28 | loss: 0.68595 |  0:00:23s\n",
      "epoch 29 | loss: 0.68123 |  0:00:23s\n",
      "epoch 30 | loss: 0.687   |  0:00:24s\n",
      "epoch 31 | loss: 0.68133 |  0:00:25s\n",
      "epoch 32 | loss: 0.67795 |  0:00:26s\n",
      "epoch 33 | loss: 0.66472 |  0:00:27s\n",
      "epoch 34 | loss: 0.66091 |  0:00:27s\n",
      "epoch 35 | loss: 0.6646  |  0:00:28s\n",
      "epoch 36 | loss: 0.65611 |  0:00:29s\n",
      "epoch 37 | loss: 0.65455 |  0:00:30s\n",
      "epoch 38 | loss: 0.66586 |  0:00:31s\n",
      "epoch 39 | loss: 0.66394 |  0:00:31s\n",
      "epoch 40 | loss: 0.65257 |  0:00:32s\n",
      "epoch 41 | loss: 0.64246 |  0:00:33s\n",
      "epoch 42 | loss: 0.63558 |  0:00:34s\n",
      "epoch 43 | loss: 0.63244 |  0:00:35s\n",
      "epoch 44 | loss: 0.63041 |  0:00:35s\n",
      "epoch 45 | loss: 0.62899 |  0:00:36s\n",
      "epoch 46 | loss: 0.62364 |  0:00:37s\n",
      "epoch 47 | loss: 0.63522 |  0:00:38s\n",
      "epoch 48 | loss: 0.61863 |  0:00:38s\n",
      "epoch 49 | loss: 0.6168  |  0:00:39s\n",
      "epoch 50 | loss: 0.62771 |  0:00:40s\n",
      "epoch 51 | loss: 0.61714 |  0:00:41s\n",
      "epoch 52 | loss: 0.62268 |  0:00:42s\n",
      "epoch 53 | loss: 0.61805 |  0:00:42s\n",
      "epoch 54 | loss: 0.62085 |  0:00:43s\n",
      "epoch 55 | loss: 0.62321 |  0:00:44s\n",
      "epoch 56 | loss: 0.60987 |  0:00:45s\n",
      "epoch 57 | loss: 0.61264 |  0:00:46s\n",
      "epoch 58 | loss: 0.62425 |  0:00:46s\n",
      "epoch 59 | loss: 0.61772 |  0:00:47s\n",
      "epoch 60 | loss: 0.61937 |  0:00:48s\n",
      "epoch 61 | loss: 0.61455 |  0:00:49s\n",
      "epoch 62 | loss: 0.62203 |  0:00:50s\n",
      "epoch 63 | loss: 0.61643 |  0:00:50s\n",
      "epoch 64 | loss: 0.61809 |  0:00:51s\n",
      "epoch 65 | loss: 0.61195 |  0:00:52s\n",
      "epoch 66 | loss: 0.6113  |  0:00:53s\n",
      "epoch 67 | loss: 0.61544 |  0:00:53s\n",
      "epoch 68 | loss: 0.60963 |  0:00:54s\n",
      "epoch 69 | loss: 0.61476 |  0:00:55s\n",
      "epoch 70 | loss: 0.61994 |  0:00:56s\n",
      "epoch 71 | loss: 0.62167 |  0:00:57s\n",
      "epoch 72 | loss: 0.62025 |  0:00:57s\n",
      "epoch 73 | loss: 0.62246 |  0:00:58s\n",
      "epoch 74 | loss: 0.61675 |  0:00:59s\n",
      "epoch 75 | loss: 0.62163 |  0:01:00s\n",
      "epoch 76 | loss: 0.61538 |  0:01:01s\n",
      "epoch 77 | loss: 0.62006 |  0:01:01s\n",
      "epoch 78 | loss: 0.6197  |  0:01:02s\n",
      "epoch 79 | loss: 0.61954 |  0:01:03s\n",
      "epoch 80 | loss: 0.60996 |  0:01:04s\n",
      "epoch 81 | loss: 0.61431 |  0:01:04s\n",
      "epoch 82 | loss: 0.61371 |  0:01:05s\n",
      "epoch 83 | loss: 0.60431 |  0:01:06s\n",
      "epoch 84 | loss: 0.60464 |  0:01:07s\n",
      "epoch 85 | loss: 0.61717 |  0:01:08s\n",
      "epoch 86 | loss: 0.61067 |  0:01:08s\n",
      "epoch 87 | loss: 0.60935 |  0:01:09s\n",
      "epoch 88 | loss: 0.61311 |  0:01:10s\n",
      "epoch 89 | loss: 0.61525 |  0:01:11s\n",
      "epoch 90 | loss: 0.61628 |  0:01:11s\n",
      "epoch 91 | loss: 0.60632 |  0:01:12s\n",
      "epoch 92 | loss: 0.6073  |  0:01:13s\n",
      "epoch 93 | loss: 0.60259 |  0:01:14s\n",
      "epoch 94 | loss: 0.6059  |  0:01:15s\n",
      "epoch 95 | loss: 0.61361 |  0:01:15s\n",
      "epoch 96 | loss: 0.60519 |  0:01:16s\n",
      "epoch 97 | loss: 0.60657 |  0:01:17s\n",
      "epoch 98 | loss: 0.61471 |  0:01:18s\n",
      "epoch 99 | loss: 0.61277 |  0:01:19s\n",
      "Eval TABNET\n",
      "Accuracy: 0.88\n",
      "Precision: 0.91\n",
      "Recall: 0.85\n",
      "F1-score: 0.88\n",
      "ROC-AUC score: 0.88\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 16:55:28,244]\u001B[0m A new study created in memory with name: no-name-e16abbe0-8bd7-46b4-92d2-29d801bd6717\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.61444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:55:43,305]\u001B[0m Trial 0 finished with value: 0.6144444444444445 and parameters: {'n_d': 19, 'n_a': 37, 'n_steps': 10, 'gamma': 0.8832689656056156, 'n_independent': 4, 'n_shared': 2, 'lambda_sparse': 0.05113629322458039}. Best is trial 0 with value: 0.6144444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:56:00,567]\u001B[0m Trial 1 finished with value: 0.5524999999999999 and parameters: {'n_d': 53, 'n_a': 63, 'n_steps': 7, 'gamma': 0.9569660048901557, 'n_independent': 2, 'n_shared': 6, 'lambda_sparse': 0.03399778928766522}. Best is trial 0 with value: 0.6144444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.5475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:56:29,686]\u001B[0m Trial 2 finished with value: 0.5475 and parameters: {'n_d': 14, 'n_a': 54, 'n_steps': 16, 'gamma': 0.5312370081078162, 'n_independent': 5, 'n_shared': 7, 'lambda_sparse': 0.045723751820289545}. Best is trial 0 with value: 0.6144444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.56333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:56:39,052]\u001B[0m Trial 3 finished with value: 0.5633333333333334 and parameters: {'n_d': 22, 'n_a': 40, 'n_steps': 15, 'gamma': 1.774248081066656, 'n_independent': 1, 'n_shared': 1, 'lambda_sparse': 0.05125252428166586}. Best is trial 0 with value: 0.6144444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.54972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:56:46,316]\u001B[0m Trial 4 finished with value: 0.5497222222222222 and parameters: {'n_d': 48, 'n_a': 24, 'n_steps': 6, 'gamma': 1.309708821706409, 'n_independent': 1, 'n_shared': 8, 'lambda_sparse': 0.09955985943237472}. Best is trial 0 with value: 0.6144444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.58194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:57:14,571]\u001B[0m Trial 5 finished with value: 0.5819444444444445 and parameters: {'n_d': 24, 'n_a': 50, 'n_steps': 9, 'gamma': 1.0991781868953172, 'n_independent': 4, 'n_shared': 3, 'lambda_sparse': 0.007313985218637126}. Best is trial 0 with value: 0.6144444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.51389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:57:20,611]\u001B[0m Trial 6 finished with value: 0.5138888888888888 and parameters: {'n_d': 12, 'n_a': 14, 'n_steps': 3, 'gamma': 0.6228358394549124, 'n_independent': 9, 'n_shared': 8, 'lambda_sparse': 0.012715068902952455}. Best is trial 0 with value: 0.6144444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.57278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:57:59,551]\u001B[0m Trial 7 finished with value: 0.5727777777777778 and parameters: {'n_d': 59, 'n_a': 46, 'n_steps': 7, 'gamma': 1.6092658483790885, 'n_independent': 8, 'n_shared': 8, 'lambda_sparse': 0.08731862801006741}. Best is trial 0 with value: 0.6144444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.54806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:58:11,811]\u001B[0m Trial 8 finished with value: 0.5480555555555556 and parameters: {'n_d': 11, 'n_a': 27, 'n_steps': 7, 'gamma': 1.6612237517096853, 'n_independent': 8, 'n_shared': 4, 'lambda_sparse': 0.04586500126756518}. Best is trial 0 with value: 0.6144444444444445.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:58:15,352]\u001B[0m Trial 9 finished with value: 0.5236111111111111 and parameters: {'n_d': 22, 'n_a': 47, 'n_steps': 2, 'gamma': 1.5224836452816077, 'n_independent': 3, 'n_shared': 6, 'lambda_sparse': 0.03272778356225988}. Best is trial 0 with value: 0.6144444444444445.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.52361\n",
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.63583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:58:29,403]\u001B[0m Trial 10 finished with value: 0.6358333333333334 and parameters: {'n_d': 38, 'n_a': 31, 'n_steps': 13, 'gamma': 0.16970743748628092, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.06881096960722845}. Best is trial 10 with value: 0.6358333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.66056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:58:48,042]\u001B[0m Trial 11 finished with value: 0.6605555555555556 and parameters: {'n_d': 37, 'n_a': 31, 'n_steps': 13, 'gamma': 0.1129568337087199, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.06980836466538906}. Best is trial 11 with value: 0.6605555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.59417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 16:59:13,534]\u001B[0m Trial 12 finished with value: 0.5941666666666666 and parameters: {'n_d': 37, 'n_a': 27, 'n_steps': 13, 'gamma': 0.1276783676616875, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.07239631084856317}. Best is trial 11 with value: 0.6605555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.52889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:00:00,781]\u001B[0m Trial 13 finished with value: 0.5288888888888889 and parameters: {'n_d': 36, 'n_a': 9, 'n_steps': 19, 'gamma': 0.11874503442801776, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.07470255550429944}. Best is trial 11 with value: 0.6605555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.61889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:00:25,434]\u001B[0m Trial 14 finished with value: 0.6188888888888889 and parameters: {'n_d': 36, 'n_a': 22, 'n_steps': 13, 'gamma': 0.39233647410759354, 'n_independent': 7, 'n_shared': 4, 'lambda_sparse': 0.06762552875854196}. Best is trial 11 with value: 0.6605555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.61847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:00:52,864]\u001B[0m Trial 15 finished with value: 0.6184722222222223 and parameters: {'n_d': 41, 'n_a': 32, 'n_steps': 13, 'gamma': 0.3535004877203024, 'n_independent': 10, 'n_shared': 3, 'lambda_sparse': 0.06431019150156368}. Best is trial 11 with value: 0.6605555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.61389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:01:11,320]\u001B[0m Trial 16 finished with value: 0.6138888888888888 and parameters: {'n_d': 29, 'n_a': 17, 'n_steps': 18, 'gamma': 0.6961965940997336, 'n_independent': 5, 'n_shared': 1, 'lambda_sparse': 0.08406265261409918}. Best is trial 11 with value: 0.6605555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.63444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:01:54,005]\u001B[0m Trial 17 finished with value: 0.6344444444444444 and parameters: {'n_d': 44, 'n_a': 34, 'n_steps': 12, 'gamma': 0.25895065686493973, 'n_independent': 7, 'n_shared': 3, 'lambda_sparse': 0.06121831159937898}. Best is trial 11 with value: 0.6605555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.6225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:02:16,710]\u001B[0m Trial 18 finished with value: 0.6225 and parameters: {'n_d': 31, 'n_a': 41, 'n_steps': 16, 'gamma': 0.44997880215710395, 'n_independent': 7, 'n_shared': 2, 'lambda_sparse': 0.07850669192388993}. Best is trial 11 with value: 0.6605555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:02:31,921]\u001B[0m Trial 19 finished with value: 0.625 and parameters: {'n_d': 63, 'n_a': 30, 'n_steps': 11, 'gamma': 0.10244322525413752, 'n_independent': 4, 'n_shared': 5, 'lambda_sparse': 0.0923011599384239}. Best is trial 11 with value: 0.6605555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.57167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:03:33,296]\u001B[0m Trial 20 finished with value: 0.5716666666666667 and parameters: {'n_d': 52, 'n_a': 19, 'n_steps': 15, 'gamma': 1.993848471030037, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.08078381213701966}. Best is trial 11 with value: 0.6605555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.56806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:03:50,114]\u001B[0m Trial 21 finished with value: 0.5680555555555554 and parameters: {'n_d': 45, 'n_a': 34, 'n_steps': 12, 'gamma': 0.24907835187791413, 'n_independent': 7, 'n_shared': 3, 'lambda_sparse': 0.06515335054733204}. Best is trial 11 with value: 0.6605555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.60167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:04:12,115]\u001B[0m Trial 22 finished with value: 0.6016666666666666 and parameters: {'n_d': 43, 'n_a': 38, 'n_steps': 9, 'gamma': 0.30663735941687065, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.059933916323737936}. Best is trial 11 with value: 0.6605555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.66847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:04:33,710]\u001B[0m Trial 23 finished with value: 0.6684722222222222 and parameters: {'n_d': 33, 'n_a': 31, 'n_steps': 14, 'gamma': 0.21908290166246946, 'n_independent': 8, 'n_shared': 2, 'lambda_sparse': 0.05889033740336025}. Best is trial 23 with value: 0.6684722222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.57778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:05:23,234]\u001B[0m Trial 24 finished with value: 0.5777777777777778 and parameters: {'n_d': 29, 'n_a': 29, 'n_steps': 17, 'gamma': 0.5445057743986929, 'n_independent': 8, 'n_shared': 2, 'lambda_sparse': 0.07233096603391276}. Best is trial 23 with value: 0.6684722222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.62417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:05:44,501]\u001B[0m Trial 25 finished with value: 0.6241666666666666 and parameters: {'n_d': 31, 'n_a': 23, 'n_steps': 14, 'gamma': 0.6931742018019317, 'n_independent': 5, 'n_shared': 4, 'lambda_sparse': 0.05694948971985098}. Best is trial 23 with value: 0.6684722222222222.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.72425 |  0:00:01s\n",
      "epoch 1  | loss: 1.52487 |  0:00:02s\n",
      "epoch 2  | loss: 1.14351 |  0:00:04s\n",
      "epoch 3  | loss: 0.94538 |  0:00:05s\n",
      "epoch 4  | loss: 0.88348 |  0:00:06s\n",
      "epoch 5  | loss: 0.81569 |  0:00:08s\n",
      "epoch 6  | loss: 0.77017 |  0:00:09s\n",
      "epoch 7  | loss: 0.70602 |  0:00:10s\n",
      "epoch 8  | loss: 0.71584 |  0:00:12s\n",
      "epoch 9  | loss: 0.70532 |  0:00:13s\n",
      "epoch 10 | loss: 0.6859  |  0:00:15s\n",
      "epoch 11 | loss: 0.66364 |  0:00:16s\n",
      "epoch 12 | loss: 0.6713  |  0:00:17s\n",
      "epoch 13 | loss: 0.64624 |  0:00:19s\n",
      "epoch 14 | loss: 0.63611 |  0:00:20s\n",
      "epoch 15 | loss: 0.62369 |  0:00:22s\n",
      "epoch 16 | loss: 0.61473 |  0:00:23s\n",
      "epoch 17 | loss: 0.59405 |  0:00:24s\n",
      "epoch 18 | loss: 0.59121 |  0:00:26s\n",
      "epoch 19 | loss: 0.5867  |  0:00:27s\n",
      "epoch 20 | loss: 0.5738  |  0:00:29s\n",
      "epoch 21 | loss: 0.56116 |  0:00:30s\n",
      "epoch 22 | loss: 0.54863 |  0:00:31s\n",
      "epoch 23 | loss: 0.54058 |  0:00:33s\n",
      "epoch 24 | loss: 0.53945 |  0:00:34s\n",
      "epoch 25 | loss: 0.54212 |  0:00:35s\n",
      "epoch 26 | loss: 0.53615 |  0:00:37s\n",
      "epoch 27 | loss: 0.5229  |  0:00:38s\n",
      "epoch 28 | loss: 0.5135  |  0:00:39s\n",
      "epoch 29 | loss: 0.52523 |  0:00:41s\n",
      "epoch 30 | loss: 0.49509 |  0:00:42s\n",
      "epoch 31 | loss: 0.48726 |  0:00:43s\n",
      "epoch 32 | loss: 0.49308 |  0:00:45s\n",
      "epoch 33 | loss: 0.51269 |  0:00:46s\n",
      "epoch 34 | loss: 0.4764  |  0:00:48s\n",
      "epoch 35 | loss: 0.48762 |  0:00:49s\n",
      "epoch 36 | loss: 0.46826 |  0:00:50s\n",
      "epoch 37 | loss: 0.46169 |  0:00:52s\n",
      "epoch 38 | loss: 0.44742 |  0:00:53s\n",
      "epoch 39 | loss: 0.42866 |  0:00:55s\n",
      "epoch 40 | loss: 0.44452 |  0:00:56s\n",
      "epoch 41 | loss: 0.4276  |  0:00:57s\n",
      "epoch 42 | loss: 0.40489 |  0:00:59s\n",
      "epoch 43 | loss: 0.41722 |  0:01:00s\n",
      "epoch 44 | loss: 0.40073 |  0:01:02s\n",
      "epoch 45 | loss: 0.42651 |  0:01:03s\n",
      "epoch 46 | loss: 0.39622 |  0:01:04s\n",
      "epoch 47 | loss: 0.39904 |  0:01:06s\n",
      "epoch 48 | loss: 0.38296 |  0:01:07s\n",
      "epoch 49 | loss: 0.37255 |  0:01:09s\n",
      "epoch 50 | loss: 0.3691  |  0:01:10s\n",
      "epoch 51 | loss: 0.37177 |  0:01:11s\n",
      "epoch 52 | loss: 0.35887 |  0:01:13s\n",
      "epoch 53 | loss: 0.36297 |  0:01:14s\n",
      "epoch 54 | loss: 0.3506  |  0:01:16s\n",
      "epoch 55 | loss: 0.37278 |  0:01:17s\n",
      "epoch 56 | loss: 0.37645 |  0:01:18s\n",
      "epoch 57 | loss: 0.36829 |  0:01:20s\n",
      "epoch 58 | loss: 0.33479 |  0:01:21s\n",
      "epoch 59 | loss: 0.33476 |  0:01:23s\n",
      "epoch 60 | loss: 0.32634 |  0:01:24s\n",
      "epoch 61 | loss: 0.31982 |  0:01:25s\n",
      "epoch 62 | loss: 0.31419 |  0:01:27s\n",
      "epoch 63 | loss: 0.3164  |  0:01:28s\n",
      "epoch 64 | loss: 0.31931 |  0:01:30s\n",
      "epoch 65 | loss: 0.30682 |  0:01:31s\n",
      "epoch 66 | loss: 0.30517 |  0:01:32s\n",
      "epoch 67 | loss: 0.30732 |  0:01:34s\n",
      "epoch 68 | loss: 0.2923  |  0:01:35s\n",
      "epoch 69 | loss: 0.28353 |  0:01:37s\n",
      "epoch 70 | loss: 0.30086 |  0:01:38s\n",
      "epoch 71 | loss: 0.30864 |  0:01:39s\n",
      "epoch 72 | loss: 0.30149 |  0:01:41s\n",
      "epoch 73 | loss: 0.2884  |  0:01:42s\n",
      "epoch 74 | loss: 0.2818  |  0:01:43s\n",
      "epoch 75 | loss: 0.28552 |  0:01:45s\n",
      "epoch 76 | loss: 0.27593 |  0:01:46s\n",
      "epoch 77 | loss: 0.28945 |  0:01:48s\n",
      "epoch 78 | loss: 0.27398 |  0:01:49s\n",
      "epoch 79 | loss: 0.28174 |  0:01:50s\n",
      "epoch 80 | loss: 0.26523 |  0:01:52s\n",
      "epoch 81 | loss: 0.27792 |  0:01:53s\n",
      "epoch 82 | loss: 0.26585 |  0:01:55s\n",
      "epoch 83 | loss: 0.27193 |  0:01:56s\n",
      "epoch 84 | loss: 0.25433 |  0:01:57s\n",
      "epoch 85 | loss: 0.2574  |  0:01:59s\n",
      "epoch 86 | loss: 0.26637 |  0:02:00s\n",
      "epoch 87 | loss: 0.26736 |  0:02:01s\n",
      "epoch 88 | loss: 0.27201 |  0:02:03s\n",
      "epoch 89 | loss: 0.28462 |  0:02:04s\n",
      "epoch 90 | loss: 0.29618 |  0:02:06s\n",
      "epoch 91 | loss: 0.29143 |  0:02:07s\n",
      "epoch 92 | loss: 0.26356 |  0:02:08s\n",
      "epoch 93 | loss: 0.26398 |  0:02:10s\n",
      "epoch 94 | loss: 0.26618 |  0:02:11s\n",
      "epoch 95 | loss: 0.27341 |  0:02:12s\n",
      "epoch 96 | loss: 0.25365 |  0:02:14s\n",
      "epoch 97 | loss: 0.27387 |  0:02:15s\n",
      "epoch 98 | loss: 0.25494 |  0:02:17s\n",
      "epoch 99 | loss: 0.24955 |  0:02:18s\n",
      "Eval TABNET\n",
      "Accuracy: 0.57\n",
      "Precision: 0.56\n",
      "Recall: 0.6\n",
      "F1-score: 0.58\n",
      "ROC-AUC score: 0.57\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc4AAAHsCAYAAABbgk2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoHklEQVR4nO3deViVdf7/8dfhIMiiKEOROVmSyzjlktWkSbmLYQxuialU0zS22KCZRiwuaYWGSZrjmq1mUGYumc2PGtOpa7R+mS2TldvXhUwzUAQEBM7vj36db1Ystx74eJ/zfFwX1+XZPvcbva7evd73/bmPw+VyuQQAAOrEz3QBAADYCY0TAAALaJwAAFhA4wQAwAIaJwAAFtA4AQCwgMYJ26isrNRzzz2noUOHKj4+XrGxscrMzFR5efk5rXnvvfcqJiZGK1assPz5zz//XElJSWd9/F/q06ePunTpouLi4jOeX716tdq3b6+33367xs+fPHlSt912W7Wvx8fHq7Cw0CO1Ar7K33QBQF1Nnz5dJ06c0AsvvKAmTZqopKREkyZNUlpamjIzM89qzSNHjuj999/Xjh075HQ6LX++Y8eOmj9//lkduzrNmzdXbm6uBg8e7H5uzZo1ioiIqPWzJ06c0Oeff17t62vXrvVEiYBPI3HCFg4dOqT169fr8ccfV5MmTSRJwcHBeuSRR9SvXz9JP6atSZMm6eabb1ZcXJyeeOIJVVRUSPqxwT399NMaOXKk+vTpo5UrV6qoqEh33XWXKioqNHToUB04cEDt27dXfn6++7g/PS4uLlZSUpLi4+M1ZMgQpaenq6qqStu2bdPNN998Vsevzp///GetW7fO/TgvL08lJSWKiopyP7dq1SrdcsstGjx4sHr37u1eLyUlRaWlpYqPj1dlZaWuvPJKjR8/XjExMfr888/dv8+CBQs0cuRIVVZW6vvvv1d0dLS2bt3qiX8qwOvROGEL//3vf9WmTRuFhoae8fwFF1ygmJgYSdKjjz6qZs2aaf369Xr99df19ddf69lnn5UklZeXq3nz5srOztb8+fOVkZGhRo0aaenSpWrcuLHWrl2rVq1aVXv83NxcFRcXa+3atVq1apUk6eDBg2e8x+rxy8rKfvNYPXv21FdffaWjR49K+jEl/jx9FhcX67XXXtPSpUu1Zs0aZWVluRN3RkaG+/dxOp06ffq0evfurX/+85/q2LGje417771X/v7+Wr58uR566CGNGTNG3bp1q/XfAQCNEzbh5+enqqqqGt+zZcsWjRkzRg6HQwEBARo5cqS2bNnifr1v376SpCuuuELl5eUqKSmp8/Gvvvpq7d69W4mJiVq6dKluv/12XXrppfVy/EaNGikmJkZvvvmmJGnjxo3uVCtJISEhWrx4sTZv3qynnnpKixcvrvF3ueaaa371nNPp1Jw5c7Rs2TK5XC7dfffddf67AHwdjRO20KlTJ+3du1dFRUVnPH/kyBGNHTtWpaWlqqqqksPhcL9WVVXlHpVKUmBgoCS531PbbZp/ftHRJZdcotzcXI0dO1ZFRUX6y1/+on/9619nvN+Txx88eLDWrVun7du3q3Xr1mrWrJn7te+++06DBw9WXl6err76ak2YMKHG3yM4OPg3n8/Ly1NgYKAOHDigEydO1LgGgP9F44QtREZGKi4uTqmpqe7mWVRUpOnTp6tZs2Zq3LixoqOjtWLFCrlcLpWXl+vVV1/V9ddfb+k44eHh7otrfkp8krRy5UqlpKQoOjpakydPVnR0tL788sszPuuJ4/+kc+fOKi0tVVZWloYMGXLGa1988YXCw8N13333KTo6Wps2bZL04xXC/v7+qqysrPV/CgoLCzV58mTNmjVLN998s9LS0s6qTsAX0ThhG9OmTVObNm00cuRIxcfH65ZbblGbNm306KOPSpLS09OVn5+vuLg4xcXFqXXr1rrnnnssHSM9PV0zZszQkCFDtGfPHl1wwQWSfkyAlZWVio2N1dChQ3Xy5EklJib+6rPnevyfi4+P1759+3TDDTec8XyPHj0UGRmpgQMH6qabbtLhw4cVHh6u/fv364ILLlCnTp00aNAgFRQU1Ph79urVS9HR0br//vt18OBBvfzyy2ddK+BLHHytGAAAdUfiBADAAhonAAAWcOcgAIDPqKysVHp6uvbt2yen06mMjAyFhIQoPT1dhYWFqqys1BNPPFHjvm4aJwDAZ/x0FXp2dra2bdumjIwMhYWFKS4uTrGxsdq6dav27t1bY+Pk4iAAgE+pqKiQv7+/3njjDW3fvl3btm3Trbfeqs2bN6tly5ZKS0urdv+zdB4mzm6zNpsuAfCISTe1M10CcM6Gd25Rb2sHXXW/x9d8/uEblJOT436ckJCghISEM97j7++v5ORk5ebmav78+Vq9erWaNm2q559/XgsWLNCyZcs0fvz4ao9x3jVOAADO1m81yt8ye/ZsTZo0SSNGjFCTJk3Up08fST9+tV9WVlaNn+WqWgCAGQ4/z//UYs2aNVqyZIkkKSgoSA6HQ3/605+0efOP086PPvpIbdq0qXENEicAwIyf3du5oQwYMEApKSkaPXq0KioqlJqaqg4dOig9PV3Z2dkKDQ3Vk08+WeMaNE4AgM8IDg7WvHnzfvX8c889V+c1aJwAADPqMFo9H9mzagAADCFxAgDMMHCO0xNonAAAMxjVAgDg/UicAAAzbDqqJXECAGABiRMAYAbnOAEA8H4kTgCAGTY9x0njBACYwagWAADvR+IEAJhh01EtiRMAAAtInAAAM2x6jpPGCQAwg1EtAADej8QJADDDpqNae1YNAIAhJE4AgBk2TZw0TgCAGX5cHAQAgNcjcQIAzLDpqNaeVQMAYAiJEwBghk1vgEDjBACYwagWAADvR+IEAJhh01EtiRMAAAtInAAAMzjHCQCA9yNxAgDMsOk5ThonAMAMRrUAAHg/EicAwAybjmpJnAAAWEDiBACYYdNznDROAIAZjGoBAPB+JE4AgBk2HdXas2oAAAwhcQIAzLBp4qRxAgDM4OIgAAC8H4kTAGCGTUe19qwaAABDSJwAADM4xwkAgPcjcQIAzLDpOU4aJwDADEa1AAB4PxInAMAIB4kTAADvR+IEABhh18RJ4wQAmGHPvsmoFgAAK0icAAAj7DqqJXECAGABiRMAYIRdEyeNEwBghF0bJ6NaAAAsIHECAIwgcQIA4ANInAAAM+wZOEmcAADfUVlZqZSUFI0cOVKjR4/WgQMH3K+tX79eCQkJta5B4wQAGOFwODz+U5tNmzZJkrKzs5WUlKSMjAxJ0s6dO7Vq1Sq5XK5a16BxAgCMMNE4+/Xrp5kzZ0qSvv32W0VERKigoEBz5sxRampqnermHCcAwGvk5OQoJyfH/TghIeFX41d/f38lJycrNzdX8+bNU1pamlJTUxUYGFinYzhcdcmlDajbrM2mSwA8YtJN7UyXAJyz4Z1b1Nva4YkrPb5m/kuj6vze77//Xn379lVERIRatmypsrIy7d69W8OGDVNaWlq1nyNxAgB8xpo1a3TkyBHdfffdCgoKUkREhDZu3KjAwEAdOnRIEydOrLFpSjROAIAhJm6AMGDAAKWkpGj06NGqqKiwNKL9CY0TAGCGgX2cwcHBmjdv3m++9vvf/16vvvpqrWtwVS0AABaQOAEARnCvWgAAfACJEwBghF0TJ40TAGCEXRsno1oAACwgcQIAzLBn4CRxAgBgBYkTAGAE5zgBAPABJE4AgBF2TZw0TgCAEXZtnIxqAQCwgMQJADCCxAkAgA8gcQIAzLBn4KRxAgDMYFQLAIAPIHECAIwgcQIA4ANInAAAI+yaOGmcAAAz7Nk3GdUCAGAFiRMAYIRdR7UkTgAALCBxAgCMIHECAOADSJxezs8hpdzUTpeGB6vS5dKjG75WcIBTD/ZvqyqXS+UVVZrx5lfKLzltulSgRpUVFVq9aLYKvv9OFadPq/ewRIVFXKh1y+bKz8+p37W4REPumSw/P/KAXdg1cdI4vVx0m99Jksau2KGurcI0vu/lCg3015O5u7TraLEGd2mhxG6tNO9fewxXCtRsx79zFdykqW75e5pKTp7Qgof+pouj2qn3sNvVvms3vTr/UX29fas6XHO96VJRRzROnJe27PpBH+z+QZJ0UdPGyi8u1+y3d+mH4nJJktPPobKKKpMlAnVyZfeeurJbT/djP6dTF7duq1NFhXK5XCo7VSKnv9NghfAV9do4q6qqGJucBypd0pRB7dWrXYRS3vjS3TQ7tmyqW7perHte/tRwhUDtAhsHS5LKTpVo5dxp6j/yr5IcWr/8KW1a/ZIaB4eq9R+7GK0RFtkzcHr+4qCDBw/qvvvu04033qh+/fqpV69eGjt2rPbt2+fpQ8GCmRu+1i1LP1TKTe3UuJGf+v3hAiXHtNXE177Q8VOc34Q9HD92VM88MkFdbhigztH9tOH5p/W3GfP1wFMv6aobB2jji4tMlwgf4PHEmZaWpgcffFCdO3d2P7djxw6lpKQoOzvb04dDLQZecaEubBKoF7ceVOnpKrlcLvVqF6HBXS7WfSs/VWFphekSgTopOp6v5x+bpLg7x+vyjldLkoJCmygwKESS1CQ8Qvu//sJkibCIc5z/X3l5+RlNU5K6dOni6cOgjt775pjSY9tr0ejO8vfzU9a7e5Qe215HCss0a+gVkqTtB47rmff3G64UqNl7b7ysU0Unten1F7Xp9RclSUPunqyceTPk5+eU099fQ+6eZLhKWGHXxulwuVwuTy44bdo0lZeX64YbblCTJk1UXFyszZs3KyAgQI888kitn+82a7MnywGMmXRTO9MlAOdseOcW9bb25Q9u9Piae568yeNr/pLHE+f06dP1zjvv6OOPP1ZRUZFCQ0PVu3dv9e/f39OHAgDYmE0Dp+cbp8PhUP/+/WmUAACvxD5OAIARdj3HSeMEABhh077JTd4BALCCxAkAMMKuo1oSJwAAFpA4AQBG2DRwkjgBALCCxAkAMMLPz56Rk8YJADCCUS0AAD6AxAkAMILtKAAA+AASJwDACJsGThonAMAMRrUAAPgAEicAwAgSJwAAPoDECQAwwqaBk8YJADCDUS0AAD6AxAkAMMKmgZPECQCAFSROAIARnOMEAMAHkDgBAEbYNHDSOAEAZjCqBQDAB5A4AQBG2DRw0jgBAL6jsrJS6enp2rdvn5xOpzIyMlRcXKyZM2fK6XQqICBAs2fPVkRERLVr0DgBAEaYOMe5adMmSVJ2dra2bdumjIwMnTx5UlOmTFGHDh2UnZ2tZcuWKSUlpdo1aJwAACNMjGr79eunXr16SZK+/fZbRURE6JFHHtGFF14o6cdEGhgYWOMaNE4AgNfIyclRTk6O+3FCQoISEhLOeI+/v7+Sk5OVm5ur+fPnu5vm9u3btWLFCr388ss1HsPhcrlcni/97HWbtdl0CYBHTLqpnekSgHM2vHOLelu7++wtHl/zP8k31vm933//vUaMGKENGzbovffe06JFi7Rw4UJdcsklNX6O7SgAAJ+xZs0aLVmyRJIUFBQkh8Oh3NxcrVixQi+99FKtTVNiVAsAMMTEOc4BAwYoJSVFo0ePVkVFhVJTU5WamqoWLVro73//uyTp2muvVVJSUrVr0DgBAEaYuKo2ODhY8+bNO+O5fv36WVqDUS0AABaQOAEARtj1zkEkTgAALCBxAgCM4NtRAADwASROAIARdk2cNE4AgBE27ZuMagEAsILECQAwwq6jWhInAAAWkDgBAEbYNHDSOAEAZjCqBQDAB5A4AQBG2DRwkjgBALCCxAkAMMLPppGTxgkAMMKmfZNRLQAAVpA4AQBGsB0FAAAfQOIEABjhZ8/ASeMEAJjBqBYAAB9A4gQAGGHTwEniBADAChInAMAIh+wZOUmcAABYQOIEABjBdhQAACxgOwoAAD6AxAkAMMKmgZPECQCAFSROAIARfJE1AAAW2LRvMqoFAMAKEicAwAi2owAA4ANInAAAI2waOGmcAAAz7HpVLaNaAAAsIHECAIywZ94kcQIAYImlxFlVVSU/P3otAODcee12lI0bN2rDhg1644031KNHDy1fvrwh6gIA4LxUa+N89tlndf3112vdunXavHmzNm3a1BB1AQC8nJ/D8z8NodZRbWBgoCQpJCREAQEBKi4urveiAADez2tHtb///e81bNgwDRs2TAsWLFCnTp0aoi4AAM5LtSbOWbNmqbi4WCEhIerYsaMiIiIaoi4AgJezaeCsvnFOnDix2hj95JNP1ltBAACcz6ptnCNHjmzIOgAAPsau5zirbZx/+tOfJElFRUVatmyZvv/+e/Xq1Uvt27dvsOIAAN6roa6C9bRaLw5KTU3VJZdcov/5n/9RRESE0tLSGqIuAADOS7U2zuPHj2v48OHy9/dX165d5XK5GqIuAICXczgcHv9pCHW6f96ePXskSd999x233AMA+LRat6Okp6crNTVVe/bsUVJSkqZNm9YQdQEAvJxNT3HW3jjbtWunRYsWKS8vT5deeqmaNm3aEHUBALyc136R9apVqzRq1CgtWbJECQkJeuuttxqiLgAAzku1Js7s7GytXbtWgYGBKikp0e23367Y2NiGqA0A4MVsGjhrT5zNmjWTv/+P/bVx48aMagEAPq3WW+7l5+dr6NCh6ty5s7788ks1bty4IesDAHgpr7tz0G/dcu/mm2+u12IAADjf1XrLvePHj+v9999XRUWFXC6Xjh496n4NAICzZdPAWfvFQUlJSbrsssv0zTffKDAwUEFBQQ1RFwDAy3ntdhRJmjFjhlq3bq3nnntOJ06cqO+aAAA4b9WaOCWprKxMp06dksPhUElJSX3XBADwASYCZ2VlpdLT07Vv3z45nU5lZGTI5XLp4YcflsPhUNu2bTVt2rQaby9ba+IcPXq0XnjhBfXo0UM9e/ZUVFSUR38JAAAayqZNmyT9eI+CpKQkZWRkKCMjQxMmTNDKlSvlcrn07rvv1rhGrYkzJibG/eebbrpJx44dO8eyAQAwsx2lX79+6tWrlyTp22+/VUREhN577z33Ra833nijPvjgA/Xv37/aNeo0qv1JaGio7rjjDq1atersq67Fe5N61tvaQENqfu39pksAztnwTxbU29r18V1bOTk5ysnJcT9OSEhQQkLCGe/x9/dXcnKycnNzNX/+fG3atMndxENCQnTy5Mkaj2GpcUri+zgBAOet32qUv2X27NmaNGmSRowYobKyMvfzxcXFtd4hz3LDt+udHgAA5xcTX2S9Zs0aLVmyRJIUFBQkh8OhK6+8Utu2bZMkbdmyRddcc02Na9R6y72fc7lcOnjwYK2FAQBwPhowYIBSUlI0evRoVVRUKDU1VZdffrmmTJmiuXPnKioq6oxre36Lw1XN7PXDDz+s9kP1eeeg0op6WxpoUJzjhDc4VY/nOCes/crjaz4V/wePr/lLtd5yDwCA+uBn0zN/9XFREwAAXsvyVbUAAHiCXS82rbVxHjlyRJmZmSooKFBMTIzat2+vzp07N0RtAACcd2od1U6ZMkXDhg1TeXm5rrnmGj322GMNURcAwMv5OTz/0yB11/aGsrIyde/eXQ6HQ1FRUQoMDGyIugAAOC/VOqoNCAjQv//9b1VVVWnHjh0KCAhoiLoAAF7Opqc4a0+cM2fO1OrVq1VQUKBnn31W06dPb4CyAADezs/h8PhPQ6g1cV500UXKyspqiFoAADjv1do4o6Oj3X8+fvy4LrnkEm3cuLFeiwIAeD+73kig1sb5/vvvu/+cl5enBQvq7/ZLAACc7yzdAKFly5bau3dvfdUCAPAhdr04qNbG+fNvSTl69Kh+97vf1XtRAADv11AX83harY0zNjbW/aWegYGBuvLKK+u9KAAAzle1Ns7ly5frlVdeaYhaAAA+xKaBs/bGGRYWphdeeEGtW7eWn9+P10D9/EpbAAB8Sa2Ns3nz5vrqq6/01Vf/+4WjNE4AwLmy6/dxVts4J0yYoKeeekoZGRkNWQ8AwEfY9eKgavef5ufnN2QdAADYQrWJ8+DBg5o7d+5vvjZx4sR6KwgA4BtsGjirb5yNGzdW69atG7IWAADOe9U2zoiICA0ZMqQhawEA+BC7XhxU7TlObnQAAMCvVZs4k5OTG7IOAICPcciekdPSTd4BAPAUrxvVAgCAXyNxAgCMIHECAOADSJwAACMcNr0DAo0TAGAEo1oAAHwAiRMAYIRNJ7UkTgAArCBxAgCMsOv3cdI4AQBGcHEQAAA+gMQJADDCppNaEicAAFaQOAEARvjZ9GvFSJwAAFhA4gQAGGHXc5w0TgCAEWxHAQDAB5A4AQBG2PXOQSROAAAsIHECAIywaeCkcQIAzGBUCwCADyBxAgCMsGngJHECAGAFiRMAYIRdkxuNEwBghMOms1q7NnwAAIwgcQIAjLBn3iRxAgBgCYkTAGAEN0AAAMAHkDgBAEbYM2/SOAEAhth0UsuoFgAAK0icAAAjuAECAAA+gMQJADDCrsmNxgkAMIJRLQAAPoDECQAwwkTePH36tFJTU5WXl6fy8nLde++9uvjiizVt2jQ5nU5ddtlleuyxx+TnV32upHECAHzGunXr1KxZM2VmZqqgoEBDhgzRFVdcoXHjxqlnz5568MEH9d5776lPnz7VrkHjBAAYYeIc58CBAxUTE+N+7HQ61aFDBx0/flwul0vFxcXy96+5NdI4AQBG1MdFNjk5OcrJyXE/TkhIUEJCgvtxSEiIJKmoqEhJSUmaMGGCHA6HZsyYoUWLFqlJkya67rrrajyGw+Vyueqh9rNWWmG6AsAzml97v+kSgHN26pMF9bb26k8Pe3zNoZ1b1Pqew4cPa9y4cRo1apSGDx+u7t2768UXX1Tbtm318ssva/fu3Zo2bVq1nydxAgCMMDGqPXbsmO68805NnTpV3bt3lySFhYUpNDRUknThhRdq+/btNa5B4wQA+IzFixersLBQCxcu1MKFCyVJjz76qB544AH5+/urUaNGmjlzZo1rMKoF6gmjWniD+hzVrvnsO4+vObjTRR5f85e4AQIAABYwqgUAGGHTO+7ROAEAZvgZuXfQuWNUCwCABSROAIARdh3VkjgBALCAxAkAMMJh03OcNE4AgBGMagEA8AEkTgCAEWxHAQDAB5A4AQBG2PUcJ40TAGCEXRsno1oAACwgcQIAjLDrPk4SJwAAFpA4AQBG+NkzcNI4AQBmMKoFAMAHkDgBAEawHQUAAB9A4gQAGME5TgAAfACJEwBgBNtRAACwgFEtAAA+gMQJADDCrttRaJxe7vTp05o2JVXf5uWpvLxcY+++V7369JUkvfXmer2ycoVeWpljuEqgdn5+Di2cMkrtLrtQlVUujZ22QkXFpfrH1FFq3jRYTj+H/jrlJe07dMx0qfByNE4vt+HNdWoW1kyPz8rU8eMFShg2RL369NVXO3fqjdWr5HK5TJcI1MmgGztKkvr8JUs3XN1Wsx8cquOFJcp56yO9nvuJbrymrdpfFknjtBGbBk7OcXq7AQMGalzSePdjp79Tx48XaF7WHD30cKrBygBr1r/3mcY9+ookqdXF4Tr6w0l17xKllpHNtWHx/RoZe622/N9dhquEFX4Oh8d/GqTuBjkKjAkOCVFISKiKi4v04IQkjfv7eE2fkqbJyakKDgkxXR5gSWVllZbNSNTch4brjXc+0aUtfqeCwhINumeBDn6Xrwf/0t90ifABNE4f8N3hw7rrL7fp5j/Hq1Wry7R//349NnO6kidN1N49u/VExmOmSwTq7G9TX1KnwTO0cOooHS8q0YbNn0uS3tr8hbr+sZXh6mCFox5+GoLHz3EmJibq9OnTZzzncrnkcDiUnZ3t6cOhFj8cO6Z7xt6plLSpuq5bd0nSG+s2SJLy8g4pedJEPZSSZrJEoE5uHXStWkY215xn/49KSk+rqqpK73+8WzHRf9QrGz5SdNc22rnnsOky4QM83jgnTZqk9PR0/eMf/5DT6fT08rDomWWLVXiiUEsXL9TSxQslSf9YvEyNGzc2XBlgzdp3P9XSR8Yod/kENfJ3avKc1/XZ14e0cOpojb3lBp0oOqU7Up43XSassOnVQQ5XPVxW+cwzz+jSSy9V//7WzzeUVni6GsCM5tfeb7oE4Jyd+mRBva29bc8Jj6953eVhHl/zl+plO8pdd91VH8sCAGAc+zgBAEbY9c5BXFULAIAFJE4AgBE2DZwkTgAArCBxAgDMsGnkpHECAIzgi6wBAPABJE4AgBFsRwEAwAeQOAEARtg0cNI4AQCG2LRzMqoFAMACEicAwAi2owAA4ANInAAAI+y6HYXGCQAwwqZ9k1EtAABWkDgBAGbYNHKSOAEAsIDECQAwgu0oAAD4ABInAMAItqMAAGCBTfsmo1oAAKwgcQIAzLBp5CRxAgBgAYkTAGCEXbej0DgBAEZwVS0AAOe506dPKzU1VXl5eSovL9e9996rLl26KD09XYWFhaqsrNQTTzyhVq1aVbsGjRMAYISJwLlu3To1a9ZMmZmZKigo0JAhQ9StWzfFxcUpNjZWW7du1d69e2mcAABI0sCBAxUTE+N+7HQ6tX37drVv31533HGHWrZsqbS0tBrX4KpaAIAZDs//5OTkaOjQoe6fnJycMw4ZEhKi0NBQFRUVKSkpSRMmTFBeXp6aNm2q559/Xi1atNCyZctqLJvECQAwoj6uqk1ISFBCQkKN7zl8+LDGjRunUaNGKS4uTrNmzVKfPn0kSX369FFWVlaNnydxAgB8xrFjx3TnnXdq8uTJGj58uCTp6quv1ubNmyVJH330kdq0aVPjGiROAIARJrajLF68WIWFhVq4cKEWLlwoSZo1a5bS09OVnZ2t0NBQPfnkkzWu4XC5XK6GKLauSitMVwB4RvNr7zddAnDOTn2yoN7W/vq7Eo+v2f6iYI+v+UskTgCAETa9/wHnOAEAsILECQAww6aRk8YJADDCrjd5Z1QLAIAFJE4AgBF2/XYUEicAABaQOAEARtg0cNI4AQCG2LRzMqoFAMACEicAwAi2owAA4ANInAAAI+y6HYXGCQAwwqZ9k1EtAABWkDgBAGbYNHKSOAEAsIDECQAwgu0oAAD4ABInAMAItqMAAGCBTfsmo1oAAKwgcQIAjLDrqJbECQCABSROAIAh9oycNE4AgBGMagEA8AEkTgCAETYNnCROAACsIHECAIyw6zlOGicAwAhu8g4AgA8gcQIAzLBn4CRxAgBgBYkTAGCETQMniRMAACtInAAAI9iOAgCABWxHAQDAB5A4AQBm2DNwkjgBALCCxAkAMMKmgZPGCQAww65X1TKqBQDAAhInAMAItqMAAOADSJwAACM4xwkAgA+gcQIAYAGjWgCAEYxqAQDwASROAIARbEcBAMAHkDgBAEbY9RwnjRMAYIRN+yajWgAArCBxAgDMsGnkJHECAGABiRMAYIRdt6PQOAEARtj1qlpGtQAAWEDiBAAYYdPASeIEAMAKEicAwAybRk4aJwDACLteVcuoFgDgM06fPq3Jkydr1KhRGj58uN599133a+vXr1dCQkKta5A4AQBGmNiOsm7dOjVr1kyZmZkqKCjQkCFD1LdvX+3cuVOrVq2Sy+WqdQ0SJwDAZwwcOFDjx493P3Y6nSooKNCcOXOUmppapzXOu8TZ+LyrCDg7pz5ZYLoE4LxWH/+9z8nJUU5OjvtxQkLCGePXkJAQSVJRUZGSkpI0fvx4paWlKTU1VYGBgXU6hsNVl1wKAICXOHz4sMaNG6dRo0apXbt2SklJUXh4uMrKyrR7924NGzZMaWlp1X6exgkA8BnHjh1TYmKipk6dqu7du5/x2qFDhzRx4kS9+uqrNa7BOU4AgM9YvHixCgsLtXDhQiUmJioxMVGlpaWW1iBxAgBgAYkTAAALaJwAAFhA4/QhVVVVmjp1qhISEpSYmKj9+/ebLgk4a59++qkSExNNlwEfxK5JH/LOO++ovLxcOTk52rFjh2bNmqVFixaZLguwbNmyZVq3bp2CgoJMlwIfROL0IR9//LFuuOEGSVKXLl30xRdfGK4IODutWrXS008/bboM+Cgapw8pKipSaGio+7HT6VRFRYXBioCzExMTI39/BmYwg8bpQ0JDQ1VcXOx+XFVVxX98AMAiGqcP6dq1q7Zs2SJJ2rFjh9q1a2e4IgCwH+KGD+nfv78++OADjRw5Ui6XS48//rjpkgDAdrhzEAAAFjCqBQDAAhonAAAW0DgBALCAxgkAgAU0TgAALKBxwva2bdum7t27u7+UdsSIEXrppZfOaq05c+Zo9erV2rlzpxYsWFDt+3Jzc3XkyJE6rbllyxY9/PDDZzx36NAhjRgxok6fr6/3Ajg77OOEV+jWrZuysrIkSeXl5Ro4cKDi4+PVtGnTs1qvQ4cO6tChQ7Wvv/jii5o+fboiIyPPan0A9kXjhNcpKiqSn5+fnE6nEhMT1bx5cxUWFmrp0qWaPn269u/fr6qqKk2YMEHXXXed/vnPf2rRokUKDw/X6dOnFRUVpW3btik7O1tZWVl67bXX9Morr6iqqkp9+/ZVx44dtXPnTiUnJ2vlypXKycnRm2++KYfDodjYWN12223as2ePUlNTFRQUpKCgIIWFhdWp9g8//NCddEtLSzV79mw1atRI+fn5uueee5Sfn6+ePXtq3LhxOnz4sKZMmaKysjIFBgZq5syZZ6yVlZWlrVu3qqqqSoMGDdIdd9zh6b9qwCfROOEVtm7dqsTERDkcDjVq1EhTpkxRSEiIJCkuLk79+/fXypUr1bx5cz3++OMqKCjQmDFjtGHDBmVmZuq1115Ts2bNNHbs2DPW/eGHH9xfYRUQEKBZs2bp2muvVYcOHTR9+nQdOHBAb731llauXCmHw6E77rhD0dHRmjdvnpKSktSjRw8tXbpUe/furdPvsWvXLmVmZioyMlKLFy/W22+/rbi4OJWUlCgzM1PBwcEaPXq0+vbtq8WLFysxMVE9e/bUf/7zH82ZM0cPPPCAe601a9ZoxYoVioyM1OrVqz33lw34OBonvMLPR7W/1Lp1a0nSN998o48//lifffaZJKmiokLHjh1TaGiomjdvLkm66qqrzvjswYMH1bZtWzVu3FiSlJqaesbr33zzjb799lt3mjtx4oQOHDigXbt2qVOnTpJ+vEdwXRtnZGSkHnvsMQUHB+vIkSPq2rWrJOkPf/iDmjRpIknq2LGj9u3bp2+++UZLlizRM888I5fLpUaNGp2x1ty5czV37lwdO3bM/XVyAM4djRNez+FwSJKioqJ00UUX6Z577lFpaakWLVqkpk2b6uTJk8rPz1d4eLg+//xzXXTRRe7PtmrVSnv37lV5ebkCAgKUlJSktLQ0ORwOuVwuRUVFqU2bNnrmmWfkcDj0/PPPq127doqKitInn3yiG2+80dL3nqanp+udd95RaGiokpOT9dMdMffs2aPi4mIFBgbqs88+U0JCgqKionTnnXeqa9eu2rNnjz766CP3OuXl5Xr77bc1d+5cuVwuDRo0SIMGDVLLli099LcK+C4aJ3zGyJEjlZ6erjFjxqioqEijRo1SQECAMjIy9Ne//lVhYWG/+pq18PBw/e1vf9OYMWPkcDjUu3dvRUZG6qqrrtJDDz2kZ599Vt27d9ett96q8vJyderUSZGRkZo2bZoeeOABLV++XOHh4QoMDPxVPbt27dLQoUPdjx9++GHFx8drxIgRatq0qSIiInT06FFJUlhYmB544AHl5+crNjZWbdq0UXJysqZPn66ysjKVlpYqLS3NvVZAQIDCwsIUHx+vsLAw9ejRQxdffHE9/c0CvoWbvAMAYAH7OAEAsIDGCQCABTROAAAsoHECAGABjRMAAAtonAAAWEDjBADAAhonAAAW/D8/NwV5QRW+YAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 17:08:04,240]\u001B[0m A new study created in memory with name: no-name-8dd046cc-8116-49ba-bf57-ac3cc6ff79ca\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.65972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:08:15,982]\u001B[0m Trial 0 finished with value: 0.6597222222222222 and parameters: {'n_d': 36, 'n_a': 24, 'n_steps': 5, 'gamma': 1.6015449109059732, 'n_independent': 4, 'n_shared': 9, 'lambda_sparse': 0.041988653065769876}. Best is trial 0 with value: 0.6597222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.68875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:08:26,647]\u001B[0m Trial 1 finished with value: 0.68875 and parameters: {'n_d': 56, 'n_a': 62, 'n_steps': 12, 'gamma': 0.4904254298157268, 'n_independent': 4, 'n_shared': 1, 'lambda_sparse': 0.08008183920867112}. Best is trial 1 with value: 0.68875.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.72694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:09:34,419]\u001B[0m Trial 2 finished with value: 0.7269444444444444 and parameters: {'n_d': 25, 'n_a': 14, 'n_steps': 19, 'gamma': 0.20588634684599993, 'n_independent': 7, 'n_shared': 8, 'lambda_sparse': 0.002891794647374012}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.71833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:10:18,398]\u001B[0m Trial 3 finished with value: 0.7183333333333333 and parameters: {'n_d': 39, 'n_a': 64, 'n_steps': 12, 'gamma': 1.2853797284559079, 'n_independent': 5, 'n_shared': 6, 'lambda_sparse': 0.006177176183329743}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.70056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:10:35,915]\u001B[0m Trial 4 finished with value: 0.7005555555555555 and parameters: {'n_d': 54, 'n_a': 25, 'n_steps': 6, 'gamma': 0.6006058863228728, 'n_independent': 1, 'n_shared': 9, 'lambda_sparse': 0.05958914553038774}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.71056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:10:41,949]\u001B[0m Trial 5 finished with value: 0.7105555555555555 and parameters: {'n_d': 8, 'n_a': 48, 'n_steps': 3, 'gamma': 0.38304940794653597, 'n_independent': 4, 'n_shared': 8, 'lambda_sparse': 0.03078300455948902}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:10:50,421]\u001B[0m Trial 6 finished with value: 0.7225 and parameters: {'n_d': 44, 'n_a': 60, 'n_steps': 8, 'gamma': 1.121894759222953, 'n_independent': 2, 'n_shared': 1, 'lambda_sparse': 0.004361388450485588}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.68083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:12:05,421]\u001B[0m Trial 7 finished with value: 0.6808333333333333 and parameters: {'n_d': 27, 'n_a': 56, 'n_steps': 14, 'gamma': 1.3532100403048484, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.035208801066595644}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.70472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:12:52,501]\u001B[0m Trial 8 finished with value: 0.7047222222222222 and parameters: {'n_d': 31, 'n_a': 40, 'n_steps': 8, 'gamma': 1.2477274511556184, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.017699297361071935}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.69444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:13:22,997]\u001B[0m Trial 9 finished with value: 0.6944444444444443 and parameters: {'n_d': 50, 'n_a': 19, 'n_steps': 17, 'gamma': 1.0761827546766076, 'n_independent': 1, 'n_shared': 4, 'lambda_sparse': 0.07092492658329563}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.68139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:14:01,833]\u001B[0m Trial 10 finished with value: 0.6813888888888888 and parameters: {'n_d': 19, 'n_a': 9, 'n_steps': 18, 'gamma': 0.14975896801391775, 'n_independent': 8, 'n_shared': 6, 'lambda_sparse': 0.08971344966169413}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.68722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:14:23,289]\u001B[0m Trial 11 finished with value: 0.6872222222222222 and parameters: {'n_d': 43, 'n_a': 36, 'n_steps': 9, 'gamma': 0.8082256375447977, 'n_independent': 7, 'n_shared': 4, 'lambda_sparse': 0.0017392889143566632}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:14:27,136]\u001B[0m Trial 12 finished with value: 0.6897222222222222 and parameters: {'n_d': 22, 'n_a': 10, 'n_steps': 1, 'gamma': 0.8647479218299251, 'n_independent': 9, 'n_shared': 7, 'lambda_sparse': 0.018523123882889934}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.68972\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.67944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:15:01,221]\u001B[0m Trial 13 finished with value: 0.6794444444444444 and parameters: {'n_d': 62, 'n_a': 35, 'n_steps': 15, 'gamma': 0.16619130318036623, 'n_independent': 2, 'n_shared': 4, 'lambda_sparse': 0.000436070903427429}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.68764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:15:59,176]\u001B[0m Trial 14 finished with value: 0.687638888888889 and parameters: {'n_d': 45, 'n_a': 47, 'n_steps': 19, 'gamma': 1.736780311928859, 'n_independent': 7, 'n_shared': 1, 'lambda_sparse': 0.019526498759465324}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.70083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:16:14,602]\u001B[0m Trial 15 finished with value: 0.7008333333333333 and parameters: {'n_d': 11, 'n_a': 18, 'n_steps': 11, 'gamma': 0.8027392819897136, 'n_independent': 3, 'n_shared': 3, 'lambda_sparse': 0.05124518006521478}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.71417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:16:33,687]\u001B[0m Trial 16 finished with value: 0.7141666666666666 and parameters: {'n_d': 31, 'n_a': 29, 'n_steps': 7, 'gamma': 1.9840278920293917, 'n_independent': 6, 'n_shared': 7, 'lambda_sparse': 0.013372916726508727}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.53625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:17:01,493]\u001B[0m Trial 17 finished with value: 0.53625 and parameters: {'n_d': 19, 'n_a': 54, 'n_steps': 15, 'gamma': 1.0466746766843404, 'n_independent': 9, 'n_shared': 5, 'lambda_sparse': 0.02756877790245243}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.69139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:17:08,976]\u001B[0m Trial 18 finished with value: 0.6913888888888888 and parameters: {'n_d': 36, 'n_a': 42, 'n_steps': 4, 'gamma': 0.3405764136611057, 'n_independent': 2, 'n_shared': 10, 'lambda_sparse': 0.011280753117968705}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.69861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:17:42,497]\u001B[0m Trial 19 finished with value: 0.6986111111111112 and parameters: {'n_d': 25, 'n_a': 16, 'n_steps': 10, 'gamma': 0.6882021894046112, 'n_independent': 5, 'n_shared': 8, 'lambda_sparse': 0.024587423632058205}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.66917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:18:10,563]\u001B[0m Trial 20 finished with value: 0.6691666666666667 and parameters: {'n_d': 15, 'n_a': 30, 'n_steps': 13, 'gamma': 0.5768739303270671, 'n_independent': 7, 'n_shared': 2, 'lambda_sparse': 0.0004897689563332134}. Best is trial 2 with value: 0.7269444444444444.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.77802 |  0:00:02s\n",
      "epoch 1  | loss: 1.38324 |  0:00:04s\n",
      "epoch 2  | loss: 1.20836 |  0:00:07s\n",
      "epoch 3  | loss: 1.13322 |  0:00:09s\n",
      "epoch 4  | loss: 1.21583 |  0:00:11s\n",
      "epoch 5  | loss: 0.87362 |  0:00:14s\n",
      "epoch 6  | loss: 1.25408 |  0:00:16s\n",
      "epoch 7  | loss: 1.0269  |  0:00:18s\n",
      "epoch 8  | loss: 0.96536 |  0:00:21s\n",
      "epoch 9  | loss: 0.71605 |  0:00:23s\n",
      "epoch 10 | loss: 0.70171 |  0:00:26s\n",
      "epoch 11 | loss: 0.65509 |  0:00:28s\n",
      "epoch 12 | loss: 0.66054 |  0:00:30s\n",
      "epoch 13 | loss: 0.64408 |  0:00:33s\n",
      "epoch 14 | loss: 0.64109 |  0:00:35s\n",
      "epoch 15 | loss: 0.61362 |  0:00:37s\n",
      "epoch 16 | loss: 0.6245  |  0:00:40s\n",
      "epoch 17 | loss: 0.61055 |  0:00:42s\n",
      "epoch 18 | loss: 0.59188 |  0:00:44s\n",
      "epoch 19 | loss: 0.59559 |  0:00:47s\n",
      "epoch 20 | loss: 0.56662 |  0:00:49s\n",
      "epoch 21 | loss: 0.56538 |  0:00:51s\n",
      "epoch 22 | loss: 0.55692 |  0:00:54s\n",
      "epoch 23 | loss: 0.54466 |  0:00:56s\n",
      "epoch 24 | loss: 0.55177 |  0:00:58s\n",
      "epoch 25 | loss: 0.53911 |  0:01:01s\n",
      "epoch 26 | loss: 0.54434 |  0:01:03s\n",
      "epoch 27 | loss: 0.5454  |  0:01:05s\n",
      "epoch 28 | loss: 0.53062 |  0:01:08s\n",
      "epoch 29 | loss: 0.52494 |  0:01:10s\n",
      "epoch 30 | loss: 0.5151  |  0:01:12s\n",
      "epoch 31 | loss: 0.52289 |  0:01:15s\n",
      "epoch 32 | loss: 0.50521 |  0:01:17s\n",
      "epoch 33 | loss: 0.50448 |  0:01:19s\n",
      "epoch 34 | loss: 0.49458 |  0:01:22s\n",
      "epoch 35 | loss: 0.48958 |  0:01:24s\n",
      "epoch 36 | loss: 0.47246 |  0:01:26s\n",
      "epoch 37 | loss: 0.4763  |  0:01:29s\n",
      "epoch 38 | loss: 0.48864 |  0:01:31s\n",
      "epoch 39 | loss: 0.46906 |  0:01:34s\n",
      "epoch 40 | loss: 0.4627  |  0:01:36s\n",
      "epoch 41 | loss: 0.46094 |  0:01:38s\n",
      "epoch 42 | loss: 0.45765 |  0:01:41s\n",
      "epoch 43 | loss: 0.44726 |  0:01:43s\n",
      "epoch 44 | loss: 0.43458 |  0:01:46s\n",
      "epoch 45 | loss: 0.43429 |  0:01:48s\n",
      "epoch 46 | loss: 0.43455 |  0:01:50s\n",
      "epoch 47 | loss: 0.42802 |  0:01:53s\n",
      "epoch 48 | loss: 0.43401 |  0:01:55s\n",
      "epoch 49 | loss: 0.40396 |  0:01:57s\n",
      "epoch 50 | loss: 0.41248 |  0:02:00s\n",
      "epoch 51 | loss: 0.40416 |  0:02:02s\n",
      "epoch 52 | loss: 0.39521 |  0:02:04s\n",
      "epoch 53 | loss: 0.38104 |  0:02:07s\n",
      "epoch 54 | loss: 0.37419 |  0:02:09s\n",
      "epoch 55 | loss: 0.3809  |  0:02:11s\n",
      "epoch 56 | loss: 0.37229 |  0:02:14s\n",
      "epoch 57 | loss: 0.35928 |  0:02:16s\n",
      "epoch 58 | loss: 0.3656  |  0:02:18s\n",
      "epoch 59 | loss: 0.35496 |  0:02:21s\n",
      "epoch 60 | loss: 0.35704 |  0:02:23s\n",
      "epoch 61 | loss: 0.33997 |  0:02:25s\n",
      "epoch 62 | loss: 0.34588 |  0:02:28s\n",
      "epoch 63 | loss: 0.33975 |  0:02:30s\n",
      "epoch 64 | loss: 0.34076 |  0:02:33s\n",
      "epoch 65 | loss: 0.35002 |  0:02:35s\n",
      "epoch 66 | loss: 0.34679 |  0:02:37s\n",
      "epoch 67 | loss: 0.34494 |  0:02:40s\n",
      "epoch 68 | loss: 0.33642 |  0:02:42s\n",
      "epoch 69 | loss: 0.36733 |  0:02:44s\n",
      "epoch 70 | loss: 0.34326 |  0:02:47s\n",
      "epoch 71 | loss: 0.34321 |  0:02:49s\n",
      "epoch 72 | loss: 0.31878 |  0:02:51s\n",
      "epoch 73 | loss: 0.33416 |  0:02:54s\n",
      "epoch 74 | loss: 0.31608 |  0:02:56s\n",
      "epoch 75 | loss: 0.30844 |  0:02:58s\n",
      "epoch 76 | loss: 0.29054 |  0:03:01s\n",
      "epoch 77 | loss: 0.29139 |  0:03:03s\n",
      "epoch 78 | loss: 0.28186 |  0:03:06s\n",
      "epoch 79 | loss: 0.27361 |  0:03:08s\n",
      "epoch 80 | loss: 0.25924 |  0:03:10s\n",
      "epoch 81 | loss: 0.25492 |  0:03:13s\n",
      "epoch 82 | loss: 0.25367 |  0:03:15s\n",
      "epoch 83 | loss: 0.24126 |  0:03:17s\n",
      "epoch 84 | loss: 0.24063 |  0:03:20s\n",
      "epoch 85 | loss: 0.21136 |  0:03:22s\n",
      "epoch 86 | loss: 0.22874 |  0:03:24s\n",
      "epoch 87 | loss: 0.21925 |  0:03:27s\n",
      "epoch 88 | loss: 0.21929 |  0:03:29s\n",
      "epoch 89 | loss: 0.23251 |  0:03:31s\n",
      "epoch 90 | loss: 0.22481 |  0:03:34s\n",
      "epoch 91 | loss: 0.24023 |  0:03:36s\n",
      "epoch 92 | loss: 0.21736 |  0:03:38s\n",
      "epoch 93 | loss: 0.22594 |  0:03:41s\n",
      "epoch 94 | loss: 0.23454 |  0:03:43s\n",
      "epoch 95 | loss: 0.22668 |  0:03:45s\n",
      "epoch 96 | loss: 0.21823 |  0:03:48s\n",
      "epoch 97 | loss: 0.22    |  0:03:50s\n",
      "epoch 98 | loss: 0.21598 |  0:03:53s\n",
      "epoch 99 | loss: 0.21514 |  0:03:55s\n",
      "Eval TABNET\n",
      "Accuracy: 0.66\n",
      "Precision: 0.65\n",
      "Recall: 0.68\n",
      "F1-score: 0.67\n",
      "ROC-AUC score: 0.66\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 17:22:07,580]\u001B[0m A new study created in memory with name: no-name-5db07954-06d1-4a64-9ca8-ba55e4454a2b\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.78833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:22:55,830]\u001B[0m Trial 0 finished with value: 0.7883333333333333 and parameters: {'n_d': 63, 'n_a': 11, 'n_steps': 15, 'gamma': 1.8070231051646855, 'n_independent': 5, 'n_shared': 6, 'lambda_sparse': 0.07295096023807451}. Best is trial 0 with value: 0.7883333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.75056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:23:02,638]\u001B[0m Trial 1 finished with value: 0.7505555555555555 and parameters: {'n_d': 59, 'n_a': 37, 'n_steps': 5, 'gamma': 1.9317951243805618, 'n_independent': 3, 'n_shared': 2, 'lambda_sparse': 0.024052195392917124}. Best is trial 0 with value: 0.7883333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.76917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:23:20,556]\u001B[0m Trial 2 finished with value: 0.7691666666666667 and parameters: {'n_d': 25, 'n_a': 30, 'n_steps': 9, 'gamma': 1.1580158211340863, 'n_independent': 7, 'n_shared': 2, 'lambda_sparse': 0.07426241161698494}. Best is trial 0 with value: 0.7883333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.71681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:24:21,522]\u001B[0m Trial 3 finished with value: 0.7168055555555556 and parameters: {'n_d': 13, 'n_a': 47, 'n_steps': 19, 'gamma': 1.7672468524728038, 'n_independent': 8, 'n_shared': 7, 'lambda_sparse': 0.06588029507634151}. Best is trial 0 with value: 0.7883333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:24:39,051]\u001B[0m Trial 4 finished with value: 0.8049999999999999 and parameters: {'n_d': 10, 'n_a': 44, 'n_steps': 8, 'gamma': 0.39460154867636454, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.02868386961166435}. Best is trial 4 with value: 0.8049999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.47764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:25:36,858]\u001B[0m Trial 5 finished with value: 0.4776388888888889 and parameters: {'n_d': 32, 'n_a': 63, 'n_steps': 19, 'gamma': 1.0574363730988514, 'n_independent': 9, 'n_shared': 8, 'lambda_sparse': 0.09613542856973188}. Best is trial 4 with value: 0.8049999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.78639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:25:45,907]\u001B[0m Trial 6 finished with value: 0.7863888888888888 and parameters: {'n_d': 55, 'n_a': 61, 'n_steps': 2, 'gamma': 1.0211484958752348, 'n_independent': 6, 'n_shared': 7, 'lambda_sparse': 0.04494764584415797}. Best is trial 4 with value: 0.8049999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:26:13,574]\u001B[0m Trial 7 finished with value: 0.8275 and parameters: {'n_d': 38, 'n_a': 23, 'n_steps': 12, 'gamma': 0.4350155814949984, 'n_independent': 8, 'n_shared': 4, 'lambda_sparse': 0.07008526244256684}. Best is trial 7 with value: 0.8275.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.74833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:26:22,165]\u001B[0m Trial 8 finished with value: 0.7483333333333333 and parameters: {'n_d': 35, 'n_a': 34, 'n_steps': 9, 'gamma': 1.0469597948207334, 'n_independent': 1, 'n_shared': 3, 'lambda_sparse': 0.07858319013617618}. Best is trial 7 with value: 0.8275.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.81278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:26:44,366]\u001B[0m Trial 9 finished with value: 0.8127777777777778 and parameters: {'n_d': 51, 'n_a': 49, 'n_steps': 19, 'gamma': 0.33190174362535874, 'n_independent': 1, 'n_shared': 2, 'lambda_sparse': 0.08095261267279666}. Best is trial 7 with value: 0.8275.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.8325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:27:31,952]\u001B[0m Trial 10 finished with value: 0.8325 and parameters: {'n_d': 44, 'n_a': 20, 'n_steps': 13, 'gamma': 0.10966939476802195, 'n_independent': 10, 'n_shared': 4, 'lambda_sparse': 0.04839564296765415}. Best is trial 10 with value: 0.8325.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.78333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:28:58,098]\u001B[0m Trial 11 finished with value: 0.7833333333333334 and parameters: {'n_d': 45, 'n_a': 17, 'n_steps': 13, 'gamma': 0.14897756664887185, 'n_independent': 10, 'n_shared': 4, 'lambda_sparse': 0.04302819929930065}. Best is trial 10 with value: 0.8325.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:30:55,593]\u001B[0m Trial 12 finished with value: 0.7999999999999999 and parameters: {'n_d': 43, 'n_a': 22, 'n_steps': 13, 'gamma': 0.13677856453560966, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.05616393869057812}. Best is trial 10 with value: 0.8325.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.80389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:31:34,413]\u001B[0m Trial 13 finished with value: 0.803888888888889 and parameters: {'n_d': 24, 'n_a': 24, 'n_steps': 14, 'gamma': 0.5243593100345583, 'n_independent': 9, 'n_shared': 4, 'lambda_sparse': 0.0044842843132479535}. Best is trial 10 with value: 0.8325.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.80944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:32:11,023]\u001B[0m Trial 14 finished with value: 0.8094444444444445 and parameters: {'n_d': 43, 'n_a': 15, 'n_steps': 11, 'gamma': 0.5989203577577507, 'n_independent': 8, 'n_shared': 4, 'lambda_sparse': 0.056013598419736535}. Best is trial 10 with value: 0.8325.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.84774 |  0:00:01s\n",
      "epoch 1  | loss: 1.27871 |  0:00:03s\n",
      "epoch 2  | loss: 1.6479  |  0:00:04s\n",
      "epoch 3  | loss: 1.79105 |  0:00:06s\n",
      "epoch 4  | loss: 1.5361  |  0:00:08s\n",
      "epoch 5  | loss: 1.17171 |  0:00:09s\n",
      "epoch 6  | loss: 1.19494 |  0:00:11s\n",
      "epoch 7  | loss: 0.97627 |  0:00:13s\n",
      "epoch 8  | loss: 0.79976 |  0:00:15s\n",
      "epoch 9  | loss: 0.88039 |  0:00:17s\n",
      "epoch 10 | loss: 0.79093 |  0:00:19s\n",
      "epoch 11 | loss: 0.72426 |  0:00:20s\n",
      "epoch 12 | loss: 0.7252  |  0:00:22s\n",
      "epoch 13 | loss: 0.70845 |  0:00:24s\n",
      "epoch 14 | loss: 0.70542 |  0:00:26s\n",
      "epoch 15 | loss: 0.69527 |  0:00:28s\n",
      "epoch 16 | loss: 0.70178 |  0:00:30s\n",
      "epoch 17 | loss: 0.7086  |  0:00:31s\n",
      "epoch 18 | loss: 0.69469 |  0:00:33s\n",
      "epoch 19 | loss: 0.6822  |  0:00:35s\n",
      "epoch 20 | loss: 0.67429 |  0:00:37s\n",
      "epoch 21 | loss: 0.66776 |  0:00:39s\n",
      "epoch 22 | loss: 0.66365 |  0:00:40s\n",
      "epoch 23 | loss: 0.66107 |  0:00:42s\n",
      "epoch 24 | loss: 0.65332 |  0:00:44s\n",
      "epoch 25 | loss: 0.65364 |  0:00:46s\n",
      "epoch 26 | loss: 0.64727 |  0:00:48s\n",
      "epoch 27 | loss: 0.64424 |  0:00:49s\n",
      "epoch 28 | loss: 0.64323 |  0:00:51s\n",
      "epoch 29 | loss: 0.63667 |  0:00:53s\n",
      "epoch 30 | loss: 0.64302 |  0:00:55s\n",
      "epoch 31 | loss: 0.62093 |  0:00:57s\n",
      "epoch 32 | loss: 0.61993 |  0:00:59s\n",
      "epoch 33 | loss: 0.60761 |  0:01:01s\n",
      "epoch 34 | loss: 0.61548 |  0:01:02s\n",
      "epoch 35 | loss: 0.60827 |  0:01:04s\n",
      "epoch 36 | loss: 0.59414 |  0:01:06s\n",
      "epoch 37 | loss: 0.5936  |  0:01:08s\n",
      "epoch 38 | loss: 0.58501 |  0:01:10s\n",
      "epoch 39 | loss: 0.57968 |  0:01:12s\n",
      "epoch 40 | loss: 0.56961 |  0:01:13s\n",
      "epoch 41 | loss: 0.563   |  0:01:15s\n",
      "epoch 42 | loss: 0.56289 |  0:01:17s\n",
      "epoch 43 | loss: 0.57257 |  0:01:19s\n",
      "epoch 44 | loss: 0.55433 |  0:01:21s\n",
      "epoch 45 | loss: 0.55536 |  0:01:22s\n",
      "epoch 46 | loss: 0.54617 |  0:01:24s\n",
      "epoch 47 | loss: 0.5364  |  0:01:26s\n",
      "epoch 48 | loss: 0.52053 |  0:01:28s\n",
      "epoch 49 | loss: 0.52332 |  0:01:30s\n",
      "epoch 50 | loss: 0.4926  |  0:01:31s\n",
      "epoch 51 | loss: 0.51616 |  0:01:33s\n",
      "epoch 52 | loss: 0.50465 |  0:01:35s\n",
      "epoch 53 | loss: 0.49916 |  0:01:37s\n",
      "epoch 54 | loss: 0.49073 |  0:01:39s\n",
      "epoch 55 | loss: 0.50566 |  0:01:41s\n",
      "epoch 56 | loss: 0.48884 |  0:01:43s\n",
      "epoch 57 | loss: 0.4686  |  0:01:44s\n",
      "epoch 58 | loss: 0.47475 |  0:01:46s\n",
      "epoch 59 | loss: 0.45304 |  0:01:48s\n",
      "epoch 60 | loss: 0.44799 |  0:01:50s\n",
      "epoch 61 | loss: 0.45573 |  0:01:52s\n",
      "epoch 62 | loss: 0.43991 |  0:01:53s\n",
      "epoch 63 | loss: 0.43956 |  0:01:55s\n",
      "epoch 64 | loss: 0.41942 |  0:01:57s\n",
      "epoch 65 | loss: 0.4331  |  0:01:59s\n",
      "epoch 66 | loss: 0.43854 |  0:02:01s\n",
      "epoch 67 | loss: 0.43634 |  0:02:03s\n",
      "epoch 68 | loss: 0.40723 |  0:02:04s\n",
      "epoch 69 | loss: 0.42189 |  0:02:06s\n",
      "epoch 70 | loss: 0.41737 |  0:02:08s\n",
      "epoch 71 | loss: 0.41055 |  0:02:10s\n",
      "epoch 72 | loss: 0.40279 |  0:02:12s\n",
      "epoch 73 | loss: 0.39356 |  0:02:13s\n",
      "epoch 74 | loss: 0.38611 |  0:02:15s\n",
      "epoch 75 | loss: 0.39425 |  0:02:17s\n",
      "epoch 76 | loss: 0.3781  |  0:02:19s\n",
      "epoch 77 | loss: 0.37946 |  0:02:21s\n",
      "epoch 78 | loss: 0.37356 |  0:02:23s\n",
      "epoch 79 | loss: 0.35188 |  0:02:24s\n",
      "epoch 80 | loss: 0.3486  |  0:02:26s\n",
      "epoch 81 | loss: 0.34111 |  0:02:28s\n",
      "epoch 82 | loss: 0.36369 |  0:02:30s\n",
      "epoch 83 | loss: 0.33055 |  0:02:32s\n",
      "epoch 84 | loss: 0.34873 |  0:02:34s\n",
      "epoch 85 | loss: 0.32709 |  0:02:35s\n",
      "epoch 86 | loss: 0.34066 |  0:02:37s\n",
      "epoch 87 | loss: 0.31884 |  0:02:39s\n",
      "epoch 88 | loss: 0.32236 |  0:02:41s\n",
      "epoch 89 | loss: 0.29792 |  0:02:43s\n",
      "epoch 90 | loss: 0.31346 |  0:02:45s\n",
      "epoch 91 | loss: 0.30436 |  0:02:46s\n",
      "epoch 92 | loss: 0.27907 |  0:02:48s\n",
      "epoch 93 | loss: 0.28037 |  0:02:50s\n",
      "epoch 94 | loss: 0.29338 |  0:02:52s\n",
      "epoch 95 | loss: 0.28606 |  0:02:54s\n",
      "epoch 96 | loss: 0.28414 |  0:02:55s\n",
      "epoch 97 | loss: 0.28472 |  0:02:57s\n",
      "epoch 98 | loss: 0.26614 |  0:02:59s\n",
      "epoch 99 | loss: 0.26981 |  0:03:01s\n",
      "Eval TABNET\n",
      "Accuracy: 0.61\n",
      "Precision: 0.61\n",
      "Recall: 0.62\n",
      "F1-score: 0.61\n",
      "ROC-AUC score: 0.61\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 17:35:13,830]\u001B[0m A new study created in memory with name: no-name-63a2de0a-281f-41ca-99fc-8259e54d8b62\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.68556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:35:20,391]\u001B[0m Trial 0 finished with value: 0.6855555555555556 and parameters: {'n_d': 40, 'n_a': 55, 'n_steps': 4, 'gamma': 1.326970529033433, 'n_independent': 5, 'n_shared': 3, 'lambda_sparse': 0.05140395568041079}. Best is trial 0 with value: 0.6855555555555556.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.71222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:35:43,962]\u001B[0m Trial 1 finished with value: 0.7122222222222222 and parameters: {'n_d': 44, 'n_a': 58, 'n_steps': 12, 'gamma': 1.220346753887144, 'n_independent': 2, 'n_shared': 8, 'lambda_sparse': 0.016587424236343178}. Best is trial 1 with value: 0.7122222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.69639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:36:07,701]\u001B[0m Trial 2 finished with value: 0.696388888888889 and parameters: {'n_d': 23, 'n_a': 36, 'n_steps': 12, 'gamma': 1.0614427288275172, 'n_independent': 2, 'n_shared': 9, 'lambda_sparse': 0.024310933377603337}. Best is trial 1 with value: 0.7122222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.75444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:36:38,684]\u001B[0m Trial 3 finished with value: 0.7544444444444444 and parameters: {'n_d': 21, 'n_a': 54, 'n_steps': 19, 'gamma': 1.5393563790626004, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.08536363608530824}. Best is trial 3 with value: 0.7544444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.71111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:36:50,560]\u001B[0m Trial 4 finished with value: 0.711111111111111 and parameters: {'n_d': 32, 'n_a': 26, 'n_steps': 5, 'gamma': 0.43473050147586934, 'n_independent': 8, 'n_shared': 3, 'lambda_sparse': 0.08777917897328105}. Best is trial 3 with value: 0.7544444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.66444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:37:05,388]\u001B[0m Trial 5 finished with value: 0.6644444444444445 and parameters: {'n_d': 34, 'n_a': 11, 'n_steps': 14, 'gamma': 0.990465710735968, 'n_independent': 4, 'n_shared': 4, 'lambda_sparse': 0.023117641787616595}. Best is trial 3 with value: 0.7544444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.73806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:38:10,172]\u001B[0m Trial 6 finished with value: 0.7380555555555556 and parameters: {'n_d': 37, 'n_a': 51, 'n_steps': 9, 'gamma': 0.7191354849247591, 'n_independent': 5, 'n_shared': 9, 'lambda_sparse': 0.02738812213514443}. Best is trial 3 with value: 0.7544444444444444.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:38:12,909]\u001B[0m Trial 7 finished with value: 0.7619444444444444 and parameters: {'n_d': 17, 'n_a': 11, 'n_steps': 1, 'gamma': 1.0995373757441742, 'n_independent': 1, 'n_shared': 3, 'lambda_sparse': 0.07372722194954746}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.76194\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.71056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:38:40,029]\u001B[0m Trial 8 finished with value: 0.7105555555555556 and parameters: {'n_d': 42, 'n_a': 45, 'n_steps': 11, 'gamma': 0.4094301992945244, 'n_independent': 4, 'n_shared': 6, 'lambda_sparse': 0.05304352262835501}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.70542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:38:54,102]\u001B[0m Trial 9 finished with value: 0.7054166666666666 and parameters: {'n_d': 36, 'n_a': 18, 'n_steps': 13, 'gamma': 0.4510345439517559, 'n_independent': 3, 'n_shared': 7, 'lambda_sparse': 0.09649247342050195}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:38:55,963]\u001B[0m Trial 10 finished with value: 0.7224999999999999 and parameters: {'n_d': 8, 'n_a': 8, 'n_steps': 1, 'gamma': 1.9478881343789927, 'n_independent': 10, 'n_shared': 1, 'lambda_sparse': 0.07039175762859676}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.7225\n",
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.70111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:39:36,812]\u001B[0m Trial 11 finished with value: 0.7011111111111111 and parameters: {'n_d': 62, 'n_a': 64, 'n_steps': 19, 'gamma': 1.5533016498471195, 'n_independent': 7, 'n_shared': 1, 'lambda_sparse': 0.07964820877688186}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.73417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:39:57,827]\u001B[0m Trial 12 finished with value: 0.7341666666666666 and parameters: {'n_d': 13, 'n_a': 35, 'n_steps': 19, 'gamma': 1.5813752492763915, 'n_independent': 1, 'n_shared': 4, 'lambda_sparse': 0.07164553407167126}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.68861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:40:16,765]\u001B[0m Trial 13 finished with value: 0.6886111111111111 and parameters: {'n_d': 23, 'n_a': 26, 'n_steps': 16, 'gamma': 0.8320293346563828, 'n_independent': 7, 'n_shared': 2, 'lambda_sparse': 0.09901858811079169}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.70972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:40:34,952]\u001B[0m Trial 14 finished with value: 0.7097222222222221 and parameters: {'n_d': 19, 'n_a': 44, 'n_steps': 8, 'gamma': 0.12599031072899913, 'n_independent': 7, 'n_shared': 4, 'lambda_sparse': 0.0653983842474575}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.70889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:40:46,643]\u001B[0m Trial 15 finished with value: 0.7088888888888888 and parameters: {'n_d': 17, 'n_a': 28, 'n_steps': 6, 'gamma': 1.4452067648138214, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.08395795063663632}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:40:52,276]\u001B[0m Trial 16 finished with value: 0.6625 and parameters: {'n_d': 27, 'n_a': 43, 'n_steps': 2, 'gamma': 1.7681938871747134, 'n_independent': 6, 'n_shared': 5, 'lambda_sparse': 0.061662919321681386}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.6625\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.67972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:41:09,200]\u001B[0m Trial 17 finished with value: 0.6797222222222222 and parameters: {'n_d': 51, 'n_a': 16, 'n_steps': 15, 'gamma': 1.1842791961754577, 'n_independent': 1, 'n_shared': 2, 'lambda_sparse': 0.03901990584966545}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.70444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:41:49,126]\u001B[0m Trial 18 finished with value: 0.7044444444444444 and parameters: {'n_d': 9, 'n_a': 36, 'n_steps': 17, 'gamma': 1.7261745783580382, 'n_independent': 9, 'n_shared': 1, 'lambda_sparse': 0.077428871754514}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.74556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:42:02,523]\u001B[0m Trial 19 finished with value: 0.7455555555555555 and parameters: {'n_d': 25, 'n_a': 63, 'n_steps': 7, 'gamma': 1.363783448319356, 'n_independent': 6, 'n_shared': 3, 'lambda_sparse': 0.0031304567794955204}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.70639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:42:08,291]\u001B[0m Trial 20 finished with value: 0.706388888888889 and parameters: {'n_d': 16, 'n_a': 50, 'n_steps': 4, 'gamma': 1.1788610227858263, 'n_independent': 4, 'n_shared': 5, 'lambda_sparse': 0.05850646886982965}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:42:26,225]\u001B[0m Trial 21 finished with value: 0.71 and parameters: {'n_d': 28, 'n_a': 64, 'n_steps': 7, 'gamma': 1.348458416598111, 'n_independent': 6, 'n_shared': 3, 'lambda_sparse': 0.00020256764669830674}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.67889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:42:45,310]\u001B[0m Trial 22 finished with value: 0.6788888888888889 and parameters: {'n_d': 25, 'n_a': 58, 'n_steps': 10, 'gamma': 1.469364196465408, 'n_independent': 8, 'n_shared': 2, 'lambda_sparse': 0.043890726064444524}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.72833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:42:51,208]\u001B[0m Trial 23 finished with value: 0.7283333333333334 and parameters: {'n_d': 21, 'n_a': 59, 'n_steps': 3, 'gamma': 1.3989564862347632, 'n_independent': 6, 'n_shared': 3, 'lambda_sparse': 0.09118379247175729}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:42:53,191]\u001B[0m Trial 24 finished with value: 0.7055555555555555 and parameters: {'n_d': 14, 'n_a': 51, 'n_steps': 1, 'gamma': 1.6760221061069467, 'n_independent': 5, 'n_shared': 1, 'lambda_sparse': 0.07363120062444196}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.70556\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.68861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:43:05,772]\u001B[0m Trial 25 finished with value: 0.6886111111111112 and parameters: {'n_d': 29, 'n_a': 18, 'n_steps': 7, 'gamma': 0.9860803418805926, 'n_independent': 3, 'n_shared': 4, 'lambda_sparse': 0.08428531455538565}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.69056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:43:31,486]\u001B[0m Trial 26 finished with value: 0.6905555555555555 and parameters: {'n_d': 13, 'n_a': 61, 'n_steps': 9, 'gamma': 1.259899034197026, 'n_independent': 8, 'n_shared': 6, 'lambda_sparse': 0.064252355491522}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.67111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:43:45,764]\u001B[0m Trial 27 finished with value: 0.6711111111111111 and parameters: {'n_d': 31, 'n_a': 40, 'n_steps': 5, 'gamma': 1.5930912205007854, 'n_independent': 3, 'n_shared': 10, 'lambda_sparse': 0.09189151199765788}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.70833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:44:16,804]\u001B[0m Trial 28 finished with value: 0.7083333333333333 and parameters: {'n_d': 19, 'n_a': 54, 'n_steps': 17, 'gamma': 1.4532281448636533, 'n_independent': 7, 'n_shared': 2, 'lambda_sparse': 0.07903362578096115}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:44:23,452]\u001B[0m Trial 29 finished with value: 0.7013888888888888 and parameters: {'n_d': 25, 'n_a': 31, 'n_steps': 3, 'gamma': 1.3536988892604644, 'n_independent': 5, 'n_shared': 3, 'lambda_sparse': 0.05469236989047682}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.70139\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.69944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:44:33,021]\u001B[0m Trial 30 finished with value: 0.6994444444444444 and parameters: {'n_d': 48, 'n_a': 54, 'n_steps': 4, 'gamma': 1.2734806480487129, 'n_independent': 6, 'n_shared': 5, 'lambda_sparse': 0.04543934926291783}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.69778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:45:31,811]\u001B[0m Trial 31 finished with value: 0.6977777777777778 and parameters: {'n_d': 39, 'n_a': 49, 'n_steps': 9, 'gamma': 0.8800106886182912, 'n_independent': 5, 'n_shared': 10, 'lambda_sparse': 0.0011752622701354035}. Best is trial 7 with value: 0.7619444444444444.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.76492 |  0:00:00s\n",
      "epoch 1  | loss: 0.70187 |  0:00:00s\n",
      "epoch 2  | loss: 0.68515 |  0:00:00s\n",
      "epoch 3  | loss: 0.67348 |  0:00:00s\n",
      "epoch 4  | loss: 0.6611  |  0:00:00s\n",
      "epoch 5  | loss: 0.64756 |  0:00:00s\n",
      "epoch 6  | loss: 0.64368 |  0:00:00s\n",
      "epoch 7  | loss: 0.63298 |  0:00:00s\n",
      "epoch 8  | loss: 0.63358 |  0:00:00s\n",
      "epoch 9  | loss: 0.62634 |  0:00:00s\n",
      "epoch 10 | loss: 0.62416 |  0:00:00s\n",
      "epoch 11 | loss: 0.61244 |  0:00:00s\n",
      "epoch 12 | loss: 0.61103 |  0:00:01s\n",
      "epoch 13 | loss: 0.59526 |  0:00:01s\n",
      "epoch 14 | loss: 0.60682 |  0:00:01s\n",
      "epoch 15 | loss: 0.58827 |  0:00:01s\n",
      "epoch 16 | loss: 0.58889 |  0:00:01s\n",
      "epoch 17 | loss: 0.58497 |  0:00:01s\n",
      "epoch 18 | loss: 0.58602 |  0:00:01s\n",
      "epoch 19 | loss: 0.57189 |  0:00:01s\n",
      "epoch 20 | loss: 0.57366 |  0:00:01s\n",
      "epoch 21 | loss: 0.57281 |  0:00:01s\n",
      "epoch 22 | loss: 0.58228 |  0:00:01s\n",
      "epoch 23 | loss: 0.56757 |  0:00:01s\n",
      "epoch 24 | loss: 0.56797 |  0:00:01s\n",
      "epoch 25 | loss: 0.56608 |  0:00:01s\n",
      "epoch 26 | loss: 0.57035 |  0:00:01s\n",
      "epoch 27 | loss: 0.56852 |  0:00:01s\n",
      "epoch 28 | loss: 0.56126 |  0:00:02s\n",
      "epoch 29 | loss: 0.56548 |  0:00:02s\n",
      "epoch 30 | loss: 0.56833 |  0:00:02s\n",
      "epoch 31 | loss: 0.57304 |  0:00:02s\n",
      "epoch 32 | loss: 0.56616 |  0:00:02s\n",
      "epoch 33 | loss: 0.55673 |  0:00:02s\n",
      "epoch 34 | loss: 0.56799 |  0:00:02s\n",
      "epoch 35 | loss: 0.56321 |  0:00:02s\n",
      "epoch 36 | loss: 0.56146 |  0:00:02s\n",
      "epoch 37 | loss: 0.56676 |  0:00:02s\n",
      "epoch 38 | loss: 0.55494 |  0:00:02s\n",
      "epoch 39 | loss: 0.54783 |  0:00:02s\n",
      "epoch 40 | loss: 0.55272 |  0:00:02s\n",
      "epoch 41 | loss: 0.563   |  0:00:02s\n",
      "epoch 42 | loss: 0.56058 |  0:00:02s\n",
      "epoch 43 | loss: 0.5619  |  0:00:03s\n",
      "epoch 44 | loss: 0.55143 |  0:00:03s\n",
      "epoch 45 | loss: 0.54404 |  0:00:03s\n",
      "epoch 46 | loss: 0.54436 |  0:00:03s\n",
      "epoch 47 | loss: 0.55149 |  0:00:03s\n",
      "epoch 48 | loss: 0.55188 |  0:00:03s\n",
      "epoch 49 | loss: 0.55525 |  0:00:03s\n",
      "epoch 50 | loss: 0.54916 |  0:00:03s\n",
      "epoch 51 | loss: 0.54907 |  0:00:03s\n",
      "epoch 52 | loss: 0.55474 |  0:00:03s\n",
      "epoch 53 | loss: 0.55832 |  0:00:03s\n",
      "epoch 54 | loss: 0.54965 |  0:00:03s\n",
      "epoch 55 | loss: 0.55272 |  0:00:03s\n",
      "epoch 56 | loss: 0.53888 |  0:00:03s\n",
      "epoch 57 | loss: 0.5469  |  0:00:03s\n",
      "epoch 58 | loss: 0.54101 |  0:00:03s\n",
      "epoch 59 | loss: 0.54356 |  0:00:04s\n",
      "epoch 60 | loss: 0.53344 |  0:00:04s\n",
      "epoch 61 | loss: 0.53807 |  0:00:04s\n",
      "epoch 62 | loss: 0.54913 |  0:00:04s\n",
      "epoch 63 | loss: 0.5543  |  0:00:04s\n",
      "epoch 64 | loss: 0.54586 |  0:00:04s\n",
      "epoch 65 | loss: 0.54421 |  0:00:04s\n",
      "epoch 66 | loss: 0.55087 |  0:00:04s\n",
      "epoch 67 | loss: 0.54827 |  0:00:04s\n",
      "epoch 68 | loss: 0.54432 |  0:00:04s\n",
      "epoch 69 | loss: 0.54835 |  0:00:04s\n",
      "epoch 70 | loss: 0.53736 |  0:00:04s\n",
      "epoch 71 | loss: 0.54231 |  0:00:04s\n",
      "epoch 72 | loss: 0.53124 |  0:00:04s\n",
      "epoch 73 | loss: 0.54551 |  0:00:04s\n",
      "epoch 74 | loss: 0.53035 |  0:00:04s\n",
      "epoch 75 | loss: 0.53456 |  0:00:04s\n",
      "epoch 76 | loss: 0.52886 |  0:00:05s\n",
      "epoch 77 | loss: 0.52364 |  0:00:05s\n",
      "epoch 78 | loss: 0.52389 |  0:00:05s\n",
      "epoch 79 | loss: 0.53208 |  0:00:05s\n",
      "epoch 80 | loss: 0.52872 |  0:00:05s\n",
      "epoch 81 | loss: 0.52774 |  0:00:05s\n",
      "epoch 82 | loss: 0.52853 |  0:00:05s\n",
      "epoch 83 | loss: 0.52959 |  0:00:05s\n",
      "epoch 84 | loss: 0.5189  |  0:00:05s\n",
      "epoch 85 | loss: 0.53045 |  0:00:05s\n",
      "epoch 86 | loss: 0.52677 |  0:00:05s\n",
      "epoch 87 | loss: 0.5356  |  0:00:05s\n",
      "epoch 88 | loss: 0.53643 |  0:00:05s\n",
      "epoch 89 | loss: 0.53682 |  0:00:05s\n",
      "epoch 90 | loss: 0.53718 |  0:00:05s\n",
      "epoch 91 | loss: 0.52633 |  0:00:06s\n",
      "epoch 92 | loss: 0.52003 |  0:00:06s\n",
      "epoch 93 | loss: 0.52419 |  0:00:06s\n",
      "epoch 94 | loss: 0.52972 |  0:00:06s\n",
      "epoch 95 | loss: 0.5196  |  0:00:06s\n",
      "epoch 96 | loss: 0.52773 |  0:00:06s\n",
      "epoch 97 | loss: 0.5283  |  0:00:06s\n",
      "epoch 98 | loss: 0.52768 |  0:00:06s\n",
      "epoch 99 | loss: 0.52691 |  0:00:06s\n",
      "Eval TABNET\n",
      "Accuracy: 0.62\n",
      "Precision: 0.63\n",
      "Recall: 0.6\n",
      "F1-score: 0.62\n",
      "ROC-AUC score: 0.62\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 17:45:38,498]\u001B[0m A new study created in memory with name: no-name-6e003d19-29c2-42f2-b01a-592bb50229b4\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.8239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:45:53,410]\u001B[0m Trial 0 finished with value: 0.8239011778224647 and parameters: {'n_d': 10, 'n_a': 12, 'n_steps': 16, 'gamma': 1.1931353017464597, 'n_independent': 2, 'n_shared': 2, 'lambda_sparse': 0.0993919029503537}. Best is trial 0 with value: 0.8239011778224647.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:46:00,706]\u001B[0m Trial 1 finished with value: 0.8213157138753233 and parameters: {'n_d': 31, 'n_a': 17, 'n_steps': 5, 'gamma': 0.9734410333333332, 'n_independent': 4, 'n_shared': 1, 'lambda_sparse': 0.025659596220865985}. Best is trial 0 with value: 0.8239011778224647.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.82132\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.78483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:47:58,255]\u001B[0m Trial 2 finished with value: 0.7848319448434358 and parameters: {'n_d': 22, 'n_a': 39, 'n_steps': 18, 'gamma': 1.0502911179042012, 'n_independent': 9, 'n_shared': 3, 'lambda_sparse': 0.032936881873155466}. Best is trial 0 with value: 0.8239011778224647.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.75352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:49:39,861]\u001B[0m Trial 3 finished with value: 0.7535191037058316 and parameters: {'n_d': 60, 'n_a': 35, 'n_steps': 19, 'gamma': 1.5876199699913374, 'n_independent': 5, 'n_shared': 10, 'lambda_sparse': 0.0963076721537148}. Best is trial 0 with value: 0.8239011778224647.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.76156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:50:36,079]\u001B[0m Trial 4 finished with value: 0.7615627693191611 and parameters: {'n_d': 33, 'n_a': 63, 'n_steps': 12, 'gamma': 1.3751938967582875, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.06781112663390852}. Best is trial 0 with value: 0.8239011778224647.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.79805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:50:45,540]\u001B[0m Trial 5 finished with value: 0.7980465383510487 and parameters: {'n_d': 17, 'n_a': 24, 'n_steps': 17, 'gamma': 0.6234540630800516, 'n_independent': 1, 'n_shared': 4, 'lambda_sparse': 0.0003474245539309902}. Best is trial 0 with value: 0.8239011778224647.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.7472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:51:49,003]\u001B[0m Trial 6 finished with value: 0.7471990807239299 and parameters: {'n_d': 61, 'n_a': 53, 'n_steps': 13, 'gamma': 0.9796538438873232, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.0740149868175701}. Best is trial 0 with value: 0.8239011778224647.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.79747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:52:24,663]\u001B[0m Trial 7 finished with value: 0.7974719908072393 and parameters: {'n_d': 61, 'n_a': 58, 'n_steps': 5, 'gamma': 1.5407845997032392, 'n_independent': 10, 'n_shared': 4, 'lambda_sparse': 0.08617095196862051}. Best is trial 0 with value: 0.8239011778224647.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.81413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:53:27,055]\u001B[0m Trial 8 finished with value: 0.8141338695777075 and parameters: {'n_d': 33, 'n_a': 63, 'n_steps': 12, 'gamma': 0.3418338959542686, 'n_independent': 8, 'n_shared': 7, 'lambda_sparse': 0.01607645593269461}. Best is trial 0 with value: 0.8239011778224647.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.73916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:54:25,812]\u001B[0m Trial 9 finished with value: 0.7391554151106003 and parameters: {'n_d': 15, 'n_a': 26, 'n_steps': 19, 'gamma': 1.7956525140858692, 'n_independent': 3, 'n_shared': 9, 'lambda_sparse': 0.045405555396067686}. Best is trial 0 with value: 0.8239011778224647.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:54:26,524]\u001B[0m Trial 10 finished with value: 0.8194484343579431 and parameters: {'n_d': 8, 'n_a': 8, 'n_steps': 1, 'gamma': 1.9422814920040696, 'n_independent': 2, 'n_shared': 1, 'lambda_sparse': 0.09767584584378806}. Best is trial 0 with value: 0.8239011778224647.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.81945\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.82419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:54:36,919]\u001B[0m Trial 11 finished with value: 0.8241884515943695 and parameters: {'n_d': 45, 'n_a': 9, 'n_steps': 7, 'gamma': 1.055630300128422, 'n_independent': 4, 'n_shared': 1, 'lambda_sparse': 0.05835988164536511}. Best is trial 11 with value: 0.8241884515943695.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.80006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:54:44,103]\u001B[0m Trial 12 finished with value: 0.8000574547543808 and parameters: {'n_d': 47, 'n_a': 8, 'n_steps': 7, 'gamma': 1.222211300790164, 'n_independent': 3, 'n_shared': 2, 'lambda_sparse': 0.06002104895984407}. Best is trial 11 with value: 0.8241884515943695.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.86929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:54:53,932]\u001B[0m Trial 13 finished with value: 0.8692904337833954 and parameters: {'n_d': 46, 'n_a': 17, 'n_steps': 9, 'gamma': 0.7836194431657715, 'n_independent': 1, 'n_shared': 3, 'lambda_sparse': 0.07845232144547518}. Best is trial 13 with value: 0.8692904337833954.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.76242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:54:59,438]\u001B[0m Trial 14 finished with value: 0.7624245906348751 and parameters: {'n_d': 47, 'n_a': 19, 'n_steps': 8, 'gamma': 0.7164082373602815, 'n_independent': 1, 'n_shared': 4, 'lambda_sparse': 0.050071636079120505}. Best is trial 13 with value: 0.8692904337833954.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.81729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:55:15,440]\u001B[0m Trial 15 finished with value: 0.8172938810686584 and parameters: {'n_d': 45, 'n_a': 33, 'n_steps': 9, 'gamma': 0.26123667723906296, 'n_independent': 5, 'n_shared': 3, 'lambda_sparse': 0.07491683115242223}. Best is trial 13 with value: 0.8692904337833954.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.82132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:55:21,141]\u001B[0m Trial 16 finished with value: 0.8213157138753231 and parameters: {'n_d': 41, 'n_a': 18, 'n_steps': 3, 'gamma': 0.6964199037102321, 'n_independent': 4, 'n_shared': 6, 'lambda_sparse': 0.05956414833306153}. Best is trial 13 with value: 0.8692904337833954.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.81988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:55:54,482]\u001B[0m Trial 17 finished with value: 0.8198793450158001 and parameters: {'n_d': 53, 'n_a': 45, 'n_steps': 10, 'gamma': 0.8381843674925766, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.08204679871803079}. Best is trial 13 with value: 0.8692904337833954.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.02599 |  0:00:00s\n",
      "epoch 1  | loss: 1.49316 |  0:00:00s\n",
      "epoch 2  | loss: 1.2327  |  0:00:01s\n",
      "epoch 3  | loss: 1.04393 |  0:00:01s\n",
      "epoch 4  | loss: 0.97337 |  0:00:02s\n",
      "epoch 5  | loss: 0.93645 |  0:00:02s\n",
      "epoch 6  | loss: 0.9287  |  0:00:02s\n",
      "epoch 7  | loss: 0.92506 |  0:00:03s\n",
      "epoch 8  | loss: 0.93387 |  0:00:03s\n",
      "epoch 9  | loss: 0.89704 |  0:00:04s\n",
      "epoch 10 | loss: 0.84184 |  0:00:04s\n",
      "epoch 11 | loss: 0.77781 |  0:00:04s\n",
      "epoch 12 | loss: 0.78728 |  0:00:05s\n",
      "epoch 13 | loss: 0.78888 |  0:00:05s\n",
      "epoch 14 | loss: 0.74322 |  0:00:06s\n",
      "epoch 15 | loss: 0.74144 |  0:00:06s\n",
      "epoch 16 | loss: 0.74174 |  0:00:07s\n",
      "epoch 17 | loss: 0.72328 |  0:00:07s\n",
      "epoch 18 | loss: 0.72561 |  0:00:07s\n",
      "epoch 19 | loss: 0.72635 |  0:00:08s\n",
      "epoch 20 | loss: 0.71219 |  0:00:08s\n",
      "epoch 21 | loss: 0.70811 |  0:00:09s\n",
      "epoch 22 | loss: 0.70439 |  0:00:09s\n",
      "epoch 23 | loss: 0.70463 |  0:00:09s\n",
      "epoch 24 | loss: 0.68522 |  0:00:10s\n",
      "epoch 25 | loss: 0.68678 |  0:00:10s\n",
      "epoch 26 | loss: 0.69326 |  0:00:11s\n",
      "epoch 27 | loss: 0.68527 |  0:00:11s\n",
      "epoch 28 | loss: 0.70222 |  0:00:11s\n",
      "epoch 29 | loss: 0.68454 |  0:00:12s\n",
      "epoch 30 | loss: 0.67846 |  0:00:12s\n",
      "epoch 31 | loss: 0.66269 |  0:00:13s\n",
      "epoch 32 | loss: 0.6701  |  0:00:13s\n",
      "epoch 33 | loss: 0.66503 |  0:00:13s\n",
      "epoch 34 | loss: 0.65883 |  0:00:14s\n",
      "epoch 35 | loss: 0.65788 |  0:00:14s\n",
      "epoch 36 | loss: 0.65591 |  0:00:15s\n",
      "epoch 37 | loss: 0.65454 |  0:00:15s\n",
      "epoch 38 | loss: 0.65224 |  0:00:15s\n",
      "epoch 39 | loss: 0.65568 |  0:00:16s\n",
      "epoch 40 | loss: 0.65711 |  0:00:16s\n",
      "epoch 41 | loss: 0.65615 |  0:00:17s\n",
      "epoch 42 | loss: 0.6593  |  0:00:17s\n",
      "epoch 43 | loss: 0.65998 |  0:00:17s\n",
      "epoch 44 | loss: 0.66034 |  0:00:18s\n",
      "epoch 45 | loss: 0.64813 |  0:00:18s\n",
      "epoch 46 | loss: 0.65041 |  0:00:19s\n",
      "epoch 47 | loss: 0.65189 |  0:00:19s\n",
      "epoch 48 | loss: 0.64607 |  0:00:19s\n",
      "epoch 49 | loss: 0.63951 |  0:00:20s\n",
      "epoch 50 | loss: 0.64724 |  0:00:20s\n",
      "epoch 51 | loss: 0.63443 |  0:00:21s\n",
      "epoch 52 | loss: 0.64278 |  0:00:21s\n",
      "epoch 53 | loss: 0.63866 |  0:00:21s\n",
      "epoch 54 | loss: 0.62762 |  0:00:22s\n",
      "epoch 55 | loss: 0.64442 |  0:00:22s\n",
      "epoch 56 | loss: 0.6418  |  0:00:23s\n",
      "epoch 57 | loss: 0.63337 |  0:00:23s\n",
      "epoch 58 | loss: 0.62415 |  0:00:23s\n",
      "epoch 59 | loss: 0.61274 |  0:00:24s\n",
      "epoch 60 | loss: 0.62639 |  0:00:24s\n",
      "epoch 61 | loss: 0.62493 |  0:00:25s\n",
      "epoch 62 | loss: 0.6225  |  0:00:25s\n",
      "epoch 63 | loss: 0.61784 |  0:00:25s\n",
      "epoch 64 | loss: 0.61871 |  0:00:26s\n",
      "epoch 65 | loss: 0.62081 |  0:00:26s\n",
      "epoch 66 | loss: 0.61356 |  0:00:27s\n",
      "epoch 67 | loss: 0.61275 |  0:00:27s\n",
      "epoch 68 | loss: 0.61729 |  0:00:28s\n",
      "epoch 69 | loss: 0.60314 |  0:00:28s\n",
      "epoch 70 | loss: 0.61009 |  0:00:28s\n",
      "epoch 71 | loss: 0.61252 |  0:00:29s\n",
      "epoch 72 | loss: 0.6134  |  0:00:29s\n",
      "epoch 73 | loss: 0.61368 |  0:00:30s\n",
      "epoch 74 | loss: 0.60778 |  0:00:30s\n",
      "epoch 75 | loss: 0.61288 |  0:00:30s\n",
      "epoch 76 | loss: 0.59964 |  0:00:31s\n",
      "epoch 77 | loss: 0.60195 |  0:00:31s\n",
      "epoch 78 | loss: 0.60367 |  0:00:32s\n",
      "epoch 79 | loss: 0.5973  |  0:00:32s\n",
      "epoch 80 | loss: 0.60364 |  0:00:32s\n",
      "epoch 81 | loss: 0.61772 |  0:00:33s\n",
      "epoch 82 | loss: 0.59574 |  0:00:33s\n",
      "epoch 83 | loss: 0.5952  |  0:00:34s\n",
      "epoch 84 | loss: 0.59157 |  0:00:34s\n",
      "epoch 85 | loss: 0.60288 |  0:00:34s\n",
      "epoch 86 | loss: 0.59432 |  0:00:35s\n",
      "epoch 87 | loss: 0.58874 |  0:00:35s\n",
      "epoch 88 | loss: 0.58738 |  0:00:36s\n",
      "epoch 89 | loss: 0.59191 |  0:00:36s\n",
      "epoch 90 | loss: 0.59441 |  0:00:36s\n",
      "epoch 91 | loss: 0.59754 |  0:00:37s\n",
      "epoch 92 | loss: 0.6046  |  0:00:37s\n",
      "epoch 93 | loss: 0.5987  |  0:00:38s\n",
      "epoch 94 | loss: 0.60585 |  0:00:38s\n",
      "epoch 95 | loss: 0.58793 |  0:00:39s\n",
      "epoch 96 | loss: 0.58919 |  0:00:39s\n",
      "epoch 97 | loss: 0.58214 |  0:00:39s\n",
      "epoch 98 | loss: 0.58083 |  0:00:40s\n",
      "epoch 99 | loss: 0.58438 |  0:00:40s\n",
      "Eval TABNET\n",
      "Accuracy: 0.76\n",
      "Precision: 0.76\n",
      "Recall: 0.76\n",
      "F1-score: 0.76\n",
      "ROC-AUC score: 0.76\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 17:56:35,537]\u001B[0m A new study created in memory with name: no-name-7a08a3a9-6309-476b-9f7f-86d18569c57c\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.67972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 17:58:38,192]\u001B[0m Trial 0 finished with value: 0.6797222222222222 and parameters: {'n_d': 58, 'n_a': 34, 'n_steps': 14, 'gamma': 1.044150343938151, 'n_independent': 8, 'n_shared': 8, 'lambda_sparse': 0.0010945068145414517}. Best is trial 0 with value: 0.6797222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.67972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:00:28,355]\u001B[0m Trial 1 finished with value: 0.6797222222222222 and parameters: {'n_d': 12, 'n_a': 61, 'n_steps': 18, 'gamma': 0.9693170169704064, 'n_independent': 9, 'n_shared': 5, 'lambda_sparse': 0.0689638942403096}. Best is trial 0 with value: 0.6797222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.74722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:00:41,623]\u001B[0m Trial 2 finished with value: 0.7472222222222222 and parameters: {'n_d': 41, 'n_a': 17, 'n_steps': 4, 'gamma': 0.1450993947542321, 'n_independent': 10, 'n_shared': 6, 'lambda_sparse': 0.04177094528397816}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.69917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:00:47,807]\u001B[0m Trial 3 finished with value: 0.6991666666666666 and parameters: {'n_d': 24, 'n_a': 26, 'n_steps': 3, 'gamma': 0.9297624334158482, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.09096234080492804}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.67278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:00:58,589]\u001B[0m Trial 4 finished with value: 0.6727777777777778 and parameters: {'n_d': 27, 'n_a': 59, 'n_steps': 6, 'gamma': 0.5909311310273517, 'n_independent': 5, 'n_shared': 4, 'lambda_sparse': 0.05013920686758419}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.68917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:01:07,042]\u001B[0m Trial 5 finished with value: 0.6891666666666667 and parameters: {'n_d': 50, 'n_a': 61, 'n_steps': 2, 'gamma': 1.9316531960375067, 'n_independent': 9, 'n_shared': 3, 'lambda_sparse': 0.060020025390342444}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.68597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:01:44,446]\u001B[0m Trial 6 finished with value: 0.6859722222222222 and parameters: {'n_d': 50, 'n_a': 51, 'n_steps': 15, 'gamma': 0.4891885883723308, 'n_independent': 5, 'n_shared': 8, 'lambda_sparse': 0.09292650846504671}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.68958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:02:16,935]\u001B[0m Trial 7 finished with value: 0.6895833333333333 and parameters: {'n_d': 36, 'n_a': 26, 'n_steps': 12, 'gamma': 0.8129133208077975, 'n_independent': 5, 'n_shared': 8, 'lambda_sparse': 0.07905401639366043}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.61972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:02:33,353]\u001B[0m Trial 8 finished with value: 0.6197222222222223 and parameters: {'n_d': 32, 'n_a': 19, 'n_steps': 16, 'gamma': 1.8820600518250867, 'n_independent': 5, 'n_shared': 3, 'lambda_sparse': 0.03436652970378182}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.69833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:02:56,033]\u001B[0m Trial 9 finished with value: 0.6983333333333335 and parameters: {'n_d': 27, 'n_a': 44, 'n_steps': 18, 'gamma': 1.283345313665677, 'n_independent': 2, 'n_shared': 4, 'lambda_sparse': 0.04608340047073263}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.62528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:03:10,766]\u001B[0m Trial 10 finished with value: 0.6252777777777777 and parameters: {'n_d': 46, 'n_a': 8, 'n_steps': 7, 'gamma': 0.10964544132788345, 'n_independent': 1, 'n_shared': 10, 'lambda_sparse': 0.026879021450073332}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:03:14,845]\u001B[0m Trial 11 finished with value: 0.6788888888888889 and parameters: {'n_d': 16, 'n_a': 18, 'n_steps': 2, 'gamma': 0.10730542951428836, 'n_independent': 10, 'n_shared': 1, 'lambda_sparse': 0.09836123480781635}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.67889\n",
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.65778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:03:22,593]\u001B[0m Trial 12 finished with value: 0.6577777777777779 and parameters: {'n_d': 22, 'n_a': 32, 'n_steps': 6, 'gamma': 1.4418233007141326, 'n_independent': 7, 'n_shared': 1, 'lambda_sparse': 0.07921312559227196}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:03:30,028]\u001B[0m Trial 13 finished with value: 0.6825 and parameters: {'n_d': 43, 'n_a': 9, 'n_steps': 1, 'gamma': 0.4347439373979868, 'n_independent': 10, 'n_shared': 6, 'lambda_sparse': 0.08287591152762605}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.6825\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.69389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:04:00,492]\u001B[0m Trial 14 finished with value: 0.6938888888888889 and parameters: {'n_d': 38, 'n_a': 21, 'n_steps': 9, 'gamma': 0.7061266173626396, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.06217855892679039}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.67778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:04:09,312]\u001B[0m Trial 15 finished with value: 0.6777777777777778 and parameters: {'n_d': 59, 'n_a': 41, 'n_steps': 4, 'gamma': 0.32506245414315416, 'n_independent': 7, 'n_shared': 2, 'lambda_sparse': 0.09987394671166314}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.69667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:04:32,609]\u001B[0m Trial 16 finished with value: 0.6966666666666667 and parameters: {'n_d': 25, 'n_a': 27, 'n_steps': 9, 'gamma': 0.7193054728922408, 'n_independent': 3, 'n_shared': 7, 'lambda_sparse': 0.06700832824436406}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.66306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:04:44,470]\u001B[0m Trial 17 finished with value: 0.6630555555555555 and parameters: {'n_d': 9, 'n_a': 14, 'n_steps': 4, 'gamma': 0.3301558419059696, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.04621841049363887}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.68333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:04:57,799]\u001B[0m Trial 18 finished with value: 0.6833333333333333 and parameters: {'n_d': 17, 'n_a': 26, 'n_steps': 4, 'gamma': 0.8846325640774134, 'n_independent': 8, 'n_shared': 5, 'lambda_sparse': 0.08394910657089355}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.65861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:05:39,540]\u001B[0m Trial 19 finished with value: 0.658611111111111 and parameters: {'n_d': 32, 'n_a': 39, 'n_steps': 11, 'gamma': 1.1849842599873233, 'n_independent': 9, 'n_shared': 3, 'lambda_sparse': 0.030543811841459476}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.71944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:05:50,687]\u001B[0m Trial 20 finished with value: 0.7194444444444444 and parameters: {'n_d': 41, 'n_a': 14, 'n_steps': 7, 'gamma': 0.6120339453188564, 'n_independent': 3, 'n_shared': 7, 'lambda_sparse': 0.0898563047577498}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.63389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:06:02,137]\u001B[0m Trial 21 finished with value: 0.6338888888888888 and parameters: {'n_d': 41, 'n_a': 13, 'n_steps': 8, 'gamma': 0.6459579780819505, 'n_independent': 3, 'n_shared': 6, 'lambda_sparse': 0.08809504184567882}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.66333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:06:12,340]\u001B[0m Trial 22 finished with value: 0.6633333333333333 and parameters: {'n_d': 52, 'n_a': 22, 'n_steps': 5, 'gamma': 0.8524646032296093, 'n_independent': 3, 'n_shared': 7, 'lambda_sparse': 0.09082422482817039}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.71028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:06:17,206]\u001B[0m Trial 23 finished with value: 0.7102777777777778 and parameters: {'n_d': 33, 'n_a': 15, 'n_steps': 3, 'gamma': 0.28559720954331635, 'n_independent': 4, 'n_shared': 7, 'lambda_sparse': 0.07490681920509384}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:06:22,144]\u001B[0m Trial 24 finished with value: 0.7020833333333333 and parameters: {'n_d': 34, 'n_a': 14, 'n_steps': 1, 'gamma': 0.26053644358083233, 'n_independent': 4, 'n_shared': 9, 'lambda_sparse': 0.07514296268333366}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.70208\n",
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.67306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:06:37,995]\u001B[0m Trial 25 finished with value: 0.6730555555555554 and parameters: {'n_d': 44, 'n_a': 13, 'n_steps': 7, 'gamma': 0.5137493149783574, 'n_independent': 4, 'n_shared': 7, 'lambda_sparse': 0.07170941201205167}. Best is trial 2 with value: 0.7472222222222222.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.03135 |  0:00:00s\n",
      "epoch 1  | loss: 0.91838 |  0:00:01s\n",
      "epoch 2  | loss: 0.88546 |  0:00:02s\n",
      "epoch 3  | loss: 0.86804 |  0:00:02s\n",
      "epoch 4  | loss: 0.8008  |  0:00:03s\n",
      "epoch 5  | loss: 0.75415 |  0:00:04s\n",
      "epoch 6  | loss: 0.764   |  0:00:04s\n",
      "epoch 7  | loss: 0.75926 |  0:00:05s\n",
      "epoch 8  | loss: 0.74317 |  0:00:06s\n",
      "epoch 9  | loss: 0.75088 |  0:00:06s\n",
      "epoch 10 | loss: 0.73387 |  0:00:07s\n",
      "epoch 11 | loss: 0.71796 |  0:00:08s\n",
      "epoch 12 | loss: 0.70439 |  0:00:08s\n",
      "epoch 13 | loss: 0.70258 |  0:00:09s\n",
      "epoch 14 | loss: 0.67583 |  0:00:10s\n",
      "epoch 15 | loss: 0.69461 |  0:00:10s\n",
      "epoch 16 | loss: 0.68136 |  0:00:11s\n",
      "epoch 17 | loss: 0.65599 |  0:00:12s\n",
      "epoch 18 | loss: 0.65715 |  0:00:12s\n",
      "epoch 19 | loss: 0.66304 |  0:00:13s\n",
      "epoch 20 | loss: 0.65882 |  0:00:14s\n",
      "epoch 21 | loss: 0.64906 |  0:00:14s\n",
      "epoch 22 | loss: 0.6465  |  0:00:15s\n",
      "epoch 23 | loss: 0.64725 |  0:00:16s\n",
      "epoch 24 | loss: 0.63734 |  0:00:17s\n",
      "epoch 25 | loss: 0.63765 |  0:00:17s\n",
      "epoch 26 | loss: 0.63679 |  0:00:18s\n",
      "epoch 27 | loss: 0.62977 |  0:00:19s\n",
      "epoch 28 | loss: 0.63633 |  0:00:19s\n",
      "epoch 29 | loss: 0.63551 |  0:00:20s\n",
      "epoch 30 | loss: 0.63058 |  0:00:21s\n",
      "epoch 31 | loss: 0.62695 |  0:00:21s\n",
      "epoch 32 | loss: 0.61444 |  0:00:22s\n",
      "epoch 33 | loss: 0.61838 |  0:00:23s\n",
      "epoch 34 | loss: 0.6232  |  0:00:23s\n",
      "epoch 35 | loss: 0.618   |  0:00:24s\n",
      "epoch 36 | loss: 0.60584 |  0:00:25s\n",
      "epoch 37 | loss: 0.61884 |  0:00:25s\n",
      "epoch 38 | loss: 0.60263 |  0:00:26s\n",
      "epoch 39 | loss: 0.61709 |  0:00:27s\n",
      "epoch 40 | loss: 0.60229 |  0:00:27s\n",
      "epoch 41 | loss: 0.61625 |  0:00:28s\n",
      "epoch 42 | loss: 0.61878 |  0:00:29s\n",
      "epoch 43 | loss: 0.59683 |  0:00:29s\n",
      "epoch 44 | loss: 0.60227 |  0:00:30s\n",
      "epoch 45 | loss: 0.59262 |  0:00:31s\n",
      "epoch 46 | loss: 0.58717 |  0:00:31s\n",
      "epoch 47 | loss: 0.58641 |  0:00:32s\n",
      "epoch 48 | loss: 0.58654 |  0:00:33s\n",
      "epoch 49 | loss: 0.59224 |  0:00:33s\n",
      "epoch 50 | loss: 0.57816 |  0:00:34s\n",
      "epoch 51 | loss: 0.58454 |  0:00:35s\n",
      "epoch 52 | loss: 0.58156 |  0:00:35s\n",
      "epoch 53 | loss: 0.57641 |  0:00:36s\n",
      "epoch 54 | loss: 0.57742 |  0:00:37s\n",
      "epoch 55 | loss: 0.57762 |  0:00:37s\n",
      "epoch 56 | loss: 0.5622  |  0:00:38s\n",
      "epoch 57 | loss: 0.5757  |  0:00:39s\n",
      "epoch 58 | loss: 0.56527 |  0:00:39s\n",
      "epoch 59 | loss: 0.56004 |  0:00:40s\n",
      "epoch 60 | loss: 0.56202 |  0:00:41s\n",
      "epoch 61 | loss: 0.55478 |  0:00:41s\n",
      "epoch 62 | loss: 0.55392 |  0:00:42s\n",
      "epoch 63 | loss: 0.534   |  0:00:43s\n",
      "epoch 64 | loss: 0.53348 |  0:00:43s\n",
      "epoch 65 | loss: 0.53122 |  0:00:44s\n",
      "epoch 66 | loss: 0.53421 |  0:00:45s\n",
      "epoch 67 | loss: 0.51757 |  0:00:46s\n",
      "epoch 68 | loss: 0.53279 |  0:00:46s\n",
      "epoch 69 | loss: 0.52703 |  0:00:47s\n",
      "epoch 70 | loss: 0.50942 |  0:00:48s\n",
      "epoch 71 | loss: 0.51966 |  0:00:48s\n",
      "epoch 72 | loss: 0.51626 |  0:00:49s\n",
      "epoch 73 | loss: 0.50622 |  0:00:50s\n",
      "epoch 74 | loss: 0.50012 |  0:00:50s\n",
      "epoch 75 | loss: 0.50369 |  0:00:51s\n",
      "epoch 76 | loss: 0.50094 |  0:00:52s\n",
      "epoch 77 | loss: 0.49334 |  0:00:52s\n",
      "epoch 78 | loss: 0.49119 |  0:00:53s\n",
      "epoch 79 | loss: 0.47274 |  0:00:54s\n",
      "epoch 80 | loss: 0.4821  |  0:00:54s\n",
      "epoch 81 | loss: 0.4777  |  0:00:55s\n",
      "epoch 82 | loss: 0.48272 |  0:00:56s\n",
      "epoch 83 | loss: 0.47065 |  0:00:56s\n",
      "epoch 84 | loss: 0.46065 |  0:00:57s\n",
      "epoch 85 | loss: 0.462   |  0:00:58s\n",
      "epoch 86 | loss: 0.45222 |  0:00:58s\n",
      "epoch 87 | loss: 0.45098 |  0:00:59s\n",
      "epoch 88 | loss: 0.44954 |  0:01:00s\n",
      "epoch 89 | loss: 0.44392 |  0:01:00s\n",
      "epoch 90 | loss: 0.44711 |  0:01:01s\n",
      "epoch 91 | loss: 0.45035 |  0:01:02s\n",
      "epoch 92 | loss: 0.44829 |  0:01:02s\n",
      "epoch 93 | loss: 0.41817 |  0:01:03s\n",
      "epoch 94 | loss: 0.41538 |  0:01:04s\n",
      "epoch 95 | loss: 0.42025 |  0:01:04s\n",
      "epoch 96 | loss: 0.41286 |  0:01:05s\n",
      "epoch 97 | loss: 0.40875 |  0:01:06s\n",
      "epoch 98 | loss: 0.40374 |  0:01:07s\n",
      "epoch 99 | loss: 0.41753 |  0:01:07s\n",
      "Eval TABNET\n",
      "Accuracy: 0.55\n",
      "Precision: 0.56\n",
      "Recall: 0.5\n",
      "F1-score: 0.53\n",
      "ROC-AUC score: 0.55\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc4AAAHsCAYAAABbgk2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAm40lEQVR4nO3de1iVdbr/8c8C5KwgQ2E5WjIexj1pZkdHTfOEaWxES0hlxmlmLLcNHtKIg0pZYWEyOqaoabU1g3LMQ2azqTGd5hrd/jIn29lo6vaA5wFFIEFg/f5otyYrWDwGfHnWer+ui+tynb7PDZG3n/s5OZxOp1MAAKBefEwXAACAndA4AQCwgMYJAIAFNE4AACygcQIAYAGNEwAAC2icsI3q6mq9/PLLGjlypOLi4jRs2DBlZ2ersrLyB605ceJExcTEaPXq1ZY/v3fvXiUnJ1/19r9twIAB6tGjh8rKyq54ft26derSpYvefffdOj9/8eJF/eIXv6j19bi4OJWUlDRIrYC38jNdAFBfmZmZunDhgl599VW1bNlS5eXlmj59utLT05WdnX1Va54+fVoffvih9uzZI19fX8uf79atmxYuXHhV265N69atVVBQoBEjRrieW79+vSIjI91+9sKFC9q7d2+tr2/YsKEhSgS8GokTtnD8+HFt2rRJzz77rFq2bClJCg4O1pNPPqlBgwZJ+iptTZ8+Xffdd59iY2P1/PPPq6qqStJXDe4Pf/iDEhMTNWDAAK1Zs0alpaX6zW9+o6qqKo0cOVJHjx5Vly5dVFRU5Nru14/LysqUnJysuLg4xcfHKyMjQzU1Ndq5c6fuu+++q9p+bf793/9dGzdudD0uLCxUeXm5oqOjXc+tXbtWDzzwgEaMGKF77rnHtV5qaqouXbqkuLg4VVdX66abbtLkyZMVExOjvXv3ur6fRYsWKTExUdXV1Tp79qz69OmjHTt2NMR/KsDj0ThhC//zP/+jjh07KjQ09Irnr7nmGsXExEiSnn76aYWHh2vTpk364x//qH/84x9auXKlJKmyslKtW7dWXl6eFi5cqKysLLVo0ULLli1TYGCgNmzYoPbt29e6/YKCApWVlWnDhg1au3atJOnYsWNXvMfq9isqKr53W/369dPnn3+uM2fOSPoqJX4zfZaVlenNN9/UsmXLtH79euXk5LgSd1ZWluv78fX11eXLl3XPPffoT3/6k7p16+ZaY+LEifLz89OKFSv0+OOPa9y4cbrrrrvc/ncAQOOETfj4+KimpqbO92zfvl3jxo2Tw+GQv7+/EhMTtX37dtfrAwcOlCT97Gc/U2VlpcrLy+u9/VtvvVVffPGFkpKStGzZMv3yl7/UDTfc0Cjbb9GihWJiYvT2229LkrZs2eJKtZIUEhKi3Nxcbdu2Tb///e+Vm5tb5/dy2223fec5X19fzZs3T8uXL5fT6dTDDz9c758F4O1onLCF7t2769ChQyotLb3i+dOnT2vChAm6dOmSampq5HA4XK/V1NS4RqWSFBAQIEmu97i7TPM3Dzpq166dCgoKNGHCBJWWlupXv/qV/vznP1/x/obc/ogRI7Rx40bt3r1bHTp0UHh4uOu1U6dOacSIESosLNStt96qKVOm1Pl9BAcHf+/zhYWFCggI0NGjR3XhwoU61wDwLzRO2EJUVJRiY2OVlpbmap6lpaXKzMxUeHi4AgMD1adPH61evVpOp1OVlZV644039POf/9zSdiIiIlwH13yd+CRpzZo1Sk1NVZ8+fTRjxgz16dNHn3322RWfbYjtf+3mm2/WpUuXlJOTo/j4+Cte+/TTTxUREaH/+I//UJ8+fbR161ZJXx0h7Ofnp+rqarf/KCgpKdGMGTM0d+5c3XfffUpPT7+qOgFvROOEbcyePVsdO3ZUYmKi4uLi9MADD6hjx456+umnJUkZGRkqKipSbGysYmNj1aFDBz3yyCOWtpGRkaGnnnpK8fHxOnjwoK655hpJXyXA6upqDRs2TCNHjtTFixeVlJT0nc/+0O1/U1xcnA4fPqy+ffte8Xzv3r0VFRWloUOH6t5779XJkycVERGhI0eO6JprrlH37t01fPhwFRcX1/l99u/fX3369NGjjz6qY8eO6bXXXrvqWgFv4uC2YgAA1B+JEwAAC2icAABYwJWDAABeo7q6WhkZGTp8+LB8fX2VlZWlkJAQZWRkqKSkRNXV1Xr++efrPK+bxgkA8BpfH4Wel5ennTt3KisrS2FhYYqNjdWwYcO0Y8cOHTp0qM7GycFBAACvUlVVJT8/P7311lvavXu3du7cqQcffFDbtm1T27ZtlZ6eXuv5z1IzTJxBtzxqugSgQRTvWmS6BOAHC2zELtEYf9+/8kRf5efnux4nJCQoISHhivf4+fkpJSVFBQUFWrhwodatW6dWrVrplVde0aJFi7R8+XJNnjy51m00u8RJ44SnoHHCE9itcX75cf3/vzt79qxGjx6tL7/8Ulu2bFHr1q312WefKScnR8uXL6/1cxxVCwAww+HT8F9urF+/XkuXLpUkBQUFyeFw6I477tC2bdskSbt27VLHjh3rXKPZjWoBAF7iG9d2bipDhgxRamqqxo4dq6qqKqWlpalr167KyMhQXl6eQkND9cILL9S5Bo0TAOA1goODtWDBgu88//LLL9d7DRonAMCMeoxWmyN7Vg0AgCEkTgCAGQb2cTYEGicAwAxGtQAAeD4SJwDADJuOakmcAABYQOIEAJjBPk4AADwfiRMAYIZN93HSOAEAZjCqBQDA85E4AQBm2HRUS+IEAMACEicAwAyb7uOkcQIAzGBUCwCA5yNxAgDMsOmo1p5VAwBgCIkTAGCGTRMnjRMAYIYPBwcBAODxSJwAADNsOqq1Z9UAABhC4gQAmGHTCyDQOAEAZjCqBQDA85E4AQBm2HRUS+IEAMACEicAwAz2cQIA4PlInAAAM2y6j5PGCQAwg1EtAACej8QJADDDpqNaEicAABaQOAEAZth0HyeNEwBgBqNaAAA8H4kTAGCGTUe19qwaAABDSJwAADNsmjhpnAAAMzg4CAAAz0fiBACYYdNRrT2rBgDAEBInAMAM9nECAOD5SJwAADNsuo+TxgkAMINRLQAAno/ECQAwwkHiBADA85E4AQBG2DVx0jgBAGbYs28yqgUAwAoSJwDACLuOakmcAABYQOIEABhh18RJ4wQAGGHXxsmoFgAAC0icAAAjSJwAAHgBEicAwAx7Bk4SJwDAe1RXVys1NVWJiYkaO3asjh496npt06ZNSkhIcLsGjRMAYITD4WjwL3e2bt0qScrLy1NycrKysrIkSfv27dPatWvldDrdrkHjBAAYYaJxDho0SHPmzJEknThxQpGRkSouLta8efOUlpZWr7rZxwkA8Bj5+fnKz893PU5ISPjO+NXPz08pKSkqKCjQggULlJ6errS0NAUEBNRrGw5nfXJpEwq65VHTJQANonjXItMlAD9YYCPGq4ikNQ2+ZtGqMfV+79mzZzVw4EBFRkaqbdu2qqio0BdffKFRo0YpPT291s+ROAEAXmP9+vU6ffq0Hn74YQUFBSkyMlJbtmxRQECAjh8/rmnTptXZNCUaJwDAEBMXQBgyZIhSU1M1duxYVVVVWRrRfo3GCQAww8B5nMHBwVqwYMH3vvbjH/9Yb7zxhts1OKoWAAALSJwAACO4Vi0AAF6AxAkAMMKuiZPGCQAwwq6Nk1EtAAAWkDgBAGbYM3CSOAEAsILECQAwgn2cAAB4ARInAMAIuyZOGicAwAi7Nk5GtQAAWEDiBAAYQeIEAMALkDgBAGbYM3DSOAEAZjCqBQDAC5A4AQBGkDgBAPACJE4AgBF2TZw0TgCAGfbsm4xqAQCwgsQJADDCrqNaEicAABaQOAEARpA4AQDwAiROD+fj49DimWPU+cZrVV3j1ITZq1Vadkkvzhqj1q2C5evj0K9nrtLh4+dMlwrU6fLly5o9M00nCgtVWVmpCQ9PVP8BAyVJ77y9Sa+vWa1Va/INVwkr7Jo4aZwebvjd3SRJA36Vo763dtJzj43U+ZJy5b+zS38s+Fh339ZJXW6MonGi2dv89kaFh4Xr2bnZOn++WAmj4tV/wEB9vm+f3lq3Vk6n03SJsMiujZNRrYfb9MEnmvT065Kk9tdH6Mw/L6pXj2i1jWqtzbmPKnHY7dr+/w4YrhJwb8iQoZqUPNn12NfPV+fPF2tBzjw9/kSawcrgbRq1cdbU1DTm8qin6uoaLX8qSfMfv19vvfexbrjuRyouKdfwRxbp2KkiPfarwaZLBNwKDglRSEioyspK9diUZE363WRlzkzXjJQ0BYeEmC4PV8PRCF9NoMFHtceOHVNWVpY+/fRT+fn5qaamRp07d1Zqaqo6dOjQ0JtDPf121ipl/Kiltq+aofOl5dq8ba8k6Z1tnyrz0VjD1QH1c+rkSU2dPEmjE8eoffsbdeTIET0zJ1MVFRU6dPALPZ/1jB5PTTddJjxcgzfO9PR0PfbYY7r55ptdz+3Zs0epqanKy8tr6M3BjQeH3662Ua01b+V/qfzSZdXU1OjDj75QTJ9/0+ubd6lPz47ad/Ck6TIBt/557pwemfCQUtNn6c67ekmS3tq4WZJUWHhcKdOn0TRtxq77OBu8cVZWVl7RNCWpR48eDb0Z1NOG9/+uZU+OU8GKKWrh56sZ8/6oT/5xXItnjdWEB/rqQumXGp/6iukyAbdeWp6rkgslWpa7WMtyF0uSXsxdrsDAQMOV4WrZtXE6nA18KNrs2bNVWVmpvn37qmXLliorK9O2bdvk7++vJ5980u3ng255tCHLAYwp3rXIdAnADxbYiOde/OSxLQ2+5sEX7m3wNb+twX8kmZmZeu+99/TRRx+ptLRUoaGhuueeezR4MAegAAD+xaaBs+Ebp8Ph0ODBg2mUAACPxAUQAABG2HUfJ40TAGCETfsmVw4CAMAKEicAwAi7jmpJnAAAWEDiBAAYYdPASeIEAMAKEicAwAgfH3tGThonAMAIRrUAAHgBEicAwAhORwEAwAuQOAEARtg0cNI4AQBmMKoFAMALkDgBAEaQOAEA8AIkTgCAETYNnDROAIAZjGoBAPACJE4AgBE2DZwkTgAArCBxAgCMYB8nAABegMQJADDCpoGTxgkAMINRLQAAXoDECQAwwqaBk8YJAPAe1dXVysjI0OHDh+Xr66usrCyVlZVpzpw58vX1lb+/v5577jlFRkbWugaNEwBghIl9nFu3bpUk5eXlaefOncrKytLFixc1c+ZMde3aVXl5eVq+fLlSU1NrXYPGCQAwwsSodtCgQerfv78k6cSJE4qMjNSTTz6pa6+9VtJXiTQgIKDONWicAACPkZ+fr/z8fNfjhIQEJSQkXPEePz8/paSkqKCgQAsXLnQ1zd27d2v16tV67bXX6tyGw+l0Ohu+9KsXdMujpksAGkTxrkWmSwB+sMBGjFe9ntve4Gv+LeXuer/37NmzGj16tDZv3qwPPvhAS5Ys0eLFi9WuXbs6P8fpKAAAr7F+/XotXbpUkhQUFCSHw6GCggKtXr1aq1atcts0JUa1AABDTOzjHDJkiFJTUzV27FhVVVUpLS1NaWlpuu666/S73/1OknT77bcrOTm51jVonAAAI0wcVRscHKwFCxZc8dygQYMsrcGoFgAAC0icAAAj7HrlIBInAAAWkDgBAEZwdxQAALwAiRMAYIRdEyeNEwBghE37JqNaAACsIHECAIyw66iWxAkAgAUkTgCAETYNnDROAIAZjGoBAPACJE4AgBE2DZwkTgAArCBxAgCM8LFp5KRxAgCMsGnfZFQLAIAVJE4AgBGcjgIAgBcgcQIAjPCxZ+CkcQIAzGBUCwCAFyBxAgCMsGngJHECAGAFiRMAYIRD9oycJE4AACwgcQIAjOB0FAAALOB0FAAAvACJEwBghE0DJ4kTAAArSJwAACO4kTUAABbYtG8yqgUAwAoSJwDACE5HAQDAC5A4AQBG2DRw0jgBAGbY9ahaRrUAAFhA4gQAGGHPvEniBADAEkuJs6amRj4+9FoAwA/nsaejbNmyRZs3b9Zbb72l3r17a8WKFU1RFwAAzZLbxrly5Ur9/Oc/18aNG7Vt2zZt3bq1KeoCAHg4H0fDfzUFt6PagIAASVJISIj8/f1VVlbW6EUBADyfx45qf/zjH2vUqFEaNWqUFi1apO7duzdFXQAANEtuE+fcuXNVVlamkJAQdevWTZGRkU1RFwDAw9k0cNbeOKdNm1ZrjH7hhRcarSAAAJqzWhtnYmJiU9YBAPAydt3HWWvjvOOOOyRJpaWlWr58uc6ePav+/furS5cuTVYcAMBzNdVRsA3N7cFBaWlpateunf73f/9XkZGRSk9Pb4q6AABoltw2zvPnz+v++++Xn5+fevbsKafT2RR1AQA8nMPhaPCvplCv6+cdPHhQknTq1CkuuQcA8GpuT0fJyMhQWlqaDh48qOTkZM2ePbsp6gIAeDib7uJ03zg7d+6sJUuWqLCwUDfccINatWrVFHUBADycx97Ieu3atRozZoyWLl2qhIQEvfPOO01RFwAAzZLbxJmXl6cNGzYoICBA5eXl+uUvf6lhw4Y1RW0AAA9m08DpPnGGh4fLz++r/hoYGMioFgDg1dxecq+oqEgjR47UzTffrM8++0yBgYFNWR8AwEN53JWDvu+Se/fdd1+jFgMAQHPn9pJ758+f14cffqiqqio5nU6dOXPG9RoAAFfLpoHT/cFBycnJuvHGG7V//34FBAQoKCioKeoCAHg4jz0dRZKeeuopdejQQS+//LIuXLjQ2DUBANBsuU2cklRRUaEvv/xSDodD5eXljV0TAMALmAic1dXVysjI0OHDh+Xr66usrCw5nU498cQTcjgc6tSpk2bPnl3n5WXdJs6xY8fq1VdfVe/evdWvXz9FR0c36DcBAEBT2bp1q6SvrlGQnJysrKwsZWVlacqUKVqzZo2cTqfef//9OtdwmzhjYmJcf7733nt17ty5H1g2AABmTkcZNGiQ+vfvL0k6ceKEIiMj9cEHH7gOer377rv117/+VYMHD651jXqNar8WGhqq8ePHa+3atVdftRsPzZrUaGsDTemxTftMlwD8YC/Gd220tRvjXlv5+fnKz893PU5ISFBCQsIV7/Hz81NKSooKCgq0cOFCbd261dXEQ0JCdPHixTq3YalxSuJ+nACAZuv7GuX3ee655zR9+nSNHj1aFRUVrufLysrcXiHPcsO365UeAADNi4kbWa9fv15Lly6VJAUFBcnhcOimm27Szp07JUnbt2/XbbfdVucabi+5901Op1PHjh1zWxgAAM3RkCFDlJqaqrFjx6qqqkppaWn6yU9+opkzZ2r+/PmKjo6+4tie72Ppknt1PQ8AgBU+BgaYwcHBWrBgwXeeX716db3XcHvJPQAAGoOJxtkQGuOgJgAAPJblo2oBAGgIdj3Y1G3jPH36tLKzs1VcXKyYmBh16dJFN998c1PUBgBAs+N2VDtz5kyNGjVKlZWVuu222/TMM880RV0AAA/n42j4ryap290bKioq1KtXLzkcDkVHRysgIKAp6gIAoFlyO6r19/fXX/7yF9XU1GjPnj3y9/dviroAAB7Oprs43SfOOXPmaN26dSouLtbKlSuVmZnZBGUBADydj8PR4F9NwW3ibNOmjXJycpqiFgAAmj23jbNPnz6uP58/f17t2rXTli1bGrUoAIDns+uFBNw2zg8//ND158LCQi1atKhRCwIAoDmzdAGEtm3b6tChQ41VCwDAi9j14CC3jfObd0k5c+aMfvSjHzV6UQAAz9dUB/M0NLeNc9iwYa6begYEBOimm25q9KIAAGiu3DbOFStW6PXXX2+KWgAAXsSmgdN94wwLC9Orr76qDh06yMfnq2OgvnmkLQAA3sRt42zdurU+//xzff75567naJwAgB/KrvfjrLVxTpkyRb///e+VlZXVlPUAALyEXQ8OqvX806KioqasAwAAW6g1cR47dkzz58//3temTZvWaAUBALyDTQNn7Y0zMDBQHTp0aMpaAABo9mptnJGRkYqPj2/KWgAAXsSuBwfVuo+TCx0AAPBdtSbOlJSUpqwDAOBlHLJn5LR0kXcAABqKx41qAQDAd5E4AQBGkDgBAPACJE4AgBEOm14BgcYJADCCUS0AAF6AxAkAMMKmk1oSJwAAVpA4AQBG2PV+nDROAIARHBwEAIAXIHECAIyw6aSWxAkAgBUkTgCAET42va0YiRMAAAtInAAAI+y6j5PGCQAwgtNRAADwAiROAIARdr1yEIkTAAALSJwAACNsGjhpnAAAMxjVAgDgBUicAAAjbBo4SZwAAFhB4gQAGGHX5EbjBAAY4bDprNauDR8AACNInAAAI+yZN0mcAABYQuIEABjBBRAAAPACJE4AgBH2zJs0TgCAITad1DKqBQDAChInAMAILoAAAIAXIHECAIywa3KjcQIAjGBUCwCAFyBxAgCMMJE3L1++rLS0NBUWFqqyslITJ07U9ddfr9mzZ8vX11c33nijnnnmGfn41J4raZwAAK+xceNGhYeHKzs7W8XFxYqPj9fPfvYzTZo0Sf369dNjjz2mDz74QAMGDKh1DRonAMAIE/s4hw4dqpiYGNdjX19fde3aVefPn5fT6VRZWZn8/OpujTROAIARjXGQTX5+vvLz812PExISlJCQ4HocEhIiSSotLVVycrKmTJkih8Ohp556SkuWLFHLli1155131rkNGicAwGN8u1F+n5MnT2rSpEkaM2aMYmNj1atXL7322mvq1KmTXnvtNc2dO1ezZ8+u9fM0TgCAESZGtefOndNDDz2kWbNmqVevXpKksLAwhYaGSpKuvfZa7d69u841aJwAAK+Rm5urkpISLV68WIsXL5YkPf3005o6dar8/PzUokULzZkzp841HE6n09kUxdbXpLf2mS4BAPB/Xozv2mhrr//kVIOvOaJ7mwZf89u4AAIAABYwqgUAGGHTK+7ROAEAZvgYuXbQD8eoFgAAC0icAAAj7DqqJXECAGABiRMAYITDpvs4aZwAACMY1QIA4AVInAAAIzgdBQAAL0DiBAAYYdd9nDROAIARdm2cjGoBALCAxAkAMMKu53GSOAEAsIDECQAwwseegZPGCQAwg1EtAABegMQJADCC01EAAPACJE4AgBHs4wQAwAuQOAEARnA6CgAAFjCqBQDAC5A4AQBG2PV0FBqnh3NIGtvzOl0b6i+nU1q1+4QckpJuvV5Op3SypEL5fz8lp+lCATf4XUZzQeP0cN2uC5Ukzd9+RJ0igzWqW5QkadNnZ3XgXLkSe7RR9+ta6u8nL5osE3CL32XPY9PASeP0dJ+cLNWnp0olSRHBLVRyqUo3tQnVgXPlkqTPTpfqp9eG8JcNmj1+lz2Pj01ntRwc5AVqnFLSrdfpge5R+vjElX+pXLpcoyA/X0OVAdbwu4zmgMTpJVZ9dFIbAs5oRv8O8vf917+XAlv46MvL1QYrA6zhd9lz2DNvNkLjTEpK0uXLl694zul0yuFwKC8vr6E3BzfuaNdK4UEt9F/7/6nKaqdqnE4dOf+lOkUG68C5cv1bVKj2ny0zXSbgFr/LaC4avHFOnz5dGRkZevHFF+Xry9jEtD0nLiqp5/Wa2vcG+fhIf9x7WqcuVmrMLW3k6+PQ6YuV+riQfUJo/vhd9kA2jZwOp9PZ4Edvv/TSS7rhhhs0ePBgy5+d9Na+hi4HAHCVXozv2mhr7zx4ocHXvPMnYQ2+5rc1yj7O3/zmN42xLAAAxnFwEADACJuejcLpKAAAWEHiBAAYYdPASeIEAMAKEicAwAybRk4aJwDACG5kDQCAFyBxAgCM4HQUAAC8AIkTAGCETQMnjRMAYIhNOyejWgAALCBxAgCM4HQUAAC8AIkTAGCEXU9HoXECAIywad9kVAsAgBUkTgCAGTaNnCROAAAsIHECAIzgdBQAALwAiRMAYASnowAAYIFN+yajWgAArCBxAgDMsGnkJHECAGABiRMAYIRdT0ehcQIAjOCoWgAAmrnLly8rLS1NhYWFqqys1MSJE9WjRw9lZGSopKRE1dXVev7559W+ffta16BxAgCMMBE4N27cqPDwcGVnZ6u4uFjx8fG66667FBsbq2HDhmnHjh06dOgQjRMAAEkaOnSoYmJiXI99fX21e/dudenSRePHj1fbtm2Vnp5e5xocVQsAMMPR8F/5+fkaOXKk6ys/P/+KTYaEhCg0NFSlpaVKTk7WlClTVFhYqFatWumVV17Rddddp+XLl9dZNokTAGBEYxxVm5CQoISEhDrfc/LkSU2aNEljxoxRbGys5s6dqwEDBkiSBgwYoJycnDo/T+IEAHiNc+fO6aGHHtKMGTN0//33S5JuvfVWbdu2TZK0a9cudezYsc41SJwAACNMnI6Sm5urkpISLV68WIsXL5YkzZ07VxkZGcrLy1NoaKheeOGFOtdwOJ1OZ1MUW1+T3tpnugQAwP95Mb5ro639j1PlDb5mlzbBDb7mt5E4AQBG2PT6B+zjBADAChInAMAMm0ZOGicAwAi7XuSdUS0AABaQOAEARtj17igkTgAALCBxAgCMsGngpHECAAyxaedkVAsAgAUkTgCAEZyOAgCAFyBxAgCMsOvpKDROAIARNu2bjGoBALCCxAkAMMOmkZPECQCABSROAIARnI4CAIAXIHECAIzgdBQAACywad9kVAsAgBUkTgCAEXYd1ZI4AQCwgMQJADDEnpGTxgkAMIJRLQAAXoDECQAwwqaBk8QJAIAVJE4AgBF23cdJ4wQAGMFF3gEA8AIkTgCAGfYMnCROAACsIHECAIywaeAkcQIAYAWJEwBgBKejAABgAaejAADgBUicAAAz7Bk4SZwAAFhB4gQAGGHTwEnjBACYYdejahnVAgBgAYkTAGAEp6MAAOAFSJwAACPYxwkAgBegcQIAYAGjWgCAEYxqAQDwAiROAIARnI4CAIAXIHECAIyw6z5OGicAwAib9k1GtQAAWEHiBACYYdPISeIEAMACEicAwAi7no5C4wQAGGHXo2oZ1QIAYAGJEwBghE0DJ4kTAAArSJwAADNsGjlpnAAAI+x6VC2jWgCA17h8+bJmzJihMWPG6P7779f777/vem3Tpk1KSEhwuwaJEwBghInTUTZu3Kjw8HBlZ2eruLhY8fHxGjhwoPbt26e1a9fK6XS6XYPECQDwGkOHDtXkyZNdj319fVVcXKx58+YpLS2tXms0u8T5YnxX0yUAAJpAYCN0oPz8fOXn57seJyQkXDF+DQkJkSSVlpYqOTlZkydPVnp6utLS0hQQEFCvbTic9cmlAAB4iJMnT2rSpEkaM2aMOnfurNTUVEVERKiiokJffPGFRo0apfT09Fo/T+MEAHiNc+fOKSkpSbNmzVKvXr2ueO348eOaNm2a3njjjTrXYB8nAMBr5ObmqqSkRIsXL1ZSUpKSkpJ06dIlS2uQOAEAsIDECQCABTROAAAsoHF6kZqaGs2aNUsJCQlKSkrSkSNHTJcEXLW///3vSkpKMl0GvFCzO48Tjee9995TZWWl8vPztWfPHs2dO1dLliwxXRZg2fLly7Vx40YFBQWZLgVeiMTpRT766CP17dtXktSjRw99+umnhisCrk779u31hz/8wXQZ8FI0Ti9SWlqq0NBQ12NfX19VVVUZrAi4OjExMfLzY2AGM2icXiQ0NFRlZWWuxzU1NfzlAwAW0Ti9SM+ePbV9+3ZJ0p49e9S5c2fDFQGA/RA3vMjgwYP117/+VYmJiXI6nXr22WdNlwQAtsOVgwAAsIBRLQAAFtA4AQCwgMYJAIAFNE4AACygcQIAYAGNE7a3c+dO9erVy3VT2tGjR2vVqlVXtda8efO0bt067du3T4sWLar1fQUFBTp9+nS91ty+fbueeOKJK547fvy4Ro8eXa/PN9Z7AVwdzuOER7jrrruUk5MjSaqsrNTQoUMVFxenVq1aXdV6Xbt2VdeuXWt9/T//8z+VmZmpqKioq1ofgH3ROOFxSktL5ePjI19fXyUlJal169YqKSnRsmXLlJmZqSNHjqimpkZTpkzRnXfeqT/96U9asmSJIiIidPnyZUVHR2vnzp3Ky8tTTk6O3nzzTb3++uuqqanRwIED1a1bN+3bt08pKSlas2aN8vPz9fbbb8vhcGjYsGH6xS9+oYMHDyotLU1BQUEKCgpSWFhYvWr/7//+b1fSvXTpkp577jm1aNFCRUVFeuSRR1RUVKR+/fpp0qRJOnnypGbOnKmKigoFBARozpw5V6yVk5OjHTt2qKamRsOHD9f48eMb+kcNeCUaJzzCjh07lJSUJIfDoRYtWmjmzJkKCQmRJMXGxmrw4MFas2aNWrdurWeffVbFxcUaN26cNm/erOzsbL355psKDw/XhAkTrlj3n//8p+sWVv7+/po7d65uv/12de3aVZmZmTp69KjeeecdrVmzRg6HQ+PHj1efPn20YMECJScnq3fv3lq2bJkOHTpUr+/jwIEDys7OVlRUlHJzc/Xuu+8qNjZW5eXlys7OVnBwsMaOHauBAwcqNzdXSUlJ6tevn/72t79p3rx5mjp1qmut9evXa/Xq1YqKitK6desa7ocNeDkaJzzCN0e139ahQwdJ0v79+/XRRx/pk08+kSRVVVXp3LlzCg0NVevWrSVJt9xyyxWfPXbsmDp16qTAwEBJUlpa2hWv79+/XydOnHCluQsXLujo0aM6cOCAunfvLumrawTXt3FGRUXpmWeeUXBwsE6fPq2ePXtKkn7605+qZcuWkqRu3brp8OHD2r9/v5YuXaqXXnpJTqdTLVq0uGKt+fPna/78+Tp37pzrdnIAfjgaJzyew+GQJEVHR6tNmzZ65JFHdOnSJS1ZskStWrXSxYsXVVRUpIiICO3du1dt2rRxfbZ9+/Y6dOiQKisr5e/vr+TkZKWnp8vhcMjpdCo6OlodO3bUSy+9JIfDoVdeeUWdO3dWdHS0Pv74Y919992W7nuakZGh9957T6GhoUpJSdHXV8Q8ePCgysrKFBAQoE8++UQJCQmKjo7WQw89pJ49e+rgwYPatWuXa53Kykq9++67mj9/vpxOp4YPH67hw4erbdu2DfRTBbwXjRNeIzExURkZGRo3bpxKS0s1ZswY+fv7KysrS7/+9a8VFhb2ndusRURE6Le//a3GjRsnh8Ohe+65R1FRUbrlllv0+OOPa+XKlerVq5cefPBBVVZWqnv37oqKitLs2bM1depUrVixQhEREQoICPhOPQcOHNDIkSNdj5944gnFxcVp9OjRatWqlSIjI3XmzBlJUlhYmKZOnaqioiINGzZMHTt2VEpKijIzM1VRUaFLly4pPT3dtZa/v7/CwsIUFxensLAw9e7dW9dff30j/WQB78JF3gEAsIDzOAEAsIDGCQCABTROAAAsoHECAGABjRMAAAtonAAAWEDjBADAAhonAAAW/H9fJgEroExCzgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 18:07:46,243]\u001B[0m A new study created in memory with name: no-name-7ea4964b-369b-447d-9e5f-cb31e1a8602f\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.80444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:08:15,226]\u001B[0m Trial 0 finished with value: 0.8044444444444444 and parameters: {'n_d': 18, 'n_a': 59, 'n_steps': 10, 'gamma': 1.4731116297531948, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.04692909852402033}. Best is trial 0 with value: 0.8044444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.88778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:08:47,873]\u001B[0m Trial 1 finished with value: 0.8877777777777777 and parameters: {'n_d': 45, 'n_a': 40, 'n_steps': 7, 'gamma': 1.2078286718840212, 'n_independent': 4, 'n_shared': 6, 'lambda_sparse': 0.03227957087938371}. Best is trial 1 with value: 0.8877777777777777.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.79042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:09:09,021]\u001B[0m Trial 2 finished with value: 0.7904166666666665 and parameters: {'n_d': 24, 'n_a': 61, 'n_steps': 12, 'gamma': 1.8590263193780672, 'n_independent': 3, 'n_shared': 6, 'lambda_sparse': 0.034454653067518444}. Best is trial 1 with value: 0.8877777777777777.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.78944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:09:49,497]\u001B[0m Trial 3 finished with value: 0.7894444444444444 and parameters: {'n_d': 19, 'n_a': 25, 'n_steps': 19, 'gamma': 1.9946082592437289, 'n_independent': 7, 'n_shared': 4, 'lambda_sparse': 0.055087427740039274}. Best is trial 1 with value: 0.8877777777777777.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.89389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:10:08,648]\u001B[0m Trial 4 finished with value: 0.8938888888888888 and parameters: {'n_d': 51, 'n_a': 39, 'n_steps': 5, 'gamma': 0.11332058674103457, 'n_independent': 9, 'n_shared': 4, 'lambda_sparse': 0.080582377293631}. Best is trial 4 with value: 0.8938888888888888.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.79472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:10:37,230]\u001B[0m Trial 5 finished with value: 0.7947222222222222 and parameters: {'n_d': 17, 'n_a': 27, 'n_steps': 17, 'gamma': 1.4582147877380274, 'n_independent': 3, 'n_shared': 5, 'lambda_sparse': 0.055227934484990644}. Best is trial 4 with value: 0.8938888888888888.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 46 and best_val_0_auc = 0.87306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:11:35,823]\u001B[0m Trial 6 finished with value: 0.8730555555555556 and parameters: {'n_d': 49, 'n_a': 58, 'n_steps': 9, 'gamma': 1.593349479583764, 'n_independent': 4, 'n_shared': 4, 'lambda_sparse': 0.07191562298347588}. Best is trial 4 with value: 0.8938888888888888.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_auc = 0.84389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:13:40,882]\u001B[0m Trial 7 finished with value: 0.8438888888888889 and parameters: {'n_d': 24, 'n_a': 53, 'n_steps': 17, 'gamma': 1.744230144912649, 'n_independent': 9, 'n_shared': 3, 'lambda_sparse': 0.031076439854505814}. Best is trial 4 with value: 0.8938888888888888.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.82639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:14:09,597]\u001B[0m Trial 8 finished with value: 0.8263888888888888 and parameters: {'n_d': 58, 'n_a': 32, 'n_steps': 10, 'gamma': 1.1887314838793626, 'n_independent': 8, 'n_shared': 3, 'lambda_sparse': 0.057466836002114594}. Best is trial 4 with value: 0.8938888888888888.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:14:22,108]\u001B[0m Trial 9 finished with value: 0.8794444444444444 and parameters: {'n_d': 26, 'n_a': 40, 'n_steps': 1, 'gamma': 1.8822032038079841, 'n_independent': 7, 'n_shared': 9, 'lambda_sparse': 0.03547970339273384}. Best is trial 4 with value: 0.8938888888888888.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.87944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:14:27,588]\u001B[0m Trial 10 finished with value: 0.8572222222222222 and parameters: {'n_d': 39, 'n_a': 16, 'n_steps': 2, 'gamma': 0.12988284156460483, 'n_independent': 1, 'n_shared': 9, 'lambda_sparse': 0.08009374044341298}. Best is trial 4 with value: 0.8938888888888888.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.85722\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.90722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:14:59,571]\u001B[0m Trial 11 finished with value: 0.9072222222222222 and parameters: {'n_d': 45, 'n_a': 44, 'n_steps': 5, 'gamma': 0.6209458316132812, 'n_independent': 5, 'n_shared': 7, 'lambda_sparse': 0.0103022909289196}. Best is trial 11 with value: 0.9072222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:15:31,415]\u001B[0m Trial 12 finished with value: 0.895 and parameters: {'n_d': 62, 'n_a': 45, 'n_steps': 5, 'gamma': 0.33153919211984473, 'n_independent': 6, 'n_shared': 7, 'lambda_sparse': 0.006681132009092629}. Best is trial 11 with value: 0.9072222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.89472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:16:14,747]\u001B[0m Trial 13 finished with value: 0.8947222222222223 and parameters: {'n_d': 60, 'n_a': 49, 'n_steps': 5, 'gamma': 0.5396582715579675, 'n_independent': 6, 'n_shared': 8, 'lambda_sparse': 0.001446163958114038}. Best is trial 11 with value: 0.9072222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.88167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:16:38,790]\u001B[0m Trial 14 finished with value: 0.8816666666666666 and parameters: {'n_d': 64, 'n_a': 47, 'n_steps': 5, 'gamma': 0.6789325572828783, 'n_independent': 5, 'n_shared': 7, 'lambda_sparse': 0.0011772638996399212}. Best is trial 11 with value: 0.9072222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.67556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:16:56,802]\u001B[0m Trial 15 finished with value: 0.6755555555555556 and parameters: {'n_d': 8, 'n_a': 12, 'n_steps': 13, 'gamma': 0.6852626793636136, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.01670316836529888}. Best is trial 11 with value: 0.9072222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:17:07,795]\u001B[0m Trial 16 finished with value: 0.88 and parameters: {'n_d': 35, 'n_a': 46, 'n_steps': 3, 'gamma': 0.4331713640416255, 'n_independent': 1, 'n_shared': 7, 'lambda_sparse': 0.014981239119919203}. Best is trial 11 with value: 0.9072222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.89306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:17:46,803]\u001B[0m Trial 17 finished with value: 0.8930555555555555 and parameters: {'n_d': 54, 'n_a': 33, 'n_steps': 7, 'gamma': 0.9578345166947553, 'n_independent': 5, 'n_shared': 7, 'lambda_sparse': 0.01338163187490175}. Best is trial 11 with value: 0.9072222222222222.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.4716  |  0:00:00s\n",
      "epoch 1  | loss: 1.0274  |  0:00:01s\n",
      "epoch 2  | loss: 0.8042  |  0:00:02s\n",
      "epoch 3  | loss: 0.78542 |  0:00:03s\n",
      "epoch 4  | loss: 0.7401  |  0:00:03s\n",
      "epoch 5  | loss: 0.70648 |  0:00:04s\n",
      "epoch 6  | loss: 0.69075 |  0:00:05s\n",
      "epoch 7  | loss: 0.68548 |  0:00:06s\n",
      "epoch 8  | loss: 0.65642 |  0:00:07s\n",
      "epoch 9  | loss: 0.65525 |  0:00:07s\n",
      "epoch 10 | loss: 0.63184 |  0:00:08s\n",
      "epoch 11 | loss: 0.62601 |  0:00:09s\n",
      "epoch 12 | loss: 0.62372 |  0:00:10s\n",
      "epoch 13 | loss: 0.61099 |  0:00:10s\n",
      "epoch 14 | loss: 0.61138 |  0:00:11s\n",
      "epoch 15 | loss: 0.61546 |  0:00:12s\n",
      "epoch 16 | loss: 0.5985  |  0:00:13s\n",
      "epoch 17 | loss: 0.60598 |  0:00:14s\n",
      "epoch 18 | loss: 0.61097 |  0:00:14s\n",
      "epoch 19 | loss: 0.60092 |  0:00:15s\n",
      "epoch 20 | loss: 0.59763 |  0:00:16s\n",
      "epoch 21 | loss: 0.59691 |  0:00:17s\n",
      "epoch 22 | loss: 0.60088 |  0:00:17s\n",
      "epoch 23 | loss: 0.59452 |  0:00:18s\n",
      "epoch 24 | loss: 0.59497 |  0:00:19s\n",
      "epoch 25 | loss: 0.5948  |  0:00:20s\n",
      "epoch 26 | loss: 0.59508 |  0:00:21s\n",
      "epoch 27 | loss: 0.59138 |  0:00:21s\n",
      "epoch 28 | loss: 0.59098 |  0:00:22s\n",
      "epoch 29 | loss: 0.58877 |  0:00:23s\n",
      "epoch 30 | loss: 0.5852  |  0:00:24s\n",
      "epoch 31 | loss: 0.59209 |  0:00:24s\n",
      "epoch 32 | loss: 0.59263 |  0:00:25s\n",
      "epoch 33 | loss: 0.5881  |  0:00:26s\n",
      "epoch 34 | loss: 0.58663 |  0:00:27s\n",
      "epoch 35 | loss: 0.58122 |  0:00:28s\n",
      "epoch 36 | loss: 0.58399 |  0:00:28s\n",
      "epoch 37 | loss: 0.57655 |  0:00:29s\n",
      "epoch 38 | loss: 0.57085 |  0:00:30s\n",
      "epoch 39 | loss: 0.57494 |  0:00:31s\n",
      "epoch 40 | loss: 0.5777  |  0:00:32s\n",
      "epoch 41 | loss: 0.56929 |  0:00:32s\n",
      "epoch 42 | loss: 0.57485 |  0:00:33s\n",
      "epoch 43 | loss: 0.57593 |  0:00:34s\n",
      "epoch 44 | loss: 0.56767 |  0:00:35s\n",
      "epoch 45 | loss: 0.57541 |  0:00:35s\n",
      "epoch 46 | loss: 0.5673  |  0:00:36s\n",
      "epoch 47 | loss: 0.57321 |  0:00:37s\n",
      "epoch 48 | loss: 0.57546 |  0:00:38s\n",
      "epoch 49 | loss: 0.56997 |  0:00:38s\n",
      "epoch 50 | loss: 0.56587 |  0:00:39s\n",
      "epoch 51 | loss: 0.56987 |  0:00:40s\n",
      "epoch 52 | loss: 0.56752 |  0:00:41s\n",
      "epoch 53 | loss: 0.55856 |  0:00:42s\n",
      "epoch 54 | loss: 0.56946 |  0:00:42s\n",
      "epoch 55 | loss: 0.56309 |  0:00:43s\n",
      "epoch 56 | loss: 0.56217 |  0:00:44s\n",
      "epoch 57 | loss: 0.56147 |  0:00:45s\n",
      "epoch 58 | loss: 0.56049 |  0:00:46s\n",
      "epoch 59 | loss: 0.55892 |  0:00:46s\n",
      "epoch 60 | loss: 0.5482  |  0:00:47s\n",
      "epoch 61 | loss: 0.55617 |  0:00:48s\n",
      "epoch 62 | loss: 0.54888 |  0:00:49s\n",
      "epoch 63 | loss: 0.54488 |  0:00:49s\n",
      "epoch 64 | loss: 0.55935 |  0:00:50s\n",
      "epoch 65 | loss: 0.54783 |  0:00:51s\n",
      "epoch 66 | loss: 0.54936 |  0:00:52s\n",
      "epoch 67 | loss: 0.54413 |  0:00:52s\n",
      "epoch 68 | loss: 0.54149 |  0:00:53s\n",
      "epoch 69 | loss: 0.54573 |  0:00:54s\n",
      "epoch 70 | loss: 0.55184 |  0:00:55s\n",
      "epoch 71 | loss: 0.55887 |  0:00:56s\n",
      "epoch 72 | loss: 0.5572  |  0:00:56s\n",
      "epoch 73 | loss: 0.5535  |  0:00:57s\n",
      "epoch 74 | loss: 0.55083 |  0:00:58s\n",
      "epoch 75 | loss: 0.56799 |  0:00:59s\n",
      "epoch 76 | loss: 0.56244 |  0:00:59s\n",
      "epoch 77 | loss: 0.56874 |  0:01:00s\n",
      "epoch 78 | loss: 0.54408 |  0:01:01s\n",
      "epoch 79 | loss: 0.55619 |  0:01:02s\n",
      "epoch 80 | loss: 0.54551 |  0:01:03s\n",
      "epoch 81 | loss: 0.54462 |  0:01:03s\n",
      "epoch 82 | loss: 0.54609 |  0:01:04s\n",
      "epoch 83 | loss: 0.53511 |  0:01:05s\n",
      "epoch 84 | loss: 0.55667 |  0:01:06s\n",
      "epoch 85 | loss: 0.55182 |  0:01:06s\n",
      "epoch 86 | loss: 0.54573 |  0:01:07s\n",
      "epoch 87 | loss: 0.54676 |  0:01:08s\n",
      "epoch 88 | loss: 0.54027 |  0:01:09s\n",
      "epoch 89 | loss: 0.53662 |  0:01:10s\n",
      "epoch 90 | loss: 0.53943 |  0:01:10s\n",
      "epoch 91 | loss: 0.53553 |  0:01:11s\n",
      "epoch 92 | loss: 0.51535 |  0:01:12s\n",
      "epoch 93 | loss: 0.53833 |  0:01:13s\n",
      "epoch 94 | loss: 0.54324 |  0:01:13s\n",
      "epoch 95 | loss: 0.53814 |  0:01:14s\n",
      "epoch 96 | loss: 0.53758 |  0:01:15s\n",
      "epoch 97 | loss: 0.53439 |  0:01:16s\n",
      "epoch 98 | loss: 0.53404 |  0:01:17s\n",
      "epoch 99 | loss: 0.53508 |  0:01:17s\n",
      "Eval TABNET\n",
      "Accuracy: 0.87\n",
      "Precision: 0.88\n",
      "Recall: 0.85\n",
      "F1-score: 0.86\n",
      "ROC-AUC score: 0.87\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 18:19:05,322]\u001B[0m A new study created in memory with name: no-name-71c7f650-8ceb-4c0b-9904-7d5f867e6c1b\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:19:08,876]\u001B[0m Trial 0 finished with value: 0.8508333333333333 and parameters: {'n_d': 43, 'n_a': 9, 'n_steps': 1, 'gamma': 0.20419317819151328, 'n_independent': 9, 'n_shared': 1, 'lambda_sparse': 0.07893728553292256}. Best is trial 0 with value: 0.8508333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.85083\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.86583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:19:29,402]\u001B[0m Trial 1 finished with value: 0.8658333333333333 and parameters: {'n_d': 49, 'n_a': 47, 'n_steps': 5, 'gamma': 0.7016490185583372, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.00024780377406875386}. Best is trial 1 with value: 0.8658333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.86917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:19:46,599]\u001B[0m Trial 2 finished with value: 0.8691666666666666 and parameters: {'n_d': 23, 'n_a': 63, 'n_steps': 7, 'gamma': 1.0981458870850958, 'n_independent': 3, 'n_shared': 7, 'lambda_sparse': 0.08520412874284468}. Best is trial 2 with value: 0.8691666666666666.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:21:56,017]\u001B[0m Trial 3 finished with value: 0.8674999999999999 and parameters: {'n_d': 19, 'n_a': 49, 'n_steps': 17, 'gamma': 1.8345005385078155, 'n_independent': 5, 'n_shared': 10, 'lambda_sparse': 0.020982623638165727}. Best is trial 2 with value: 0.8691666666666666.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:22:43,358]\u001B[0m Trial 4 finished with value: 0.8825000000000001 and parameters: {'n_d': 46, 'n_a': 37, 'n_steps': 11, 'gamma': 0.5283681890827683, 'n_independent': 8, 'n_shared': 3, 'lambda_sparse': 0.0645572665107956}. Best is trial 4 with value: 0.8825000000000001.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.85972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:22:59,268]\u001B[0m Trial 5 finished with value: 0.8597222222222223 and parameters: {'n_d': 28, 'n_a': 44, 'n_steps': 5, 'gamma': 0.2599680568234681, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.04062464667717183}. Best is trial 4 with value: 0.8825000000000001.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.87694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:23:13,438]\u001B[0m Trial 6 finished with value: 0.8769444444444444 and parameters: {'n_d': 21, 'n_a': 49, 'n_steps': 4, 'gamma': 1.209642241027965, 'n_independent': 9, 'n_shared': 4, 'lambda_sparse': 0.017024785287649245}. Best is trial 4 with value: 0.8825000000000001.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:23:20,747]\u001B[0m Trial 7 finished with value: 0.8900000000000001 and parameters: {'n_d': 20, 'n_a': 36, 'n_steps': 1, 'gamma': 1.4091730981127908, 'n_independent': 10, 'n_shared': 9, 'lambda_sparse': 0.08836729974665411}. Best is trial 7 with value: 0.8900000000000001.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.89\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.8725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:23:53,718]\u001B[0m Trial 8 finished with value: 0.8725 and parameters: {'n_d': 63, 'n_a': 14, 'n_steps': 6, 'gamma': 1.7521124082192219, 'n_independent': 9, 'n_shared': 7, 'lambda_sparse': 0.032198094042801884}. Best is trial 7 with value: 0.8900000000000001.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:24:54,069]\u001B[0m Trial 9 finished with value: 0.865 and parameters: {'n_d': 50, 'n_a': 63, 'n_steps': 10, 'gamma': 0.8374109909009604, 'n_independent': 2, 'n_shared': 10, 'lambda_sparse': 0.0491052090339259}. Best is trial 7 with value: 0.8900000000000001.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.85361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:26:24,144]\u001B[0m Trial 10 finished with value: 0.8536111111111112 and parameters: {'n_d': 10, 'n_a': 30, 'n_steps': 19, 'gamma': 1.3938382914759826, 'n_independent': 5, 'n_shared': 8, 'lambda_sparse': 0.09674951974701686}. Best is trial 7 with value: 0.8900000000000001.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.86778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:27:00,539]\u001B[0m Trial 11 finished with value: 0.8677777777777778 and parameters: {'n_d': 36, 'n_a': 26, 'n_steps': 14, 'gamma': 0.5713867188784678, 'n_independent': 7, 'n_shared': 3, 'lambda_sparse': 0.06396530826263368}. Best is trial 7 with value: 0.8900000000000001.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.88639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:27:48,919]\u001B[0m Trial 12 finished with value: 0.8863888888888889 and parameters: {'n_d': 9, 'n_a': 35, 'n_steps': 11, 'gamma': 1.488700619160914, 'n_independent': 7, 'n_shared': 4, 'lambda_sparse': 0.06332611337248094}. Best is trial 7 with value: 0.8900000000000001.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.89167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:28:24,996]\u001B[0m Trial 13 finished with value: 0.8916666666666667 and parameters: {'n_d': 8, 'n_a': 22, 'n_steps': 10, 'gamma': 1.5233367540086389, 'n_independent': 6, 'n_shared': 5, 'lambda_sparse': 0.061974006484449416}. Best is trial 13 with value: 0.8916666666666667.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:28:27,552]\u001B[0m Trial 14 finished with value: 0.8783333333333334 and parameters: {'n_d': 16, 'n_a': 21, 'n_steps': 1, 'gamma': 1.9887717751878924, 'n_independent': 4, 'n_shared': 5, 'lambda_sparse': 0.09566828085256046}. Best is trial 13 with value: 0.8916666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.87833\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.89111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:28:57,751]\u001B[0m Trial 15 finished with value: 0.8911111111111111 and parameters: {'n_d': 30, 'n_a': 21, 'n_steps': 14, 'gamma': 1.568804172965387, 'n_independent': 1, 'n_shared': 9, 'lambda_sparse': 0.07853253483808229}. Best is trial 13 with value: 0.8916666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.91139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:29:22,942]\u001B[0m Trial 16 finished with value: 0.9113888888888889 and parameters: {'n_d': 32, 'n_a': 19, 'n_steps': 14, 'gamma': 1.5882497698187312, 'n_independent': 1, 'n_shared': 6, 'lambda_sparse': 0.07436178591014067}. Best is trial 16 with value: 0.9113888888888889.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.7719  |  0:00:00s\n",
      "epoch 1  | loss: 1.46712 |  0:00:01s\n",
      "epoch 2  | loss: 1.38483 |  0:00:02s\n",
      "epoch 3  | loss: 1.26699 |  0:00:03s\n",
      "epoch 4  | loss: 1.13765 |  0:00:04s\n",
      "epoch 5  | loss: 0.99426 |  0:00:05s\n",
      "epoch 6  | loss: 0.93184 |  0:00:06s\n",
      "epoch 7  | loss: 1.04956 |  0:00:06s\n",
      "epoch 8  | loss: 2.19818 |  0:00:07s\n",
      "epoch 9  | loss: 1.22096 |  0:00:08s\n",
      "epoch 10 | loss: 1.57292 |  0:00:09s\n",
      "epoch 11 | loss: 1.06579 |  0:00:10s\n",
      "epoch 12 | loss: 1.19207 |  0:00:11s\n",
      "epoch 13 | loss: 1.2934  |  0:00:12s\n",
      "epoch 14 | loss: 1.07942 |  0:00:13s\n",
      "epoch 15 | loss: 2.36614 |  0:00:14s\n",
      "epoch 16 | loss: 1.81351 |  0:00:15s\n",
      "epoch 17 | loss: 1.30054 |  0:00:16s\n",
      "epoch 18 | loss: 3.65919 |  0:00:17s\n",
      "epoch 19 | loss: 4.09402 |  0:00:18s\n",
      "epoch 20 | loss: 1.83097 |  0:00:19s\n",
      "epoch 21 | loss: 1.74255 |  0:00:20s\n",
      "epoch 22 | loss: 3.78546 |  0:00:20s\n",
      "epoch 23 | loss: 4.04328 |  0:00:21s\n",
      "epoch 24 | loss: 3.45779 |  0:00:22s\n",
      "epoch 25 | loss: 2.58918 |  0:00:23s\n",
      "epoch 26 | loss: 1.27774 |  0:00:24s\n",
      "epoch 27 | loss: 0.85234 |  0:00:25s\n",
      "epoch 28 | loss: 0.818   |  0:00:26s\n",
      "epoch 29 | loss: 0.95961 |  0:00:27s\n",
      "epoch 30 | loss: 0.81519 |  0:00:28s\n",
      "epoch 31 | loss: 0.6953  |  0:00:29s\n",
      "epoch 32 | loss: 0.66346 |  0:00:30s\n",
      "epoch 33 | loss: 0.653   |  0:00:31s\n",
      "epoch 34 | loss: 0.64241 |  0:00:31s\n",
      "epoch 35 | loss: 0.69663 |  0:00:32s\n",
      "epoch 36 | loss: 0.77676 |  0:00:33s\n",
      "epoch 37 | loss: 0.95015 |  0:00:34s\n",
      "epoch 38 | loss: 0.82616 |  0:00:35s\n",
      "epoch 39 | loss: 1.14132 |  0:00:36s\n",
      "epoch 40 | loss: 0.89038 |  0:00:37s\n",
      "epoch 41 | loss: 0.70155 |  0:00:38s\n",
      "epoch 42 | loss: 0.65979 |  0:00:39s\n",
      "epoch 43 | loss: 0.65713 |  0:00:40s\n",
      "epoch 44 | loss: 0.65074 |  0:00:41s\n",
      "epoch 45 | loss: 0.65359 |  0:00:42s\n",
      "epoch 46 | loss: 0.66238 |  0:00:43s\n",
      "epoch 47 | loss: 0.70431 |  0:00:43s\n",
      "epoch 48 | loss: 0.78781 |  0:00:44s\n",
      "epoch 49 | loss: 0.64979 |  0:00:45s\n",
      "epoch 50 | loss: 0.6727  |  0:00:46s\n",
      "epoch 51 | loss: 0.64184 |  0:00:47s\n",
      "epoch 52 | loss: 0.64621 |  0:00:48s\n",
      "epoch 53 | loss: 0.63187 |  0:00:49s\n",
      "epoch 54 | loss: 0.62812 |  0:00:50s\n",
      "epoch 55 | loss: 0.62767 |  0:00:51s\n",
      "epoch 56 | loss: 0.62607 |  0:00:52s\n",
      "epoch 57 | loss: 0.63072 |  0:00:53s\n",
      "epoch 58 | loss: 0.63358 |  0:00:54s\n",
      "epoch 59 | loss: 0.61447 |  0:00:55s\n",
      "epoch 60 | loss: 0.62644 |  0:00:55s\n",
      "epoch 61 | loss: 0.67355 |  0:00:56s\n",
      "epoch 62 | loss: 0.63095 |  0:00:57s\n",
      "epoch 63 | loss: 0.71959 |  0:00:58s\n",
      "epoch 64 | loss: 0.67133 |  0:00:59s\n",
      "epoch 65 | loss: 0.6397  |  0:01:00s\n",
      "epoch 66 | loss: 0.70164 |  0:01:01s\n",
      "epoch 67 | loss: 0.70844 |  0:01:02s\n",
      "epoch 68 | loss: 0.64139 |  0:01:03s\n",
      "epoch 69 | loss: 0.62006 |  0:01:04s\n",
      "epoch 70 | loss: 0.64878 |  0:01:05s\n",
      "epoch 71 | loss: 0.61985 |  0:01:06s\n",
      "epoch 72 | loss: 0.62467 |  0:01:06s\n",
      "epoch 73 | loss: 0.63551 |  0:01:07s\n",
      "epoch 74 | loss: 0.63219 |  0:01:08s\n",
      "epoch 75 | loss: 0.62313 |  0:01:09s\n",
      "epoch 76 | loss: 0.6285  |  0:01:10s\n",
      "epoch 77 | loss: 0.63594 |  0:01:11s\n",
      "epoch 78 | loss: 0.62717 |  0:01:12s\n",
      "epoch 79 | loss: 0.62021 |  0:01:13s\n",
      "epoch 80 | loss: 0.61887 |  0:01:14s\n",
      "epoch 81 | loss: 0.61345 |  0:01:15s\n",
      "epoch 82 | loss: 0.62129 |  0:01:16s\n",
      "epoch 83 | loss: 0.62054 |  0:01:17s\n",
      "epoch 84 | loss: 0.61651 |  0:01:18s\n",
      "epoch 85 | loss: 0.60921 |  0:01:18s\n",
      "epoch 86 | loss: 0.60867 |  0:01:19s\n",
      "epoch 87 | loss: 0.61192 |  0:01:20s\n",
      "epoch 88 | loss: 0.607   |  0:01:21s\n",
      "epoch 89 | loss: 0.62015 |  0:01:22s\n",
      "epoch 90 | loss: 0.61408 |  0:01:23s\n",
      "epoch 91 | loss: 0.61276 |  0:01:24s\n",
      "epoch 92 | loss: 0.61351 |  0:01:25s\n",
      "epoch 93 | loss: 0.60629 |  0:01:26s\n",
      "epoch 94 | loss: 0.60387 |  0:01:27s\n",
      "epoch 95 | loss: 0.6034  |  0:01:28s\n",
      "epoch 96 | loss: 0.60767 |  0:01:29s\n",
      "epoch 97 | loss: 0.60253 |  0:01:29s\n",
      "epoch 98 | loss: 0.59635 |  0:01:30s\n",
      "epoch 99 | loss: 0.60368 |  0:01:31s\n",
      "Eval TABNET\n",
      "Accuracy: 0.78\n",
      "Precision: 0.76\n",
      "Recall: 0.8\n",
      "F1-score: 0.78\n",
      "ROC-AUC score: 0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 18:30:55,485]\u001B[0m A new study created in memory with name: no-name-3e22453d-ef20-46ff-8631-e72f5a281bb3\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.94056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:31:09,648]\u001B[0m Trial 0 finished with value: 0.9405555555555557 and parameters: {'n_d': 12, 'n_a': 19, 'n_steps': 15, 'gamma': 0.31295338909885334, 'n_independent': 3, 'n_shared': 3, 'lambda_sparse': 0.014734381494363562}. Best is trial 0 with value: 0.9405555555555557.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.87778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:32:44,569]\u001B[0m Trial 1 finished with value: 0.8777777777777778 and parameters: {'n_d': 34, 'n_a': 33, 'n_steps': 17, 'gamma': 1.8368892567086597, 'n_independent': 8, 'n_shared': 6, 'lambda_sparse': 0.009542680243036492}. Best is trial 0 with value: 0.9405555555555557.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.87194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:33:24,641]\u001B[0m Trial 2 finished with value: 0.8719444444444444 and parameters: {'n_d': 53, 'n_a': 64, 'n_steps': 13, 'gamma': 1.0789458305072364, 'n_independent': 1, 'n_shared': 9, 'lambda_sparse': 0.08992385102155122}. Best is trial 0 with value: 0.9405555555555557.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.94389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:33:47,301]\u001B[0m Trial 3 finished with value: 0.9438888888888888 and parameters: {'n_d': 25, 'n_a': 36, 'n_steps': 5, 'gamma': 1.83518749409181, 'n_independent': 9, 'n_shared': 1, 'lambda_sparse': 0.06968788808793423}. Best is trial 3 with value: 0.9438888888888888.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_auc = 0.96083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:34:53,268]\u001B[0m Trial 4 finished with value: 0.9608333333333334 and parameters: {'n_d': 40, 'n_a': 53, 'n_steps': 8, 'gamma': 0.692151557985821, 'n_independent': 8, 'n_shared': 6, 'lambda_sparse': 0.08181760229743347}. Best is trial 4 with value: 0.9608333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.89583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:35:24,974]\u001B[0m Trial 5 finished with value: 0.8958333333333334 and parameters: {'n_d': 46, 'n_a': 38, 'n_steps': 15, 'gamma': 1.1672683455580715, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.02160071003368606}. Best is trial 4 with value: 0.9608333333333334.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:35:27,434]\u001B[0m Trial 6 finished with value: 0.9369444444444444 and parameters: {'n_d': 17, 'n_a': 11, 'n_steps': 4, 'gamma': 0.421393440969159, 'n_independent': 3, 'n_shared': 2, 'lambda_sparse': 0.048061409782677124}. Best is trial 4 with value: 0.9608333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.93694\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.93694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:35:45,494]\u001B[0m Trial 7 finished with value: 0.9369444444444444 and parameters: {'n_d': 48, 'n_a': 61, 'n_steps': 1, 'gamma': 0.10886406155129949, 'n_independent': 8, 'n_shared': 8, 'lambda_sparse': 0.03867900462504645}. Best is trial 4 with value: 0.9608333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.90833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:36:23,698]\u001B[0m Trial 8 finished with value: 0.9083333333333333 and parameters: {'n_d': 62, 'n_a': 29, 'n_steps': 5, 'gamma': 1.0857890495581093, 'n_independent': 9, 'n_shared': 5, 'lambda_sparse': 0.09084190120287326}. Best is trial 4 with value: 0.9608333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.93889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:36:53,283]\u001B[0m Trial 9 finished with value: 0.9388888888888889 and parameters: {'n_d': 13, 'n_a': 64, 'n_steps': 15, 'gamma': 0.19906131572284708, 'n_independent': 3, 'n_shared': 6, 'lambda_sparse': 0.051429040893166515}. Best is trial 4 with value: 0.9608333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.94167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:38:08,740]\u001B[0m Trial 10 finished with value: 0.9416666666666667 and parameters: {'n_d': 35, 'n_a': 48, 'n_steps': 9, 'gamma': 0.6908338839739591, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.07310751002616223}. Best is trial 4 with value: 0.9608333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.87056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:38:47,949]\u001B[0m Trial 11 finished with value: 0.8705555555555556 and parameters: {'n_d': 25, 'n_a': 48, 'n_steps': 8, 'gamma': 1.9857002183391401, 'n_independent': 10, 'n_shared': 4, 'lambda_sparse': 0.06990695668443972}. Best is trial 4 with value: 0.9608333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.93694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:39:15,791]\u001B[0m Trial 12 finished with value: 0.9369444444444444 and parameters: {'n_d': 25, 'n_a': 48, 'n_steps': 6, 'gamma': 1.533288572122078, 'n_independent': 8, 'n_shared': 7, 'lambda_sparse': 0.07153891540389169}. Best is trial 4 with value: 0.9608333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.93611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:40:24,288]\u001B[0m Trial 13 finished with value: 0.9361111111111111 and parameters: {'n_d': 26, 'n_a': 41, 'n_steps': 11, 'gamma': 0.7763912224848648, 'n_independent': 10, 'n_shared': 4, 'lambda_sparse': 0.09654998422673117}. Best is trial 4 with value: 0.9608333333333334.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:40:31,922]\u001B[0m Trial 14 finished with value: 0.9230555555555555 and parameters: {'n_d': 41, 'n_a': 28, 'n_steps': 1, 'gamma': 1.5073595613480966, 'n_independent': 7, 'n_shared': 1, 'lambda_sparse': 0.08030360090855962}. Best is trial 4 with value: 0.9608333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_auc = 0.92306\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.94194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:41:05,241]\u001B[0m Trial 15 finished with value: 0.9419444444444445 and parameters: {'n_d': 29, 'n_a': 55, 'n_steps': 7, 'gamma': 0.7453174398222433, 'n_independent': 5, 'n_shared': 7, 'lambda_sparse': 0.06125795682181234}. Best is trial 4 with value: 0.9608333333333334.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.7165  |  0:00:01s\n",
      "epoch 1  | loss: 1.37187 |  0:00:02s\n",
      "epoch 2  | loss: 1.21483 |  0:00:04s\n",
      "epoch 3  | loss: 1.00427 |  0:00:05s\n",
      "epoch 4  | loss: 1.0022  |  0:00:07s\n",
      "epoch 5  | loss: 0.92484 |  0:00:08s\n",
      "epoch 6  | loss: 0.91546 |  0:00:09s\n",
      "epoch 7  | loss: 0.87419 |  0:00:11s\n",
      "epoch 8  | loss: 0.85725 |  0:00:12s\n",
      "epoch 9  | loss: 0.89277 |  0:00:14s\n",
      "epoch 10 | loss: 0.93791 |  0:00:15s\n",
      "epoch 11 | loss: 0.82454 |  0:00:17s\n",
      "epoch 12 | loss: 0.82228 |  0:00:18s\n",
      "epoch 13 | loss: 0.81025 |  0:00:20s\n",
      "epoch 14 | loss: 0.77638 |  0:00:21s\n",
      "epoch 15 | loss: 0.76601 |  0:00:23s\n",
      "epoch 16 | loss: 0.75691 |  0:00:24s\n",
      "epoch 17 | loss: 0.74611 |  0:00:26s\n",
      "epoch 18 | loss: 0.74118 |  0:00:27s\n",
      "epoch 19 | loss: 0.7358  |  0:00:28s\n",
      "epoch 20 | loss: 0.723   |  0:00:30s\n",
      "epoch 21 | loss: 0.72842 |  0:00:31s\n",
      "epoch 22 | loss: 0.71055 |  0:00:33s\n",
      "epoch 23 | loss: 0.72263 |  0:00:34s\n",
      "epoch 24 | loss: 0.7103  |  0:00:36s\n",
      "epoch 25 | loss: 0.71616 |  0:00:37s\n",
      "epoch 26 | loss: 0.70694 |  0:00:39s\n",
      "epoch 27 | loss: 0.70366 |  0:00:40s\n",
      "epoch 28 | loss: 0.69842 |  0:00:41s\n",
      "epoch 29 | loss: 0.69063 |  0:00:43s\n",
      "epoch 30 | loss: 0.68942 |  0:00:45s\n",
      "epoch 31 | loss: 0.69681 |  0:00:46s\n",
      "epoch 32 | loss: 0.69774 |  0:00:47s\n",
      "epoch 33 | loss: 0.69211 |  0:00:49s\n",
      "epoch 34 | loss: 0.69147 |  0:00:50s\n",
      "epoch 35 | loss: 0.68989 |  0:00:52s\n",
      "epoch 36 | loss: 0.68326 |  0:00:53s\n",
      "epoch 37 | loss: 0.68265 |  0:00:55s\n",
      "epoch 38 | loss: 0.67514 |  0:00:56s\n",
      "epoch 39 | loss: 0.66612 |  0:00:57s\n",
      "epoch 40 | loss: 0.66216 |  0:00:59s\n",
      "epoch 41 | loss: 0.65101 |  0:01:00s\n",
      "epoch 42 | loss: 0.65546 |  0:01:02s\n",
      "epoch 43 | loss: 0.65908 |  0:01:03s\n",
      "epoch 44 | loss: 0.66258 |  0:01:05s\n",
      "epoch 45 | loss: 0.64941 |  0:01:06s\n",
      "epoch 46 | loss: 0.64118 |  0:01:07s\n",
      "epoch 47 | loss: 0.63165 |  0:01:09s\n",
      "epoch 48 | loss: 0.63218 |  0:01:10s\n",
      "epoch 49 | loss: 0.63824 |  0:01:12s\n",
      "epoch 50 | loss: 0.63746 |  0:01:13s\n",
      "epoch 51 | loss: 0.63306 |  0:01:14s\n",
      "epoch 52 | loss: 0.63432 |  0:01:16s\n",
      "epoch 53 | loss: 0.62691 |  0:01:17s\n",
      "epoch 54 | loss: 0.63589 |  0:01:19s\n",
      "epoch 55 | loss: 0.62355 |  0:01:20s\n",
      "epoch 56 | loss: 0.62146 |  0:01:22s\n",
      "epoch 57 | loss: 0.62309 |  0:01:23s\n",
      "epoch 58 | loss: 0.63158 |  0:01:24s\n",
      "epoch 59 | loss: 0.63159 |  0:01:26s\n",
      "epoch 60 | loss: 0.61358 |  0:01:27s\n",
      "epoch 61 | loss: 0.61626 |  0:01:29s\n",
      "epoch 62 | loss: 0.62066 |  0:01:30s\n",
      "epoch 63 | loss: 0.6096  |  0:01:31s\n",
      "epoch 64 | loss: 0.60964 |  0:01:33s\n",
      "epoch 65 | loss: 0.60627 |  0:01:34s\n",
      "epoch 66 | loss: 0.61172 |  0:01:36s\n",
      "epoch 67 | loss: 0.6073  |  0:01:37s\n",
      "epoch 68 | loss: 0.61259 |  0:01:39s\n",
      "epoch 69 | loss: 0.59953 |  0:01:40s\n",
      "epoch 70 | loss: 0.58762 |  0:01:41s\n",
      "epoch 71 | loss: 0.5971  |  0:01:43s\n",
      "epoch 72 | loss: 0.57786 |  0:01:44s\n",
      "epoch 73 | loss: 0.5797  |  0:01:46s\n",
      "epoch 74 | loss: 0.5821  |  0:01:47s\n",
      "epoch 75 | loss: 0.56983 |  0:01:49s\n",
      "epoch 76 | loss: 0.57058 |  0:01:50s\n",
      "epoch 77 | loss: 0.58644 |  0:01:51s\n",
      "epoch 78 | loss: 0.56603 |  0:01:53s\n",
      "epoch 79 | loss: 0.57234 |  0:01:54s\n",
      "epoch 80 | loss: 0.57184 |  0:01:56s\n",
      "epoch 81 | loss: 0.55829 |  0:01:57s\n",
      "epoch 82 | loss: 0.56806 |  0:01:58s\n",
      "epoch 83 | loss: 0.57125 |  0:02:00s\n",
      "epoch 84 | loss: 0.55574 |  0:02:01s\n",
      "epoch 85 | loss: 0.5615  |  0:02:03s\n",
      "epoch 86 | loss: 0.56199 |  0:02:04s\n",
      "epoch 87 | loss: 0.5501  |  0:02:05s\n",
      "epoch 88 | loss: 0.5575  |  0:02:07s\n",
      "epoch 89 | loss: 0.56446 |  0:02:08s\n",
      "epoch 90 | loss: 0.56512 |  0:02:10s\n",
      "epoch 91 | loss: 0.54595 |  0:02:11s\n",
      "epoch 92 | loss: 0.55124 |  0:02:13s\n",
      "epoch 93 | loss: 0.5419  |  0:02:14s\n",
      "epoch 94 | loss: 0.52957 |  0:02:15s\n",
      "epoch 95 | loss: 0.5214  |  0:02:17s\n",
      "epoch 96 | loss: 0.51276 |  0:02:18s\n",
      "epoch 97 | loss: 0.51955 |  0:02:20s\n",
      "epoch 98 | loss: 0.50493 |  0:02:21s\n",
      "epoch 99 | loss: 0.49136 |  0:02:23s\n",
      "Eval TABNET\n",
      "Accuracy: 0.83\n",
      "Precision: 0.82\n",
      "Recall: 0.85\n",
      "F1-score: 0.84\n",
      "ROC-AUC score: 0.83\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 18:43:29,335]\u001B[0m A new study created in memory with name: no-name-32b6793f-43b0-4328-8e55-1bdc8da2a136\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.57139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:43:51,208]\u001B[0m Trial 0 finished with value: 0.571388888888889 and parameters: {'n_d': 46, 'n_a': 31, 'n_steps': 15, 'gamma': 0.28130749922527337, 'n_independent': 1, 'n_shared': 8, 'lambda_sparse': 0.05388925433191993}. Best is trial 0 with value: 0.571388888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.55083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:43:57,452]\u001B[0m Trial 1 finished with value: 0.5508333333333333 and parameters: {'n_d': 45, 'n_a': 23, 'n_steps': 5, 'gamma': 0.8278061925834442, 'n_independent': 6, 'n_shared': 2, 'lambda_sparse': 0.08361623022831233}. Best is trial 0 with value: 0.571388888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.58583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:44:04,102]\u001B[0m Trial 2 finished with value: 0.5858333333333334 and parameters: {'n_d': 56, 'n_a': 59, 'n_steps': 3, 'gamma': 1.3423806135669767, 'n_independent': 3, 'n_shared': 7, 'lambda_sparse': 0.02030158419825036}. Best is trial 2 with value: 0.5858333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.52264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:44:19,023]\u001B[0m Trial 3 finished with value: 0.5226388888888889 and parameters: {'n_d': 50, 'n_a': 40, 'n_steps': 6, 'gamma': 1.3603648666134596, 'n_independent': 10, 'n_shared': 6, 'lambda_sparse': 0.07701896134527722}. Best is trial 2 with value: 0.5858333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.60389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:44:32,540]\u001B[0m Trial 4 finished with value: 0.6038888888888889 and parameters: {'n_d': 64, 'n_a': 14, 'n_steps': 7, 'gamma': 0.5112573945845017, 'n_independent': 7, 'n_shared': 1, 'lambda_sparse': 0.016284658606051973}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.57764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:45:15,032]\u001B[0m Trial 5 finished with value: 0.5776388888888888 and parameters: {'n_d': 62, 'n_a': 16, 'n_steps': 16, 'gamma': 1.946584979660881, 'n_independent': 6, 'n_shared': 9, 'lambda_sparse': 0.006544422762800102}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.56944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:45:30,280]\u001B[0m Trial 6 finished with value: 0.5694444444444444 and parameters: {'n_d': 62, 'n_a': 29, 'n_steps': 10, 'gamma': 0.27491162976339034, 'n_independent': 4, 'n_shared': 1, 'lambda_sparse': 0.020906866475408858}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:45:33,970]\u001B[0m Trial 7 finished with value: 0.565 and parameters: {'n_d': 25, 'n_a': 21, 'n_steps': 3, 'gamma': 1.9345168589332316, 'n_independent': 9, 'n_shared': 1, 'lambda_sparse': 0.07302517549575488}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.565\n",
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.53889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:45:57,562]\u001B[0m Trial 8 finished with value: 0.538888888888889 and parameters: {'n_d': 48, 'n_a': 60, 'n_steps': 6, 'gamma': 1.9891234393967245, 'n_independent': 7, 'n_shared': 8, 'lambda_sparse': 0.0041707672043116385}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:46:00,310]\u001B[0m Trial 9 finished with value: 0.5540277777777778 and parameters: {'n_d': 13, 'n_a': 29, 'n_steps': 1, 'gamma': 1.3336212161740473, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.06636802063013066}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.55403\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.55167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:46:12,338]\u001B[0m Trial 10 finished with value: 0.5516666666666666 and parameters: {'n_d': 27, 'n_a': 8, 'n_steps': 10, 'gamma': 0.6486253392514066, 'n_independent': 8, 'n_shared': 4, 'lambda_sparse': 0.09853292237468689}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.53986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:46:26,278]\u001B[0m Trial 11 finished with value: 0.5398611111111111 and parameters: {'n_d': 63, 'n_a': 63, 'n_steps': 8, 'gamma': 1.1582640307779934, 'n_independent': 3, 'n_shared': 5, 'lambda_sparse': 0.030952009160934504}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.57833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:46:30,611]\u001B[0m Trial 12 finished with value: 0.5783333333333334 and parameters: {'n_d': 55, 'n_a': 47, 'n_steps': 2, 'gamma': 0.5916927371360398, 'n_independent': 4, 'n_shared': 6, 'lambda_sparse': 0.03391574722836357}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.56972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:46:34,152]\u001B[0m Trial 13 finished with value: 0.5697222222222221 and parameters: {'n_d': 36, 'n_a': 51, 'n_steps': 4, 'gamma': 0.1394834290916782, 'n_independent': 2, 'n_shared': 3, 'lambda_sparse': 0.02122891941472547}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.58444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:46:58,544]\u001B[0m Trial 14 finished with value: 0.5844444444444444 and parameters: {'n_d': 55, 'n_a': 42, 'n_steps': 13, 'gamma': 0.9338429883366395, 'n_independent': 4, 'n_shared': 7, 'lambda_sparse': 0.04769376319542458}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.58208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:47:50,635]\u001B[0m Trial 15 finished with value: 0.5820833333333334 and parameters: {'n_d': 37, 'n_a': 54, 'n_steps': 19, 'gamma': 1.5912474765034055, 'n_independent': 8, 'n_shared': 4, 'lambda_sparse': 0.0014082929349637369}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.57028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:48:11,483]\u001B[0m Trial 16 finished with value: 0.5702777777777778 and parameters: {'n_d': 55, 'n_a': 8, 'n_steps': 8, 'gamma': 1.0444497173616762, 'n_independent': 5, 'n_shared': 7, 'lambda_sparse': 0.01638600132624473}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.59361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:48:19,797]\u001B[0m Trial 17 finished with value: 0.5936111111111111 and parameters: {'n_d': 64, 'n_a': 38, 'n_steps': 8, 'gamma': 0.5727874759993083, 'n_independent': 1, 'n_shared': 3, 'lambda_sparse': 0.03666468203410924}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.56611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:48:25,722]\u001B[0m Trial 18 finished with value: 0.566111111111111 and parameters: {'n_d': 8, 'n_a': 34, 'n_steps': 12, 'gamma': 0.4916383247025955, 'n_independent': 1, 'n_shared': 2, 'lambda_sparse': 0.037642538072963305}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.55722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:48:41,264]\u001B[0m Trial 19 finished with value: 0.5572222222222222 and parameters: {'n_d': 37, 'n_a': 16, 'n_steps': 7, 'gamma': 0.7708107665521582, 'n_independent': 8, 'n_shared': 3, 'lambda_sparse': 0.04310103329227731}. Best is trial 4 with value: 0.6038888888888889.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.60861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:49:10,241]\u001B[0m Trial 20 finished with value: 0.6086111111111112 and parameters: {'n_d': 42, 'n_a': 39, 'n_steps': 10, 'gamma': 0.4078202882036803, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.05506183642113253}. Best is trial 20 with value: 0.6086111111111112.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.67028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:49:30,229]\u001B[0m Trial 21 finished with value: 0.6702777777777778 and parameters: {'n_d': 24, 'n_a': 40, 'n_steps': 10, 'gamma': 0.4510539605060807, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.05669157129773306}. Best is trial 21 with value: 0.6702777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.55681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:49:51,080]\u001B[0m Trial 22 finished with value: 0.5568055555555556 and parameters: {'n_d': 21, 'n_a': 45, 'n_steps': 10, 'gamma': 0.33858997421118797, 'n_independent': 10, 'n_shared': 1, 'lambda_sparse': 0.0542943403200561}. Best is trial 21 with value: 0.6702777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 12 with best_epoch = 2 and best_val_0_auc = 0.62528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:50:12,359]\u001B[0m Trial 23 finished with value: 0.6252777777777778 and parameters: {'n_d': 30, 'n_a': 36, 'n_steps': 12, 'gamma': 0.417112008449486, 'n_independent': 9, 'n_shared': 2, 'lambda_sparse': 0.06122116775229947}. Best is trial 21 with value: 0.6702777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.56611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:50:29,221]\u001B[0m Trial 24 finished with value: 0.5661111111111111 and parameters: {'n_d': 29, 'n_a': 35, 'n_steps': 12, 'gamma': 0.11991967240501711, 'n_independent': 9, 'n_shared': 2, 'lambda_sparse': 0.06025685043802423}. Best is trial 21 with value: 0.6702777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.58194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:51:47,925]\u001B[0m Trial 25 finished with value: 0.5819444444444445 and parameters: {'n_d': 32, 'n_a': 46, 'n_steps': 14, 'gamma': 0.405572424100751, 'n_independent': 10, 'n_shared': 4, 'lambda_sparse': 0.058854491411274606}. Best is trial 21 with value: 0.6702777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.61472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:52:35,352]\u001B[0m Trial 26 finished with value: 0.6147222222222223 and parameters: {'n_d': 19, 'n_a': 51, 'n_steps': 17, 'gamma': 0.7020731770590114, 'n_independent': 9, 'n_shared': 2, 'lambda_sparse': 0.04597271583443682}. Best is trial 21 with value: 0.6702777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.59083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:53:33,236]\u001B[0m Trial 27 finished with value: 0.5908333333333333 and parameters: {'n_d': 23, 'n_a': 51, 'n_steps': 18, 'gamma': 0.7423589150146044, 'n_independent': 9, 'n_shared': 3, 'lambda_sparse': 0.0471902136476401}. Best is trial 21 with value: 0.6702777777777778.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.17711 |  0:00:01s\n",
      "epoch 1  | loss: 1.18481 |  0:00:02s\n",
      "epoch 2  | loss: 0.92639 |  0:00:03s\n",
      "epoch 3  | loss: 0.88259 |  0:00:05s\n",
      "epoch 4  | loss: 0.87541 |  0:00:06s\n",
      "epoch 5  | loss: 0.79107 |  0:00:07s\n",
      "epoch 6  | loss: 0.84555 |  0:00:09s\n",
      "epoch 7  | loss: 0.80931 |  0:00:10s\n",
      "epoch 8  | loss: 0.81208 |  0:00:11s\n",
      "epoch 9  | loss: 0.75322 |  0:00:13s\n",
      "epoch 10 | loss: 0.76153 |  0:00:14s\n",
      "epoch 11 | loss: 0.72374 |  0:00:15s\n",
      "epoch 12 | loss: 0.715   |  0:00:16s\n",
      "epoch 13 | loss: 0.66915 |  0:00:18s\n",
      "epoch 14 | loss: 0.68013 |  0:00:19s\n",
      "epoch 15 | loss: 0.6739  |  0:00:20s\n",
      "epoch 16 | loss: 0.66802 |  0:00:22s\n",
      "epoch 17 | loss: 0.66408 |  0:00:23s\n",
      "epoch 18 | loss: 0.65551 |  0:00:24s\n",
      "epoch 19 | loss: 0.65476 |  0:00:26s\n",
      "epoch 20 | loss: 0.64814 |  0:00:27s\n",
      "epoch 21 | loss: 0.64428 |  0:00:28s\n",
      "epoch 22 | loss: 0.63546 |  0:00:30s\n",
      "epoch 23 | loss: 0.62946 |  0:00:31s\n",
      "epoch 24 | loss: 0.61817 |  0:00:32s\n",
      "epoch 25 | loss: 0.62229 |  0:00:33s\n",
      "epoch 26 | loss: 0.6014  |  0:00:35s\n",
      "epoch 27 | loss: 0.59773 |  0:00:36s\n",
      "epoch 28 | loss: 0.58497 |  0:00:37s\n",
      "epoch 29 | loss: 0.59542 |  0:00:39s\n",
      "epoch 30 | loss: 0.58543 |  0:00:40s\n",
      "epoch 31 | loss: 0.58606 |  0:00:41s\n",
      "epoch 32 | loss: 0.58263 |  0:00:43s\n",
      "epoch 33 | loss: 0.58118 |  0:00:44s\n",
      "epoch 34 | loss: 0.57802 |  0:00:45s\n",
      "epoch 35 | loss: 0.57782 |  0:00:46s\n",
      "epoch 36 | loss: 0.55465 |  0:00:48s\n",
      "epoch 37 | loss: 0.54594 |  0:00:49s\n",
      "epoch 38 | loss: 0.52838 |  0:00:50s\n",
      "epoch 39 | loss: 0.51986 |  0:00:51s\n",
      "epoch 40 | loss: 0.51058 |  0:00:53s\n",
      "epoch 41 | loss: 0.50603 |  0:00:54s\n",
      "epoch 42 | loss: 0.4996  |  0:00:55s\n",
      "epoch 43 | loss: 0.4932  |  0:00:56s\n",
      "epoch 44 | loss: 0.48699 |  0:00:58s\n",
      "epoch 45 | loss: 0.49641 |  0:00:59s\n",
      "epoch 46 | loss: 0.49025 |  0:01:00s\n",
      "epoch 47 | loss: 0.48797 |  0:01:01s\n",
      "epoch 48 | loss: 0.48874 |  0:01:03s\n",
      "epoch 49 | loss: 0.46152 |  0:01:04s\n",
      "epoch 50 | loss: 0.44232 |  0:01:05s\n",
      "epoch 51 | loss: 0.45072 |  0:01:06s\n",
      "epoch 52 | loss: 0.45233 |  0:01:08s\n",
      "epoch 53 | loss: 0.44552 |  0:01:09s\n",
      "epoch 54 | loss: 0.42879 |  0:01:10s\n",
      "epoch 55 | loss: 0.4245  |  0:01:11s\n",
      "epoch 56 | loss: 0.4102  |  0:01:13s\n",
      "epoch 57 | loss: 0.40022 |  0:01:14s\n",
      "epoch 58 | loss: 0.3981  |  0:01:15s\n",
      "epoch 59 | loss: 0.39051 |  0:01:16s\n",
      "epoch 60 | loss: 0.38162 |  0:01:18s\n",
      "epoch 61 | loss: 0.38587 |  0:01:19s\n",
      "epoch 62 | loss: 0.37018 |  0:01:20s\n",
      "epoch 63 | loss: 0.37702 |  0:01:21s\n",
      "epoch 64 | loss: 0.38624 |  0:01:23s\n",
      "epoch 65 | loss: 0.38404 |  0:01:24s\n",
      "epoch 66 | loss: 0.40774 |  0:01:25s\n",
      "epoch 67 | loss: 0.38278 |  0:01:26s\n",
      "epoch 68 | loss: 0.38066 |  0:01:28s\n",
      "epoch 69 | loss: 0.3753  |  0:01:29s\n",
      "epoch 70 | loss: 0.36468 |  0:01:30s\n",
      "epoch 71 | loss: 0.35301 |  0:01:31s\n",
      "epoch 72 | loss: 0.3598  |  0:01:33s\n",
      "epoch 73 | loss: 0.34613 |  0:01:34s\n",
      "epoch 74 | loss: 0.3467  |  0:01:35s\n",
      "epoch 75 | loss: 0.34309 |  0:01:36s\n",
      "epoch 76 | loss: 0.33808 |  0:01:38s\n",
      "epoch 77 | loss: 0.37163 |  0:01:39s\n",
      "epoch 78 | loss: 0.35636 |  0:01:40s\n",
      "epoch 79 | loss: 0.33636 |  0:01:41s\n",
      "epoch 80 | loss: 0.32913 |  0:01:43s\n",
      "epoch 81 | loss: 0.31909 |  0:01:44s\n",
      "epoch 82 | loss: 0.30876 |  0:01:45s\n",
      "epoch 83 | loss: 0.3074  |  0:01:46s\n",
      "epoch 84 | loss: 0.30116 |  0:01:48s\n",
      "epoch 85 | loss: 0.28676 |  0:01:49s\n",
      "epoch 86 | loss: 0.27678 |  0:01:50s\n",
      "epoch 87 | loss: 0.29279 |  0:01:51s\n",
      "epoch 88 | loss: 0.30006 |  0:01:53s\n",
      "epoch 89 | loss: 0.28826 |  0:01:54s\n",
      "epoch 90 | loss: 0.29447 |  0:01:55s\n",
      "epoch 91 | loss: 0.28231 |  0:01:56s\n",
      "epoch 92 | loss: 0.29602 |  0:01:58s\n",
      "epoch 93 | loss: 0.27752 |  0:01:59s\n",
      "epoch 94 | loss: 0.27573 |  0:02:00s\n",
      "epoch 95 | loss: 0.27263 |  0:02:01s\n",
      "epoch 96 | loss: 0.26564 |  0:02:03s\n",
      "epoch 97 | loss: 0.27667 |  0:02:04s\n",
      "epoch 98 | loss: 0.2634  |  0:02:05s\n",
      "epoch 99 | loss: 0.27033 |  0:02:06s\n",
      "Eval TABNET\n",
      "Accuracy: 0.51\n",
      "Precision: 0.51\n",
      "Recall: 0.45\n",
      "F1-score: 0.48\n",
      "ROC-AUC score: 0.51\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 18:55:41,048]\u001B[0m A new study created in memory with name: no-name-91ff40d2-7e8c-4c6c-b65b-981fbe5fce44\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.98111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:56:10,337]\u001B[0m Trial 0 finished with value: 0.981111111111111 and parameters: {'n_d': 59, 'n_a': 64, 'n_steps': 6, 'gamma': 0.22188663597973032, 'n_independent': 1, 'n_shared': 9, 'lambda_sparse': 0.022855107269285486}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:56:22,194]\u001B[0m Trial 1 finished with value: 0.9694444444444444 and parameters: {'n_d': 60, 'n_a': 12, 'n_steps': 3, 'gamma': 0.6694223149703127, 'n_independent': 2, 'n_shared': 6, 'lambda_sparse': 0.08237847683190325}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.96944\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.94944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:56:30,084]\u001B[0m Trial 2 finished with value: 0.9494444444444444 and parameters: {'n_d': 30, 'n_a': 25, 'n_steps': 8, 'gamma': 1.2714058350637198, 'n_independent': 3, 'n_shared': 1, 'lambda_sparse': 0.005432130560032583}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:57:07,626]\u001B[0m Trial 3 finished with value: 0.92 and parameters: {'n_d': 19, 'n_a': 38, 'n_steps': 13, 'gamma': 1.3533743044384143, 'n_independent': 7, 'n_shared': 5, 'lambda_sparse': 0.014001442516472798}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.93694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:57:49,139]\u001B[0m Trial 4 finished with value: 0.9369444444444445 and parameters: {'n_d': 23, 'n_a': 56, 'n_steps': 10, 'gamma': 1.7546296232870429, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.06444823403953528}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.74778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:59:29,970]\u001B[0m Trial 5 finished with value: 0.7477777777777779 and parameters: {'n_d': 52, 'n_a': 14, 'n_steps': 16, 'gamma': 1.1042599872130099, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.08248239964089463}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 18:59:35,087]\u001B[0m Trial 6 finished with value: 0.9597222222222223 and parameters: {'n_d': 38, 'n_a': 58, 'n_steps': 4, 'gamma': 0.40548833118100214, 'n_independent': 1, 'n_shared': 2, 'lambda_sparse': 0.08139235403187617}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.95972\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.97167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:00:00,108]\u001B[0m Trial 7 finished with value: 0.9716666666666666 and parameters: {'n_d': 62, 'n_a': 25, 'n_steps': 11, 'gamma': 0.4882852524231801, 'n_independent': 5, 'n_shared': 2, 'lambda_sparse': 0.08248677425976746}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.97417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:01:18,807]\u001B[0m Trial 8 finished with value: 0.9741666666666666 and parameters: {'n_d': 18, 'n_a': 57, 'n_steps': 7, 'gamma': 0.88655575937472, 'n_independent': 9, 'n_shared': 10, 'lambda_sparse': 0.05443809798628853}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.86028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:04:09,819]\u001B[0m Trial 9 finished with value: 0.8602777777777778 and parameters: {'n_d': 46, 'n_a': 56, 'n_steps': 18, 'gamma': 1.6137075100424465, 'n_independent': 9, 'n_shared': 10, 'lambda_sparse': 0.019986100992916287}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:04:19,745]\u001B[0m Trial 10 finished with value: 0.9744444444444443 and parameters: {'n_d': 10, 'n_a': 44, 'n_steps': 2, 'gamma': 0.10075915720712625, 'n_independent': 4, 'n_shared': 7, 'lambda_sparse': 0.03482805226701451}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.97444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:04:23,924]\u001B[0m Trial 11 finished with value: 0.9633333333333334 and parameters: {'n_d': 8, 'n_a': 43, 'n_steps': 1, 'gamma': 0.14945018911567293, 'n_independent': 4, 'n_shared': 7, 'lambda_sparse': 0.030642773382153633}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.96333\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.98028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:04:40,709]\u001B[0m Trial 12 finished with value: 0.9802777777777778 and parameters: {'n_d': 43, 'n_a': 46, 'n_steps': 5, 'gamma': 0.11454303818625466, 'n_independent': 1, 'n_shared': 8, 'lambda_sparse': 0.03426279868747081}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.98056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:05:04,356]\u001B[0m Trial 13 finished with value: 0.9805555555555556 and parameters: {'n_d': 50, 'n_a': 48, 'n_steps': 6, 'gamma': 0.34982116217816206, 'n_independent': 1, 'n_shared': 8, 'lambda_sparse': 0.03740259228498565}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.91611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:05:20,109]\u001B[0m Trial 14 finished with value: 0.9161111111111111 and parameters: {'n_d': 53, 'n_a': 63, 'n_steps': 7, 'gamma': 0.7451923020597603, 'n_independent': 2, 'n_shared': 8, 'lambda_sparse': 0.04629692768257122}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:05:44,610]\u001B[0m Trial 15 finished with value: 0.9774999999999999 and parameters: {'n_d': 53, 'n_a': 49, 'n_steps': 6, 'gamma': 0.39305563783680336, 'n_independent': 6, 'n_shared': 4, 'lambda_sparse': 0.002499068106524123}. Best is trial 0 with value: 0.981111111111111.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.12055 |  0:00:01s\n",
      "epoch 1  | loss: 1.43464 |  0:00:02s\n",
      "epoch 2  | loss: 1.2622  |  0:00:03s\n",
      "epoch 3  | loss: 1.05701 |  0:00:04s\n",
      "epoch 4  | loss: 0.91152 |  0:00:05s\n",
      "epoch 5  | loss: 0.81509 |  0:00:06s\n",
      "epoch 6  | loss: 0.74049 |  0:00:07s\n",
      "epoch 7  | loss: 0.71336 |  0:00:08s\n",
      "epoch 8  | loss: 0.68698 |  0:00:09s\n",
      "epoch 9  | loss: 0.71843 |  0:00:10s\n",
      "epoch 10 | loss: 0.678   |  0:00:11s\n",
      "epoch 11 | loss: 0.65691 |  0:00:12s\n",
      "epoch 12 | loss: 0.6482  |  0:00:13s\n",
      "epoch 13 | loss: 0.64517 |  0:00:14s\n",
      "epoch 14 | loss: 0.64231 |  0:00:15s\n",
      "epoch 15 | loss: 0.62945 |  0:00:16s\n",
      "epoch 16 | loss: 0.61039 |  0:00:17s\n",
      "epoch 17 | loss: 0.6207  |  0:00:18s\n",
      "epoch 18 | loss: 0.61304 |  0:00:19s\n",
      "epoch 19 | loss: 0.61568 |  0:00:20s\n",
      "epoch 20 | loss: 0.6024  |  0:00:21s\n",
      "epoch 21 | loss: 0.6091  |  0:00:22s\n",
      "epoch 22 | loss: 0.60043 |  0:00:23s\n",
      "epoch 23 | loss: 0.60274 |  0:00:24s\n",
      "epoch 24 | loss: 0.58418 |  0:00:25s\n",
      "epoch 25 | loss: 0.58911 |  0:00:26s\n",
      "epoch 26 | loss: 0.57879 |  0:00:27s\n",
      "epoch 27 | loss: 0.58664 |  0:00:28s\n",
      "epoch 28 | loss: 0.57966 |  0:00:29s\n",
      "epoch 29 | loss: 0.57302 |  0:00:31s\n",
      "epoch 30 | loss: 0.56453 |  0:00:32s\n",
      "epoch 31 | loss: 0.56473 |  0:00:33s\n",
      "epoch 32 | loss: 0.5645  |  0:00:34s\n",
      "epoch 33 | loss: 0.5589  |  0:00:35s\n",
      "epoch 34 | loss: 0.56383 |  0:00:36s\n",
      "epoch 35 | loss: 0.56856 |  0:00:37s\n",
      "epoch 36 | loss: 0.55172 |  0:00:38s\n",
      "epoch 37 | loss: 0.54144 |  0:00:39s\n",
      "epoch 38 | loss: 0.53605 |  0:00:40s\n",
      "epoch 39 | loss: 0.52977 |  0:00:41s\n",
      "epoch 40 | loss: 0.53575 |  0:00:42s\n",
      "epoch 41 | loss: 0.53243 |  0:00:43s\n",
      "epoch 42 | loss: 0.5328  |  0:00:44s\n",
      "epoch 43 | loss: 0.51363 |  0:00:45s\n",
      "epoch 44 | loss: 0.51083 |  0:00:46s\n",
      "epoch 45 | loss: 0.51229 |  0:00:47s\n",
      "epoch 46 | loss: 0.51091 |  0:00:48s\n",
      "epoch 47 | loss: 0.51003 |  0:00:49s\n",
      "epoch 48 | loss: 0.49014 |  0:00:50s\n",
      "epoch 49 | loss: 0.50323 |  0:00:51s\n",
      "epoch 50 | loss: 0.48379 |  0:00:52s\n",
      "epoch 51 | loss: 0.48687 |  0:00:53s\n",
      "epoch 52 | loss: 0.48145 |  0:00:54s\n",
      "epoch 53 | loss: 0.46363 |  0:00:55s\n",
      "epoch 54 | loss: 0.45844 |  0:00:56s\n",
      "epoch 55 | loss: 0.44539 |  0:00:57s\n",
      "epoch 56 | loss: 0.45176 |  0:00:58s\n",
      "epoch 57 | loss: 0.4265  |  0:00:59s\n",
      "epoch 58 | loss: 0.43262 |  0:01:00s\n",
      "epoch 59 | loss: 0.43913 |  0:01:01s\n",
      "epoch 60 | loss: 0.42029 |  0:01:03s\n",
      "epoch 61 | loss: 0.4023  |  0:01:04s\n",
      "epoch 62 | loss: 0.43065 |  0:01:05s\n",
      "epoch 63 | loss: 0.40828 |  0:01:06s\n",
      "epoch 64 | loss: 0.39633 |  0:01:07s\n",
      "epoch 65 | loss: 0.39383 |  0:01:08s\n",
      "epoch 66 | loss: 0.36884 |  0:01:09s\n",
      "epoch 67 | loss: 0.37789 |  0:01:10s\n",
      "epoch 68 | loss: 0.3631  |  0:01:11s\n",
      "epoch 69 | loss: 0.38253 |  0:01:12s\n",
      "epoch 70 | loss: 0.38446 |  0:01:13s\n",
      "epoch 71 | loss: 0.38877 |  0:01:14s\n",
      "epoch 72 | loss: 0.3977  |  0:01:15s\n",
      "epoch 73 | loss: 0.39304 |  0:01:16s\n",
      "epoch 74 | loss: 0.38067 |  0:01:17s\n",
      "epoch 75 | loss: 0.37641 |  0:01:18s\n",
      "epoch 76 | loss: 0.40015 |  0:01:19s\n",
      "epoch 77 | loss: 0.37526 |  0:01:20s\n",
      "epoch 78 | loss: 0.3801  |  0:01:21s\n",
      "epoch 79 | loss: 0.37742 |  0:01:22s\n",
      "epoch 80 | loss: 0.36451 |  0:01:23s\n",
      "epoch 81 | loss: 0.34966 |  0:01:24s\n",
      "epoch 82 | loss: 0.35638 |  0:01:25s\n",
      "epoch 83 | loss: 0.33293 |  0:01:26s\n",
      "epoch 84 | loss: 0.30275 |  0:01:27s\n",
      "epoch 85 | loss: 0.31277 |  0:01:28s\n",
      "epoch 86 | loss: 0.30247 |  0:01:29s\n",
      "epoch 87 | loss: 0.29044 |  0:01:30s\n",
      "epoch 88 | loss: 0.27683 |  0:01:31s\n",
      "epoch 89 | loss: 0.28312 |  0:01:32s\n",
      "epoch 90 | loss: 0.2704  |  0:01:34s\n",
      "epoch 91 | loss: 0.25052 |  0:01:35s\n",
      "epoch 92 | loss: 0.24971 |  0:01:36s\n",
      "epoch 93 | loss: 0.22908 |  0:01:37s\n",
      "epoch 94 | loss: 0.22817 |  0:01:38s\n",
      "epoch 95 | loss: 0.22267 |  0:01:39s\n",
      "epoch 96 | loss: 0.20743 |  0:01:40s\n",
      "epoch 97 | loss: 0.21462 |  0:01:41s\n",
      "epoch 98 | loss: 0.22012 |  0:01:42s\n",
      "epoch 99 | loss: 0.21872 |  0:01:43s\n",
      "Eval TABNET\n",
      "Accuracy: 0.78\n",
      "Precision: 0.79\n",
      "Recall: 0.75\n",
      "F1-score: 0.77\n",
      "ROC-AUC score: 0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 19:07:28,619]\u001B[0m A new study created in memory with name: no-name-f67beba2-6d71-4c82-936b-e69475ed2c94\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.77611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:07:51,674]\u001B[0m Trial 0 finished with value: 0.7761111111111111 and parameters: {'n_d': 64, 'n_a': 18, 'n_steps': 4, 'gamma': 1.4784073382658118, 'n_independent': 5, 'n_shared': 9, 'lambda_sparse': 0.045195408540225454}. Best is trial 0 with value: 0.7761111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.65444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:08:45,123]\u001B[0m Trial 1 finished with value: 0.6544444444444445 and parameters: {'n_d': 58, 'n_a': 14, 'n_steps': 11, 'gamma': 1.530956551105909, 'n_independent': 10, 'n_shared': 8, 'lambda_sparse': 0.006685025153234933}. Best is trial 0 with value: 0.7761111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.83222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:09:06,451]\u001B[0m Trial 2 finished with value: 0.8322222222222222 and parameters: {'n_d': 60, 'n_a': 61, 'n_steps': 5, 'gamma': 0.35981622655918954, 'n_independent': 8, 'n_shared': 2, 'lambda_sparse': 0.011958976249099617}. Best is trial 2 with value: 0.8322222222222222.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_auc = 0.84444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:11:22,541]\u001B[0m Trial 3 finished with value: 0.8444444444444446 and parameters: {'n_d': 53, 'n_a': 54, 'n_steps': 19, 'gamma': 0.2895093454384007, 'n_independent': 3, 'n_shared': 8, 'lambda_sparse': 0.08653500352125743}. Best is trial 3 with value: 0.8444444444444446.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.64861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:12:15,514]\u001B[0m Trial 4 finished with value: 0.648611111111111 and parameters: {'n_d': 33, 'n_a': 8, 'n_steps': 14, 'gamma': 1.8713808035026496, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.011290023979237226}. Best is trial 3 with value: 0.8444444444444446.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:12:31,535]\u001B[0m Trial 5 finished with value: 0.8347222222222221 and parameters: {'n_d': 32, 'n_a': 32, 'n_steps': 1, 'gamma': 1.113290932043474, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.0014466562675606713}. Best is trial 3 with value: 0.8444444444444446.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_auc = 0.83472\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_auc = 0.77639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:12:50,577]\u001B[0m Trial 6 finished with value: 0.7763888888888889 and parameters: {'n_d': 40, 'n_a': 29, 'n_steps': 1, 'gamma': 1.2248576153015713, 'n_independent': 9, 'n_shared': 9, 'lambda_sparse': 0.026628698656685094}. Best is trial 3 with value: 0.8444444444444446.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.75694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:13:36,714]\u001B[0m Trial 7 finished with value: 0.7569444444444444 and parameters: {'n_d': 48, 'n_a': 59, 'n_steps': 11, 'gamma': 0.2642211504037809, 'n_independent': 2, 'n_shared': 9, 'lambda_sparse': 0.011615695404385843}. Best is trial 3 with value: 0.8444444444444446.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.76944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:14:30,846]\u001B[0m Trial 8 finished with value: 0.7694444444444444 and parameters: {'n_d': 24, 'n_a': 35, 'n_steps': 16, 'gamma': 0.5233082058711654, 'n_independent': 10, 'n_shared': 1, 'lambda_sparse': 0.08327269891663593}. Best is trial 3 with value: 0.8444444444444446.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.82111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:14:43,999]\u001B[0m Trial 9 finished with value: 0.8211111111111111 and parameters: {'n_d': 24, 'n_a': 29, 'n_steps': 3, 'gamma': 0.4814732852786333, 'n_independent': 2, 'n_shared': 10, 'lambda_sparse': 0.0033912846529406057}. Best is trial 3 with value: 0.8444444444444446.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.79861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:15:51,320]\u001B[0m Trial 10 finished with value: 0.7986111111111112 and parameters: {'n_d': 48, 'n_a': 48, 'n_steps': 19, 'gamma': 0.10000440710893382, 'n_independent': 4, 'n_shared': 5, 'lambda_sparse': 0.09894040060569595}. Best is trial 3 with value: 0.8444444444444446.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.81639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:16:18,173]\u001B[0m Trial 11 finished with value: 0.8163888888888889 and parameters: {'n_d': 9, 'n_a': 48, 'n_steps': 7, 'gamma': 0.8259635297604763, 'n_independent': 4, 'n_shared': 7, 'lambda_sparse': 0.06662567726204383}. Best is trial 3 with value: 0.8444444444444446.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.81528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:16:54,784]\u001B[0m Trial 12 finished with value: 0.8152777777777778 and parameters: {'n_d': 33, 'n_a': 46, 'n_steps': 8, 'gamma': 0.8597352447469406, 'n_independent': 6, 'n_shared': 4, 'lambda_sparse': 0.047196400400706405}. Best is trial 3 with value: 0.8444444444444446.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.81889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:18:30,176]\u001B[0m Trial 13 finished with value: 0.8188888888888888 and parameters: {'n_d': 48, 'n_a': 40, 'n_steps': 19, 'gamma': 0.7452149411037794, 'n_independent': 1, 'n_shared': 10, 'lambda_sparse': 0.06288803164058196}. Best is trial 3 with value: 0.8444444444444446.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.57428 |  0:00:03s\n",
      "epoch 1  | loss: 3.19225 |  0:00:06s\n",
      "epoch 2  | loss: 2.04252 |  0:00:09s\n",
      "epoch 3  | loss: 1.73695 |  0:00:12s\n",
      "epoch 4  | loss: 1.26475 |  0:00:15s\n",
      "epoch 5  | loss: 1.04131 |  0:00:18s\n",
      "epoch 6  | loss: 0.99118 |  0:00:21s\n",
      "epoch 7  | loss: 0.88043 |  0:00:24s\n",
      "epoch 8  | loss: 0.89832 |  0:00:27s\n",
      "epoch 9  | loss: 0.94554 |  0:00:30s\n",
      "epoch 10 | loss: 0.857   |  0:00:33s\n",
      "epoch 11 | loss: 0.81834 |  0:00:36s\n",
      "epoch 12 | loss: 0.81403 |  0:00:39s\n",
      "epoch 13 | loss: 0.80362 |  0:00:42s\n",
      "epoch 14 | loss: 0.80261 |  0:00:45s\n",
      "epoch 15 | loss: 0.78936 |  0:00:48s\n",
      "epoch 16 | loss: 0.77122 |  0:00:51s\n",
      "epoch 17 | loss: 0.76511 |  0:00:54s\n",
      "epoch 18 | loss: 0.7608  |  0:00:57s\n",
      "epoch 19 | loss: 0.75418 |  0:01:00s\n",
      "epoch 20 | loss: 0.76349 |  0:01:04s\n",
      "epoch 21 | loss: 0.74793 |  0:01:07s\n",
      "epoch 22 | loss: 0.74349 |  0:01:10s\n",
      "epoch 23 | loss: 0.72657 |  0:01:13s\n",
      "epoch 24 | loss: 0.73788 |  0:01:16s\n",
      "epoch 25 | loss: 0.72338 |  0:01:19s\n",
      "epoch 26 | loss: 0.72651 |  0:01:22s\n",
      "epoch 27 | loss: 0.71753 |  0:01:25s\n",
      "epoch 28 | loss: 0.70104 |  0:01:28s\n",
      "epoch 29 | loss: 0.70325 |  0:01:31s\n",
      "epoch 30 | loss: 0.69547 |  0:01:34s\n",
      "epoch 31 | loss: 0.67802 |  0:01:37s\n",
      "epoch 32 | loss: 0.67453 |  0:01:40s\n",
      "epoch 33 | loss: 0.66092 |  0:01:43s\n",
      "epoch 34 | loss: 0.67718 |  0:01:46s\n",
      "epoch 35 | loss: 0.66249 |  0:01:49s\n",
      "epoch 36 | loss: 0.6684  |  0:01:52s\n",
      "epoch 37 | loss: 0.63996 |  0:01:55s\n",
      "epoch 38 | loss: 0.6457  |  0:01:58s\n",
      "epoch 39 | loss: 0.64501 |  0:02:01s\n",
      "epoch 40 | loss: 0.62618 |  0:02:04s\n",
      "epoch 41 | loss: 0.62468 |  0:02:07s\n",
      "epoch 42 | loss: 0.61402 |  0:02:10s\n",
      "epoch 43 | loss: 0.60998 |  0:02:13s\n",
      "epoch 44 | loss: 0.62135 |  0:02:16s\n",
      "epoch 45 | loss: 0.61711 |  0:02:19s\n",
      "epoch 46 | loss: 0.60872 |  0:02:22s\n",
      "epoch 47 | loss: 0.61262 |  0:02:25s\n",
      "epoch 48 | loss: 0.58383 |  0:02:28s\n",
      "epoch 49 | loss: 0.57071 |  0:02:31s\n",
      "epoch 50 | loss: 0.56755 |  0:02:34s\n",
      "epoch 51 | loss: 0.55665 |  0:02:37s\n",
      "epoch 52 | loss: 0.54076 |  0:02:40s\n",
      "epoch 53 | loss: 0.5346  |  0:02:43s\n",
      "epoch 54 | loss: 0.52341 |  0:02:46s\n",
      "epoch 55 | loss: 0.5199  |  0:02:49s\n",
      "epoch 56 | loss: 0.48676 |  0:02:52s\n",
      "epoch 57 | loss: 0.48688 |  0:02:56s\n",
      "epoch 58 | loss: 0.47298 |  0:02:59s\n",
      "epoch 59 | loss: 0.4629  |  0:03:02s\n",
      "epoch 60 | loss: 0.45411 |  0:03:05s\n",
      "epoch 61 | loss: 0.44226 |  0:03:07s\n",
      "epoch 62 | loss: 0.47383 |  0:03:10s\n",
      "epoch 63 | loss: 0.4716  |  0:03:13s\n",
      "epoch 64 | loss: 0.47396 |  0:03:16s\n",
      "epoch 65 | loss: 0.48942 |  0:03:19s\n",
      "epoch 66 | loss: 0.47477 |  0:03:23s\n",
      "epoch 67 | loss: 0.47371 |  0:03:26s\n",
      "epoch 68 | loss: 0.46062 |  0:03:29s\n",
      "epoch 69 | loss: 0.44796 |  0:03:31s\n",
      "epoch 70 | loss: 0.45958 |  0:03:34s\n",
      "epoch 71 | loss: 0.45737 |  0:03:37s\n",
      "epoch 72 | loss: 0.44305 |  0:03:40s\n",
      "epoch 73 | loss: 0.44439 |  0:03:43s\n",
      "epoch 74 | loss: 0.42919 |  0:03:47s\n",
      "epoch 75 | loss: 0.42398 |  0:03:50s\n",
      "epoch 76 | loss: 0.40277 |  0:03:53s\n",
      "epoch 77 | loss: 0.41564 |  0:03:55s\n",
      "epoch 78 | loss: 0.40309 |  0:03:58s\n",
      "epoch 79 | loss: 0.40083 |  0:04:01s\n",
      "epoch 80 | loss: 0.38435 |  0:04:04s\n",
      "epoch 81 | loss: 0.36382 |  0:04:07s\n",
      "epoch 82 | loss: 0.36094 |  0:04:11s\n",
      "epoch 83 | loss: 0.355   |  0:04:13s\n",
      "epoch 84 | loss: 0.34764 |  0:04:16s\n",
      "epoch 85 | loss: 0.34294 |  0:04:20s\n",
      "epoch 86 | loss: 0.34693 |  0:04:22s\n",
      "epoch 87 | loss: 0.35226 |  0:04:25s\n",
      "epoch 88 | loss: 0.3587  |  0:04:28s\n",
      "epoch 89 | loss: 0.34608 |  0:04:31s\n",
      "epoch 90 | loss: 0.34306 |  0:04:34s\n",
      "epoch 91 | loss: 0.3403  |  0:04:37s\n",
      "epoch 92 | loss: 0.33663 |  0:04:40s\n",
      "epoch 93 | loss: 0.32299 |  0:04:44s\n",
      "epoch 94 | loss: 0.32586 |  0:04:47s\n",
      "epoch 95 | loss: 0.33023 |  0:04:50s\n",
      "epoch 96 | loss: 0.33301 |  0:04:53s\n",
      "epoch 97 | loss: 0.32108 |  0:04:56s\n",
      "epoch 98 | loss: 0.31087 |  0:04:59s\n",
      "epoch 99 | loss: 0.32497 |  0:05:02s\n",
      "Eval TABNET\n",
      "Accuracy: 0.57\n",
      "Precision: 0.55\n",
      "Recall: 0.68\n",
      "F1-score: 0.61\n",
      "ROC-AUC score: 0.57\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 19:23:34,475]\u001B[0m A new study created in memory with name: no-name-1d2345d7-52c7-4239-ad78-eaee0725b2de\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.60778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:23:50,920]\u001B[0m Trial 0 finished with value: 0.6077777777777778 and parameters: {'n_d': 12, 'n_a': 36, 'n_steps': 6, 'gamma': 1.6830147166973881, 'n_independent': 9, 'n_shared': 2, 'lambda_sparse': 0.08132677092454078}. Best is trial 0 with value: 0.6077777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.63083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:24:17,039]\u001B[0m Trial 1 finished with value: 0.6308333333333334 and parameters: {'n_d': 9, 'n_a': 17, 'n_steps': 13, 'gamma': 0.9429408584440852, 'n_independent': 5, 'n_shared': 4, 'lambda_sparse': 0.08758534980421115}. Best is trial 1 with value: 0.6308333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.64833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:24:45,369]\u001B[0m Trial 2 finished with value: 0.6483333333333334 and parameters: {'n_d': 61, 'n_a': 62, 'n_steps': 10, 'gamma': 0.8989734108918409, 'n_independent': 1, 'n_shared': 6, 'lambda_sparse': 0.080394084473108}. Best is trial 2 with value: 0.6483333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:25:04,269]\u001B[0m Trial 3 finished with value: 0.6599999999999999 and parameters: {'n_d': 27, 'n_a': 46, 'n_steps': 4, 'gamma': 0.9480858647070401, 'n_independent': 6, 'n_shared': 7, 'lambda_sparse': 0.023543172080264494}. Best is trial 3 with value: 0.6599999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.58806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:25:33,583]\u001B[0m Trial 4 finished with value: 0.5880555555555556 and parameters: {'n_d': 38, 'n_a': 45, 'n_steps': 11, 'gamma': 1.4443771131615541, 'n_independent': 5, 'n_shared': 5, 'lambda_sparse': 0.05985205759706631}. Best is trial 3 with value: 0.6599999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.65417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:25:55,414]\u001B[0m Trial 5 finished with value: 0.6541666666666666 and parameters: {'n_d': 11, 'n_a': 34, 'n_steps': 13, 'gamma': 0.6096471470789635, 'n_independent': 4, 'n_shared': 3, 'lambda_sparse': 0.004559586345483381}. Best is trial 3 with value: 0.6599999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.65889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:26:09,648]\u001B[0m Trial 6 finished with value: 0.6588888888888889 and parameters: {'n_d': 15, 'n_a': 14, 'n_steps': 13, 'gamma': 1.1774012324302807, 'n_independent': 2, 'n_shared': 7, 'lambda_sparse': 0.040242054633868096}. Best is trial 3 with value: 0.6599999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.69028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:27:18,004]\u001B[0m Trial 7 finished with value: 0.6902777777777778 and parameters: {'n_d': 55, 'n_a': 52, 'n_steps': 14, 'gamma': 0.6864140607228504, 'n_independent': 9, 'n_shared': 4, 'lambda_sparse': 0.07075147121240057}. Best is trial 7 with value: 0.6902777777777778.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:27:24,021]\u001B[0m Trial 8 finished with value: 0.6519444444444444 and parameters: {'n_d': 21, 'n_a': 11, 'n_steps': 1, 'gamma': 0.9899388693559664, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.0022635440053914275}. Best is trial 7 with value: 0.6902777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.65194\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:29:00,664]\u001B[0m Trial 9 finished with value: 0.635 and parameters: {'n_d': 59, 'n_a': 35, 'n_steps': 12, 'gamma': 0.5229273858514696, 'n_independent': 9, 'n_shared': 10, 'lambda_sparse': 0.04458904284014121}. Best is trial 7 with value: 0.6902777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.64722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:29:52,004]\u001B[0m Trial 10 finished with value: 0.6472222222222223 and parameters: {'n_d': 47, 'n_a': 64, 'n_steps': 19, 'gamma': 0.20633101848409818, 'n_independent': 7, 'n_shared': 1, 'lambda_sparse': 0.06353186150362516}. Best is trial 7 with value: 0.6902777777777778.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:30:03,867]\u001B[0m Trial 11 finished with value: 0.6083333333333333 and parameters: {'n_d': 28, 'n_a': 53, 'n_steps': 1, 'gamma': 0.6488118711282936, 'n_independent': 7, 'n_shared': 8, 'lambda_sparse': 0.02594443580386782}. Best is trial 7 with value: 0.6902777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.60833\n",
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.56319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:30:55,443]\u001B[0m Trial 12 finished with value: 0.5631944444444446 and parameters: {'n_d': 42, 'n_a': 49, 'n_steps': 17, 'gamma': 1.8774198351343974, 'n_independent': 7, 'n_shared': 9, 'lambda_sparse': 0.09709717552055075}. Best is trial 7 with value: 0.6902777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.67389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:31:15,816]\u001B[0m Trial 13 finished with value: 0.6738888888888889 and parameters: {'n_d': 51, 'n_a': 44, 'n_steps': 6, 'gamma': 1.2212318713673096, 'n_independent': 3, 'n_shared': 6, 'lambda_sparse': 0.024386789094085003}. Best is trial 7 with value: 0.6902777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.61139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:31:32,105]\u001B[0m Trial 14 finished with value: 0.611388888888889 and parameters: {'n_d': 51, 'n_a': 26, 'n_steps': 8, 'gamma': 1.2442886039718941, 'n_independent': 4, 'n_shared': 5, 'lambda_sparse': 0.06734670232003506}. Best is trial 7 with value: 0.6902777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.61639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:32:10,131]\u001B[0m Trial 15 finished with value: 0.616388888888889 and parameters: {'n_d': 54, 'n_a': 53, 'n_steps': 16, 'gamma': 1.3924446348835964, 'n_independent': 3, 'n_shared': 4, 'lambda_sparse': 0.05610220585319673}. Best is trial 7 with value: 0.6902777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.64556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:32:28,019]\u001B[0m Trial 16 finished with value: 0.6455555555555555 and parameters: {'n_d': 64, 'n_a': 42, 'n_steps': 8, 'gamma': 1.5623418864647554, 'n_independent': 1, 'n_shared': 6, 'lambda_sparse': 0.07047951715881932}. Best is trial 7 with value: 0.6902777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.62028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:32:37,562]\u001B[0m Trial 17 finished with value: 0.6202777777777778 and parameters: {'n_d': 47, 'n_a': 56, 'n_steps': 4, 'gamma': 1.2983340286651823, 'n_independent': 3, 'n_shared': 4, 'lambda_sparse': 0.04928048423329963}. Best is trial 7 with value: 0.6902777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.60375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:34:31,440]\u001B[0m Trial 18 finished with value: 0.60375 and parameters: {'n_d': 56, 'n_a': 28, 'n_steps': 15, 'gamma': 1.0984591543203366, 'n_independent': 10, 'n_shared': 7, 'lambda_sparse': 0.03675725938165399}. Best is trial 7 with value: 0.6902777777777778.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.95282 |  0:00:02s\n",
      "epoch 1  | loss: 2.42176 |  0:00:05s\n",
      "epoch 2  | loss: 1.87177 |  0:00:08s\n",
      "epoch 3  | loss: 1.50358 |  0:00:11s\n",
      "epoch 4  | loss: 1.49022 |  0:00:14s\n",
      "epoch 5  | loss: 1.48707 |  0:00:17s\n",
      "epoch 6  | loss: 1.4002  |  0:00:20s\n",
      "epoch 7  | loss: 1.6091  |  0:00:23s\n",
      "epoch 8  | loss: 1.76313 |  0:00:26s\n",
      "epoch 9  | loss: 1.26264 |  0:00:28s\n",
      "epoch 10 | loss: 1.40468 |  0:00:31s\n",
      "epoch 11 | loss: 1.07948 |  0:00:34s\n",
      "epoch 12 | loss: 1.04495 |  0:00:37s\n",
      "epoch 13 | loss: 1.00553 |  0:00:40s\n",
      "epoch 14 | loss: 1.01394 |  0:00:43s\n",
      "epoch 15 | loss: 0.90892 |  0:00:46s\n",
      "epoch 16 | loss: 0.9152  |  0:00:48s\n",
      "epoch 17 | loss: 0.85777 |  0:00:51s\n",
      "epoch 18 | loss: 0.83103 |  0:00:54s\n",
      "epoch 19 | loss: 0.8289  |  0:00:57s\n",
      "epoch 20 | loss: 0.79349 |  0:01:00s\n",
      "epoch 21 | loss: 0.79636 |  0:01:03s\n",
      "epoch 22 | loss: 0.76735 |  0:01:05s\n",
      "epoch 23 | loss: 0.76223 |  0:01:08s\n",
      "epoch 24 | loss: 0.74754 |  0:01:11s\n",
      "epoch 25 | loss: 0.74425 |  0:01:14s\n",
      "epoch 26 | loss: 0.72009 |  0:01:17s\n",
      "epoch 27 | loss: 0.71892 |  0:01:19s\n",
      "epoch 28 | loss: 0.71552 |  0:01:22s\n",
      "epoch 29 | loss: 0.71214 |  0:01:25s\n",
      "epoch 30 | loss: 0.71123 |  0:01:28s\n",
      "epoch 31 | loss: 0.69449 |  0:01:30s\n",
      "epoch 32 | loss: 0.704   |  0:01:33s\n",
      "epoch 33 | loss: 0.6978  |  0:01:36s\n",
      "epoch 34 | loss: 0.69851 |  0:01:39s\n",
      "epoch 35 | loss: 0.69852 |  0:01:42s\n",
      "epoch 36 | loss: 0.69203 |  0:01:44s\n",
      "epoch 37 | loss: 0.68411 |  0:01:47s\n",
      "epoch 38 | loss: 0.68438 |  0:01:50s\n",
      "epoch 39 | loss: 0.67001 |  0:01:53s\n",
      "epoch 40 | loss: 0.66132 |  0:01:55s\n",
      "epoch 41 | loss: 0.66078 |  0:01:58s\n",
      "epoch 42 | loss: 0.65738 |  0:02:01s\n",
      "epoch 43 | loss: 0.66111 |  0:02:04s\n",
      "epoch 44 | loss: 0.65637 |  0:02:07s\n",
      "epoch 45 | loss: 0.65079 |  0:02:09s\n",
      "epoch 46 | loss: 0.64236 |  0:02:12s\n",
      "epoch 47 | loss: 0.64878 |  0:02:15s\n",
      "epoch 48 | loss: 0.64792 |  0:02:18s\n",
      "epoch 49 | loss: 0.64206 |  0:02:20s\n",
      "epoch 50 | loss: 0.62401 |  0:02:23s\n",
      "epoch 51 | loss: 0.62074 |  0:02:26s\n",
      "epoch 52 | loss: 0.61434 |  0:02:29s\n",
      "epoch 53 | loss: 0.60133 |  0:02:31s\n",
      "epoch 54 | loss: 0.60238 |  0:02:34s\n",
      "epoch 55 | loss: 0.587   |  0:02:37s\n",
      "epoch 56 | loss: 0.59279 |  0:02:40s\n",
      "epoch 57 | loss: 0.5906  |  0:02:43s\n",
      "epoch 58 | loss: 0.58845 |  0:02:45s\n",
      "epoch 59 | loss: 0.58647 |  0:02:48s\n",
      "epoch 60 | loss: 0.56246 |  0:02:51s\n",
      "epoch 61 | loss: 0.5775  |  0:02:53s\n",
      "epoch 62 | loss: 0.55755 |  0:02:56s\n",
      "epoch 63 | loss: 0.54654 |  0:02:59s\n",
      "epoch 64 | loss: 0.539   |  0:03:02s\n",
      "epoch 65 | loss: 0.53361 |  0:03:04s\n",
      "epoch 66 | loss: 0.53817 |  0:03:07s\n",
      "epoch 67 | loss: 0.54005 |  0:03:10s\n",
      "epoch 68 | loss: 0.52686 |  0:03:13s\n",
      "epoch 69 | loss: 0.51593 |  0:03:16s\n",
      "epoch 70 | loss: 0.50879 |  0:03:19s\n",
      "epoch 71 | loss: 0.50642 |  0:03:21s\n",
      "epoch 72 | loss: 0.50812 |  0:03:24s\n",
      "epoch 73 | loss: 0.49116 |  0:03:27s\n",
      "epoch 74 | loss: 0.48132 |  0:03:30s\n",
      "epoch 75 | loss: 0.48858 |  0:03:33s\n",
      "epoch 76 | loss: 0.47446 |  0:03:35s\n",
      "epoch 77 | loss: 0.47326 |  0:03:38s\n",
      "epoch 78 | loss: 0.48367 |  0:03:41s\n",
      "epoch 79 | loss: 0.47421 |  0:03:44s\n",
      "epoch 80 | loss: 0.45253 |  0:03:46s\n",
      "epoch 81 | loss: 0.45431 |  0:03:49s\n",
      "epoch 82 | loss: 0.45706 |  0:03:52s\n",
      "epoch 83 | loss: 0.45725 |  0:03:55s\n",
      "epoch 84 | loss: 0.43511 |  0:03:58s\n",
      "epoch 85 | loss: 0.41544 |  0:04:00s\n",
      "epoch 86 | loss: 0.42283 |  0:04:03s\n",
      "epoch 87 | loss: 0.40405 |  0:04:06s\n",
      "epoch 88 | loss: 0.40722 |  0:04:09s\n",
      "epoch 89 | loss: 0.4052  |  0:04:11s\n",
      "epoch 90 | loss: 0.40392 |  0:04:14s\n",
      "epoch 91 | loss: 0.39271 |  0:04:17s\n",
      "epoch 92 | loss: 0.40751 |  0:04:20s\n",
      "epoch 93 | loss: 0.3931  |  0:04:22s\n",
      "epoch 94 | loss: 0.40995 |  0:04:25s\n",
      "epoch 95 | loss: 0.41579 |  0:04:28s\n",
      "epoch 96 | loss: 0.3985  |  0:04:31s\n",
      "epoch 97 | loss: 0.38977 |  0:04:34s\n",
      "epoch 98 | loss: 0.38851 |  0:04:36s\n",
      "epoch 99 | loss: 0.38965 |  0:04:39s\n",
      "Eval TABNET\n",
      "Accuracy: 0.48\n",
      "Precision: 0.48\n",
      "Recall: 0.5\n",
      "F1-score: 0.49\n",
      "ROC-AUC score: 0.48\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 19:39:13,015]\u001B[0m A new study created in memory with name: no-name-70b8f931-3252-4dd4-ab79-d69fc7b09571\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.53444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:39:23,087]\u001B[0m Trial 0 finished with value: 0.5344444444444444 and parameters: {'n_d': 20, 'n_a': 42, 'n_steps': 6, 'gamma': 1.5849740541837252, 'n_independent': 8, 'n_shared': 4, 'lambda_sparse': 0.03770676717308511}. Best is trial 0 with value: 0.5344444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.55778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:40:19,070]\u001B[0m Trial 1 finished with value: 0.5577777777777778 and parameters: {'n_d': 18, 'n_a': 58, 'n_steps': 14, 'gamma': 0.32744828330738407, 'n_independent': 10, 'n_shared': 3, 'lambda_sparse': 0.04294421622695258}. Best is trial 1 with value: 0.5577777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.52083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:40:24,373]\u001B[0m Trial 2 finished with value: 0.5208333333333334 and parameters: {'n_d': 22, 'n_a': 33, 'n_steps': 5, 'gamma': 0.25276911115703316, 'n_independent': 4, 'n_shared': 2, 'lambda_sparse': 0.020759897352523326}. Best is trial 1 with value: 0.5577777777777778.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.60403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:40:44,442]\u001B[0m Trial 3 finished with value: 0.6040277777777777 and parameters: {'n_d': 17, 'n_a': 34, 'n_steps': 14, 'gamma': 1.71723193429546, 'n_independent': 3, 'n_shared': 9, 'lambda_sparse': 0.0035404967250836847}. Best is trial 3 with value: 0.6040277777777777.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.54056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:41:34,961]\u001B[0m Trial 4 finished with value: 0.5405555555555556 and parameters: {'n_d': 11, 'n_a': 30, 'n_steps': 17, 'gamma': 1.824328131921529, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.0766018588363364}. Best is trial 3 with value: 0.6040277777777777.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.51139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:41:49,667]\u001B[0m Trial 5 finished with value: 0.5113888888888889 and parameters: {'n_d': 44, 'n_a': 43, 'n_steps': 2, 'gamma': 0.3870486166168431, 'n_independent': 5, 'n_shared': 6, 'lambda_sparse': 0.005769860331875943}. Best is trial 3 with value: 0.6040277777777777.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.56028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:42:14,665]\u001B[0m Trial 6 finished with value: 0.5602777777777778 and parameters: {'n_d': 60, 'n_a': 61, 'n_steps': 7, 'gamma': 0.3311919146469404, 'n_independent': 7, 'n_shared': 3, 'lambda_sparse': 0.08699285489046582}. Best is trial 3 with value: 0.6040277777777777.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.60708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:42:28,011]\u001B[0m Trial 7 finished with value: 0.6070833333333334 and parameters: {'n_d': 63, 'n_a': 53, 'n_steps': 9, 'gamma': 0.5668494413265436, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.01976479267669755}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:42:39,500]\u001B[0m Trial 8 finished with value: 0.51 and parameters: {'n_d': 56, 'n_a': 44, 'n_steps': 4, 'gamma': 1.246630177782052, 'n_independent': 10, 'n_shared': 5, 'lambda_sparse': 0.051743682897571884}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.53292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:44:00,165]\u001B[0m Trial 9 finished with value: 0.5329166666666667 and parameters: {'n_d': 33, 'n_a': 45, 'n_steps': 17, 'gamma': 1.6409371417638134, 'n_independent': 6, 'n_shared': 8, 'lambda_sparse': 0.059562780436920204}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:44:06,988]\u001B[0m Trial 10 finished with value: 0.5905555555555555 and parameters: {'n_d': 45, 'n_a': 9, 'n_steps': 11, 'gamma': 0.7580299835315072, 'n_independent': 1, 'n_shared': 1, 'lambda_sparse': 0.02363079982931499}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.59056\n",
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.53278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:44:25,494]\u001B[0m Trial 11 finished with value: 0.5327777777777778 and parameters: {'n_d': 32, 'n_a': 24, 'n_steps': 10, 'gamma': 1.0019059320009354, 'n_independent': 3, 'n_shared': 7, 'lambda_sparse': 0.0006210662183566765}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.55167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:44:51,835]\u001B[0m Trial 12 finished with value: 0.5516666666666666 and parameters: {'n_d': 8, 'n_a': 53, 'n_steps': 12, 'gamma': 1.9546489706721026, 'n_independent': 2, 'n_shared': 10, 'lambda_sparse': 0.016956874748438475}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.60111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:45:47,300]\u001B[0m Trial 13 finished with value: 0.6011111111111112 and parameters: {'n_d': 51, 'n_a': 21, 'n_steps': 14, 'gamma': 0.7270581491290827, 'n_independent': 4, 'n_shared': 8, 'lambda_sparse': 0.0024255182827476293}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.54569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:45:59,739]\u001B[0m Trial 14 finished with value: 0.5456944444444445 and parameters: {'n_d': 27, 'n_a': 52, 'n_steps': 9, 'gamma': 1.29764376247092, 'n_independent': 8, 'n_shared': 1, 'lambda_sparse': 0.028790074220678138}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.59833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:46:51,966]\u001B[0m Trial 15 finished with value: 0.5983333333333333 and parameters: {'n_d': 39, 'n_a': 64, 'n_steps': 14, 'gamma': 0.6896956363136434, 'n_independent': 3, 'n_shared': 8, 'lambda_sparse': 0.013968992924120717}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.57528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:47:27,656]\u001B[0m Trial 16 finished with value: 0.5752777777777778 and parameters: {'n_d': 63, 'n_a': 37, 'n_steps': 19, 'gamma': 1.3480314754877643, 'n_independent': 5, 'n_shared': 5, 'lambda_sparse': 0.03254940626608935}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.49556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:47:41,810]\u001B[0m Trial 17 finished with value: 0.4955555555555555 and parameters: {'n_d': 52, 'n_a': 18, 'n_steps': 9, 'gamma': 0.9595590563397338, 'n_independent': 1, 'n_shared': 9, 'lambda_sparse': 0.011310274554980904}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.56528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:47:59,583]\u001B[0m Trial 18 finished with value: 0.5652777777777778 and parameters: {'n_d': 15, 'n_a': 51, 'n_steps': 13, 'gamma': 0.5648113568054716, 'n_independent': 4, 'n_shared': 6, 'lambda_sparse': 0.024527814232458076}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.54056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:48:27,431]\u001B[0m Trial 19 finished with value: 0.5405555555555556 and parameters: {'n_d': 26, 'n_a': 29, 'n_steps': 16, 'gamma': 0.10389383696417942, 'n_independent': 7, 'n_shared': 4, 'lambda_sparse': 0.011496646948662407}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.50917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:48:44,373]\u001B[0m Trial 20 finished with value: 0.5091666666666668 and parameters: {'n_d': 41, 'n_a': 39, 'n_steps': 8, 'gamma': 1.9889644680540381, 'n_independent': 2, 'n_shared': 7, 'lambda_sparse': 0.032979023786284915}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.54069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:49:19,030]\u001B[0m Trial 21 finished with value: 0.5406944444444445 and parameters: {'n_d': 51, 'n_a': 18, 'n_steps': 15, 'gamma': 0.8059950007075694, 'n_independent': 4, 'n_shared': 9, 'lambda_sparse': 0.0006387908631224201}. Best is trial 7 with value: 0.6070833333333334.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.64734 |  0:00:01s\n",
      "epoch 1  | loss: 1.54534 |  0:00:02s\n",
      "epoch 2  | loss: 1.26267 |  0:00:03s\n",
      "epoch 3  | loss: 0.97879 |  0:00:04s\n",
      "epoch 4  | loss: 0.84541 |  0:00:04s\n",
      "epoch 5  | loss: 0.82251 |  0:00:06s\n",
      "epoch 6  | loss: 0.80717 |  0:00:07s\n",
      "epoch 7  | loss: 0.73751 |  0:00:07s\n",
      "epoch 8  | loss: 0.7587  |  0:00:08s\n",
      "epoch 9  | loss: 0.6848  |  0:00:09s\n",
      "epoch 10 | loss: 0.66828 |  0:00:10s\n",
      "epoch 11 | loss: 0.62172 |  0:00:11s\n",
      "epoch 12 | loss: 0.63701 |  0:00:12s\n",
      "epoch 13 | loss: 0.60995 |  0:00:13s\n",
      "epoch 14 | loss: 0.60501 |  0:00:14s\n",
      "epoch 15 | loss: 0.58148 |  0:00:15s\n",
      "epoch 16 | loss: 0.57661 |  0:00:16s\n",
      "epoch 17 | loss: 0.55378 |  0:00:17s\n",
      "epoch 18 | loss: 0.54845 |  0:00:18s\n",
      "epoch 19 | loss: 0.5632  |  0:00:19s\n",
      "epoch 20 | loss: 0.54352 |  0:00:20s\n",
      "epoch 21 | loss: 0.56414 |  0:00:21s\n",
      "epoch 22 | loss: 0.54499 |  0:00:22s\n",
      "epoch 23 | loss: 0.52093 |  0:00:23s\n",
      "epoch 24 | loss: 0.51796 |  0:00:24s\n",
      "epoch 25 | loss: 0.51738 |  0:00:25s\n",
      "epoch 26 | loss: 0.49915 |  0:00:26s\n",
      "epoch 27 | loss: 0.48086 |  0:00:27s\n",
      "epoch 28 | loss: 0.46931 |  0:00:28s\n",
      "epoch 29 | loss: 0.47147 |  0:00:29s\n",
      "epoch 30 | loss: 0.46392 |  0:00:30s\n",
      "epoch 31 | loss: 0.4644  |  0:00:31s\n",
      "epoch 32 | loss: 0.45669 |  0:00:32s\n",
      "epoch 33 | loss: 0.44665 |  0:00:33s\n",
      "epoch 34 | loss: 0.42302 |  0:00:34s\n",
      "epoch 35 | loss: 0.41543 |  0:00:35s\n",
      "epoch 36 | loss: 0.4133  |  0:00:36s\n",
      "epoch 37 | loss: 0.4221  |  0:00:37s\n",
      "epoch 38 | loss: 0.38435 |  0:00:38s\n",
      "epoch 39 | loss: 0.38672 |  0:00:39s\n",
      "epoch 40 | loss: 0.383   |  0:00:40s\n",
      "epoch 41 | loss: 0.37472 |  0:00:41s\n",
      "epoch 42 | loss: 0.38449 |  0:00:42s\n",
      "epoch 43 | loss: 0.37012 |  0:00:43s\n",
      "epoch 44 | loss: 0.36113 |  0:00:44s\n",
      "epoch 45 | loss: 0.34338 |  0:00:45s\n",
      "epoch 46 | loss: 0.33871 |  0:00:46s\n",
      "epoch 47 | loss: 0.34322 |  0:00:47s\n",
      "epoch 48 | loss: 0.32699 |  0:00:48s\n",
      "epoch 49 | loss: 0.31818 |  0:00:49s\n",
      "epoch 50 | loss: 0.30027 |  0:00:50s\n",
      "epoch 51 | loss: 0.30477 |  0:00:51s\n",
      "epoch 52 | loss: 0.29046 |  0:00:52s\n",
      "epoch 53 | loss: 0.30708 |  0:00:53s\n",
      "epoch 54 | loss: 0.28805 |  0:00:54s\n",
      "epoch 55 | loss: 0.27751 |  0:00:55s\n",
      "epoch 56 | loss: 0.27971 |  0:00:56s\n",
      "epoch 57 | loss: 0.26965 |  0:00:57s\n",
      "epoch 58 | loss: 0.26928 |  0:00:58s\n",
      "epoch 59 | loss: 0.2697  |  0:00:59s\n",
      "epoch 60 | loss: 0.26257 |  0:01:00s\n",
      "epoch 61 | loss: 0.26673 |  0:01:01s\n",
      "epoch 62 | loss: 0.24973 |  0:01:02s\n",
      "epoch 63 | loss: 0.25112 |  0:01:03s\n",
      "epoch 64 | loss: 0.25222 |  0:01:03s\n",
      "epoch 65 | loss: 0.22863 |  0:01:04s\n",
      "epoch 66 | loss: 0.23082 |  0:01:05s\n",
      "epoch 67 | loss: 0.2151  |  0:01:06s\n",
      "epoch 68 | loss: 0.24071 |  0:01:07s\n",
      "epoch 69 | loss: 0.21899 |  0:01:08s\n",
      "epoch 70 | loss: 0.22006 |  0:01:09s\n",
      "epoch 71 | loss: 0.20751 |  0:01:10s\n",
      "epoch 72 | loss: 0.20045 |  0:01:11s\n",
      "epoch 73 | loss: 0.20417 |  0:01:12s\n",
      "epoch 74 | loss: 0.17561 |  0:01:13s\n",
      "epoch 75 | loss: 0.18995 |  0:01:14s\n",
      "epoch 76 | loss: 0.18708 |  0:01:15s\n",
      "epoch 77 | loss: 0.18867 |  0:01:16s\n",
      "epoch 78 | loss: 0.19706 |  0:01:17s\n",
      "epoch 79 | loss: 0.18204 |  0:01:18s\n",
      "epoch 80 | loss: 0.2007  |  0:01:19s\n",
      "epoch 81 | loss: 0.19773 |  0:01:20s\n",
      "epoch 82 | loss: 0.19021 |  0:01:22s\n",
      "epoch 83 | loss: 0.17679 |  0:01:23s\n",
      "epoch 84 | loss: 0.17146 |  0:01:24s\n",
      "epoch 85 | loss: 0.17215 |  0:01:25s\n",
      "epoch 86 | loss: 0.15985 |  0:01:26s\n",
      "epoch 87 | loss: 0.17468 |  0:01:27s\n",
      "epoch 88 | loss: 0.14444 |  0:01:28s\n",
      "epoch 89 | loss: 0.14911 |  0:01:29s\n",
      "epoch 90 | loss: 0.14456 |  0:01:30s\n",
      "epoch 91 | loss: 0.1445  |  0:01:31s\n",
      "epoch 92 | loss: 0.15724 |  0:01:32s\n",
      "epoch 93 | loss: 0.13786 |  0:01:33s\n",
      "epoch 94 | loss: 0.14533 |  0:01:34s\n",
      "epoch 95 | loss: 0.1356  |  0:01:35s\n",
      "epoch 96 | loss: 0.12572 |  0:01:36s\n",
      "epoch 97 | loss: 0.13332 |  0:01:37s\n",
      "epoch 98 | loss: 0.12625 |  0:01:38s\n",
      "epoch 99 | loss: 0.12125 |  0:01:39s\n",
      "Eval TABNET\n",
      "Accuracy: 0.49\n",
      "Precision: 0.49\n",
      "Recall: 0.55\n",
      "F1-score: 0.52\n",
      "ROC-AUC score: 0.49\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 19:50:59,311]\u001B[0m A new study created in memory with name: no-name-dde65224-cc7f-439a-af61-08810878434a\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:51:01,213]\u001B[0m Trial 0 finished with value: 0.743177247917265 and parameters: {'n_d': 44, 'n_a': 19, 'n_steps': 2, 'gamma': 0.4541291387092946, 'n_independent': 1, 'n_shared': 2, 'lambda_sparse': 0.048256699011348526}. Best is trial 0 with value: 0.743177247917265.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.74318\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.7449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:51:39,062]\u001B[0m Trial 1 finished with value: 0.7449008905486929 and parameters: {'n_d': 27, 'n_a': 19, 'n_steps': 14, 'gamma': 0.3270770773901843, 'n_independent': 10, 'n_shared': 4, 'lambda_sparse': 0.023736216764034496}. Best is trial 1 with value: 0.7449008905486929.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.76616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:52:12,930]\u001B[0m Trial 2 finished with value: 0.7661591496696352 and parameters: {'n_d': 62, 'n_a': 29, 'n_steps': 16, 'gamma': 0.7836249732797126, 'n_independent': 3, 'n_shared': 2, 'lambda_sparse': 0.08802768478605005}. Best is trial 2 with value: 0.7661591496696352.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.71445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:53:10,294]\u001B[0m Trial 3 finished with value: 0.7144498707268027 and parameters: {'n_d': 40, 'n_a': 55, 'n_steps': 16, 'gamma': 1.8724619692739797, 'n_independent': 2, 'n_shared': 4, 'lambda_sparse': 0.09936022149642326}. Best is trial 2 with value: 0.7661591496696352.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.70583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:53:25,221]\u001B[0m Trial 4 finished with value: 0.7058316575696638 and parameters: {'n_d': 51, 'n_a': 60, 'n_steps': 7, 'gamma': 1.5007554271142018, 'n_independent': 5, 'n_shared': 2, 'lambda_sparse': 0.07874543291884735}. Best is trial 2 with value: 0.7661591496696352.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.76386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:53:45,547]\u001B[0m Trial 5 finished with value: 0.7638609594943981 and parameters: {'n_d': 64, 'n_a': 22, 'n_steps': 4, 'gamma': 1.7154984117519787, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.024227614778574828}. Best is trial 2 with value: 0.7661591496696352.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.77593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:54:14,953]\u001B[0m Trial 6 finished with value: 0.7759264579143925 and parameters: {'n_d': 57, 'n_a': 63, 'n_steps': 8, 'gamma': 1.1772388252802326, 'n_independent': 5, 'n_shared': 3, 'lambda_sparse': 0.02251888304857825}. Best is trial 6 with value: 0.7759264579143925.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.71933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:54:51,697]\u001B[0m Trial 7 finished with value: 0.7193335248491812 and parameters: {'n_d': 9, 'n_a': 35, 'n_steps': 11, 'gamma': 1.3705726375661624, 'n_independent': 10, 'n_shared': 3, 'lambda_sparse': 0.03261626424675459}. Best is trial 6 with value: 0.7759264579143925.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_auc = 0.75582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:55:10,674]\u001B[0m Trial 8 finished with value: 0.7558172938810687 and parameters: {'n_d': 53, 'n_a': 24, 'n_steps': 6, 'gamma': 1.719120143537738, 'n_independent': 1, 'n_shared': 4, 'lambda_sparse': 0.01590931745433097}. Best is trial 6 with value: 0.7759264579143925.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.6794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:56:14,823]\u001B[0m Trial 9 finished with value: 0.6794024705544384 and parameters: {'n_d': 9, 'n_a': 30, 'n_steps': 18, 'gamma': 1.8369729853381824, 'n_independent': 7, 'n_shared': 7, 'lambda_sparse': 0.09858612826227799}. Best is trial 6 with value: 0.7759264579143925.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.72695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:56:48,350]\u001B[0m Trial 10 finished with value: 0.7269462798046539 and parameters: {'n_d': 25, 'n_a': 45, 'n_steps': 11, 'gamma': 0.9414702823468513, 'n_independent': 4, 'n_shared': 10, 'lambda_sparse': 0.0031762550428800634}. Best is trial 6 with value: 0.7759264579143925.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_auc = 0.76415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:57:17,053]\u001B[0m Trial 11 finished with value: 0.7641482332663028 and parameters: {'n_d': 64, 'n_a': 45, 'n_steps': 9, 'gamma': 0.8443514828281861, 'n_independent': 3, 'n_shared': 1, 'lambda_sparse': 0.052059886333083304}. Best is trial 6 with value: 0.7759264579143925.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.7393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 19:57:47,651]\u001B[0m Trial 12 finished with value: 0.7392990519965528 and parameters: {'n_d': 54, 'n_a': 45, 'n_steps': 14, 'gamma': 1.17452637603509, 'n_independent': 6, 'n_shared': 1, 'lambda_sparse': 0.0688207244918835}. Best is trial 6 with value: 0.7759264579143925.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_auc = 0.7676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:00:06,329]\u001B[0m Trial 13 finished with value: 0.7675955185291583 and parameters: {'n_d': 59, 'n_a': 53, 'n_steps': 13, 'gamma': 0.7277809893292371, 'n_independent': 4, 'n_shared': 8, 'lambda_sparse': 0.04460805937869147}. Best is trial 6 with value: 0.7759264579143925.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 36 and best_val_0_auc = 0.79029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:01:35,556]\u001B[0m Trial 14 finished with value: 0.7902901465096237 and parameters: {'n_d': 33, 'n_a': 62, 'n_steps': 9, 'gamma': 0.6401131306995252, 'n_independent': 5, 'n_shared': 9, 'lambda_sparse': 0.042223273135869266}. Best is trial 14 with value: 0.7902901465096237.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.25178 |  0:00:01s\n",
      "epoch 1  | loss: 1.21394 |  0:00:03s\n",
      "epoch 2  | loss: 1.03546 |  0:00:05s\n",
      "epoch 3  | loss: 1.0617  |  0:00:07s\n",
      "epoch 4  | loss: 0.98989 |  0:00:09s\n",
      "epoch 5  | loss: 0.87838 |  0:00:10s\n",
      "epoch 6  | loss: 0.85011 |  0:00:12s\n",
      "epoch 7  | loss: 0.87937 |  0:00:14s\n",
      "epoch 8  | loss: 0.80598 |  0:00:16s\n",
      "epoch 9  | loss: 0.85156 |  0:00:18s\n",
      "epoch 10 | loss: 0.77397 |  0:00:19s\n",
      "epoch 11 | loss: 0.74416 |  0:00:21s\n",
      "epoch 12 | loss: 0.77121 |  0:00:23s\n",
      "epoch 13 | loss: 0.74162 |  0:00:25s\n",
      "epoch 14 | loss: 0.77091 |  0:00:26s\n",
      "epoch 15 | loss: 0.73465 |  0:00:28s\n",
      "epoch 16 | loss: 0.72114 |  0:00:30s\n",
      "epoch 17 | loss: 0.68784 |  0:00:32s\n",
      "epoch 18 | loss: 0.67994 |  0:00:34s\n",
      "epoch 19 | loss: 0.66663 |  0:00:35s\n",
      "epoch 20 | loss: 0.67448 |  0:00:37s\n",
      "epoch 21 | loss: 0.66203 |  0:00:39s\n",
      "epoch 22 | loss: 0.65923 |  0:00:41s\n",
      "epoch 23 | loss: 0.65642 |  0:00:43s\n",
      "epoch 24 | loss: 0.65626 |  0:00:44s\n",
      "epoch 25 | loss: 0.65346 |  0:00:46s\n",
      "epoch 26 | loss: 0.65284 |  0:00:48s\n",
      "epoch 27 | loss: 0.64532 |  0:00:50s\n",
      "epoch 28 | loss: 0.65301 |  0:00:52s\n",
      "epoch 29 | loss: 0.64552 |  0:00:53s\n",
      "epoch 30 | loss: 0.6501  |  0:00:55s\n",
      "epoch 31 | loss: 0.64522 |  0:00:57s\n",
      "epoch 32 | loss: 0.63936 |  0:00:59s\n",
      "epoch 33 | loss: 0.63712 |  0:01:00s\n",
      "epoch 34 | loss: 0.64416 |  0:01:02s\n",
      "epoch 35 | loss: 0.63669 |  0:01:04s\n",
      "epoch 36 | loss: 0.63055 |  0:01:06s\n",
      "epoch 37 | loss: 0.63502 |  0:01:08s\n",
      "epoch 38 | loss: 0.62763 |  0:01:09s\n",
      "epoch 39 | loss: 0.63064 |  0:01:11s\n",
      "epoch 40 | loss: 0.62527 |  0:01:13s\n",
      "epoch 41 | loss: 0.62996 |  0:01:15s\n",
      "epoch 42 | loss: 0.63504 |  0:01:17s\n",
      "epoch 43 | loss: 0.62659 |  0:01:18s\n",
      "epoch 44 | loss: 0.62854 |  0:01:20s\n",
      "epoch 45 | loss: 0.62807 |  0:01:22s\n",
      "epoch 46 | loss: 0.63224 |  0:01:24s\n",
      "epoch 47 | loss: 0.62252 |  0:01:26s\n",
      "epoch 48 | loss: 0.62638 |  0:01:28s\n",
      "epoch 49 | loss: 0.62317 |  0:01:29s\n",
      "epoch 50 | loss: 0.62112 |  0:01:31s\n",
      "epoch 51 | loss: 0.6055  |  0:01:33s\n",
      "epoch 52 | loss: 0.61377 |  0:01:35s\n",
      "epoch 53 | loss: 0.60648 |  0:01:37s\n",
      "epoch 54 | loss: 0.60705 |  0:01:38s\n",
      "epoch 55 | loss: 0.60273 |  0:01:40s\n",
      "epoch 56 | loss: 0.58729 |  0:01:42s\n",
      "epoch 57 | loss: 0.60518 |  0:01:44s\n",
      "epoch 58 | loss: 0.59481 |  0:01:46s\n",
      "epoch 59 | loss: 0.59725 |  0:01:48s\n",
      "epoch 60 | loss: 0.58881 |  0:01:49s\n",
      "epoch 61 | loss: 0.58863 |  0:01:51s\n",
      "epoch 62 | loss: 0.57512 |  0:01:53s\n",
      "epoch 63 | loss: 0.57107 |  0:01:55s\n",
      "epoch 64 | loss: 0.57934 |  0:01:57s\n",
      "epoch 65 | loss: 0.56669 |  0:01:59s\n",
      "epoch 66 | loss: 0.55488 |  0:02:01s\n",
      "epoch 67 | loss: 0.55414 |  0:02:02s\n",
      "epoch 68 | loss: 0.55104 |  0:02:04s\n",
      "epoch 69 | loss: 0.55347 |  0:02:06s\n",
      "epoch 70 | loss: 0.53578 |  0:02:08s\n",
      "epoch 71 | loss: 0.52608 |  0:02:10s\n",
      "epoch 72 | loss: 0.52975 |  0:02:11s\n",
      "epoch 73 | loss: 0.52263 |  0:02:13s\n",
      "epoch 74 | loss: 0.52908 |  0:02:15s\n",
      "epoch 75 | loss: 0.51025 |  0:02:17s\n",
      "epoch 76 | loss: 0.51776 |  0:02:19s\n",
      "epoch 77 | loss: 0.50365 |  0:02:20s\n",
      "epoch 78 | loss: 0.50952 |  0:02:22s\n",
      "epoch 79 | loss: 0.49644 |  0:02:24s\n",
      "epoch 80 | loss: 0.48273 |  0:02:26s\n",
      "epoch 81 | loss: 0.47924 |  0:02:28s\n",
      "epoch 82 | loss: 0.49099 |  0:02:30s\n",
      "epoch 83 | loss: 0.47679 |  0:02:32s\n",
      "epoch 84 | loss: 0.46662 |  0:02:33s\n",
      "epoch 85 | loss: 0.46322 |  0:02:35s\n",
      "epoch 86 | loss: 0.45571 |  0:02:37s\n",
      "epoch 87 | loss: 0.43705 |  0:02:39s\n",
      "epoch 88 | loss: 0.43176 |  0:02:41s\n",
      "epoch 89 | loss: 0.44126 |  0:02:42s\n",
      "epoch 90 | loss: 0.4331  |  0:02:44s\n",
      "epoch 91 | loss: 0.41949 |  0:02:46s\n",
      "epoch 92 | loss: 0.41373 |  0:02:48s\n",
      "epoch 93 | loss: 0.40631 |  0:02:50s\n",
      "epoch 94 | loss: 0.40862 |  0:02:52s\n",
      "epoch 95 | loss: 0.40406 |  0:02:53s\n",
      "epoch 96 | loss: 0.40299 |  0:02:55s\n",
      "epoch 97 | loss: 0.41387 |  0:02:57s\n",
      "epoch 98 | loss: 0.41685 |  0:02:59s\n",
      "epoch 99 | loss: 0.41713 |  0:03:01s\n",
      "Eval TABNET\n",
      "Accuracy: 0.58\n",
      "Precision: 0.59\n",
      "Recall: 0.54\n",
      "F1-score: 0.57\n",
      "ROC-AUC score: 0.58\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 20:04:37,999]\u001B[0m A new study created in memory with name: no-name-02576bcc-7064-4d22-bc02-8ea4faae3d32\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_auc = 0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:05:37,748]\u001B[0m Trial 0 finished with value: 0.7324999999999999 and parameters: {'n_d': 26, 'n_a': 21, 'n_steps': 16, 'gamma': 1.2548865582632611, 'n_independent': 6, 'n_shared': 2, 'lambda_sparse': 0.05507130769403687}. Best is trial 0 with value: 0.7324999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 11 with best_epoch = 1 and best_val_0_auc = 0.60375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:06:12,604]\u001B[0m Trial 1 finished with value: 0.60375 and parameters: {'n_d': 26, 'n_a': 58, 'n_steps': 12, 'gamma': 1.6309907236984997, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.01394114695207129}. Best is trial 0 with value: 0.7324999999999999.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.85611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:06:25,769]\u001B[0m Trial 2 finished with value: 0.856111111111111 and parameters: {'n_d': 58, 'n_a': 19, 'n_steps': 2, 'gamma': 0.2328517549762896, 'n_independent': 5, 'n_shared': 9, 'lambda_sparse': 0.037667715268285974}. Best is trial 2 with value: 0.856111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_auc = 0.88111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:08:25,652]\u001B[0m Trial 3 finished with value: 0.8811111111111111 and parameters: {'n_d': 16, 'n_a': 53, 'n_steps': 15, 'gamma': 0.5614519822317668, 'n_independent': 5, 'n_shared': 10, 'lambda_sparse': 0.005270545329803311}. Best is trial 3 with value: 0.8811111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.65333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:08:50,282]\u001B[0m Trial 4 finished with value: 0.6533333333333333 and parameters: {'n_d': 58, 'n_a': 19, 'n_steps': 8, 'gamma': 1.7303740599250628, 'n_independent': 10, 'n_shared': 5, 'lambda_sparse': 0.06630942328727116}. Best is trial 3 with value: 0.8811111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_auc = 0.88167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:09:43,924]\u001B[0m Trial 5 finished with value: 0.8816666666666667 and parameters: {'n_d': 49, 'n_a': 54, 'n_steps': 6, 'gamma': 0.49601309755345535, 'n_independent': 7, 'n_shared': 7, 'lambda_sparse': 0.033059214157583984}. Best is trial 5 with value: 0.8816666666666667.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:09:51,188]\u001B[0m Trial 6 finished with value: 0.7519444444444444 and parameters: {'n_d': 30, 'n_a': 11, 'n_steps': 3, 'gamma': 1.9435676437119351, 'n_independent': 4, 'n_shared': 6, 'lambda_sparse': 0.05480547591888846}. Best is trial 5 with value: 0.8816666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.75194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:10:07,889]\u001B[0m Trial 7 finished with value: 0.8580555555555555 and parameters: {'n_d': 34, 'n_a': 20, 'n_steps': 2, 'gamma': 0.9948975837212807, 'n_independent': 9, 'n_shared': 2, 'lambda_sparse': 0.05582663771614257}. Best is trial 5 with value: 0.8816666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 43 and best_val_0_auc = 0.85806\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_auc = 0.70083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:11:05,965]\u001B[0m Trial 8 finished with value: 0.7008333333333334 and parameters: {'n_d': 26, 'n_a': 8, 'n_steps': 13, 'gamma': 1.6088287586759253, 'n_independent': 9, 'n_shared': 6, 'lambda_sparse': 0.07091642570587879}. Best is trial 5 with value: 0.8816666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.71972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:11:16,169]\u001B[0m Trial 9 finished with value: 0.7197222222222223 and parameters: {'n_d': 32, 'n_a': 22, 'n_steps': 5, 'gamma': 1.8440751279019412, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.019323257806664162}. Best is trial 5 with value: 0.8816666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_auc = 0.87333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:11:59,114]\u001B[0m Trial 10 finished with value: 0.8733333333333333 and parameters: {'n_d': 50, 'n_a': 42, 'n_steps': 9, 'gamma': 0.150083497684949, 'n_independent': 1, 'n_shared': 8, 'lambda_sparse': 0.09767977624560624}. Best is trial 5 with value: 0.8816666666666667.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.88861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:13:11,957]\u001B[0m Trial 11 finished with value: 0.8886111111111111 and parameters: {'n_d': 8, 'n_a': 61, 'n_steps': 19, 'gamma': 0.5770296802110106, 'n_independent': 3, 'n_shared': 8, 'lambda_sparse': 0.007069690374934349}. Best is trial 11 with value: 0.8886111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_auc = 0.86528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:14:11,104]\u001B[0m Trial 12 finished with value: 0.8652777777777779 and parameters: {'n_d': 8, 'n_a': 63, 'n_steps': 18, 'gamma': 0.6352520360960833, 'n_independent': 2, 'n_shared': 8, 'lambda_sparse': 0.0009765263434219906}. Best is trial 11 with value: 0.8886111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.84389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:14:34,156]\u001B[0m Trial 13 finished with value: 0.8438888888888889 and parameters: {'n_d': 45, 'n_a': 48, 'n_steps': 6, 'gamma': 0.5488443256733482, 'n_independent': 3, 'n_shared': 8, 'lambda_sparse': 0.02935025918122034}. Best is trial 11 with value: 0.8886111111111111.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 42 and best_val_0_auc = 0.88278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:17:08,685]\u001B[0m Trial 14 finished with value: 0.8827777777777778 and parameters: {'n_d': 44, 'n_a': 36, 'n_steps': 19, 'gamma': 0.8282447457589198, 'n_independent': 7, 'n_shared': 4, 'lambda_sparse': 0.02415356628316071}. Best is trial 11 with value: 0.8886111111111111.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.43598 |  0:00:02s\n",
      "epoch 1  | loss: 0.85359 |  0:00:05s\n",
      "epoch 2  | loss: 0.79557 |  0:00:07s\n",
      "epoch 3  | loss: 0.8041  |  0:00:10s\n",
      "epoch 4  | loss: 0.71043 |  0:00:12s\n",
      "epoch 5  | loss: 0.71927 |  0:00:15s\n",
      "epoch 6  | loss: 0.73358 |  0:00:17s\n",
      "epoch 7  | loss: 0.6743  |  0:00:20s\n",
      "epoch 8  | loss: 0.64044 |  0:00:23s\n",
      "epoch 9  | loss: 0.62051 |  0:00:25s\n",
      "epoch 10 | loss: 0.61445 |  0:00:28s\n",
      "epoch 11 | loss: 0.59954 |  0:00:30s\n",
      "epoch 12 | loss: 0.59192 |  0:00:33s\n",
      "epoch 13 | loss: 0.59361 |  0:00:35s\n",
      "epoch 14 | loss: 0.58164 |  0:00:38s\n",
      "epoch 15 | loss: 0.57312 |  0:00:40s\n",
      "epoch 16 | loss: 0.56955 |  0:00:43s\n",
      "epoch 17 | loss: 0.55983 |  0:00:45s\n",
      "epoch 18 | loss: 0.55678 |  0:00:48s\n",
      "epoch 19 | loss: 0.55326 |  0:00:50s\n",
      "epoch 20 | loss: 0.5553  |  0:00:53s\n",
      "epoch 21 | loss: 0.54918 |  0:00:55s\n",
      "epoch 22 | loss: 0.54882 |  0:00:58s\n",
      "epoch 23 | loss: 0.54317 |  0:01:01s\n",
      "epoch 24 | loss: 0.54    |  0:01:03s\n",
      "epoch 25 | loss: 0.54904 |  0:01:06s\n",
      "epoch 26 | loss: 0.53419 |  0:01:08s\n",
      "epoch 27 | loss: 0.53364 |  0:01:11s\n",
      "epoch 28 | loss: 0.52446 |  0:01:13s\n",
      "epoch 29 | loss: 0.52487 |  0:01:16s\n",
      "epoch 30 | loss: 0.51478 |  0:01:18s\n",
      "epoch 31 | loss: 0.52264 |  0:01:21s\n",
      "epoch 32 | loss: 0.50879 |  0:01:23s\n",
      "epoch 33 | loss: 0.49408 |  0:01:26s\n",
      "epoch 34 | loss: 0.49389 |  0:01:28s\n",
      "epoch 35 | loss: 0.47823 |  0:01:31s\n",
      "epoch 36 | loss: 0.48146 |  0:01:33s\n",
      "epoch 37 | loss: 0.46166 |  0:01:36s\n",
      "epoch 38 | loss: 0.48532 |  0:01:38s\n",
      "epoch 39 | loss: 0.46351 |  0:01:41s\n",
      "epoch 40 | loss: 0.46199 |  0:01:44s\n",
      "epoch 41 | loss: 0.44174 |  0:01:46s\n",
      "epoch 42 | loss: 0.446   |  0:01:49s\n",
      "epoch 43 | loss: 0.43934 |  0:01:51s\n",
      "epoch 44 | loss: 0.44084 |  0:01:54s\n",
      "epoch 45 | loss: 0.43581 |  0:01:56s\n",
      "epoch 46 | loss: 0.45557 |  0:01:59s\n",
      "epoch 47 | loss: 0.43523 |  0:02:01s\n",
      "epoch 48 | loss: 0.42973 |  0:02:04s\n",
      "epoch 49 | loss: 0.41824 |  0:02:06s\n",
      "epoch 50 | loss: 0.39621 |  0:02:09s\n",
      "epoch 51 | loss: 0.38991 |  0:02:11s\n",
      "epoch 52 | loss: 0.36918 |  0:02:14s\n",
      "epoch 53 | loss: 0.374   |  0:02:16s\n",
      "epoch 54 | loss: 0.37031 |  0:02:19s\n",
      "epoch 55 | loss: 0.37459 |  0:02:21s\n",
      "epoch 56 | loss: 0.37826 |  0:02:24s\n",
      "epoch 57 | loss: 0.36378 |  0:02:26s\n",
      "epoch 58 | loss: 0.3587  |  0:02:29s\n",
      "epoch 59 | loss: 0.33343 |  0:02:32s\n",
      "epoch 60 | loss: 0.34245 |  0:02:34s\n",
      "epoch 61 | loss: 0.32891 |  0:02:36s\n",
      "epoch 62 | loss: 0.32996 |  0:02:39s\n",
      "epoch 63 | loss: 0.33707 |  0:02:42s\n",
      "epoch 64 | loss: 0.32922 |  0:02:44s\n",
      "epoch 65 | loss: 0.31502 |  0:02:47s\n",
      "epoch 66 | loss: 0.32071 |  0:02:49s\n",
      "epoch 67 | loss: 0.32042 |  0:02:52s\n",
      "epoch 68 | loss: 0.30972 |  0:02:54s\n",
      "epoch 69 | loss: 0.29703 |  0:02:57s\n",
      "epoch 70 | loss: 0.29028 |  0:02:59s\n",
      "epoch 71 | loss: 0.28926 |  0:03:02s\n",
      "epoch 72 | loss: 0.2932  |  0:03:04s\n",
      "epoch 73 | loss: 0.27958 |  0:03:07s\n",
      "epoch 74 | loss: 0.26242 |  0:03:10s\n",
      "epoch 75 | loss: 0.2834  |  0:03:12s\n",
      "epoch 76 | loss: 0.25646 |  0:03:15s\n",
      "epoch 77 | loss: 0.23539 |  0:03:17s\n",
      "epoch 78 | loss: 0.25327 |  0:03:20s\n",
      "epoch 79 | loss: 0.24926 |  0:03:22s\n",
      "epoch 80 | loss: 0.25424 |  0:03:25s\n",
      "epoch 81 | loss: 0.25285 |  0:03:27s\n",
      "epoch 82 | loss: 0.23914 |  0:03:30s\n",
      "epoch 83 | loss: 0.24    |  0:03:32s\n",
      "epoch 84 | loss: 0.24227 |  0:03:35s\n",
      "epoch 85 | loss: 0.23313 |  0:03:37s\n",
      "epoch 86 | loss: 0.21694 |  0:03:40s\n",
      "epoch 87 | loss: 0.20877 |  0:03:42s\n",
      "epoch 88 | loss: 0.22511 |  0:03:45s\n",
      "epoch 89 | loss: 0.20095 |  0:03:47s\n",
      "epoch 90 | loss: 0.21097 |  0:03:50s\n",
      "epoch 91 | loss: 0.17391 |  0:03:51s\n",
      "epoch 92 | loss: 0.19129 |  0:03:54s\n",
      "epoch 93 | loss: 0.19319 |  0:03:56s\n",
      "epoch 94 | loss: 0.19061 |  0:03:59s\n",
      "epoch 95 | loss: 0.19532 |  0:04:01s\n",
      "epoch 96 | loss: 0.17692 |  0:04:04s\n",
      "epoch 97 | loss: 0.18437 |  0:04:06s\n",
      "epoch 98 | loss: 0.19032 |  0:04:09s\n",
      "epoch 99 | loss: 0.184   |  0:04:11s\n",
      "Eval TABNET\n",
      "Accuracy: 0.71\n",
      "Precision: 0.73\n",
      "Recall: 0.67\n",
      "F1-score: 0.7\n",
      "ROC-AUC score: 0.71\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 20:21:22,524]\u001B[0m A new study created in memory with name: no-name-3c8c8fe9-fee3-4619-b8ca-ee4205844f7b\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.84333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:21:37,904]\u001B[0m Trial 0 finished with value: 0.8433333333333333 and parameters: {'n_d': 16, 'n_a': 40, 'n_steps': 9, 'gamma': 0.6687311710791034, 'n_independent': 6, 'n_shared': 4, 'lambda_sparse': 0.08892184388640667}. Best is trial 0 with value: 0.8433333333333333.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:21:41,619]\u001B[0m Trial 1 finished with value: 0.8372222222222222 and parameters: {'n_d': 10, 'n_a': 48, 'n_steps': 1, 'gamma': 0.7635204601835731, 'n_independent': 5, 'n_shared': 5, 'lambda_sparse': 0.03527749899788117}. Best is trial 0 with value: 0.8433333333333333.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.83722\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.86194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:22:20,087]\u001B[0m Trial 2 finished with value: 0.8619444444444444 and parameters: {'n_d': 15, 'n_a': 34, 'n_steps': 12, 'gamma': 0.728901845148476, 'n_independent': 4, 'n_shared': 5, 'lambda_sparse': 0.022265633357618456}. Best is trial 2 with value: 0.8619444444444444.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:22:28,228]\u001B[0m Trial 3 finished with value: 0.8519444444444444 and parameters: {'n_d': 31, 'n_a': 46, 'n_steps': 1, 'gamma': 1.0738973796504816, 'n_independent': 3, 'n_shared': 8, 'lambda_sparse': 0.06572159235323602}. Best is trial 2 with value: 0.8619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.85194\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.84639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:23:34,628]\u001B[0m Trial 4 finished with value: 0.8463888888888889 and parameters: {'n_d': 14, 'n_a': 59, 'n_steps': 11, 'gamma': 1.9161580790673527, 'n_independent': 5, 'n_shared': 10, 'lambda_sparse': 0.06512923039515536}. Best is trial 2 with value: 0.8619444444444444.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:23:39,275]\u001B[0m Trial 5 finished with value: 0.8219444444444444 and parameters: {'n_d': 52, 'n_a': 23, 'n_steps': 1, 'gamma': 1.0078003055056812, 'n_independent': 7, 'n_shared': 6, 'lambda_sparse': 0.08789815898069972}. Best is trial 2 with value: 0.8619444444444444.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 15 with best_epoch = 5 and best_val_0_auc = 0.82194\n",
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.88083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:23:49,649]\u001B[0m Trial 6 finished with value: 0.8808333333333334 and parameters: {'n_d': 34, 'n_a': 62, 'n_steps': 2, 'gamma': 0.21675067678692272, 'n_independent': 7, 'n_shared': 7, 'lambda_sparse': 0.09292688534072442}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.77333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:24:53,902]\u001B[0m Trial 7 finished with value: 0.7733333333333332 and parameters: {'n_d': 58, 'n_a': 45, 'n_steps': 13, 'gamma': 1.8269143883110224, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.001400410091945235}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.80306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:25:20,182]\u001B[0m Trial 8 finished with value: 0.8030555555555556 and parameters: {'n_d': 11, 'n_a': 27, 'n_steps': 14, 'gamma': 1.8424410117584482, 'n_independent': 8, 'n_shared': 1, 'lambda_sparse': 0.026577696416944185}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.78389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:26:23,081]\u001B[0m Trial 9 finished with value: 0.783888888888889 and parameters: {'n_d': 13, 'n_a': 30, 'n_steps': 19, 'gamma': 1.6329316521491888, 'n_independent': 5, 'n_shared': 7, 'lambda_sparse': 0.062168923611570184}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.86167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:26:44,034]\u001B[0m Trial 10 finished with value: 0.8616666666666667 and parameters: {'n_d': 40, 'n_a': 10, 'n_steps': 6, 'gamma': 0.19797745011038176, 'n_independent': 10, 'n_shared': 2, 'lambda_sparse': 0.0928923739390124}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_auc = 0.85111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:26:58,783]\u001B[0m Trial 11 finished with value: 0.851111111111111 and parameters: {'n_d': 26, 'n_a': 63, 'n_steps': 6, 'gamma': 0.3257218823865072, 'n_independent': 2, 'n_shared': 4, 'lambda_sparse': 0.09900447778866893}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.84653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:27:48,485]\u001B[0m Trial 12 finished with value: 0.8465277777777778 and parameters: {'n_d': 43, 'n_a': 55, 'n_steps': 17, 'gamma': 0.3928329319709444, 'n_independent': 3, 'n_shared': 8, 'lambda_sparse': 0.04274675983492211}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:28:11,082]\u001B[0m Trial 13 finished with value: 0.865 and parameters: {'n_d': 25, 'n_a': 34, 'n_steps': 6, 'gamma': 0.2072122014799926, 'n_independent': 8, 'n_shared': 3, 'lambda_sparse': 0.017665228315204617}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 14 with best_epoch = 4 and best_val_0_auc = 0.80417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:28:20,697]\u001B[0m Trial 14 finished with value: 0.8041666666666666 and parameters: {'n_d': 25, 'n_a': 18, 'n_steps': 5, 'gamma': 0.12745490145928964, 'n_independent': 9, 'n_shared': 3, 'lambda_sparse': 0.05446066682548128}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_auc = 0.86083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:28:38,130]\u001B[0m Trial 15 finished with value: 0.8608333333333333 and parameters: {'n_d': 34, 'n_a': 37, 'n_steps': 4, 'gamma': 0.44705252214966823, 'n_independent': 9, 'n_shared': 1, 'lambda_sparse': 0.0738361342338712}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_auc = 0.86306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:29:22,316]\u001B[0m Trial 16 finished with value: 0.8630555555555556 and parameters: {'n_d': 22, 'n_a': 53, 'n_steps': 8, 'gamma': 0.11736213987432208, 'n_independent': 7, 'n_shared': 7, 'lambda_sparse': 0.08016618083620573}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.86694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:29:32,139]\u001B[0m Trial 17 finished with value: 0.8669444444444445 and parameters: {'n_d': 47, 'n_a': 19, 'n_steps': 3, 'gamma': 0.3530845632160503, 'n_independent': 8, 'n_shared': 3, 'lambda_sparse': 0.05171257427958436}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.87083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:29:45,746]\u001B[0m Trial 18 finished with value: 0.8708333333333333 and parameters: {'n_d': 48, 'n_a': 8, 'n_steps': 3, 'gamma': 0.5460259701421414, 'n_independent': 10, 'n_shared': 6, 'lambda_sparse': 0.05104111779145718}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_auc = 0.86694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:30:12,366]\u001B[0m Trial 19 finished with value: 0.8669444444444445 and parameters: {'n_d': 63, 'n_a': 11, 'n_steps': 3, 'gamma': 0.5595694871776976, 'n_independent': 10, 'n_shared': 8, 'lambda_sparse': 0.07752622356023889}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_auc = 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:30:49,227]\u001B[0m Trial 20 finished with value: 0.85 and parameters: {'n_d': 52, 'n_a': 16, 'n_steps': 8, 'gamma': 0.4822518766703444, 'n_independent': 10, 'n_shared': 6, 'lambda_sparse': 0.046009373036535774}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_auc = 0.84972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:31:08,080]\u001B[0m Trial 21 finished with value: 0.8497222222222222 and parameters: {'n_d': 46, 'n_a': 8, 'n_steps': 3, 'gamma': 0.32186544267300277, 'n_independent': 8, 'n_shared': 7, 'lambda_sparse': 0.05616815921788021}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 38 and best_val_0_auc = 0.87417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:31:32,424]\u001B[0m Trial 22 finished with value: 0.8741666666666666 and parameters: {'n_d': 49, 'n_a': 16, 'n_steps': 3, 'gamma': 0.3246144285853954, 'n_independent': 9, 'n_shared': 4, 'lambda_sparse': 0.048280722956181674}. Best is trial 6 with value: 0.8808333333333334.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.97913 |  0:00:00s\n",
      "epoch 1  | loss: 0.85468 |  0:00:00s\n",
      "epoch 2  | loss: 0.84262 |  0:00:01s\n",
      "epoch 3  | loss: 0.81516 |  0:00:01s\n",
      "epoch 4  | loss: 0.79693 |  0:00:02s\n",
      "epoch 5  | loss: 0.78887 |  0:00:02s\n",
      "epoch 6  | loss: 0.7552  |  0:00:03s\n",
      "epoch 7  | loss: 0.75155 |  0:00:03s\n",
      "epoch 8  | loss: 0.74144 |  0:00:04s\n",
      "epoch 9  | loss: 0.71665 |  0:00:04s\n",
      "epoch 10 | loss: 0.70367 |  0:00:05s\n",
      "epoch 11 | loss: 0.69493 |  0:00:05s\n",
      "epoch 12 | loss: 0.68768 |  0:00:06s\n",
      "epoch 13 | loss: 0.67446 |  0:00:06s\n",
      "epoch 14 | loss: 0.66296 |  0:00:06s\n",
      "epoch 15 | loss: 0.67361 |  0:00:07s\n",
      "epoch 16 | loss: 0.65865 |  0:00:07s\n",
      "epoch 17 | loss: 0.65676 |  0:00:08s\n",
      "epoch 18 | loss: 0.6537  |  0:00:08s\n",
      "epoch 19 | loss: 0.65494 |  0:00:09s\n",
      "epoch 20 | loss: 0.64577 |  0:00:09s\n",
      "epoch 21 | loss: 0.64413 |  0:00:10s\n",
      "epoch 22 | loss: 0.64704 |  0:00:10s\n",
      "epoch 23 | loss: 0.63796 |  0:00:11s\n",
      "epoch 24 | loss: 0.63518 |  0:00:11s\n",
      "epoch 25 | loss: 0.63545 |  0:00:12s\n",
      "epoch 26 | loss: 0.63535 |  0:00:12s\n",
      "epoch 27 | loss: 0.62968 |  0:00:13s\n",
      "epoch 28 | loss: 0.62876 |  0:00:13s\n",
      "epoch 29 | loss: 0.62848 |  0:00:13s\n",
      "epoch 30 | loss: 0.62419 |  0:00:14s\n",
      "epoch 31 | loss: 0.62066 |  0:00:14s\n",
      "epoch 32 | loss: 0.62041 |  0:00:15s\n",
      "epoch 33 | loss: 0.62386 |  0:00:15s\n",
      "epoch 34 | loss: 0.62203 |  0:00:16s\n",
      "epoch 35 | loss: 0.60824 |  0:00:16s\n",
      "epoch 36 | loss: 0.61372 |  0:00:17s\n",
      "epoch 37 | loss: 0.6291  |  0:00:17s\n",
      "epoch 38 | loss: 0.61931 |  0:00:18s\n",
      "epoch 39 | loss: 0.61546 |  0:00:18s\n",
      "epoch 40 | loss: 0.62041 |  0:00:19s\n",
      "epoch 41 | loss: 0.61889 |  0:00:19s\n",
      "epoch 42 | loss: 0.61406 |  0:00:19s\n",
      "epoch 43 | loss: 0.616   |  0:00:20s\n",
      "epoch 44 | loss: 0.61851 |  0:00:20s\n",
      "epoch 45 | loss: 0.61672 |  0:00:21s\n",
      "epoch 46 | loss: 0.61629 |  0:00:21s\n",
      "epoch 47 | loss: 0.61579 |  0:00:22s\n",
      "epoch 48 | loss: 0.61068 |  0:00:22s\n",
      "epoch 49 | loss: 0.61433 |  0:00:23s\n",
      "epoch 50 | loss: 0.60178 |  0:00:23s\n",
      "epoch 51 | loss: 0.61413 |  0:00:24s\n",
      "epoch 52 | loss: 0.60929 |  0:00:24s\n",
      "epoch 53 | loss: 0.61219 |  0:00:25s\n",
      "epoch 54 | loss: 0.61337 |  0:00:25s\n",
      "epoch 55 | loss: 0.61276 |  0:00:25s\n",
      "epoch 56 | loss: 0.61374 |  0:00:26s\n",
      "epoch 57 | loss: 0.60336 |  0:00:26s\n",
      "epoch 58 | loss: 0.6068  |  0:00:27s\n",
      "epoch 59 | loss: 0.60962 |  0:00:27s\n",
      "epoch 60 | loss: 0.60911 |  0:00:28s\n",
      "epoch 61 | loss: 0.60644 |  0:00:28s\n",
      "epoch 62 | loss: 0.61425 |  0:00:29s\n",
      "epoch 63 | loss: 0.60335 |  0:00:29s\n",
      "epoch 64 | loss: 0.6     |  0:00:30s\n",
      "epoch 65 | loss: 0.60506 |  0:00:30s\n",
      "epoch 66 | loss: 0.59827 |  0:00:31s\n",
      "epoch 67 | loss: 0.60371 |  0:00:31s\n",
      "epoch 68 | loss: 0.59603 |  0:00:31s\n",
      "epoch 69 | loss: 0.60101 |  0:00:32s\n",
      "epoch 70 | loss: 0.60202 |  0:00:32s\n",
      "epoch 71 | loss: 0.60125 |  0:00:33s\n",
      "epoch 72 | loss: 0.60377 |  0:00:33s\n",
      "epoch 73 | loss: 0.59867 |  0:00:34s\n",
      "epoch 74 | loss: 0.59999 |  0:00:34s\n",
      "epoch 75 | loss: 0.59349 |  0:00:35s\n",
      "epoch 76 | loss: 0.59483 |  0:00:35s\n",
      "epoch 77 | loss: 0.59981 |  0:00:36s\n",
      "epoch 78 | loss: 0.59907 |  0:00:36s\n",
      "epoch 79 | loss: 0.59575 |  0:00:36s\n",
      "epoch 80 | loss: 0.60093 |  0:00:37s\n",
      "epoch 81 | loss: 0.60238 |  0:00:37s\n",
      "epoch 82 | loss: 0.60385 |  0:00:38s\n",
      "epoch 83 | loss: 0.59993 |  0:00:38s\n",
      "epoch 84 | loss: 0.59551 |  0:00:39s\n",
      "epoch 85 | loss: 0.59419 |  0:00:39s\n",
      "epoch 86 | loss: 0.59567 |  0:00:40s\n",
      "epoch 87 | loss: 0.5909  |  0:00:40s\n",
      "epoch 88 | loss: 0.58954 |  0:00:41s\n",
      "epoch 89 | loss: 0.60251 |  0:00:41s\n",
      "epoch 90 | loss: 0.59561 |  0:00:42s\n",
      "epoch 91 | loss: 0.59419 |  0:00:42s\n",
      "epoch 92 | loss: 0.59563 |  0:00:43s\n",
      "epoch 93 | loss: 0.59437 |  0:00:43s\n",
      "epoch 94 | loss: 0.59793 |  0:00:43s\n",
      "epoch 95 | loss: 0.59123 |  0:00:44s\n",
      "epoch 96 | loss: 0.59157 |  0:00:44s\n",
      "epoch 97 | loss: 0.58922 |  0:00:45s\n",
      "epoch 98 | loss: 0.60011 |  0:00:45s\n",
      "epoch 99 | loss: 0.59854 |  0:00:46s\n",
      "Eval TABNET\n",
      "Accuracy: 0.78\n",
      "Precision: 0.75\n",
      "Recall: 0.82\n",
      "F1-score: 0.78\n",
      "ROC-AUC score: 0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2023-11-02 20:32:19,120]\u001B[0m A new study created in memory with name: no-name-5e55fac2-87ea-4a30-8c4a-01beb6362aff\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_auc = 0.80264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:33:24,765]\u001B[0m Trial 0 finished with value: 0.8026446280991735 and parameters: {'n_d': 64, 'n_a': 47, 'n_steps': 14, 'gamma': 1.3931666180961573, 'n_independent': 5, 'n_shared': 6, 'lambda_sparse': 0.0989313805540031}. Best is trial 0 with value: 0.8026446280991735.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.78182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:34:22,646]\u001B[0m Trial 1 finished with value: 0.7818181818181817 and parameters: {'n_d': 14, 'n_a': 14, 'n_steps': 19, 'gamma': 0.9610791685334337, 'n_independent': 6, 'n_shared': 4, 'lambda_sparse': 0.016917738158514387}. Best is trial 0 with value: 0.8026446280991735.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.78479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:34:48,635]\u001B[0m Trial 2 finished with value: 0.7847933884297521 and parameters: {'n_d': 63, 'n_a': 37, 'n_steps': 12, 'gamma': 1.7822385009069026, 'n_independent': 2, 'n_shared': 5, 'lambda_sparse': 0.05280428176357245}. Best is trial 0 with value: 0.8026446280991735.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.86512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:35:20,440]\u001B[0m Trial 3 finished with value: 0.8651239669421488 and parameters: {'n_d': 57, 'n_a': 62, 'n_steps': 6, 'gamma': 0.2000923013254274, 'n_independent': 3, 'n_shared': 9, 'lambda_sparse': 0.024826129394069512}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 10 with best_epoch = 0 and best_val_0_auc = 0.75603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:35:28,280]\u001B[0m Trial 4 finished with value: 0.7560330578512395 and parameters: {'n_d': 40, 'n_a': 40, 'n_steps': 10, 'gamma': 1.9791378623866809, 'n_independent': 2, 'n_shared': 3, 'lambda_sparse': 0.01555122701675258}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_auc = 0.79967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:35:51,642]\u001B[0m Trial 5 finished with value: 0.7996694214876033 and parameters: {'n_d': 46, 'n_a': 48, 'n_steps': 6, 'gamma': 1.370690041642945, 'n_independent': 5, 'n_shared': 4, 'lambda_sparse': 0.06765744902641657}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_auc = 0.67603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:36:48,046]\u001B[0m Trial 6 finished with value: 0.6760330578512397 and parameters: {'n_d': 62, 'n_a': 49, 'n_steps': 10, 'gamma': 1.8014324845986969, 'n_independent': 6, 'n_shared': 10, 'lambda_sparse': 0.039997171783166474}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:36:55,965]\u001B[0m Trial 7 finished with value: 0.7887603305785125 and parameters: {'n_d': 24, 'n_a': 53, 'n_steps': 2, 'gamma': 0.4394927373848485, 'n_independent': 8, 'n_shared': 2, 'lambda_sparse': 0.04761379090261171}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.78876\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_auc = 0.79074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:37:49,860]\u001B[0m Trial 8 finished with value: 0.7907438016528926 and parameters: {'n_d': 38, 'n_a': 30, 'n_steps': 17, 'gamma': 0.5163435553713964, 'n_independent': 7, 'n_shared': 4, 'lambda_sparse': 0.017553806434317667}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.80397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:38:09,074]\u001B[0m Trial 9 finished with value: 0.8039669421487604 and parameters: {'n_d': 18, 'n_a': 24, 'n_steps': 9, 'gamma': 1.5290160923620797, 'n_independent': 4, 'n_shared': 6, 'lambda_sparse': 0.03914454147321175}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.78149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:38:21,186]\u001B[0m Trial 10 finished with value: 0.7814876033057852 and parameters: {'n_d': 51, 'n_a': 64, 'n_steps': 1, 'gamma': 0.18070150515689606, 'n_independent': 10, 'n_shared': 10, 'lambda_sparse': 0.0018166173270759978}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 13 with best_epoch = 3 and best_val_0_auc = 0.79273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:38:31,327]\u001B[0m Trial 11 finished with value: 0.7927272727272727 and parameters: {'n_d': 25, 'n_a': 23, 'n_steps': 6, 'gamma': 0.1056761215418231, 'n_independent': 3, 'n_shared': 8, 'lambda_sparse': 0.03559487948965998}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 17 with best_epoch = 7 and best_val_0_auc = 0.83769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:38:40,377]\u001B[0m Trial 12 finished with value: 0.8376859504132231 and parameters: {'n_d': 12, 'n_a': 8, 'n_steps': 6, 'gamma': 0.8659907910365938, 'n_independent': 4, 'n_shared': 7, 'lambda_sparse': 0.02993460128442815}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 16 with best_epoch = 6 and best_val_0_auc = 0.78645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:38:48,712]\u001B[0m Trial 13 finished with value: 0.7864462809917356 and parameters: {'n_d': 29, 'n_a': 8, 'n_steps': 5, 'gamma': 0.8926982635569739, 'n_independent': 1, 'n_shared': 8, 'lambda_sparse': 0.02568239905455217}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_auc = 0.81124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:39:17,824]\u001B[0m Trial 14 finished with value: 0.8112396694214875 and parameters: {'n_d': 55, 'n_a': 63, 'n_steps': 4, 'gamma': 0.7315671634485512, 'n_independent': 3, 'n_shared': 8, 'lambda_sparse': 0.000996694337995499}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_auc = 0.84132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:39:35,170]\u001B[0m Trial 15 finished with value: 0.8413223140495867 and parameters: {'n_d': 8, 'n_a': 16, 'n_steps': 8, 'gamma': 1.1106674155340277, 'n_independent': 4, 'n_shared': 7, 'lambda_sparse': 0.027129325798345545}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.79339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:39:58,286]\u001B[0m Trial 16 finished with value: 0.793388429752066 and parameters: {'n_d': 32, 'n_a': 18, 'n_steps': 8, 'gamma': 1.162512051068606, 'n_independent': 1, 'n_shared': 9, 'lambda_sparse': 0.02500284323040594}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_auc = 0.79339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:40:25,457]\u001B[0m Trial 17 finished with value: 0.7933884297520661 and parameters: {'n_d': 8, 'n_a': 32, 'n_steps': 12, 'gamma': 1.0738312723662176, 'n_independent': 4, 'n_shared': 7, 'lambda_sparse': 0.010798155422718187}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_auc = 0.81388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:40:43,341]\u001B[0m Trial 18 finished with value: 0.813884297520661 and parameters: {'n_d': 46, 'n_a': 57, 'n_steps': 3, 'gamma': 0.6188232969074567, 'n_independent': 8, 'n_shared': 1, 'lambda_sparse': 0.026253879903919735}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_auc = 0.79306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:41:26,495]\u001B[0m Trial 19 finished with value: 0.7930578512396694 and parameters: {'n_d': 57, 'n_a': 41, 'n_steps': 8, 'gamma': 0.4332305392220982, 'n_independent': 3, 'n_shared': 9, 'lambda_sparse': 0.05381296417723659}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_auc = 0.79438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:42:08,778]\u001B[0m Trial 20 finished with value: 0.794380165289256 and parameters: {'n_d': 43, 'n_a': 25, 'n_steps': 14, 'gamma': 0.7405073419175054, 'n_independent': 2, 'n_shared': 7, 'lambda_sparse': 0.008115743780398962}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_auc = 0.80198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001B[32m[I 2023-11-02 20:42:20,244]\u001B[0m Trial 21 finished with value: 0.8019834710743802 and parameters: {'n_d': 8, 'n_a': 9, 'n_steps': 7, 'gamma': 0.30268512254752766, 'n_independent': 4, 'n_shared': 7, 'lambda_sparse': 0.030767706218689916}. Best is trial 3 with value: 0.8651239669421488.\u001B[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:651: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.32213 |  0:00:01s\n",
      "epoch 1  | loss: 1.26097 |  0:00:02s\n",
      "epoch 2  | loss: 0.95942 |  0:00:03s\n",
      "epoch 3  | loss: 0.94047 |  0:00:05s\n",
      "epoch 4  | loss: 0.79564 |  0:00:06s\n",
      "epoch 5  | loss: 0.73614 |  0:00:07s\n",
      "epoch 6  | loss: 0.71793 |  0:00:09s\n",
      "epoch 7  | loss: 0.69615 |  0:00:10s\n",
      "epoch 8  | loss: 0.67746 |  0:00:11s\n",
      "epoch 9  | loss: 0.63692 |  0:00:13s\n",
      "epoch 10 | loss: 0.66259 |  0:00:14s\n",
      "epoch 11 | loss: 0.63393 |  0:00:15s\n",
      "epoch 12 | loss: 0.64111 |  0:00:16s\n",
      "epoch 13 | loss: 0.63536 |  0:00:18s\n",
      "epoch 14 | loss: 0.63283 |  0:00:19s\n",
      "epoch 15 | loss: 0.62116 |  0:00:20s\n",
      "epoch 16 | loss: 0.61687 |  0:00:22s\n",
      "epoch 17 | loss: 0.6159  |  0:00:23s\n",
      "epoch 18 | loss: 0.61095 |  0:00:24s\n",
      "epoch 19 | loss: 0.61077 |  0:00:25s\n",
      "epoch 20 | loss: 0.60469 |  0:00:27s\n",
      "epoch 21 | loss: 0.61229 |  0:00:28s\n",
      "epoch 22 | loss: 0.59387 |  0:00:29s\n",
      "epoch 23 | loss: 0.60026 |  0:00:31s\n",
      "epoch 24 | loss: 0.59066 |  0:00:32s\n",
      "epoch 25 | loss: 0.58936 |  0:00:33s\n",
      "epoch 26 | loss: 0.58519 |  0:00:34s\n",
      "epoch 27 | loss: 0.58204 |  0:00:36s\n",
      "epoch 28 | loss: 0.58306 |  0:00:37s\n",
      "epoch 29 | loss: 0.57931 |  0:00:38s\n",
      "epoch 30 | loss: 0.57599 |  0:00:40s\n",
      "epoch 31 | loss: 0.57409 |  0:00:41s\n",
      "epoch 32 | loss: 0.56629 |  0:00:42s\n",
      "epoch 33 | loss: 0.56998 |  0:00:43s\n",
      "epoch 34 | loss: 0.5742  |  0:00:45s\n",
      "epoch 35 | loss: 0.57423 |  0:00:46s\n",
      "epoch 36 | loss: 0.55439 |  0:00:47s\n",
      "epoch 37 | loss: 0.55324 |  0:00:49s\n",
      "epoch 38 | loss: 0.54918 |  0:00:50s\n",
      "epoch 39 | loss: 0.55059 |  0:00:51s\n",
      "epoch 40 | loss: 0.53964 |  0:00:52s\n",
      "epoch 41 | loss: 0.54579 |  0:00:54s\n",
      "epoch 42 | loss: 0.54169 |  0:00:55s\n",
      "epoch 43 | loss: 0.51957 |  0:00:56s\n",
      "epoch 44 | loss: 0.53167 |  0:00:58s\n",
      "epoch 45 | loss: 0.53524 |  0:00:59s\n",
      "epoch 46 | loss: 0.53144 |  0:01:00s\n",
      "epoch 47 | loss: 0.54993 |  0:01:01s\n",
      "epoch 48 | loss: 0.56674 |  0:01:03s\n",
      "epoch 49 | loss: 0.54771 |  0:01:04s\n",
      "epoch 50 | loss: 0.56379 |  0:01:05s\n",
      "epoch 51 | loss: 0.5735  |  0:01:07s\n",
      "epoch 52 | loss: 0.54004 |  0:01:08s\n",
      "epoch 53 | loss: 0.52926 |  0:01:09s\n",
      "epoch 54 | loss: 0.53141 |  0:01:11s\n",
      "epoch 55 | loss: 0.52819 |  0:01:12s\n",
      "epoch 56 | loss: 0.50356 |  0:01:13s\n",
      "epoch 57 | loss: 0.48913 |  0:01:14s\n",
      "epoch 58 | loss: 0.4903  |  0:01:16s\n",
      "epoch 59 | loss: 0.47625 |  0:01:17s\n",
      "epoch 60 | loss: 0.46691 |  0:01:18s\n",
      "epoch 61 | loss: 0.44612 |  0:01:20s\n",
      "epoch 62 | loss: 0.44374 |  0:01:21s\n",
      "epoch 63 | loss: 0.44299 |  0:01:22s\n",
      "epoch 64 | loss: 0.4256  |  0:01:24s\n",
      "epoch 65 | loss: 0.42304 |  0:01:25s\n",
      "epoch 66 | loss: 0.40401 |  0:01:26s\n",
      "epoch 67 | loss: 0.41698 |  0:01:27s\n",
      "epoch 68 | loss: 0.41148 |  0:01:29s\n",
      "epoch 69 | loss: 0.40747 |  0:01:30s\n",
      "epoch 70 | loss: 0.41863 |  0:01:31s\n",
      "epoch 71 | loss: 0.41286 |  0:01:32s\n",
      "epoch 72 | loss: 0.40353 |  0:01:34s\n",
      "epoch 73 | loss: 0.38477 |  0:01:35s\n",
      "epoch 74 | loss: 0.36832 |  0:01:36s\n",
      "epoch 75 | loss: 0.36895 |  0:01:38s\n",
      "epoch 76 | loss: 0.35822 |  0:01:39s\n",
      "epoch 77 | loss: 0.36135 |  0:01:40s\n",
      "epoch 78 | loss: 0.34461 |  0:01:42s\n",
      "epoch 79 | loss: 0.3478  |  0:01:43s\n",
      "epoch 80 | loss: 0.34229 |  0:01:44s\n",
      "epoch 81 | loss: 0.3411  |  0:01:45s\n",
      "epoch 82 | loss: 0.3282  |  0:01:47s\n",
      "epoch 83 | loss: 0.32349 |  0:01:48s\n",
      "epoch 84 | loss: 0.30645 |  0:01:49s\n",
      "epoch 85 | loss: 0.31364 |  0:01:50s\n",
      "epoch 86 | loss: 0.28855 |  0:01:52s\n",
      "epoch 87 | loss: 0.31012 |  0:01:53s\n",
      "epoch 88 | loss: 0.30892 |  0:01:54s\n",
      "epoch 89 | loss: 0.30618 |  0:01:56s\n",
      "epoch 90 | loss: 0.29836 |  0:01:57s\n",
      "epoch 91 | loss: 0.30413 |  0:01:58s\n",
      "epoch 92 | loss: 0.30053 |  0:02:00s\n",
      "epoch 93 | loss: 0.28719 |  0:02:01s\n",
      "epoch 94 | loss: 0.29082 |  0:02:02s\n",
      "epoch 95 | loss: 0.29836 |  0:02:03s\n",
      "epoch 96 | loss: 0.271   |  0:02:05s\n",
      "epoch 97 | loss: 0.27579 |  0:02:06s\n",
      "epoch 98 | loss: 0.26725 |  0:02:07s\n",
      "epoch 99 | loss: 0.2567  |  0:02:09s\n",
      "Eval TABNET\n",
      "Accuracy: 0.58\n",
      "Precision: 0.59\n",
      "Recall: 0.55\n",
      "F1-score: 0.57\n",
      "ROC-AUC score: 0.58\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABNET Average accuracy: 0.6514\n",
      "TABNET Average confusion matrix: [[38.23529412 21.55882353]\n",
      " [20.11764706 39.67647059]]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Initialize LeaveOneSubjectOut cross-validator\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Function to perform LOSO CV and return average accuracy\n",
    "def evaluate_tabnet(X, y, groups):\n",
    "    tabnet_accuracies = {}\n",
    "    tabnet_confusion_matricies = {}\n",
    "    tabnet_confidence_intervals = {}\n",
    "    tabnet_models = {}\n",
    "\n",
    "    for train_index, test_index in logo.split(X, y, groups):\n",
    "        # Extract indices for training and testing data for each participant\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # fill inf values with the mean of the column\n",
    "        X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "        X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "        X_train = X_train.fillna(X_train.mean()) # fill missing values with the mean of the column or zero ? features_df.mean()\n",
    "        X_test = X_test.fillna(X_train.mean())\n",
    "        \n",
    "        # Scale the data\n",
    "        # Create separate StandardScaler instances\n",
    "        scaler_x = StandardScaler()\n",
    "        # Fit on Training Data (!)\n",
    "        scaler_x.fit(X_train.values)\n",
    "        # Transform both training and testing data\n",
    "        X_train_scaled = scaler_x.transform(X_train.values)\n",
    "        X_test_scaled = scaler_x.transform(X_test.values)\n",
    "        y_train = y_train.values.reshape(-1, 1).flatten()\n",
    "        y_test = y_test.values.reshape(-1, 1).flatten()\n",
    "        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "        \n",
    "        # TABNET\n",
    "        # Convert Pandas DataFrame to NumPy array\n",
    "        X_train_np = X_train_scaled.values\n",
    "        X_test_np = X_test_scaled.values\n",
    "        \n",
    "        # Define objective function for optuna\n",
    "        def objective(trial):\n",
    "            # Generate hyperparameter search space\n",
    "            params = {\n",
    "                'n_d': trial.suggest_int('n_d', 8, 64),\n",
    "                'n_a': trial.suggest_int('n_a', 8, 64),\n",
    "                'n_steps': trial.suggest_int('n_steps', 1, 19),\n",
    "                'gamma': trial.suggest_float('gamma', 0.1, 2.0),\n",
    "                'n_independent': trial.suggest_int('n_independent', 1, 10),\n",
    "                'n_shared': trial.suggest_int('n_shared', 1, 10),\n",
    "                'lambda_sparse': trial.suggest_float('lambda_sparse', 0.0001, 0.1),\n",
    "                # 'optimizer_fn': torch.optim.Adam,\n",
    "                # 'optimizer_params': dict(lr=2e-2, weight_decay=1e-5),\n",
    "                # 'mask_type': 'entmax',\n",
    "                # 'scheduler_params': dict(mode=\"min\", patience=5, min_lr=1e-5, factor=0.9,),\n",
    "                # 'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                'verbose': 0\n",
    "            }\n",
    "        \n",
    "            # Create TabNetClassifier object with hyperparameters from optuna\n",
    "            classifier = TabNetClassifier(**params)\n",
    "        \n",
    "            # Train and evaluate the model\n",
    "            classifier.fit(X_train_np, y_train, eval_set=[(X_test_np, y_test)])\n",
    "            val_preds = classifier.predict_proba(X_test_np)[:, 1]\n",
    "            val_auc = roc_auc_score(y_test, val_preds)\n",
    "        \n",
    "            return val_auc\n",
    "        \n",
    "        # Create optuna study\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        \n",
    "        # Optimize hyperparameters using optuna\n",
    "        study.optimize(objective, n_trials=42, timeout=600)\n",
    "        \n",
    "        # Get best hyperparameters from optuna\n",
    "        best_params = study.best_trial.params\n",
    "        print('Best trial: score {},\\nparams {}'.format(study.best_trial.value, study.best_trial.params))\n",
    "        \n",
    "        # Train final model with best hyperparameters\n",
    "        tabnet = TabNetClassifier(**best_params)\n",
    "        tabnet.fit(X_train_np, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = tabnet.predict(X_test_np)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Store the results for this fold using subject name as key\n",
    "        subject_name = groups[test_index[0]]\n",
    "        tabnet_accuracies[subject_name] = acc\n",
    "        conf_mat = evaluate_model(f\"Tabnet on {subject_name}\", y_test, y_pred)\n",
    "        tabnet_confusion_matricies[subject_name] = conf_mat\n",
    "        tabnet_models[subject_name] = tabnet\n",
    "        tabnet_confidence_intervals[subject_name] = (acc - 1.96 * np.sqrt(acc * (1 - acc) / len(y_test)), acc + 1.96 * np.sqrt(acc * (1 - acc) / len(y_test)))\n",
    "        \n",
    "    # return all the computed dictionaries\n",
    "    return tabnet_accuracies, tabnet_confusion_matricies, tabnet_confidence_intervals, tabnet_models\n",
    "\n",
    "# Evaluate\n",
    "tabnet_acc, tabnet_confusion_matricies, tabnet_confidence_intervals, tabnet_models = evaluate_tabnet(features_df, labels_df, groups)\n",
    "\n",
    "tabnet_avg_confusion_matrix = np.mean(list(tabnet_confusion_matricies.values()), axis=0)\n",
    "tabnet_avg_acc = np.mean(list(tabnet_acc.values())) \n",
    "\n",
    "print(f\"Tabnet Average accuracy: {tabnet_avg_acc:.4f}\")\n",
    "print(f\"Tabnet   Average confusion matrix: {tabnet_avg_confusion_matrix}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T18:44:30.361941500Z",
     "start_time": "2023-11-02T11:29:18.298622100Z"
    }
   },
   "id": "b7bc84bfe773d9d3"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdcAAAHsCAYAAACAOeevAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAytUlEQVR4nO3de1RVdd7H8c/hIKhcRKO00jHQKLuoMWmZeUlFTSXv4o2mMMuyCC+B4I0eTHBstNTStJwaL3Emx1GzdEZNx6YxpywrK9NRM2+ReAU0Lp79/NEz55ESztE2bN28X2udtdicvX/7d1itvn6+v733cRiGYQgAAJjGz+oJAABgNxRXAABMRnEFAMBkFFcAAExGcQUAwGQUVwAATEZxhemKi4t177336pFHHrF6KhelsLBQL7zwgnr16qWePXsqNjZW8+fP16+5Wy0/P18DBw5U9+7d9fe///2ij9+wYYOmTJlyyef/uZtuukkdOnT4xWeaPXu2brrpJn3xxRflHn/gwAE99dRTF3wvJydHAwcONG2uwJXM3+oJwH7WrVunm2++WTt27NCePXvUqFEjq6fklWEYeuKJJxQRESGXy6XAwECdOHFCjz32mM6cOaOkpKRLGvfrr7/WsWPHtG7duks6vmPHjurYseMlHVsWwzD08ccfq0WLFp7tNWvWqFatWl6PPXz4sPbt23fB9+rWravs7GxT5wpcqUiuMN2bb76pjh07qlu3bnrjjTd07tw5tWvXTjt27PDsk5SUpKVLl0qS5s6dq969e6tnz5564oknlJOTI0mKj4/Xk08+qW7dumnRokXavn27hgwZov79+6t9+/ZKS0vzjLd8+XJ17dpVvXr1UlZWlm655RbPe2WNf76PPvpIe/fuVWpqqgIDAyVJtWvX1u9//3tPEfr+++81YsQIxcbGqkePHnr11VclSQcPHlSnTp2UkZGhfv36qXPnzlq3bp327t2rtLQ05eTkqGfPntqzZ4/uuOMOzzkPHjzo2T569KgSEhLUu3dv9e7dWy+88ILncz322GOXdP6yPPDAA1q1apVne9u2bWrcuLGCg4M9v5s3b5769++v2NhYderUSevWrdO5c+c0YcIEfffddxo2bJgOHjyodu3aKSEhQV26dNGnn37q+Typqal6+umnJUm7d+9Wq1attGfPnjLnBNiOAZho9+7dxq233mocP37c+Oyzz4ymTZsax48fN1588UXj2WefNQzDME6ePGm0bNnSOH36tPHXv/7VSEpKMoqLiw3DMIzs7GzjkUceMQzDMIYOHWqkpqZ6xh41apTx4YcfGoZhGPn5+cZdd91lfPHFF8bu3buNVq1aGUeOHDEMwzBmz55tREVFGYZhlDv++V577TUjMTGx3M82ZMgQY+HChYZhGMbp06eN2NhYY/Xq1caBAweMqKgo47333jMMwzDWrl1rtG/f3jAMw/jwww+N7t27G4ZhGAcOHDCaN2/uGe/87Tlz5hgTJ040DMMwCgoKjKSkJOP06dPGX/7yF+PRRx+95PP/XFRUlLFr1y7jrrvuMgoLCw3DMIy0tDTjvffeM+677z7j888/Nw4ePGjEx8cbZ8+eNQzDMFavXm306NHjgp8nKirK+Oijj37xeQoKCozOnTsby5cvN7p3726sXLmy3L8tYDe0hWGqN998U/fdd59q166t2rVrq379+vrzn/+svn37ql+/fho3bpxWr16tDh06KCQkRBs3btQXX3yhvn37SpLcbrfOnj3rGe/OO+/0/JyVlaXNmzdr3rx52rt3rwoLC3XmzBl9/PHHat26terVqydJGjp0qGbPni1JXsf/Lz8/v3LXVs+cOaNPPvlECxculCSFhISoT58+2rx5s5o1a6Zq1aqpXbt2kqRbbrlFJ0+evKi/W5s2bfToo4/qyJEjuueeezRmzBiFhIRUyPmvuuoqNW3aVBs3blS7du308ccf69lnn/W8f/311+v3v/+93n77be3fv1+fffaZCgoKLjiWv7+/mjdv/ovf16xZUzNnztSAAQP0wAMP6IEHHriovwdwpaO4wjRnzpzRypUrFRAQoA4dOkj66YKexYsXKyEhQbfccos2bdqk5cuXe1q6brdbjzzyiAYPHixJKioq0qlTpzxj1qxZ0/Pz0KFDddNNN6lNmza6//779dlnn8kwDDmdzlKF0el0en72Nv5/NWvWzNPCPv/4zz//XIsWLdLkyZN/UXzdbrdKSkokSdWqVZOf30+rLA6H44J/H4fDUWqM4uJiz89NmzbVhg0btGXLFn344Yfq37+/FixYUOpcv/b85+vVq5dWrVqloqIidejQQf7+//+/gi+//FJPPPGEHnroIbVu3VotWrQoVXzPFxAQUOrY8+3bt09hYWH6+uuvVVRUpICAAK/zAuyCNVeY5u2331ZYWJjef/99vffee3rvvfe0fv16nTlzRmvXrtWAAQO0YMECnT17Vr/97W8lSffee6+WLVum/Px8SdKLL76o5OTkX4x9+vRpffHFFxo7dqw6d+6s77//Xt99953cbrfuvfdebdmyxbOW+tZbb3mO83X8O+64Q5GRkcrMzFRhYaEkKTc3V1OmTFH9+vUVHBysZs2aacmSJZKkvLw8rVixQvfcc4/Pf5/Q0FAVFxfrP//5jyTpnXfe8bz3/PPP6+WXX1anTp00fvx4NW7cWLt37/a8b8b5z9exY0d9+umnWrJkiXr37l3qvY8++ki33XabHn74YbVs2VIbNmzQuXPnJP30D5fz/1FQloMHD+q5557TwoULFRkZqeeff/6S5glcqSiuMM2bb76phx9+uFTyCw0NVXx8vF5//XV16NBBhw4dUv/+/T3v//fipAEDBqh79+765ptvlJWV9YuxQ0ND9eijj6p3797q0aOH5s+fr+joaO3fv18RERFKTU3VsGHD1KdPH+3Zs0c1atS4qPEladasWZKkPn366IEHHtBDDz2kzp07KzExUdJPBXDLli2KjY31XDjUp08fn/8+ISEheuaZZzR8+HD17dvXc+GUJP3ud7/Tzp071aNHD/Xt21f169dX9+7dSx3/a89/vsDAQHXo0EFFRUWKiooq9V6PHj104sQJ3X///erWrZtq1qypU6dOKT8/X40bN1ZgYKD69etXZhu9pKREY8aM0bBhwxQVFaVJkyZp7dq12rRp0yXNFbgSOYzyFpqAK8CBAwe0cuVKPfHEE/Lz89Pf//53LViwoFSCBYDKxJorrnj16tXTDz/8oNjYWDmdToWEhGjq1KlWTwtAFUZyBQDAZKy5AgCqnGPHjqldu3bas2eP9u/fr0GDBmnw4MGaPHmy3G53qX3dbrcmTZqkuLg4xcfHa//+/V7Hp7gCAKqU4uJiTZo0SdWrV5ckZWZmep4aZxiGNmzYUGr/9evXq6ioSC6XS2PGjCnzosjzUVwBAFXKtGnTNHDgQF1zzTWSfrq3u2XLlpKktm3b6l//+lep/bdt26Y2bdpIkpo3b17qUa5luewuaKrRfZbVUwBMsXvxCKunAPxq9WtX3MM/atzxpOljvj6ujVwul2c7Li5OcXFxnu3ly5erTp06atOmjebPny/ppy+v+O/DV4KCgpSXl1dqzPz8/FLP3nY6nSopKSnzASrSZVhcAQC4VD8vpj/3l7/8RQ6HQ1u2bNHXX3+tlJQUHT9+3PN+QUGBQkNDSx0THBxc6hGgbre73MIq0RYGAFjF4Wf+y4slS5Zo8eLFWrRokZo0aaJp06apbdu22rp1qyRp8+bNpZ5pLknR0dHavHmzJGn79u2/ePDKhVBcAQDWcDjMf12ClJQUzZ49W3FxcSouLlaXLl0kScnJyTp8+LBiYmIUEBCggQMHKjMzU6mpqd4/2uV2nytrrrAL1lxhBxW65vrbp00f8+y2F00f81Kw5goAsIYPbdwrlX0/GQAAFiG5AgCscYlrpFcCiisAwBq0hQEAgK9IrgAAa9i4LUxyBQDAZCRXAIA1WHMFAAC+IrkCAKxh4zVXiisAwBq0hQEAgK9IrgAAa9i4LUxyBQDAZCRXAIA1bLzmSnEFAFiDtjAAAPAVyRUAYA0bt4Xt+8kAALAIyRUAYA0bJ1eKKwDAGn5c0AQAAHxEcgUAWMPGbWH7fjIAACxCcgUAWMPGD5GguAIArEFbGAAA+IrkCgCwho3bwiRXAABMRnIFAFiDNVcAAOArkisAwBo2XnOluAIArEFbGAAA+IrkCgCwho3bwiRXAABMRnIFAFjDxmuuFFcAgDVoCwMAAF+RXAEA1rBxW9i+nwwAAIuQXAEA1rBxcqW4AgCswQVNAADAVyRXAIA1bNwWtu8nAwDAIiRXAIA1LFhzPXfunCZMmKB9+/bJ6XQqMzNTM2fOVG5uriTp0KFDatasmWbOnFnquF69eikkJESSVL9+fWVmZpZ7HoorAKDK2LhxoyQpOztbW7duVWZmpubOnStJOnXqlB588EGlpqaWOqawsFCStGjRIp/PQ3EFAFjDgjXXTp06qX379pKkw4cPKzw83PPe7NmzNXToUF1zzTWljtm5c6fOnj2rhIQElZSUaPTo0WrevHm556G4AgCsUQFtYZfLJZfL5dmOi4tTXFxcqX38/f2VkpKidevWadasWZKkY8eOacuWLb9IrZJUvXp1DRs2TP3799e3336r4cOHa+3atfL3L7uEUlwBALZxoWJ6IdOmTdPYsWM1YMAAvfPOO1q7dq169Oghp9P5i30jIiLUsGFDORwORUREKCwsTEePHtW1115b5vhcLQwAsITD4TD95c2KFSv0yiuvSJJq1Kghh8Mhp9OpLVu2qG3bthc8ZtmyZcrKypIk5eTkKD8/X1dffXW556G4AgCqjM6dO+urr77SkCFDNGzYMKWlpSkwMFD79u1TgwYNSu2bnJysw4cPq1+/fsrLy9OgQYM0atQoTZ06tdyWsCQ5DMMwKvKDXKwa3WdZPQXAFLsXj7B6CsCvVr92QIWNHdTvj6aPWbDsYdPHvBSsuQIArGHfRwvTFgYAwGwkVwCAJXy5AOlKRXIFAMBkJFcAgCXsnFwprgAAS9i5uNIWBgDAZCRXAIAlSK4AAMBnJFcAgDXsG1xJrgAAmI3kCgCwhJ3XXCmuAABL2Lm40hYGAMBkJFcAgCVIrgAAwGckVwCAJeycXCmuAABr2Le20hYGAMBsJFcAgCXs3BYmuQIAYDKSKwDAEnZOrhRXAIAl7FxcaQsDAGAykisAwBr2Da4kVwAAzEZyBQBYgjVXAADgM5IrAMASdk6uFFcAgCXsXFxpCwMAYDKSKwDAEiRXAADgM5IrAMAa9g2uFFcAgDVoCwMAAJ+RXAEAliC5AgAAn5FcAQCWsHNypbgCAKxh39pKWxgAALORXAEAlrBzW5jkCgCAyUiuAABLkFwBAIDPSK425+fn0MtPdVBU/do65zb06Mz1CqlZTbNHdlDJObd2Hzqhx2dtkGFYPVOgfCUlxZo+ZZK+P3JYxcVFGvrQo7qm3rWa/YdMOf38VC0gQCmTnlOdq8Ktnip8ZOfkSnG1ue4tIyRJHZ5Zpja3X69pw9vIcBua+uZW/e3j/frj2M66v0WE3v33PotnCpRv/drVCq0VptT0TJ06dVIjHuyvetddr6fGpKpx1M16+69/VvaihXoiKdnqqcJHVhTXc+fOacKECdq3b5+cTqcyMzOVl5enESNG6IYbbpAkDRo0SN26dfMc43a7lZ6erm+++UYBAQGaMmWKGjZsWO55KK429/aHez2F8zfXhOiHk2d0KDdftUOqS5KCawao+JzbyikCPmnXoYva3tfZs+10OjUhY7quCr9a0k//0wwIDLRqerhCbNy4UZKUnZ2trVu3KjMzUx06dNDDDz+shISECx6zfv16FRUVyeVyafv27crKytLcuXPLPU+FFle32y0/P5Z1rXbObWjBqBg9cE8jDZ76rq4Kra6Zj7fXuLgWOn2mSJs/P2j1FAGvatSsKUk6U1CgZ1NH6+HHnvIU1i8/366Vb72pmfNet3CGuGgWdIU7deqk9u3bS5IOHz6s8PBw7dixQ/v27dOGDRvUsGFDpaWlKTg42HPMtm3b1KZNG0lS8+bNtWPHDq/nMb24HjhwQJmZmdqxY4f8/f3ldrsVFRWl1NRURUREmH06+Gj4zHWa8PoH2jxjgGoEVlOn5GX6+rvjeqx7U2U90kaj5m6yeoqAVz/kfK/JKU/rgb4D1bFLd0nSxnVrteT1+XpuxksKq13H4hniSuDv76+UlBStW7dOs2bNUk5Ojvr376/bbrtNc+fO1UsvvaSUlBTP/vn5+aWKrdPpVElJifz9yy6hphfX8ePHa8yYMWrWrJnnd9u3b1dqaqqys7PNPh28GHTfzbo+PFjPv/WxzvxYIrfb0PHTZ5V3pkiSdOR4vlrdcq3FswS8O34sVymJj+qpsWmKbnG3JGndmre1esUyzXj5jwqtVcviGeJiVcSaq8vlksvl8mzHxcUpLi7uF/tNmzZNY8eO1YABA5Sdna26detKkmJiYpSRkVFq3+DgYBUUFHi23W53uYVVqoDiWlRUVKqwSj/FaFhj5b/+o/mjYrRuWl9Vc/rpmQXv6/jps/pTSleVnDNUVHJOT8zaYPU0Aa+WvvGq8vJOa/HCV7R44Ss653br2727VbfedUoflyRJahp9px4aPtLaicJnFVFcyyqm/7VixQrl5OToscceU40aNeRwOPTkk09q4sSJatq0qbZs2aJbb7211DHR0dHauHGjunXrpu3btysqKsrrPByGYe5NGJMnT1ZRUZHatGmjkJAQFRQU6B//+IcCAgL07LPPej2+RvdZZk4HsMzuxSOsngLwq9WvHVBhYzcas8b0Mff84f5y3z9z5oxSU1OVm5urkpISDR8+XNdee60yMjJUrVo1hYeHKyMjQ8HBwUpOTlZSUpLq1aun9PR07dq1S4ZhaOrUqWrUqFG55zG9uBqGofXr12vbtm2ePnV0dLRiYmJ8+lcKxRV2QXGFHVRkcW081vzi+p/nyy+ulcX0trDD4VBMTIxiYmLMHhoAgCsC97kCACzBE5oAADCZjWsrD+4HAMBsJFcAgCXs3BYmuQIAYDKSKwDAEjYOriRXAADMRnIFAFjCz8++0ZXiCgCwBG1hAADgM5IrAMAS3IoDAAB8RnIFAFjCxsGV4goAsAZtYQAA4DOSKwDAEiRXAADgM5IrAMASNg6uFFcAgDVoCwMAAJ+RXAEAlrBxcCW5AgBgNpIrAMASrLkCAACfkVwBAJawcXCluAIArEFbGAAA+IzkCgCwhI2DK8kVAACzkVwBAJaw85orxRUAYAkb11bawgAAmI3kCgCwhJ3bwiRXAABMRnIFAFjCxsGV4goAsAZtYQAA4DOSKwDAEjYOriRXAADMRnIFAFiCNVcAAOAzkisAwBJ2Tq4UVwCAJWxcW2kLAwBgNpIrAMASdm4Lk1wBADAZyRUAYAkrguu5c+c0YcIE7du3T06nU5mZmSooKFBGRoacTqcCAgI0bdo0hYeHlzquV69eCgkJkSTVr19fmZmZ5Z6H4goAsIQVbeGNGzdKkrKzs7V161ZlZmYqLy9PEydOVJMmTZSdna0FCxYoNTXVc0xhYaEkadGiRT6fh+IKAKgyOnXqpPbt20uSDh8+rPDwcD377LO65pprJP2UbAMDA0sds3PnTp09e1YJCQkqKSnR6NGj1bx583LPQ3EFAFiiIoKry+WSy+XybMfFxSkuLq7UPv7+/kpJSdG6des0a9YsT2H95JNPtHjxYi1ZsqTU/tWrV9ewYcPUv39/ffvttxo+fLjWrl0rf/+ySyjFFQBgGxcqphcybdo0jR07VgMGDNA777yjTZs2ae7cuZo/f77q1KlTat+IiAg1bNhQDodDERERCgsL09GjR3XttdeWOT5XCwMALOHncJj+8mbFihV65ZVXJEk1atSQw+HQunXrtHjxYi1atEgNGjT4xTHLli1TVlaWJCknJ0f5+fm6+uqry/9sl/D3AADgV3M4zH9507lzZ3311VcaMmSIhg0bprS0ND333HMqKCjQU089pfj4eM2aNUuSlJycrMOHD6tfv37Ky8vToEGDNGrUKE2dOrXclrAkOQzDMMz4I5mlRvdZVk8BMMXuxSOsngLwq9WvHVBhY3d+6UPTx/z7yLtNH/NSsOYKALAET2gCAAA+I7kCACzhZ9/gSnEFAFiDtjAAAPAZyRUAYAkbB1eSKwAAZiO5AgAs4ZB9oyvJFQAAk5FcAQCW4FYcAABMxq04AADAZyRXAIAlbBxcSa4AAJiN5AoAsIQvX25+paK4AgAsYePaSlsYAACzkVwBAJbgVhwAAOAzkisAwBI2Dq4UVwCANex8tTBtYQAATEZyBQBYwr65leQKAIDpLiq5ut1u+flRjwEAv16VvhVnzZo1euedd/TXv/5VrVu31muvvVYZ8wIA4IrltbguXLhQ99xzj1atWqV//OMf2rhxY2XMCwBgc34O81+XC69t4cDAQElSUFCQAgICVFBQUOGTAgDYX5VuC9evX199+/ZV3759NWfOHDVt2rQy5gUAwBXLa3LNyspSQUGBgoKCdPvttys8PLwy5gUAsDkbB9eyi+vo0aPLjOx/+MMfKmxCAABc6cosrgMHDqzMeQAAqhg7r7mWWVxbtmwpScrPz9eCBQt09OhRtW/fXjfddFOlTQ4AYF+X09W9ZvN6QVNaWpoaNGigb7/9VuHh4Ro/fnxlzAsAgCuW1+J68uRJ9evXT/7+/oqOjpZhGJUxLwCAzTkcDtNflwufnmW4Z88eSdL333/P4w8BAPDC6604EyZMUFpamvbs2aPExERNnjy5MuYFALC5yydnms9rcY2KitLcuXN16NAhNWzYUKGhoZUxLwCAzVXpL0tftmyZBg8erFdeeUVxcXF69913K2NeAABcsbwm1+zsbK1cuVKBgYE6c+aMfve736lbt26VMTcAgI3ZOLh6T65hYWHy9/+pBlevXp22MAAAXnh9/OHx48fVp08fNWvWTF999ZWqV69emfMDANjU5XTrjNku6vGHPXr0qNDJAABgB14ff3jy5En985//VElJiQzD0A8//OB5DwCAS2Xj4Or9gqbExETdcMMN2rVrlwIDA1WjRo3KmBcAwOaq9K04kvQ///M/ioiI0B//+EedOnWqoucEAMAVzWtylaTCwkKdPXtWDodDZ86cqeg5AQCqACuC67lz5zRhwgTt27dPTqdTmZmZMgxD48aNk8Ph0I033qjJkyeXetSv2+1Wenq6vvnmGwUEBGjKlClq2LBhuefxmlyHDBmiN954Q61bt1a7du0UGRn56z8dAAAW2Lhxo6SfnuGQmJiozMxMZWZmKikpSUuXLpVhGNqwYUOpY9avX6+ioiK5XC6NGTNGWVlZXs/jNbl26dLF8/P999+v3Nzci/0sAAD8ghW34nTq1Ent27eXJB0+fFjh4eHatGmT50Ldtm3b6oMPPlBMTIznmG3btqlNmzaSpObNm2vHjh1ez+NTW/i/goOD9dBDD2nZsmUXc9hFObEyscLGBipT7RZPWj0F4Fc7++mcChu7Ir5jzeVyyeVyebbj4uIUFxdXah9/f3+lpKRo3bp1mjVrljZu3Ogp9EFBQcrLyyu1f35+voKDgz3bTqdTJSUlngcsXchFFVdJfJ8rAOCydaFieiHTpk3T2LFjNWDAABUWFnp+X1BQ8IsnEQYHB6ugoMCz7Xa7yy2s0iX8w8HOT9QAAFQeK74sfcWKFXrllVckSTVq1JDD4dBtt92mrVu3SpI2b96sO++8s9Qx0dHR2rx5syRp+/btioqK8noer48/PJ9hGDpw4IDXQQEAuBx17txZqampGjJkiEpKSpSWlqZGjRpp4sSJmjFjhiIjIz3XGiUnJyspKUkxMTH64IMPNHDgQBmGoalTp3o9j8Moo8/773//u8yDKvIJTT+WVNjQQKVizRV2UJFrrkkrd5o+5gs9bzZ9zEvh9fGHAABUBD8brzJWxMVaAABUaRd9tTAAAGaw8wWyXotrTk6Opk+frhMnTqhLly666aab1KxZs8qYGwAAVySvbeGJEyeqb9++Kioq0p133qnnnnuuMuYFALA5P4f5r8uF1+JaWFioVq1ayeFwKDIyUoGBgZUxLwAArlhe28IBAQF6//335Xa7tX37dgUEBFTGvAAANmfjJVfvyTUjI0PLly/XiRMntHDhQqWnp1fCtAAAdufncJj+ulx4Ta716tXTzJkzK2MuAADYgtfieu+993p+PnnypBo0aKA1a9ZU6KQAAPZn5wcteC2u//znPz0/Hzp0SHPmVNyjsAAAsIOLeojE9ddfr71791bUXAAAVchltERqOq/F9fxvx/nhhx901VVXVfikAAD2dzldgGQ2r8W1W7duni+ODQwM1G233VbhkwIA4Ermtbi+9tprevPNNytjLgCAKsTGwdV7ca1Vq5beeOMNRUREyM/vp2u7zr+CGAAAlOa1uNauXVs7d+7Uzp3//6W2FFcAwK91OT0L2GxlFtekpCS98MILyszMrMz5AACqCDtf0FTmPbzHjx+vzHkAAGAbZSbXAwcOaMaMGRd8b/To0RU2IQBA1WDj4Fp2ca1evboiIiIqcy4AANhCmcU1PDxcvXv3rsy5AACqEDtf0FTmmisPiwAA4NKUmVxTUlIqcx4AgCrGIftG14t6cD8AAGapkm1hAABwaUiuAABLkFwBAIDPSK4AAEs4bPwUCYorAMAStIUBAIDPSK4AAEvYuCtMcgUAwGwkVwCAJez8fa4UVwCAJbigCQAA+IzkCgCwhI27wiRXAADMRnIFAFjCz8ZfOUdyBQDAZCRXAIAl7LzmSnEFAFiCW3EAAIDPSK4AAEvY+QlNJFcAAExGcgUAWMLGwZXiCgCwhp3bwhRXAECVUVxcrLS0NB06dEhFRUV6/PHHtXr1auXm5kqSDh06pGbNmmnmzJmljuvVq5dCQkIkSfXr11dmZma556G4AgAsYUVwXbVqlcLCwjR9+nSdOHFCvXv31qZNmyRJp06d0oMPPqjU1NRSxxQWFkqSFi1a5PN5KK4AgCqja9eu6tKli2fb6XR6fp49e7aGDh2qa665ptQxO3fu1NmzZ5WQkKCSkhKNHj1azZs3L/c8FFcAgCUq4nYVl8sll8vl2Y6Li1NcXJxnOygoSJKUn5+vxMREJSUlSZKOHTumLVu2/CK1SlL16tU1bNgw9e/fX99++62GDx+utWvXyt+/7BJKcQUAWMJRAX3hnxfTCzly5IhGjhypwYMHKzY2VpK0du1a9ejRo1SS/a+IiAg1bNhQDodDERERCgsL09GjR3XttdeWeQ7ucwUAVBm5ublKSEjQM888o379+nl+v2XLFrVt2/aCxyxbtkxZWVmSpJycHOXn5+vqq68u9zwUVwCAJRwV8PJm3rx5On36tF5++WXFx8crPj5eP/74o/bt26cGDRqU2jc5OVmHDx9Wv379lJeXp0GDBmnUqFGaOnVquS1hSXIYhmH4+HeoFD+WWD0DwBy1Wzxp9RSAX+3sp3MqbOw/fXzA9DEfvLOB950qAWuuAABL2PkhErSFAQAwGckVAGAJ++ZWiisAwCI27grTFgYAwGwkVwCAJSriIRKXC5IrAAAmI7kCACxh53RHcQUAWIK2MAAA8BnJFQBgCfvmVpIrAACmI7kCACxh5zVXiisAwBJ2bp3a+bMBAGAJkisAwBJ2bguTXAEAMBnJFQBgCfvmVpIrAACmI7kCACxh4yVXiisAwBp+Nm4M0xYGAMBkJFcAgCXs3BYmuQIAYDKSKwDAEg4br7lSXAEAlqAtDAAAfEZyBQBYgltxAACAz0iuAABL2HnNleIKALCEnYsrbWEAAExGcgUAWMLO97mSXAEAMBnJFQBgCT/7BleKKwDAGrSFAQCAz0iuAABLcCsOAADwGckVAGAJ1lwBAIDPSK4AAEtwKw4AACajLQwAAHxGcgUAWMLOt+JQXG2uuLhYkyem6fChQyoqKtKjjz2uyEaNNXH8ODkcDjW+8UalTZgsPz+aGLgyXF07WP9amqLuj89RyblzWvBsvAzD0Jd7jigp888yDMPqKQIUV7t7Z/UqhdUK09Ss6Tp58oTi+vbWTTffrCcTk9Si5V3KeHaSNr63QR07xVg9VcArf38/zZkwSGcLiyVJ08b0VfpLq/X+tt2aNX6gYtvfrlUbP7d4lvCVFcG1uLhYaWlpOvR/gePxxx9XvXr1NGLECN1www2SpEGDBqlbt26eY9xut9LT0/XNN98oICBAU6ZMUcOGDcs9D8XV5jp37qqYzl08205/p7766kvd2aKlJOneNm215YMPKK64ImSN6q0Fy/6pZxI6S5KimzTQ+9t2S5L+/sGX6nh3E4rrFcTPgr7wqlWrFBYWpunTp+vEiRPq3bu3Ro4cqYcfflgJCQkXPGb9+vUqKiqSy+XS9u3blZWVpblz55Z7HnqBNlczKEhBQcEqKMjXmKREPflUkmQYcvzff9Q1awYpLz/P2kkCPhgae5eOnsjX+i1fe37nOO9/znkFhaoVXN2KqeEK0rVrVz399NOebafTqR07dmjTpk0aMmSI0tLSlJ+fX+qYbdu2qU2bNpKk5s2ba8eOHV7PQ3GtAr4/ckSPPPygejzQU916xMpx3vrqmTMFCgkJtXB2gG9+16uVOt59s/624Gk1vel6vZYRr6trB3veDwkK1Km8sxbOEBfLUQEvl8ulPn36eF4ul6vUOYOCghQcHKz8/HwlJiYqKSlJTZs2VXJyspYsWaIGDRropZdeKnVMfn6+goP//781p9OpkpKScj+b6W3h+Ph4FRcXl/qd8X9JKTs72+zTwYtjubka8WiCUsdP0l13t5Ik3XzzLfro31vVouVd+uf7m9Wi5d0WzxLwLmbYC56f/7bgaT31XLamJvVSm9/eqPe37Vbn1rdq80e7rJsgLgtxcXGKi4srd58jR45o5MiRGjx4sGJjY3X69GmFhv4UMmJiYpSRkVFq/+DgYBUUFHi23W63/P3LL5+mF9exY8dqwoQJeumll+R0Os0eHhfp1QXzdPrUac2f97Lmz3tZkpQ8brymZU7RrBdmKCIystSaLHAlGTfjr3p50iAFVPPXzr3fa/n6T62eEi6GBVc05ebmKiEhQZMmTVKrVj8FjmHDhmnixIlq2rSptmzZoltvvbXUMdHR0dq4caO6deum7du3Kyoqyut5HEYFXLf+6quvqmHDhoqJufiLZH4sP2kDV4zaLZ60egrAr3b20zkVNvbWPadMH/OuRrXKfX/KlClas2aNIiMjPb9LSkrS9OnTVa1aNYWHhysjI0PBwcFKTk5WUlKS6tWrp/T0dO3atUuGYWjq1Klq1KhRueepkOL6a1BcYRcUV9iB3YprZeFWHACAJez8hCauFgYAwGQkVwCAJWwcXEmuAACYjeQKALCGjaMrxRUAYAm+LB0AAPiM5AoAsAS34gAAAJ+RXAEAlrBxcKW4AgAsYuPqSlsYAACTkVwBAJbgVhwAAOAzkisAwBJ2vhWH4goAsISNayttYQAAzEZyBQBYw8bRleQKAIDJSK4AAEtwKw4AAPAZyRUAYAluxQEAwGQ2rq20hQEAMBvJFQBgDRtHV5IrAAAmI7kCACxh51txKK4AAEvY+Wph2sIAAJiM5AoAsISNgyvJFQAAs5FcAQDWsHF0pbgCACxh56uFaQsDAGAykisAwBLcigMAAHxGcgUAWMLGwZXkCgCA2UiuAABr2Di6UlwBAJbgVhwAAOAzkisAwBLcigMAAHxGcgUAWMLGwZXiCgCwiI2rK21hAABMRnIFAFjCiltxiouLlZaWpkOHDqmoqEiPP/64rrvuOmVkZMjpdCogIEDTpk1TeHh4qeN69eqlkJAQSVL9+vWVmZlZ7nkorgCAKmPVqlUKCwvT9OnTdeLECfXu3Vv169fXxIkT1aRJE2VnZ2vBggVKTU31HFNYWChJWrRokc/nobgCACxhxa04Xbt2VZcuXTzbTqdTM2bM0DXXXCNJOnfunAIDA0sds3PnTp09e1YJCQkqKSnR6NGj1bx583LPQ3EFAFiiImqry+WSy+XybMfFxSkuLs6zHRQUJEnKz89XYmKikpKSPIX1k08+0eLFi7VkyZJSY1avXl3Dhg1T//799e2332r48OFau3at/P3LLqEUVwCAbfy8mF7IkSNHNHLkSA0ePFixsbGSpHfffVdz587V/PnzVadOnVL7R0REqGHDhnI4HIqIiFBYWJiOHj2qa6+9tsxzcLUwAMAajgp4eZGbm6uEhAQ988wz6tevnyRp5cqVWrx4sRYtWqQGDRr84phly5YpKytLkpSTk6P8/HxdffXV5X80wzAM79OpPD+WWD0DwBy1Wzxp9RSAX+3sp3MqbOxvj/1o+pg3XFW93PenTJmiNWvWKDIyUtJPa6y7d+/Wddddp9DQUElSixYtlJiYqOTkZCUlJSk8PFypqak6fPiwHA6Hxo4dq+jo6HLPQ3EFKgjFFXZQkcV1/7FC08dseFWg950qAW1hAABMxgVNAABL2PlbcSiuAABL2Li20hYGAMBsJFcAgCXs3BYmuQIAYDKSKwDAIvaNrhRXAIAlaAsDAACfkVwBAJawcXAluQIAYDaSKwDAEnZec6W4AgAs4bBxY5i2MAAAJiO5AgCsYd/gSnIFAMBsJFcAgCVsHFxJrgAAmI3kCgCwBLfiAABgMm7FAQAAPiO5AgCsYd/gSnIFAMBsJFcAgCVsHFwprgAAa9j5amHawgAAmIzkCgCwBLfiAAAAn5FcAQCWYM0VAAD4jOIKAIDJaAsDACxBWxgAAPiM5AoAsAS34gAAAJ+RXAEAlrDzmivFFQBgCRvXVtrCAACYjeQKALCGjaMryRUAAJORXAEAlrDzrTgUVwCAJex8tTBtYQAATEZyBQBYwsbBleQKAIDZSK4AAGvYOLpSXAEAluBqYQAAbKC4uFhpaWk6dOiQioqK9Pjjj6tx48YaN26cHA6HbrzxRk2ePFl+fv+/aup2u5Wenq5vvvlGAQEBmjJliho2bFjueVhzBQBYwuEw/+XNqlWrFBYWpqVLl2rBggXKyMhQZmamkpKStHTpUhmGoQ0bNpQ6Zv369SoqKpLL5dKYMWOUlZXl9TwUVwBAldG1a1c9/fTTnm2n06kvv/xSLVu2lCS1bdtW//rXv0ods23bNrVp00aS1Lx5c+3YscPreS67tnD1y25GwKU5++kcq6cAXNYq4v/3LpdLLpfLsx0XF6e4uDjPdlBQkCQpPz9fiYmJSkpK0rRp0+T4v9gbFBSkvLy8UmPm5+crODjYs+10OlVSUiJ//7I/AKUMAGAbPy+mF3LkyBGNHDlSgwcPVmxsrKZPn+55r6CgQKGhoaX2Dw4OVkFBgWfb7XaXW1gl2sIAgCokNzdXCQkJeuaZZ9SvXz9J0i233KKtW7dKkjZv3qw777yz1DHR0dHavHmzJGn79u2Kioryeh6HYRiGyXMHAOCyNGXKFK1Zs0aRkZGe340fP15TpkxRcXGxIiMjNWXKFDmdTiUnJyspKUn16tVTenq6du3aJcMwNHXqVDVq1Kjc81BcAQAwGW1hAABMRnEFAMBkFNcqxO12a9KkSYqLi1N8fLz2799v9ZSAS/bZZ58pPj7e6mkAF8StOFXI+U8Z2b59u7KysjR37lyrpwVctAULFmjVqlWqUaOG1VMBLojkWoVcylNGgMvRb37zG82ePdvqaQBlorhWIWU9ZQS40nTp0sXrTfyAlSiuVcilPGUEAHDxKK5VyKU8ZQQAcPGILVVITEyMPvjgAw0cONDzlBEAgPl4QhMAACajLQwAgMkorgAAmIziCgCAySiuAACYjOIKAIDJKK644m3dulWtWrVSfHy84uPjNWDAAC1atOiSxnr++ee1fPlyff3115ozZ06Z+61bt045OTk+jbl582aNGzeu1O8OHjyoAQMG+HR8Re0LoOJwnyts4e6779bMmTMlSUVFReratat69uyp0NDQSxqvSZMmatKkSZnv/+lPf1J6errq1q17SeMDsDeKK2wnPz9ffn5+cjqdio+PV+3atXX69GnNnz9f6enp2r9/v9xut5KSknTXXXfpb3/7m+bOnas6deqouLhYkZGR2rp1q7KzszVz5ky99dZbevPNN+V2u9WxY0fdfvvt+vrrr5WSkqKlS5fK5XJp9erVcjgc6tatmx588EHt2bNHaWlpqlGjhmrUqKFatWr5NPd///vfnsT8448/atq0aapWrZqOHz+uESNG6Pjx42rXrp1GjhypI0eOaOLEiSosLFRgYKAyMjJKjTVz5kx9+OGHcrvd6t69ux566CGz/9QAykBxhS18+OGHio+Pl8PhULVq1TRx4kQFBQVJkmJjYxUTE6OlS5eqdu3amjp1qk6cOKGhQ4fqnXfe0fTp0/XWW28pLCxMjz76aKlxjx075vl6s4CAAGVlZalFixZq0qSJ0tPT9d133+ndd9/V0qVL5XA49NBDD+nee+/Viy++qMTERLVu3Vrz58/X3r17ffocu3fv1vTp01W3bl3NmzdPa9euVWxsrM6cOaPp06erZs2aGjJkiDp27Kh58+YpPj5e7dq105YtW/T8889r1KhRnrFWrFihxYsXq27dulq+fLl5f2wAXlFcYQvnt4V/LiIiQpK0a9cubdu2TZ9//rkkqaSkRLm5uQoODlbt2rUlSXfccUepYw8cOKAbb7xR1atXlySlpaWVen/Xrl06fPiwJxWeOnVK3333nXbv3q2mTZtK+umZzr4W17p16+q5555TzZo1lZOTo+joaEnSzTffrJCQEEnS7bffrn379mnXrl165ZVX9Oqrr8owDFWrVq3UWDNmzNCMGTOUm5vr+apBAJWD4grbczgckqTIyEjVq1dPI0aM0I8//qi5c+cqNDRUeXl5On78uOrUqaMvvvhC9erV8xz7m9/8Rnv37lVRUZECAgKUmJio8ePHy+FwyDAMRUZGqnHjxnr11VflcDj0+uuvKyoqSpGRkfr000/Vtm3bi/re3AkTJmj9+vUKDg5WSkqK/vt00j179qigoECBgYH6/PPPFRcXp8jISCUkJCg6Olp79uzRRx995BmnqKhIa9eu1YwZM2QYhrp3767u3bvr+uuvN+mvCqA8FFdUGQMHDtSECRM0dOhQ5efna/DgwQoICFBmZqaGDRumWrVq/eIr+OrUqaPhw4dr6NChcjgcuu+++1S3bl3dcccdSk5O1sKFC9WqVSsNGjRIRUVFatq0qerWravJkydr1KhReu2111SnTh0FBgb+Yj67d+9Wnz59PNvjxo1Tz549NWDAAIWGhio8PFw//PCDJKlWrVoaNWqUjh8/rm7duqlx48ZKSUlRenq6CgsL9eOPP2r8+PGesQICAlSrVi317NlTtWrVUuvWrXXddddV0F8WwM/x4H4AAEzGfa4AAJiM4goAgMkorgAAmIziCgCAySiuAACYjOIKAIDJKK4AAJiM4goAgMn+Fxa0SjqM1/T0AAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the average confusion matrix\n",
    "# round the values in the confusion matrix\n",
    "tabnet_avg_confusion_matrix_round = np.round(tabnet_avg_confusion_matrix).astype(int)\n",
    "\n",
    "# Create a heatmap visualization of the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(tabnet_avg_confusion_matrix_round, annot=True, cmap=\"Blues\", fmt=\"d\", ax=ax)\n",
    "\n",
    "# Set the axis labels and title\n",
    "ax.set_xlabel(\"Predicted Labels\")\n",
    "ax.set_ylabel(\"True Labels\")\n",
    "ax.set_title(\"Average Confusion Matrix\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T18:44:30.480981900Z",
     "start_time": "2023-11-02T18:44:30.360932600Z"
    }
   },
   "id": "363344deb565fb23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculating Performance Across Participants (Subject-wise)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c0345db720ba5bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Y-axis can represent the accuracy for each participant, i.e., the percentage of correct classifications. This is the most direct measure of classifier performance and would be readily interpretable by most readers. We can use error bars to represent confidence intervals for each participant's accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68ff65d634637659"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 2160x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy for each participant with error bars representing 95% confidence intervals for each participant\n",
    "fig, ax = plt.subplots(figsize=(30, 8))\n",
    "ax.errorbar(tabnet_acc.keys(), tabnet_acc.values(), yerr=[(top - bot) / 2 for bot, top in tabnet_confidence_intervals.values()], fmt='o')\n",
    "ax.set_xlabel(\"Participant\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Accuracy for each participant with error bars representing 95% confidence intervals\")\n",
    "# Add a horizontal dashed line representing the average accuracy across participants\n",
    "ax.axhline(y=tabnet_avg_acc, color='g', linestyle='--')\n",
    "# Add horizontal lines representing the chance level accuracy (50%)\n",
    "ax.axhline(y=0.5, color='r', linestyle='-')\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T19:09:55.792249400Z",
     "start_time": "2023-11-04T19:09:55.591736400Z"
    }
   },
   "id": "6cfdc652069052e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best model is Tabnet, so we will train it on the whole dataset\n",
    "and then we will plot the feature importance and the SHAP values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8f5157470a9e37f"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No early stopping will be performed, last training weights will be used.\n"
     ]
    }
   ],
   "source": [
    "X_train = features_df\n",
    "y_train = labels_df\n",
    "\n",
    "# fill inf values with the mean of the column\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_train = X_train.fillna(X_train.mean()) # fill missing values with the mean of the column or zero ? features_df.mean()\n",
    "\n",
    "# Scale the data\n",
    "# Create separate StandardScaler instances\n",
    "scaler_x = StandardScaler()\n",
    "# Fit on Training Data (!)\n",
    "scaler_x.fit(X_train.values)\n",
    "# Transform both training and testing data\n",
    "X_train_scaled = scaler_x.transform(X_train.values)\n",
    "y_train = y_train.values.reshape(-1, 1).flatten()\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "\n",
    "# TABNET\n",
    "# Convert Pandas DataFrame to NumPy array\n",
    "X_train_np = X_train_scaled.values\n",
    "\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "all_training_model = TabNetClassifier(n_d=8, n_a=8, n_steps=1, gamma=0.1, n_independent=1, n_shared=1, lambda_sparse=0.0001, verbose=0)\n",
    "all_training_model.fit(X_train_np, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T19:51:26.373629500Z",
     "start_time": "2023-11-04T19:51:21.910370400Z"
    }
   },
   "id": "238f5b786886c148"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature importance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26eeae8e3e0434d0"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "                          importance\nDVA_Mean_Gaze_Pre           0.144940\nDVA_Mean_Fixations_Pre      0.140732\nDVA_AUC_Fixations_Pre       0.122556\nDVA_Min_Gaze_Pre            0.120229\nDVA_AUC_Gaze_Pre            0.112773\nDVA_Sem_Fixations_Pre       0.101802\nDVA_Median_Gaze_Pre         0.071729\nDVA_Min_Fixations_Pre       0.056803\nDVA_Sem_Gaze_Pre            0.024366\nMovie                       0.023865\nDVA_Std_Gaze_Pre            0.022771\nDVA_Median_Fixations_Pre    0.020747\nDVA_Std_Fixations_Pre       0.019551\nDVA_Max_Gaze_Pre            0.012135\nDVA_Max_Fixations_Pre       0.005001",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>DVA_Mean_Gaze_Pre</th>\n      <td>0.144940</td>\n    </tr>\n    <tr>\n      <th>DVA_Mean_Fixations_Pre</th>\n      <td>0.140732</td>\n    </tr>\n    <tr>\n      <th>DVA_AUC_Fixations_Pre</th>\n      <td>0.122556</td>\n    </tr>\n    <tr>\n      <th>DVA_Min_Gaze_Pre</th>\n      <td>0.120229</td>\n    </tr>\n    <tr>\n      <th>DVA_AUC_Gaze_Pre</th>\n      <td>0.112773</td>\n    </tr>\n    <tr>\n      <th>DVA_Sem_Fixations_Pre</th>\n      <td>0.101802</td>\n    </tr>\n    <tr>\n      <th>DVA_Median_Gaze_Pre</th>\n      <td>0.071729</td>\n    </tr>\n    <tr>\n      <th>DVA_Min_Fixations_Pre</th>\n      <td>0.056803</td>\n    </tr>\n    <tr>\n      <th>DVA_Sem_Gaze_Pre</th>\n      <td>0.024366</td>\n    </tr>\n    <tr>\n      <th>Movie</th>\n      <td>0.023865</td>\n    </tr>\n    <tr>\n      <th>DVA_Std_Gaze_Pre</th>\n      <td>0.022771</td>\n    </tr>\n    <tr>\n      <th>DVA_Median_Fixations_Pre</th>\n      <td>0.020747</td>\n    </tr>\n    <tr>\n      <th>DVA_Std_Fixations_Pre</th>\n      <td>0.019551</td>\n    </tr>\n    <tr>\n      <th>DVA_Max_Gaze_Pre</th>\n      <td>0.012135</td>\n    </tr>\n    <tr>\n      <th>DVA_Max_Fixations_Pre</th>\n      <td>0.005001</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(all_training_model.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T19:51:29.683891100Z",
     "start_time": "2023-11-04T19:51:29.657875300Z"
    }
   },
   "id": "ea6874938239bbff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "SHAP values for the best model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9b4bc084227d5d8"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "ename": "InvalidModelError",
     "evalue": "Model type not yet supported by TreeExplainer: <class 'pytorch_tabnet.tab_model.TabNetClassifier'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidModelError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_23012/4055750699.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m# Create object that can calculate shap values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mexplainer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mshap\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTreeExplainer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthe_best_model_ever\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;31m# Calculate Shap values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_tree.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001B[0m\n\u001B[0;32m    164\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_perturbation\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfeature_perturbation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    165\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexpected_value\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 166\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTreeEnsemble\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_missing\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel_output\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    167\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel_output\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    168\u001B[0m         \u001B[1;31m#self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_tree.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, model, data, data_missing, model_output)\u001B[0m\n\u001B[0;32m   1131\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbase_offset\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minit_params\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mparam_idx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1133\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mInvalidModelError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Model type not yet supported by TreeExplainer: \"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1134\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1135\u001B[0m         \u001B[1;31m# build a dense numpy version of all the tree objects\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mInvalidModelError\u001B[0m: Model type not yet supported by TreeExplainer: <class 'pytorch_tabnet.tab_model.TabNetClassifier'>"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(all_training_model)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Plot summary plot\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "\n",
    "# Plot summary plot\n",
    "shap.summary_plot(shap_values, X_train)\n",
    "\n",
    "# Plot force plot\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_train.iloc[0,:])\n",
    "\n",
    "# Plot force plot\n",
    "shap.force_plot(explainer.expected_value, shap_values, X_train)\n",
    "\n",
    "# Plot dependence plot\n",
    "shap.dependence_plot('DVA_Mean', shap_values, X_train, interaction_index=\"DVA_Mean\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T19:48:38.852728300Z",
     "start_time": "2023-11-04T19:48:38.060694Z"
    }
   },
   "id": "d29547feac145433"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26f01162a3d4ccc3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
